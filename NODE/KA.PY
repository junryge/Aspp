import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# CPU ê°•ì œ ì‚¬ìš© ì„¤ì •
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # GPU ì™„ì „ ë¹„í™œì„±í™”
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, RNN, SimpleRNN, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error

# ARIMA ê´€ë ¨
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller

# ì‹œê°í™”
import matplotlib.pyplot as plt
import seaborn as sns

# ëª¨ë¸ ì €ì¥
import pickle
import joblib

# TensorFlow CPU ì „ìš© ì„¤ì •
tf.config.set_visible_devices([], 'GPU')
physical_devices = tf.config.list_physical_devices('CPU')
print(f"ì‚¬ìš© ê°€ëŠ¥í•œ CPU ì¥ì¹˜: {len(physical_devices)}ê°œ")
print("GPU ì‚¬ìš©: ë¹„í™œì„±í™”ë¨")

class SemiconductorLogisticsDataGenerator:
    """ë°˜ë„ì²´ ë¬¼ë¥˜ ìƒ˜í”Œ ë°ì´í„° ìƒì„± í´ë˜ìŠ¤ (10ë¶„ ë‹¨ìœ„)"""
    
    def __init__(self, n_samples=600):
        self.n_samples = n_samples
        self.routes = ['A-B', 'B-C', 'C-D', 'D-E', 'A-C', 'B-D', 'C-E']
        self.product_types = ['DRAM', 'NAND', 'CPU', 'GPU', 'ASIC']
        self.priorities = ['High', 'Medium', 'Low']
        
    def generate_data(self):
        """ë°˜ë„ì²´ ë¬¼ë¥˜ ì´ë™ ë°ì´í„° ìƒì„± (10ë¶„ ê°„ê²©)"""
        np.random.seed(42)
        
        data = []
        # 10ë¶„ ê°„ê²©ìœ¼ë¡œ 600ê°œ = 100ì‹œê°„ (ì•½ 4ì¼) ë°ì´í„°
        start_date = datetime.now() - timedelta(minutes=self.n_samples * 10)
        
        for i in range(self.n_samples):
            timestamp = start_date + timedelta(minutes=i * 10)
            
            # ì‹œê°„ëŒ€ë³„ íŒ¨í„´
            hour = timestamp.hour
            if 0 <= hour < 6:  # ìƒˆë²½
                time_factor = 0.3
            elif 6 <= hour < 9:  # ì¶œê·¼ ì‹œê°„
                time_factor = 1.5
            elif 9 <= hour < 12:  # ì˜¤ì „
                time_factor = 1.2
            elif 12 <= hour < 14:  # ì ì‹¬ì‹œê°„
                time_factor = 0.8
            elif 14 <= hour < 18:  # ì˜¤í›„
                time_factor = 1.3
            elif 18 <= hour < 21:  # í‡´ê·¼ ì‹œê°„
                time_factor = 1.4
            else:  # ì•¼ê°„
                time_factor = 0.6
            
            # ìš”ì¼ë³„ íŒ¨í„´
            weekday_factor = 0.7 if timestamp.weekday() >= 5 else 1.0
            
            # ê¸°ë³¸ ë¬¼ë¥˜ëŸ‰ (10ë¶„ ë‹¨ìœ„)
            base_volume = 50 + np.sin(i * 0.1) * 20 + np.random.normal(0, 10)
            
            # ê²½ë¡œë³„ ë°ì´í„° ìƒì„±
            for route in self.routes:
                route_factor = np.random.uniform(0.8, 1.2)
                
                volume = base_volume * time_factor * weekday_factor * route_factor
                
                # ë³‘ëª© í˜„ìƒ ì‹œë®¬ë ˆì´ì…˜
                bottleneck = 1 if np.random.random() < 0.15 else 0
                if bottleneck:
                    delay_minutes = np.random.uniform(5, 20)  # 5-20ë¶„ ì§€ì—°
                else:
                    delay_minutes = np.random.uniform(0, 5)   # 0-5ë¶„ ì •ìƒ ì§€ì—°
                
                # ì œí’ˆ íƒ€ì…ë³„ íŠ¹ì„±
                product_type = np.random.choice(self.product_types)
                priority = np.random.choice(self.priorities)
                
                # ì²˜ë¦¬ ì‹œê°„ (ë³‘ëª© êµ¬ê°„ì—ì„œëŠ” ì¦ê°€)
                process_minutes = np.random.uniform(10, 30) * (1 + bottleneck * 0.5)
                
                # 10ë¶„ í›„ ì˜ˆì¸¡ì„ ìœ„í•œ íƒ€ê²Ÿ ê°’ ìƒì„±
                future_volume = volume * np.random.uniform(0.9, 1.1)  # Â±10% ë³€ë™
                
                data.append({
                    'timestamp': timestamp,
                    'route': route,
                    'product_type': product_type,
                    'priority': priority,
                    'current_volume': int(volume),
                    'volume_10min_later': int(future_volume),  # 10ë¶„ í›„ ë¬¼ë¥˜ëŸ‰
                    'process_minutes': round(process_minutes, 2),
                    'delay_minutes': round(delay_minutes, 2),
                    'bottleneck': bottleneck,
                    'temperature': np.random.uniform(20, 25),
                    'humidity': np.random.uniform(40, 60),
                    'hour': hour,
                    'weekday': timestamp.weekday()
                })
        
        return pd.DataFrame(data)

class HybridLogisticsPredictor:
    """LSTM, RNN, ARIMA í†µí•© í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ ëª¨ë¸ (10ë¶„ í›„ ì˜ˆì¸¡)"""
    
    def __init__(self, lookback=6):  # 6ê°œ = 60ë¶„(1ì‹œê°„) ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡
        self.lookback = lookback
        self.scaler_X = MinMaxScaler()
        self.scaler_y = MinMaxScaler()
        self.lstm_model = None
        self.rnn_model = None
        self.arima_model = None
        self.weights = {'lstm': 0.4, 'rnn': 0.3, 'arima': 0.3}
        self.model_path = 'semiconductor_logistics_models'
        
    def prepare_data(self, df):
        """ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„ (10ë¶„ ë‹¨ìœ„)"""
        # ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
        df = df.sort_values('timestamp')
        
        # ê²½ë¡œë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬
        all_X, all_y = [], []
        
        for route in df['route'].unique():
            route_data = df[df['route'] == route].copy()
            
            # íŠ¹ì„± ì„ íƒ
            features = ['current_volume', 'process_minutes', 'delay_minutes', 
                       'temperature', 'humidity', 'hour', 'weekday']
            
            X_data = route_data[features].values
            y_data = route_data['volume_10min_later'].values.reshape(-1, 1)
            
            # ì •ê·œí™”
            X_scaled = self.scaler_X.fit_transform(X_data)
            y_scaled = self.scaler_y.fit_transform(y_data)
            
            # ì‹œí€€ìŠ¤ ìƒì„± (lookback ì‹œê°„ì˜ ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡)
            for i in range(self.lookback, len(X_scaled)):
                all_X.append(X_scaled[i-self.lookback:i])
                all_y.append(y_scaled[i, 0])
        
        return np.array(all_X), np.array(all_y)
    
    def build_lstm_model(self, input_shape):
        """LSTM ëª¨ë¸ êµ¬ì¶•"""
        model = Sequential([
            LSTM(64, return_sequences=True, input_shape=input_shape),
            Dropout(0.2),
            LSTM(32, return_sequences=True),
            Dropout(0.2),
            LSTM(16),
            Dropout(0.2),
            Dense(8, activation='relu'),
            Dense(1)
        ])
        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])
        return model
    
    def build_rnn_model(self, input_shape):
        """RNN ëª¨ë¸ êµ¬ì¶•"""
        model = Sequential([
            SimpleRNN(64, return_sequences=True, input_shape=input_shape),
            Dropout(0.2),
            SimpleRNN(32),
            Dropout(0.2),
            Dense(16, activation='relu'),
            Dense(1)
        ])
        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])
        return model
    
    def train(self, df, epochs=30, batch_size=32):
        """í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ í•™ìŠµ"""
        print("ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        X, y = self.prepare_data(df)
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
        split_idx = int(0.8 * len(X))
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        print(f"í›ˆë ¨ ë°ì´í„°: {X_train.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")
        
        # LSTM ëª¨ë¸ í•™ìŠµ
        print("\nLSTM ëª¨ë¸ í•™ìŠµ ì¤‘...")
        self.lstm_model = self.build_lstm_model((X_train.shape[1], X_train.shape[2]))
        self.lstm_model.fit(X_train, y_train, 
                           epochs=epochs, 
                           batch_size=batch_size, 
                           validation_split=0.1,
                           verbose=1)
        
        # RNN ëª¨ë¸ í•™ìŠµ
        print("\nRNN ëª¨ë¸ í•™ìŠµ ì¤‘...")
        self.rnn_model = self.build_rnn_model((X_train.shape[1], X_train.shape[2]))
        self.rnn_model.fit(X_train, y_train, 
                          epochs=epochs, 
                          batch_size=batch_size, 
                          validation_split=0.1,
                          verbose=1)
        
        # ARIMA ëª¨ë¸ì€ ê° ê²½ë¡œë³„ë¡œ ë³„ë„ í•™ìŠµ (ì‹œì—°ìš©ìœ¼ë¡œ ì²« ë²ˆì§¸ ê²½ë¡œë§Œ)
        print("\nARIMA ëª¨ë¸ í•™ìŠµ ì¤‘...")
        first_route = df['route'].unique()[0]
        arima_data = df[df['route'] == first_route]['current_volume'].values[:split_idx]
        try:
            self.arima_model = ARIMA(arima_data, order=(2, 1, 1)).fit()
        except:
            print("ARIMA ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨, ê°€ì¤‘ì¹˜ ì¡°ì •")
            self.weights = {'lstm': 0.5, 'rnn': 0.5, 'arima': 0.0}
        
        # ëª¨ë¸ í‰ê°€
        self.evaluate_models(X_test, y_test)
        
        return X_test, y_test
    
    def predict_10min_later(self, recent_data):
        """10ë¶„ í›„ ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡"""
        # ì…ë ¥ ë°ì´í„° ì •ê·œí™”
        X = self.scaler_X.transform(recent_data)
        X = X.reshape(1, X.shape[0], X.shape[1])
        
        # LSTM ì˜ˆì¸¡
        lstm_pred = self.lstm_model.predict(X, verbose=0)[0, 0]
        
        # RNN ì˜ˆì¸¡
        rnn_pred = self.rnn_model.predict(X, verbose=0)[0, 0]
        
        # ARIMA ì˜ˆì¸¡ (ë‹¨ìˆœí™”)
        if self.arima_model and self.weights['arima'] > 0:
            arima_pred = self.arima_model.forecast(steps=1)[0]
            arima_pred = self.scaler_y.transform([[arima_pred]])[0, 0]
        else:
            arima_pred = 0
        
        # ê°€ì¤‘ í‰ê· 
        hybrid_pred = (
            self.weights['lstm'] * lstm_pred +
            self.weights['rnn'] * rnn_pred +
            self.weights['arima'] * arima_pred
        )
        
        # ì—­ë³€í™˜
        predicted_volume = self.scaler_y.inverse_transform([[hybrid_pred]])[0, 0]
        
        return {
            'predicted_volume_10min': int(predicted_volume),
            'lstm_prediction': int(self.scaler_y.inverse_transform([[lstm_pred]])[0, 0]),
            'rnn_prediction': int(self.scaler_y.inverse_transform([[rnn_pred]])[0, 0]),
            'confidence': self._calculate_confidence(lstm_pred, rnn_pred)
        }
    
    def _calculate_confidence(self, lstm_pred, rnn_pred):
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°"""
        # ë‘ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ì°¨ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
        diff = abs(lstm_pred - rnn_pred)
        confidence = max(0, 1 - diff) * 100
        return round(confidence, 2)
    
    def evaluate_models(self, X_test, y_test):
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        # ì˜ˆì¸¡
        lstm_pred = self.lstm_model.predict(X_test, verbose=0)
        rnn_pred = self.rnn_model.predict(X_test, verbose=0)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡
        hybrid_pred = (
            self.weights['lstm'] * lstm_pred.flatten() +
            self.weights['rnn'] * rnn_pred.flatten()
        ) / (self.weights['lstm'] + self.weights['rnn'])
        
        # ì—­ë³€í™˜
        y_test_orig = self.scaler_y.inverse_transform(y_test.reshape(-1, 1))
        hybrid_pred_orig = self.scaler_y.inverse_transform(hybrid_pred.reshape(-1, 1))
        lstm_pred_orig = self.scaler_y.inverse_transform(lstm_pred)
        rnn_pred_orig = self.scaler_y.inverse_transform(rnn_pred)
        
        # ì„±ëŠ¥ ì§€í‘œ
        print("\n=== 10ë¶„ í›„ ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ===")
        print(f"Hybrid MAE: {mean_absolute_error(y_test_orig, hybrid_pred_orig):.2f}")
        print(f"LSTM MAE: {mean_absolute_error(y_test_orig, lstm_pred_orig):.2f}")
        print(f"RNN MAE: {mean_absolute_error(y_test_orig, rnn_pred_orig):.2f}")
        
        # ì‹œê°í™”
        self.plot_predictions(y_test_orig[:100], hybrid_pred_orig[:100], 
                            lstm_pred_orig[:100], rnn_pred_orig[:100])
    
    def plot_predictions(self, y_true, hybrid_pred, lstm_pred, rnn_pred):
        """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
        plt.figure(figsize=(15, 6))
        
        time_steps = np.arange(len(y_true)) * 10  # 10ë¶„ ë‹¨ìœ„
        
        plt.plot(time_steps, y_true, label='ì‹¤ì œê°’', color='black', linewidth=2)
        plt.plot(time_steps, hybrid_pred, label='Hybrid', color='red', linewidth=2, alpha=0.8)
        plt.plot(time_steps, lstm_pred, label='LSTM', color='blue', alpha=0.6)
        plt.plot(time_steps, rnn_pred, label='RNN', color='green', alpha=0.6)
        
        plt.title('10ë¶„ í›„ ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ê²°ê³¼')
        plt.xlabel('ì‹œê°„ (ë¶„)')
        plt.ylabel('ë¬¼ë¥˜ëŸ‰')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()
    
    def save_models(self, path=None):
        """ëª¨ë¸ ì €ì¥"""
        if path is None:
            path = self.model_path
        
        os.makedirs(path, exist_ok=True)
        
        # ë”¥ëŸ¬ë‹ ëª¨ë¸ ì €ì¥
        self.lstm_model.save(f'{path}/lstm_model.h5')
        self.rnn_model.save(f'{path}/rnn_model.h5')
        
        # ARIMA ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        joblib.dump(self.arima_model, f'{path}/arima_model.pkl')
        joblib.dump(self.scaler_X, f'{path}/scaler_X.pkl')
        joblib.dump(self.scaler_y, f'{path}/scaler_y.pkl')
        joblib.dump(self.weights, f'{path}/weights.pkl')
        
        print(f"\nëª¨ë¸ì´ '{path}' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def load_models(self, path=None):
        """ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
        if path is None:
            path = self.model_path
        
        try:
            # ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
            self.lstm_model = load_model(f'{path}/lstm_model.h5')
            self.rnn_model = load_model(f'{path}/rnn_model.h5')
            
            # ARIMA ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°
            self.arima_model = joblib.load(f'{path}/arima_model.pkl')
            self.scaler_X = joblib.load(f'{path}/scaler_X.pkl')
            self.scaler_y = joblib.load(f'{path}/scaler_y.pkl')
            self.weights = joblib.load(f'{path}/weights.pkl')
            
            print(f"ëª¨ë¸ì´ '{path}' ë””ë ‰í† ë¦¬ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì¡ŒìŠµë‹ˆë‹¤.")
            return True
        except Exception as e:
            print(f"ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return False

class BottleneckPredictor:
    """ë³‘ëª© êµ¬ê°„ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self):
        self.model = None
        self.scaler = MinMaxScaler()
        self.model_path = 'semiconductor_logistics_models'
        
    def prepare_features(self, df):
        """íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§"""
        # ì›í•« ì¸ì½”ë”©
        route_dummies = pd.get_dummies(df['route'], prefix='route')
        product_dummies = pd.get_dummies(df['product_type'], prefix='product')
        priority_dummies = pd.get_dummies(df['priority'], prefix='priority')
        
        # íŠ¹ì„± ê²°í•©
        features = pd.concat([
            df[['current_volume', 'process_minutes', 'temperature', 'humidity', 'hour', 'weekday']],
            route_dummies,
            product_dummies,
            priority_dummies
        ], axis=1)
        
        return features, df['bottleneck']
    
    def build_model(self, input_shape):
        """ë³‘ëª© ì˜ˆì¸¡ ì‹ ê²½ë§ ëª¨ë¸"""
        model = Sequential([
            Dense(128, activation='relu', input_shape=(input_shape,)),
            Dropout(0.3),
            Dense(64, activation='relu'),
            Dropout(0.3),
            Dense(32, activation='relu'),
            Dense(16, activation='relu'),
            Dense(1, activation='sigmoid')
        ])
        model.compile(optimizer=Adam(learning_rate=0.001), 
                     loss='binary_crossentropy', 
                     metrics=['accuracy'])
        return model
    
    def train(self, df, epochs=30, batch_size=32):
        """ë³‘ëª© ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ"""
        print("\në³‘ëª© êµ¬ê°„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        X, y = self.prepare_features(df)
        X_scaled = self.scaler.fit_transform(X)
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # ëª¨ë¸ í•™ìŠµ
        self.model = self.build_model(X_train.shape[1])
        history = self.model.fit(
            X_train, y_train,
            epochs=epochs,
            batch_size=batch_size,
            validation_split=0.1,
            verbose=1
        )
        
        # í‰ê°€
        test_loss, test_acc = self.model.evaluate(X_test, y_test, verbose=0)
        print(f"\në³‘ëª© ì˜ˆì¸¡ ëª¨ë¸ ì •í™•ë„: {test_acc:.4f}")
        
        # ë³‘ëª© ì˜ˆì¸¡ í™•ë¥ 
        bottleneck_probs = self.model.predict(X_test, verbose=0)
        bottleneck_preds = (bottleneck_probs > 0.5).astype(int)
        
        # ê²½ë¡œë³„ ë³‘ëª© ìœ„í—˜ë„ ë¶„ì„
        self.analyze_bottleneck_risk(df, X, y)
        
        return history
    
    def analyze_bottleneck_risk(self, df, X, y):
        """ê²½ë¡œë³„ ë³‘ëª© ìœ„í—˜ë„ ë¶„ì„"""
        df_analysis = df.copy()
        df_analysis['bottleneck_prob'] = self.model.predict(self.scaler.transform(X), verbose=0)
        
        # ê²½ë¡œë³„ ë³‘ëª© ìœ„í—˜ë„
        route_risk = df_analysis.groupby('route').agg({
            'bottleneck': 'mean',
            'bottleneck_prob': 'mean',
            'delay_minutes': 'mean'
        }).round(3)
        
        print("\n=== ê²½ë¡œë³„ ë³‘ëª© ìœ„í—˜ë„ ë¶„ì„ ===")
        print(route_risk.sort_values('bottleneck_prob', ascending=False))
    
    def predict_bottleneck(self, features):
        """ë³‘ëª© êµ¬ê°„ ì˜ˆì¸¡"""
        features_scaled = self.scaler.transform(features)
        prob = self.model.predict(features_scaled, verbose=0)[0, 0]
        
        return {
            'bottleneck_probability': round(prob * 100, 2),
            'is_bottleneck': prob > 0.5,
            'risk_level': 'High' if prob > 0.7 else 'Medium' if prob > 0.3 else 'Low'
        }
    
    def save_model(self, path=None):
        """ëª¨ë¸ ì €ì¥"""
        if path is None:
            path = self.model_path
        
        os.makedirs(path, exist_ok=True)
        
        self.model.save(f'{path}/bottleneck_model.h5')
        joblib.dump(self.scaler, f'{path}/bottleneck_scaler.pkl')
        
        print(f"ë³‘ëª© ì˜ˆì¸¡ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def load_model(self, path=None):
        """ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
        if path is None:
            path = self.model_path
        
        try:
            self.model = load_model(f'{path}/bottleneck_model.h5')
            self.scaler = joblib.load(f'{path}/bottleneck_scaler.pkl')
            print("ë³‘ëª© ì˜ˆì¸¡ ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì¡ŒìŠµë‹ˆë‹¤.")
            return True
        except Exception as e:
            print(f"ë³‘ëª© ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return False

class RealTimePredictor:
    """ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.volume_predictor = HybridLogisticsPredictor()
        self.bottleneck_predictor = BottleneckPredictor()
        
    def load_all_models(self, path='semiconductor_logistics_models'):
        """ëª¨ë“  ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
        print("ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
        volume_loaded = self.volume_predictor.load_models(path)
        bottleneck_loaded = self.bottleneck_predictor.load_model(path)
        
        if volume_loaded and bottleneck_loaded:
            print("ëª¨ë“  ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì¡ŒìŠµë‹ˆë‹¤!")
            return True
        return False
    
    def predict_next_10min(self, current_data):
        """10ë¶„ í›„ ì˜ˆì¸¡ (í˜„ì¬ ìƒíƒœ ê¸°ë°˜)"""
        # current_data: ìµœê·¼ 1ì‹œê°„(6ê°œ) ë°ì´í„°
        
        # ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡
        volume_result = self.volume_predictor.predict_10min_later(current_data)
        
        # ë³‘ëª© ì˜ˆì¸¡ì„ ìœ„í•œ íŠ¹ì„± ì¤€ë¹„
        latest_features = current_data[-1:].reshape(1, -1)
        bottleneck_result = self.bottleneck_predictor.predict_bottleneck(latest_features)
        
        return {
            '10ë¶„í›„_ì˜ˆì¸¡': {
                'ì˜ˆìƒ_ë¬¼ë¥˜ëŸ‰': volume_result['predicted_volume_10min'],
                'ë³‘ëª©_í™•ë¥ ': f"{bottleneck_result['bottleneck_probability']}%",
                'ìœ„í—˜ë„': bottleneck_result['risk_level'],
                'ì˜ˆì¸¡_ì‹ ë¢°ë„': f"{volume_result['confidence']}%"
            },
            'ëª¨ë¸ë³„_ì˜ˆì¸¡': {
                'LSTM': volume_result['lstm_prediction'],
                'RNN': volume_result['rnn_prediction']
            },
            'ê¶Œì¥ì‚¬í•­': self._generate_recommendations(volume_result, bottleneck_result)
        }
    
    def _generate_recommendations(self, volume_result, bottleneck_result):
        """ì˜ˆì¸¡ ê²°ê³¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if bottleneck_result['bottleneck_probability'] > 70:
            recommendations.append("âš ï¸ ë³‘ëª© ìœ„í—˜ ë†’ìŒ: ëŒ€ì²´ ê²½ë¡œ í™œìš© ê¶Œì¥")
            recommendations.append("ğŸ“¦ ì¶”ê°€ ì²˜ë¦¬ ì¸ë ¥ ë°°ì¹˜ ê³ ë ¤")
        
        if volume_result['predicted_volume_10min'] > 100:
            recommendations.append("ğŸ“ˆ ë†’ì€ ë¬¼ë¥˜ëŸ‰ ì˜ˆìƒ: ì‚¬ì „ ì¤€ë¹„ í•„ìš”")
        
        if volume_result['confidence'] < 70:
            recommendations.append("ğŸ” ì˜ˆì¸¡ ì‹ ë¢°ë„ ë‚®ìŒ: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°•í™”")
        
        return recommendations if recommendations else ["âœ… ì •ìƒ ìš´ì˜ ì˜ˆìƒ"]

# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    print("ë°˜ë„ì²´ ë¬¼ë¥˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œ (10ë¶„ í›„ ì˜ˆì¸¡)")
    print("=" * 60)
    
    # 1. ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    print("\n1. ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘...")
    generator = SemiconductorLogisticsDataGenerator(n_samples=600)
    df = generator.generate_data()
    print(f"ìƒì„±ëœ ë°ì´í„°: {len(df)}ê°œ ë ˆì½”ë“œ")
    print(f"ë°ì´í„° ê¸°ê°„: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
    print(f"10ë¶„ ê°„ê²© ë°ì´í„°: ì´ {(df['timestamp'].max() - df['timestamp'].min()).total_seconds() / 60:.0f}ë¶„")
    
    # 2. ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
    print("\n2. í•˜ì´ë¸Œë¦¬ë“œ ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ (10ë¶„ í›„ ì˜ˆì¸¡)")
    print("=" * 60)
    predictor = HybridLogisticsPredictor(lookback=6)  # 60ë¶„ ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡
    X_test, y_test = predictor.train(df, epochs=20, batch_size=32)
    
    # 3. ë³‘ëª© êµ¬ê°„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
    print("\n3. ë³‘ëª© êµ¬ê°„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ")
    print("=" * 60)
    bottleneck_predictor = BottleneckPredictor()
    bottleneck_predictor.train(df, epochs=20, batch_size=32)
    
    # 4. ëª¨ë¸ ì €ì¥
    print("\n4. í•™ìŠµëœ ëª¨ë¸ ì €ì¥ ì¤‘...")
    predictor.save_models()
    bottleneck_predictor.save_model()
    
    # 5. ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜
    print("\n5. ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜")
    print("=" * 60)
    
    # ì‹¤ì‹œê°„ ì˜ˆì¸¡ê¸° ìƒì„± ë° ëª¨ë¸ ë¡œë“œ
    realtime = RealTimePredictor()
    if realtime.load_all_models():
        # ìµœê·¼ 1ì‹œê°„ ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡
        recent_data = df.iloc[-6:][['current_volume', 'process_minutes', 'delay_minutes', 
                                    'temperature', 'humidity', 'hour', 'weekday']].values
        
        print("\ní˜„ì¬ ìƒí™©:")
        print(f"í˜„ì¬ ì‹œê°: {df.iloc[-1]['timestamp']}")
        print(f"í˜„ì¬ ë¬¼ë¥˜ëŸ‰: {df.iloc[-1]['current_volume']}")
        print(f"í˜„ì¬ ì²˜ë¦¬ì‹œê°„: {df.iloc[-1]['process_minutes']:.1f}ë¶„")
        
        # 10ë¶„ í›„ ì˜ˆì¸¡
        prediction = realtime.predict_next_10min(recent_data)
        
        print("\n=== 10ë¶„ í›„ ì˜ˆì¸¡ ê²°ê³¼ ===")
        for key, value in prediction['10ë¶„í›„_ì˜ˆì¸¡'].items():
            print(f"{key}: {value}")
        
        print("\nëª¨ë¸ë³„ ì˜ˆì¸¡:")
        for model, pred in prediction['ëª¨ë¸ë³„_ì˜ˆì¸¡'].items():
            print(f"  {model}: {pred}")
        
        print("\nê¶Œì¥ì‚¬í•­:")
        for rec in prediction['ê¶Œì¥ì‚¬í•­']:
            print(f"  {rec}")
    
    print("\nì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ! ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")