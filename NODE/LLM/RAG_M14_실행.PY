#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step 2: TEST.CSVìš© RAG ì‹œìŠ¤í…œ ì‹¤í–‰
"""

import os
os.environ['USE_TF'] = '0'
os.environ['USE_TORCH'] = '1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TRANSFORMERS_NO_TF'] = '1'

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from datetime import datetime
import re
import pickle
import logging

# ì‹¤ì‹œê°„ ì˜ˆì¸¡ ëª¨ë“ˆ import
try:
    from ì‹¤ì‹œê°„_ì˜ˆì¸¡ import predict_latest
    PREDICTION_AVAILABLE = True
except ImportError:
    PREDICTION_AVAILABLE = False
    print("âš ï¸ ì‹¤ì‹œê°„_ì˜ˆì¸¡.py ì—†ìŒ, ì˜ˆì¸¡ ê¸°ëŠ¥ ë¹„í™œì„±í™”")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TimeSeriesRAG:
    """TEST.CSVìš© RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 csv_path,
                 model_path,
                 db_persist_path="./chroma_db",
                 embedding_model_path="./embeddings/all-MiniLM-L6-v2"):
        
        self.csv_path = csv_path
        self.model_path = model_path
        self.db_persist_path = db_persist_path
        self.embedding_model_path = embedding_model_path
        
        # ì´ˆê¸°í™”
        self._initialize()
    
    def _initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        logger.info("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # 1. CSV ë°ì´í„° ë¡œë“œ
        self._load_csv_data()
        
        # 2. ë²¡í„°DB ë¡œë“œ
        self._load_vectorstore()
        
        # 3. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        self._load_embedding_model()
        
        # 4. LLM ì„¤ì •
        self._setup_llm()
        
        logger.info("ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def _load_csv_data(self):
        """CSV ë°ì´í„° ë¡œë“œ"""
        logger.info(f"CSV ë¡œë“œ: {self.csv_path}")
        
        df = pd.read_csv(self.csv_path, encoding='utf-8')
        self.df = df[['í˜„ì¬ì‹œê°„', 'ì‹¤ì œì‹œì ', 'ì‹¤ì œê°’', 
                     'ë³´ì •ì˜ˆì¸¡', 'ì˜¤ì°¨', 'M14AM14B', 'M14BM14A', 
                     'queue_gap', 'TRANSPORT']].copy()
        
        self.df['í˜„ì¬ì‹œê°„'] = pd.to_datetime(self.df['í˜„ì¬ì‹œê°„'])
        self.df['ì‹¤ì œì‹œì '] = pd.to_datetime(self.df['ì‹¤ì œì‹œì '])
        self.df.set_index('í˜„ì¬ì‹œê°„', inplace=True)
        
        logger.info(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df)}ê°œ")
    
    def _load_vectorstore(self):
        """ë²¡í„°DB ë¡œë“œ"""
        db_file = os.path.join(self.db_persist_path, 'vectordb.pkl')
        
        if not os.path.exists(db_file):
            raise FileNotFoundError(
                f"ë²¡í„°DBê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë²¡í„°DB_TEST.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\n"
                f"ê²½ë¡œ: {db_file}"
            )
        
        logger.info(f"ë²¡í„°DB ë¡œë“œ ì¤‘: {db_file}")
        
        with open(db_file, 'rb') as f:
            db_data = pickle.load(f)
        
        self.documents = db_data['documents']
        self.embeddings = db_data['embeddings']
        
        logger.info(f"ë²¡í„°DB ë¡œë“œ ì™„ë£Œ: {len(self.documents)}ê°œ ë¬¸ì„œ")
    
    def _load_embedding_model(self):
        """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"""
        logger.info(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ: {self.embedding_model_path}")
        
        try:
            import torch
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
        except:
            device = 'cpu'
        
        logger.info(f"ë””ë°”ì´ìŠ¤: {device}")
        
        from sentence_transformers import SentenceTransformer
        self.embedding_model = SentenceTransformer(self.embedding_model_path)
        if device == 'cuda':
            self.embedding_model = self.embedding_model.to('cuda')
        
        logger.info("ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    def _setup_llm(self):
        """LLM ì„¤ì •"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {self.model_path}")
        
        logger.info(f"LLM ë¡œë“œ: {self.model_path}")
        
        from llama_cpp import Llama
        
        self.llm = Llama(
            model_path=self.model_path,
            n_ctx=4096,
            n_batch=512,
            n_gpu_layers=-1,
            n_threads=4,
            verbose=False  # sampler ì—ëŸ¬ ë°©ì§€
        )
        
        logger.info("LLM ë¡œë“œ ì™„ë£Œ")
    
    def _cosine_similarity(self, a, b):
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
    
    def _search_similar(self, query, k=5):
        """ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
        query_embedding = self.embedding_model.encode([query])[0]
        
        similarities = []
        for i, doc_embedding in enumerate(self.embeddings):
            sim = self._cosine_similarity(query_embedding, doc_embedding)
            similarities.append((i, sim))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        top_k = similarities[:k]
        
        results = []
        for idx, score in top_k:
            results.append(self.documents[idx]['content'])
        
        return results
    
    def _call_llm(self, prompt, max_tokens=300):
        """LLM í˜¸ì¶œ"""
        print(f"ğŸ’¬ í† í° ìƒì„± ì‹œì‘... (ìµœëŒ€ {max_tokens}ê°œ)")
        response = self.llm(
            prompt, 
            max_tokens=max_tokens, 
            temperature=0.7,  # ë” ì°½ì˜ì ìœ¼ë¡œ
            top_p=0.95,
            repeat_penalty=1.15,
            stop=["ì§ˆë¬¸:", "###"]  # stop í† í° ìµœì†Œí™”
        )
        result = response['choices'][0]['text'].strip()
        print(f"âœ… ìƒì„± ì™„ë£Œ ({len(result)}ì)")
        return result
    
    def get_data_at_time(self, datetime_str):
        """íŠ¹ì • ì‹œê°„ ë°ì´í„° ì¡°íšŒ"""
        try:
            dt = pd.to_datetime(datetime_str)
            
            if dt in self.df.index:
                data = self.df.loc[dt]
                return f"""
ğŸ“Š {dt} ë°ì´í„°:
- ì‹¤ì œê°’: {data['ì‹¤ì œê°’']:.1f}
- ì˜ˆì¸¡ê°’: {data['ë³´ì •ì˜ˆì¸¡']:.1f}  
- ì˜¤ì°¨: {data['ì˜¤ì°¨']:.1f}
- M14AM14B: {data['M14AM14B']}
- M14BM14A: {data['M14BM14A']}
- queue_gap: {data['queue_gap']}
- TRANSPORT: {data['TRANSPORT']}
                """
            else:
                nearest_idx = self.df.index.get_indexer([dt], method='nearest')[0]
                nearest_time = self.df.index[nearest_idx]
                data = self.df.iloc[nearest_idx]
                
                return f"""
ğŸ“Š ê°€ì¥ ê°€ê¹Œìš´ ì‹œê°„: {nearest_time}
- ì‹¤ì œê°’: {data['ì‹¤ì œê°’']:.1f}
- ì˜ˆì¸¡ê°’: {data['ë³´ì •ì˜ˆì¸¡']:.1f}
- ì˜¤ì°¨: {data['ì˜¤ì°¨']:.1f}
- M14AM14B: {data['M14AM14B']}
- M14BM14A: {data['M14BM14A']}
                """
        except Exception as e:
            return f"ì˜¤ë¥˜: {e}"
    
    def _find_max_value(self, query):
        """ìµœëŒ€ê°’ ì°¾ê¸°"""
        if "ì‹¤ì œê°’" in query:
            max_idx = self.df['ì‹¤ì œê°’'].idxmax()
            max_val = self.df.loc[max_idx, 'ì‹¤ì œê°’']
            pred_val = self.df.loc[max_idx, 'ë³´ì •ì˜ˆì¸¡']
            error = self.df.loc[max_idx, 'ì˜¤ì°¨']
            
            return f"""
ğŸ“Š ì‹¤ì œê°’ì´ ê°€ì¥ í° ì‹œê°„: {max_idx}
- ì‹¤ì œê°’: {max_val:.1f}
- ì˜ˆì¸¡ê°’: {pred_val:.1f}
- ì˜¤ì°¨: {error:.1f}
            """
        elif "ì˜ˆì¸¡ê°’" in query:
            max_idx = self.df['ë³´ì •ì˜ˆì¸¡'].idxmax()
            max_val = self.df.loc[max_idx, 'ë³´ì •ì˜ˆì¸¡']
            real_val = self.df.loc[max_idx, 'ì‹¤ì œê°’']
            error = self.df.loc[max_idx, 'ì˜¤ì°¨']
            
            return f"""
ğŸ“Š ì˜ˆì¸¡ê°’ì´ ê°€ì¥ í° ì‹œê°„: {max_idx}
- ì˜ˆì¸¡ê°’: {max_val:.1f}
- ì‹¤ì œê°’: {real_val:.1f}
- ì˜¤ì°¨: {error:.1f}
            """
        else:
            return "ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ì¤‘ ë¬´ì—‡ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?"
    
    def _find_min_value(self, query):
        """ìµœì†Œê°’ ì°¾ê¸°"""
        if "ì‹¤ì œê°’" in query:
            min_idx = self.df['ì‹¤ì œê°’'].idxmin()
            min_val = self.df.loc[min_idx, 'ì‹¤ì œê°’']
            pred_val = self.df.loc[min_idx, 'ë³´ì •ì˜ˆì¸¡']
            error = self.df.loc[min_idx, 'ì˜¤ì°¨']
            
            return f"""
ğŸ“Š ì‹¤ì œê°’ì´ ê°€ì¥ ì‘ì€ ì‹œê°„: {min_idx}
- ì‹¤ì œê°’: {min_val:.1f}
- ì˜ˆì¸¡ê°’: {pred_val:.1f}
- ì˜¤ì°¨: {error:.1f}
            """
        else:
            return "ì‹¤ì œê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ìµœì†Œê°’ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
    
    def _find_most_accurate(self):
        """ê°€ì¥ ì •í™•í•œ ì˜ˆì¸¡ ì°¾ê¸° (ì˜¤ì°¨ ì ˆëŒ€ê°’ ìµœì†Œ)"""
        self.df['ì ˆëŒ€ì˜¤ì°¨'] = self.df['ì˜¤ì°¨'].abs()
        min_idx = self.df['ì ˆëŒ€ì˜¤ì°¨'].idxmin()
        
        real_val = self.df.loc[min_idx, 'ì‹¤ì œê°’']
        pred_val = self.df.loc[min_idx, 'ë³´ì •ì˜ˆì¸¡']
        error = self.df.loc[min_idx, 'ì˜¤ì°¨']
        
        return f"""
ğŸ“Š ì˜ˆì¸¡ì´ ê°€ì¥ ì •í™•í•œ ì‹œê°„: {min_idx}
- ì‹¤ì œê°’: {real_val:.1f}
- ì˜ˆì¸¡ê°’: {pred_val:.1f}
- ì˜¤ì°¨: {error:.1f}
- ì ˆëŒ€ì˜¤ì°¨: {abs(error):.1f}
        """
    
    def _find_high_values(self, query):
        """ë†’ì€ ê°’ ì°¾ê¸°"""
        if "M14AM14B" in query:
            # ìƒìœ„ 3ê°œ ì°¾ê¸°
            top_3 = self.df.nlargest(3, 'M14AM14B')
            
            result = "ğŸ“Š M14AM14B ê°’ì´ ë†’ì€ ì‹œê°„ëŒ€ (ìƒìœ„ 3ê°œ):\n\n"
            for idx, row in top_3.iterrows():
                result += f"ì‹œê°„: {idx}\n"
                result += f"- M14AM14B: {row['M14AM14B']}\n"
                result += f"- ì‹¤ì œê°’: {row['ì‹¤ì œê°’']:.1f}\n"
                result += f"- ì˜ˆì¸¡ê°’: {row['ë³´ì •ì˜ˆì¸¡']:.1f}\n\n"
            
            return result
        else:
            return "ì–´ë–¤ ê°’ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?"
    
    def analyze_query(self, query):
        """ì¿¼ë¦¬ ë¶„ì„ ë° ì²˜ë¦¬"""
        # ì‹œê°„ íŒ¨í„´ ì¶”ì¶œ
        time_pattern = r'(\d{4}-\d{2}-\d{2}\s+\d{1,2}:\d{2})'
        time_match = re.search(time_pattern, query)
        
        # ì‹¤ì‹œê°„ ì˜ˆì¸¡ ìš”ì²­
        if PREDICTION_AVAILABLE and ("ì˜ˆì¸¡" in query or "10ë¶„ í›„" in query or "ì•ìœ¼ë¡œ" in query):
            print("ğŸ”® ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
            result = predict_latest()
            
            if 'error' in result:
                return f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {result['error']}"
            
            # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ LLMì—ê²Œ ì„¤ëª… ìš”ì²­
            print("ğŸ¤– AI ì„¤ëª… ìƒì„± ì¤‘...")
            prompt = f"""10ë¶„ í›„ ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ê²°ê³¼ì…ë‹ˆë‹¤:

í˜„ì¬ ë¬¼ë¥˜ëŸ‰: {result['í˜„ì¬ë¬¼ë¥˜ëŸ‰']:,} ({result['í˜„ì¬ìƒíƒœ']})
ì˜ˆì¸¡ ë¬¼ë¥˜ëŸ‰: {result['ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰']:,} ({result['ì˜ˆì¸¡ìƒíƒœ']})
ë³€í™”ëŸ‰: {result['ë³€í™”ëŸ‰']:+,}

ì£¼ìš” ì§€í‘œ:
- M14AM14B: {result['M14AM14B']:,}
- M14AM14BSUM: {result['M14AM14BSUM']:,}
- queue_gap: {result['queue_gap']:,}
- TRANSPORT: {result['TRANSPORT']:,}

í™©ê¸ˆíŒ¨í„´: {result['í™©ê¸ˆíŒ¨í„´']}
ìœ„í—˜ì‹ í˜¸: {', '.join(result['ìœ„í—˜ì‹ í˜¸']) if result['ìœ„í—˜ì‹ í˜¸'] else 'ì—†ìŒ'}

ìœ„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ë‹µë³€:"""
            
            explanation = self._call_llm(prompt, max_tokens=200)
            
            # ìµœì¢… ì¶œë ¥
            output = f"""
ğŸ”® ì‹¤ì‹œê°„ ì˜ˆì¸¡ ê²°ê³¼
{"="*60}
í˜„ì¬ ë¬¼ë¥˜ëŸ‰: {result['í˜„ì¬ë¬¼ë¥˜ëŸ‰']:,} [{result['í˜„ì¬ìƒíƒœ']}]
ì˜ˆì¸¡ ë¬¼ë¥˜ëŸ‰: {result['ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰']:,} [{result['ì˜ˆì¸¡ìƒíƒœ']}]
ë³€í™”ëŸ‰: {result['ë³€í™”ëŸ‰']:+,}
{"="*60}
M14AM14B: {result['M14AM14B']:,}
M14AM14BSUM: {result['M14AM14BSUM']:,}
queue_gap: {result['queue_gap']:,}
TRANSPORT: {result['TRANSPORT']:,}

í™©ê¸ˆíŒ¨í„´: {result['í™©ê¸ˆíŒ¨í„´']}
{chr(10).join(result['ìœ„í—˜ì‹ í˜¸']) if result['ìœ„í—˜ì‹ í˜¸'] else ''}

ğŸ’¡ AI ì„¤ëª…:
{explanation}
            """
            return output.strip()
        
        # ì‹¤ì œê°’/ì˜ˆì¸¡ê°’ ì¡°íšŒ
        elif time_match and ("ì‹¤ì œê°’" in query or "ì˜ˆì¸¡ê°’" in query or "ë°ì´í„°" in query or "ì˜¤ì°¨" in query):
            return self.get_data_at_time(time_match.group(1))
        
        # ê³„ì‚° í•„ìš”í•œ ì§ˆë¬¸ë“¤ - Pythonìœ¼ë¡œ ì§ì ‘ ì²˜ë¦¬
        elif "ê°€ì¥ í°" in query or "ìµœëŒ€" in query or "ìµœê³ " in query:
            return self._find_max_value(query)
        elif "ê°€ì¥ ì‘ì€" in query or "ìµœì†Œ" in query or "ìµœì €" in query:
            return self._find_min_value(query)
        elif "ê°€ì¥ ì •í™•" in query or "ì˜¤ì°¨ê°€ ì‘ì€" in query:
            return self._find_most_accurate()
        elif "ë†’ì€ ì‹œê°„ëŒ€" in query or "ë§ì€ ì‹œê°„" in query:
            return self._find_high_values(query)
        
        # ì¼ë°˜ RAG ì¿¼ë¦¬
        else:
            print("ğŸ” ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
            similar_docs = self._search_similar(query, k=3)
            context = "\n---\n".join(similar_docs)
            
            print("ğŸ¤– AI ë‹µë³€ ìƒì„± ì¤‘...")
            prompt = f"""ë°ì´í„°:
{context}

ì§ˆë¬¸: {query}

ìœ„ ë°ì´í„°ë¥¼ ë³´ê³  ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”.

ë‹µë³€:"""
            
            result = self._call_llm(prompt, max_tokens=200)
            return result

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    CSV_PATH = "./TEST.CSV"
    MODEL_PATH = "./models/Qwen3-Coder-30B-A3B-Instruct-Q3_K_M.gguf"
    DB_PATH = "./chroma_db"
    
    print("="*60)
    print("TEST.CSV RAG ì‹œìŠ¤í…œ ì‹œì‘")
    print("="*60)
    
    rag = TimeSeriesRAG(
        csv_path=CSV_PATH,
        model_path=MODEL_PATH,
        db_persist_path=DB_PATH
    )
    
    # ëŒ€í™” ë£¨í”„
    while True:
        query = input("\nì§ˆë¬¸ (ì¢…ë£Œ: quit): ").strip()
        
        if query.lower() in ['quit', 'exit']:
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        if query:
            print("\nì²˜ë¦¬ ì¤‘...")
            answer = rag.analyze_query(query)
            print(f"\n{answer}")

if __name__ == "__main__":
    main()