"""
CNN-LSTM Multi-Task ëª¨ë¸ ì¢…í•© í‰ê°€ ì‹œìŠ¤í…œ
=========================================
í•™ìŠµëœ CNN-LSTM Multi-Task ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë‹¤ê°ë„ë¡œ í‰ê°€í•©ë‹ˆë‹¤.

í‰ê°€ í•­ëª©:
1. ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ì„±ëŠ¥ (íšŒê·€ íƒœìŠ¤í¬)
   - MAE, MSE, RMSE, RÂ² Score
   - MAPE, SMAPE
   - ì˜ˆì¸¡ ì •í™•ë„ (ì˜¤ì°¨ ë²”ìœ„ë³„)

2. ë³‘ëª© ìœ„ì¹˜ ì˜ˆì¸¡ ì„±ëŠ¥ (ë¶„ë¥˜ íƒœìŠ¤í¬)
   - Accuracy, Precision, Recall, F1-Score
   - í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
   - í˜¼ë™ í–‰ë ¬

3. ì¢…í•© ì„±ëŠ¥ í‰ê°€
   - ë‘ íƒœìŠ¤í¬ì˜ í†µí•© ì„±ëŠ¥ ì ìˆ˜
   - ì‹¤ì‹œê°„ ì˜ˆì¸¡ ëŠ¥ë ¥
   - ë³‘ëª© ì˜ˆë°© íš¨ê³¼

ì‚¬ìš© ë°ì´í„°: data/0730to31.csv
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import load_model
from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score,
                           accuracy_score, precision_recall_fscore_support,
                           confusion_matrix, classification_report)
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
import os
import platform
from datetime import datetime, timedelta
import joblib
import json
import warnings
import logging

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings('ignore')

# ===================================
# 1. í™˜ê²½ ì„¤ì •
# ===================================

# CPU ëª¨ë“œ ì„¤ì •
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
tf.config.set_visible_devices([], 'GPU')

# ëœë¤ ì‹œë“œ ê³ ì •
RANDOM_SEED = 2079936
tf.random.set_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í•œê¸€ í°íŠ¸ ì„¤ì •
def set_korean_font():
    """ìš´ì˜ì²´ì œë³„ í•œê¸€ í°íŠ¸ ìë™ ì„¤ì •"""
    system = platform.system()
    
    try:
        if system == 'Windows':
            font_path = 'C:/Windows/Fonts/malgun.ttf'
            if os.path.exists(font_path):
                font_prop = fm.FontProperties(fname=font_path)
                plt.rcParams['font.family'] = font_prop.get_name()
        elif system == 'Darwin':  # macOS
            plt.rcParams['font.family'] = 'AppleGothic'
        else:  # Linux
            plt.rcParams['font.family'] = 'NanumGothic'
    except:
        print("í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨. ì˜ë¬¸ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
        return False
    
    plt.rcParams['axes.unicode_minus'] = False
    return True

USE_KOREAN = set_korean_font()

# ===================================
# 2. ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ (í•™ìŠµ ì‹œì™€ ë™ì¼)
# ===================================

def load_and_preprocess_data(data_path):
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    logger.info("í‰ê°€ ë°ì´í„° ë¡œë”© ì¤‘...")
    
    # ë°ì´í„° ë¡œë“œ
    data = pd.read_csv(data_path)
    logger.info(f"ì›ë³¸ ë°ì´í„° shape: {data.shape}")
    
    # ì‹œê°„ ì»¬ëŸ¼ ë³€í™˜
    data['CURRTIME'] = pd.to_datetime(data['CURRTIME'], format='%Y%m%d%H%M')
    data['TIME'] = pd.to_datetime(data['TIME'], format='%Y%m%d%H%M')
    
    # SUM ì»¬ëŸ¼ ì œê±°
    columns_to_drop = [col for col in data.columns if 'SUM' in col]
    data = data.drop(columns=columns_to_drop)
    
    # ì¸ë±ìŠ¤ ì„¤ì •
    data.set_index('CURRTIME', inplace=True)
    
    return data

def create_features(data):
    """íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§ (í•™ìŠµ ì‹œì™€ ë™ì¼)"""
    logger.info("íŠ¹ì§• ìƒì„± ì¤‘...")
    
    features_data = data.copy()
    
    # ì‹œê°„ íŠ¹ì§•
    features_data['hour'] = features_data.index.hour
    features_data['dayofweek'] = features_data.index.dayofweek
    features_data['is_weekend'] = (features_data.index.dayofweek >= 5).astype(int)
    features_data['month'] = features_data.index.month
    features_data['day'] = features_data.index.day
    features_data['is_peak_hour'] = features_data.index.hour.isin([8, 9, 14, 15, 16, 17]).astype(int)
    
    # íŒ¹ ê°„ ë¶ˆê· í˜• ì§€í‘œ
    features_data['imbalance_M14A_M10A'] = features_data['M14AM10A'] - features_data['M10AM14A']
    features_data['imbalance_M14A_M14B'] = features_data['M14AM14B'] - features_data['M14BM14A']
    features_data['imbalance_M14A_M16'] = features_data['M14AM16'] - features_data['M16M14A']
    
    # ì´ë™ í‰ê· 
    for window in [5, 10, 30, 60]:
        features_data[f'MA_{window}'] = features_data['TOTALCNT'].rolling(window=window, min_periods=1).mean()
    
    # í‘œì¤€í¸ì°¨
    for window in [5, 10, 30]:
        features_data[f'STD_{window}'] = features_data['TOTALCNT'].rolling(window=window, min_periods=1).std()
    
    # ìµœëŒ€/ìµœì†Œê°’
    features_data['MAX_10'] = features_data['TOTALCNT'].rolling(window=10, min_periods=1).max()
    features_data['MIN_10'] = features_data['TOTALCNT'].rolling(window=10, min_periods=1).min()
    
    # íŒ¹ë³„ ë¶€í•˜ìœ¨
    total_safe = features_data['TOTALCNT'].replace(0, 1)
    features_data['load_M14A_out'] = (features_data['M14AM10A'] + features_data['M14AM14B'] + 
                                      features_data['M14AM16']) / total_safe
    features_data['load_M14A_in'] = (features_data['M10AM14A'] + features_data['M14BM14A'] + 
                                     features_data['M16M14A']) / total_safe
    
    # ê²½ë¡œë³„ ë¹„ìœ¨
    features_data['ratio_M14A_M10A'] = (features_data['M14AM10A'] + features_data['M10AM14A']) / total_safe
    features_data['ratio_M14A_M14B'] = (features_data['M14AM14B'] + features_data['M14BM14A']) / total_safe
    features_data['ratio_M14A_M16'] = (features_data['M14AM16'] + features_data['M16M14A']) / total_safe
    
    # ë³€í™”ìœ¨
    features_data['change_rate'] = features_data['TOTALCNT'].pct_change()
    features_data['change_rate_5'] = features_data['TOTALCNT'].pct_change(5)
    features_data['change_rate_10'] = features_data['TOTALCNT'].pct_change(10)
    features_data['acceleration'] = features_data['change_rate'].diff()
    
    # ê²°ì¸¡ê°’ ë° ë¬´í•œëŒ€ ì²˜ë¦¬
    features_data = features_data.fillna(method='ffill').fillna(0)
    features_data = features_data.replace([np.inf, -np.inf], 0)
    
    # ì´ìƒì¹˜ í´ë¦¬í•‘
    numeric_columns = features_data.select_dtypes(include=[np.number]).columns
    for col in numeric_columns:
        if col not in ['TIME', 'CURRTIME']:
            upper_limit = features_data[col].quantile(0.999)
            lower_limit = features_data[col].quantile(0.001)
            features_data[col] = features_data[col].clip(lower=lower_limit, upper=upper_limit)
    
    return features_data

def create_targets(data, future_minutes=10):
    """íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±"""
    logger.info("íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì¤‘...")
    
    # ë¬¼ë¥˜ëŸ‰ íƒ€ê²Ÿ
    data['FUTURE_TOTALCNT'] = pd.NA
    
    for i in data.index:
        future_time = i + pd.Timedelta(minutes=future_minutes)
        if (future_time <= data.index.max()) & (future_time in data.index):
            data.loc[i, 'FUTURE_TOTALCNT'] = data.loc[future_time, 'TOTALCNT']
    
    # ë³‘ëª© ìœ„ì¹˜ íƒ€ê²Ÿ
    thresholds = {
        'total': data['TOTALCNT'].quantile(0.90),
        'm14a_m10a': np.percentile(data['M14AM10A'] + data['M10AM14A'], 90),
        'm14a_m14b': np.percentile(data['M14AM14B'] + data['M14BM14A'], 90),
        'm14a_m16': np.percentile(data['M14AM16'] + data['M16M14A'], 90)
    }
    
    data['BOTTLENECK_LOCATION'] = 0
    
    for i in data.index:
        future_time = i + pd.Timedelta(minutes=future_minutes)
        if (future_time <= data.index.max()) & (future_time in data.index):
            future_total = data.loc[future_time, 'TOTALCNT']
            
            if future_total > thresholds['total']:
                route_loads = {
                    1: data.loc[future_time, 'M14AM10A'] + data.loc[future_time, 'M10AM14A'],
                    2: data.loc[future_time, 'M14AM14B'] + data.loc[future_time, 'M14BM14A'],
                    3: data.loc[future_time, 'M14AM16'] + data.loc[future_time, 'M16M14A']
                }
                
                max_route = max(route_loads.items(), key=lambda x: x[1])
                if max_route[0] == 1 and max_route[1] > thresholds['m14a_m10a']:
                    data.loc[i, 'BOTTLENECK_LOCATION'] = 1
                elif max_route[0] == 2 and max_route[1] > thresholds['m14a_m14b']:
                    data.loc[i, 'BOTTLENECK_LOCATION'] = 2
                elif max_route[0] == 3 and max_route[1] > thresholds['m14a_m16']:
                    data.loc[i, 'BOTTLENECK_LOCATION'] = 3
    
    # NA ì œê±°
    data = data.dropna(subset=['FUTURE_TOTALCNT'])
    
    return data, thresholds

# ===================================
# 3. Multi-Task ëª¨ë¸ í‰ê°€ í´ë˜ìŠ¤
# ===================================

class MultiTaskModelEvaluator:
    """CNN-LSTM Multi-Task ëª¨ë¸ í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.model = None
        self.scaler = None
        self.class_mapping = None
        self.reverse_mapping = None
        
    def load_model_and_config(self):
        """ëª¨ë¸ê³¼ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        logger.info("="*60)
        logger.info("ëª¨ë¸ ë° ì„¤ì • ë¡œë”© ì¤‘...")
        logger.info("="*60)
        
        # ëª¨ë¸ ë¡œë“œ
        model_paths = [
            'model/cnn_lstm_multitask_final.keras',
            'model/cnn_lstm_multitask_best.keras'
        ]
        
        for path in model_paths:
            if os.path.exists(path):
                self.model = load_model(path, compile=False)
                logger.info(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {path}")
                break
        
        if self.model is None:
            raise FileNotFoundError("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        scaler_path = 'scaler/multitask_scaler.pkl'
        if os.path.exists(scaler_path):
            self.scaler = joblib.load(scaler_path)
            logger.info(f"âœ“ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ: {scaler_path}")
        else:
            raise FileNotFoundError("ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # í´ë˜ìŠ¤ ë§¤í•‘ ë¡œë“œ
        mapping_path = 'config/class_mapping.json'
        if os.path.exists(mapping_path):
            with open(mapping_path, 'r') as f:
                # JSONì—ì„œ ë¬¸ìì—´ í‚¤ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
                string_mapping = json.load(f)
                self.class_mapping = {int(k): v for k, v in string_mapping.items()}
                self.reverse_mapping = {v: k for k, v in self.class_mapping.items()}
            logger.info(f"âœ“ í´ë˜ìŠ¤ ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {self.class_mapping}")
        else:
            logger.warning("í´ë˜ìŠ¤ ë§¤í•‘ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë§¤í•‘ ì‚¬ìš©")
            self.class_mapping = {0: 0, 1: 1, 2: 2, 3: 3}
            self.reverse_mapping = {0: 0, 1: 1, 2: 2, 3: 3}
    
    def prepare_evaluation_data(self, data_path):
        """í‰ê°€ ë°ì´í„° ì¤€ë¹„"""
        # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        data = load_and_preprocess_data(data_path)
        data = create_features(data)
        data, thresholds = create_targets(data)
        
        # ìŠ¤ì¼€ì¼ë§í•  íŠ¹ì§• ëª©ë¡ (í•™ìŠµ ì‹œì™€ ë™ì¼)
        scale_features_list = [
            'TOTALCNT', 'M14AM10A', 'M10AM14A', 'M14AM14B', 'M14BM14A', 'M14AM16', 'M16M14A',
            'imbalance_M14A_M10A', 'imbalance_M14A_M14B', 'imbalance_M14A_M16',
            'MA_5', 'MA_10', 'MA_30', 'MA_60',
            'STD_5', 'STD_10', 'STD_30',
            'MAX_10', 'MIN_10',
            'load_M14A_out', 'load_M14A_in',
            'ratio_M14A_M10A', 'ratio_M14A_M14B', 'ratio_M14A_M16',
            'change_rate', 'change_rate_5', 'change_rate_10',
            'acceleration'
        ]
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        scale_features_list = [col for col in scale_features_list if col in data.columns]
        
        # ìŠ¤ì¼€ì¼ë§
        data_scaled, _ = self.scale_features(data, scale_features_list)
        
        # ì‹œí€€ìŠ¤ ìƒì„±
        sequence_features = [col for col in data_scaled.columns if col.startswith('scaled_')]
        target_features = ['FUTURE_TOTALCNT', 'BOTTLENECK_LOCATION']
        
        X, y_regression, y_classification = self.create_sequences(
            data_scaled,
            sequence_features,
            target_features,
            seq_length=60
        )
        
        # í´ë˜ìŠ¤ ë ˆì´ë¸” ì¬ë§¤í•‘
        unique_classes = np.unique(y_classification)
        if len(self.class_mapping) > 0:
            y_classification_mapped = np.array([self.class_mapping.get(cls, cls) for cls in y_classification])
        else:
            # ê¸°ë³¸ ë§¤í•‘
            class_mapping_temp = {old_class: new_class for new_class, old_class in enumerate(unique_classes)}
            y_classification_mapped = np.array([class_mapping_temp[cls] for cls in y_classification])
        
        logger.info(f"í‰ê°€ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
        logger.info(f"  - X shape: {X.shape}")
        logger.info(f"  - y_regression shape: {y_regression.shape}")
        logger.info(f"  - y_classification shape: {y_classification_mapped.shape}")
        logger.info(f"  - ë³‘ëª© í´ë˜ìŠ¤ ë¶„í¬: {np.unique(y_classification_mapped, return_counts=True)}")
        
        return X, y_regression, y_classification_mapped, data, thresholds
    
    def scale_features(self, data, feature_columns):
        """íŠ¹ì§• ìŠ¤ì¼€ì¼ë§"""
        scale_columns = [col for col in feature_columns if col in data.columns]
        scale_data = data[scale_columns].copy()
        
        # ë¬´í•œëŒ€ ë° NaN ì²˜ë¦¬
        scale_data = scale_data.replace([np.inf, -np.inf], np.nan)
        scale_data = scale_data.fillna(scale_data.mean())
        
        # ìŠ¤ì¼€ì¼ë§
        scaled_data = self.scaler.transform(scale_data)
        
        # ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        scaled_df = pd.DataFrame(
            scaled_data,
            columns=[f'scaled_{col}' for col in scale_columns],
            index=data.index
        )
        
        # ì›ë³¸ ë°ì´í„°ì™€ ë³‘í•©
        result = pd.concat([data, scaled_df], axis=1)
        
        return result, self.scaler
    
    def create_sequences(self, data, feature_cols, target_cols, seq_length=60):
        """ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±"""
        X, y_regression, y_classification = [], [], []
        
        # ì—°ì†ì„± í™•ì¸
        time_diff = data.index.to_series().diff()
        split_points = time_diff > pd.Timedelta(minutes=1)
        segment_ids = split_points.cumsum()
        
        for segment_id in segment_ids.unique():
            segment = data[segment_ids == segment_id]
            
            if len(segment) > seq_length:
                feature_data = segment[feature_cols].values
                regression_data = segment[target_cols[0]].values
                classification_data = segment[target_cols[1]].values
                
                for i in range(len(segment) - seq_length):
                    X.append(feature_data[i:i+seq_length])
                    y_regression.append(regression_data[i+seq_length])
                    y_classification.append(classification_data[i+seq_length])
        
        return np.array(X), np.array(y_regression), np.array(y_classification)
    
    def evaluate_regression_task(self, y_true, y_pred):
        """íšŒê·€ íƒœìŠ¤í¬ í‰ê°€ (ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡)"""
        logger.info("\n" + "="*60)
        logger.info("ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€ (íšŒê·€ íƒœìŠ¤í¬)")
        logger.info("="*60)
        
        # ê¸°ë³¸ ë©”íŠ¸ë¦­
        mae = mean_absolute_error(y_true, y_pred)
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_true, y_pred)
        
        # MAPE, SMAPE
        mask = y_true != 0
        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100
        
        denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
        mask_smape = denominator != 0
        smape = np.mean(np.abs(y_true[mask_smape] - y_pred[mask_smape]) / denominator[mask_smape]) * 100
        
        # ì˜¤ì°¨ ë²”ìœ„ë³„ ì •í™•ë„
        def accuracy_within_threshold(y_true, y_pred, threshold_percent):
            threshold = np.mean(y_true) * (threshold_percent / 100)
            within_threshold = np.abs(y_true - y_pred) <= threshold
            return np.mean(within_threshold) * 100
        
        acc_5 = accuracy_within_threshold(y_true, y_pred, 5)
        acc_10 = accuracy_within_threshold(y_true, y_pred, 10)
        acc_15 = accuracy_within_threshold(y_true, y_pred, 15)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“Š ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ì„±ëŠ¥:")
        print(f"  â€¢ MAE: {mae:.2f}")
        print(f"  â€¢ MSE: {mse:.2f}")
        print(f"  â€¢ RMSE: {rmse:.2f}")
        print(f"  â€¢ RÂ² Score: {r2:.4f} ({r2*100:.1f}%)")
        print(f"  â€¢ MAPE: {mape:.2f}%")
        print(f"  â€¢ SMAPE: {smape:.2f}%")
        
        print("\nğŸ¯ ì˜ˆì¸¡ ì •í™•ë„:")
        print(f"  â€¢ 5% ì˜¤ì°¨ ë²”ìœ„ ë‚´: {acc_5:.1f}%")
        print(f"  â€¢ 10% ì˜¤ì°¨ ë²”ìœ„ ë‚´: {acc_10:.1f}%")
        print(f"  â€¢ 15% ì˜¤ì°¨ ë²”ìœ„ ë‚´: {acc_15:.1f}%")
        
        regression_metrics = {
            'mae': mae,
            'mse': mse,
            'rmse': rmse,
            'r2': r2,
            'mape': mape,
            'smape': smape,
            'acc_5': acc_5,
            'acc_10': acc_10,
            'acc_15': acc_15
        }
        
        return regression_metrics
    
    def evaluate_classification_task(self, y_true, y_pred_probs):
        """ë¶„ë¥˜ íƒœìŠ¤í¬ í‰ê°€ (ë³‘ëª© ìœ„ì¹˜ ì˜ˆì¸¡)"""
        logger.info("\n" + "="*60)
        logger.info("ë³‘ëª© ìœ„ì¹˜ ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€ (ë¶„ë¥˜ íƒœìŠ¤í¬)")
        logger.info("="*60)
        
        # ì˜ˆì¸¡ í´ë˜ìŠ¤
        y_pred = np.argmax(y_pred_probs, axis=1)
        
        # ì „ì²´ ì •í™•ë„
        accuracy = accuracy_score(y_true, y_pred)
        
        # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
        precision, recall, f1, support = precision_recall_fscore_support(
            y_true, y_pred, average=None, zero_division=0
        )
        
        # ê°€ì¤‘ í‰ê·  ì„±ëŠ¥
        weighted_precision = np.average(precision, weights=support)
        weighted_recall = np.average(recall, weights=support)
        weighted_f1 = np.average(f1, weights=support)
        
        # í´ë˜ìŠ¤ ì´ë¦„ ì„¤ì •
        unique_classes = np.unique(y_true)
        num_classes = len(unique_classes)
        
        if self.reverse_mapping:
            # ì›ë³¸ í´ë˜ìŠ¤ë¡œ ì—­ë§¤í•‘
            original_classes = sorted([self.reverse_mapping.get(i, i) for i in unique_classes])
            
            if set(original_classes) == {0, 2, 3}:
                class_names = ['ì •ìƒ', 'M14A-M14B', 'M14A-M16']
            elif set(original_classes) == {0, 1, 2, 3}:
                class_names = ['ì •ìƒ', 'M14A-M10A', 'M14A-M14B', 'M14A-M16']
            else:
                class_names = [f'í´ë˜ìŠ¤_{i}' for i in unique_classes]
        else:
            class_names = [f'í´ë˜ìŠ¤_{i}' for i in unique_classes]
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ë³‘ëª© ìœ„ì¹˜ ì˜ˆì¸¡ ì„±ëŠ¥:")
        print(f"  â€¢ ì „ì²´ ì •í™•ë„: {accuracy:.2%}")
        print(f"  â€¢ ê°€ì¤‘ í‰ê·  ì •ë°€ë„: {weighted_precision:.2%}")
        print(f"  â€¢ ê°€ì¤‘ í‰ê·  ì¬í˜„ìœ¨: {weighted_recall:.2%}")
        print(f"  â€¢ ê°€ì¤‘ í‰ê·  F1 Score: {weighted_f1:.2%}")
        
        print("\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
        for i, class_name in enumerate(class_names):
            if i < len(precision):  # í´ë˜ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ
                print(f"\n  {class_name}:")
                print(f"    - ì •ë°€ë„: {precision[i]:.2%}")
                print(f"    - ì¬í˜„ìœ¨: {recall[i]:.2%}")
                print(f"    - F1 Score: {f1[i]:.2%}")
                print(f"    - ìƒ˜í”Œ ìˆ˜: {int(support[i])}")
        
        # ë³‘ëª© íƒì§€ ì„±ëŠ¥ (ë³‘ëª© vs ì •ìƒ)
        is_bottleneck_true = y_true > 0
        is_bottleneck_pred = y_pred > 0
        
        bottleneck_accuracy = np.mean(is_bottleneck_true == is_bottleneck_pred)
        
        # True Positive, False Positive ë“± ê³„ì‚°
        tp = np.sum((is_bottleneck_true == True) & (is_bottleneck_pred == True))
        tn = np.sum((is_bottleneck_true == False) & (is_bottleneck_pred == False))
        fp = np.sum((is_bottleneck_true == False) & (is_bottleneck_pred == True))
        fn = np.sum((is_bottleneck_true == True) & (is_bottleneck_pred == False))
        
        bottleneck_precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        bottleneck_recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        
        print(f"\nğŸš¨ ë³‘ëª© íƒì§€ ì„±ëŠ¥ (ë³‘ëª© vs ì •ìƒ):")
        print(f"  â€¢ ë³‘ëª© íƒì§€ ì •í™•ë„: {bottleneck_accuracy:.2%}")
        print(f"  â€¢ ë³‘ëª© íƒì§€ ì •ë°€ë„: {bottleneck_precision:.2%}")
        print(f"  â€¢ ë³‘ëª© íƒì§€ ì¬í˜„ìœ¨: {bottleneck_recall:.2%}")
        
        classification_metrics = {
            'accuracy': accuracy,
            'precision': precision.tolist(),
            'recall': recall.tolist(),
            'f1': f1.tolist(),
            'weighted_precision': weighted_precision,
            'weighted_recall': weighted_recall,
            'weighted_f1': weighted_f1,
            'bottleneck_accuracy': bottleneck_accuracy,
            'bottleneck_precision': bottleneck_precision,
            'bottleneck_recall': bottleneck_recall,
            'confusion_matrix': confusion_matrix(y_true, y_pred)
        }
        
        return classification_metrics, class_names
    
    def calculate_integrated_score(self, regression_metrics, classification_metrics):
        """í†µí•© ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°"""
        # íšŒê·€ íƒœìŠ¤í¬ ì ìˆ˜ (50%)
        regression_score = (
            (100 - min(regression_metrics['mape'], 100)) * 0.3 +  # MAPE
            regression_metrics['acc_10'] * 0.4 +                   # 10% ì •í™•ë„
            regression_metrics['r2'] * 100 * 0.3                   # RÂ² Score
        ) * 0.5
        
        # ë¶„ë¥˜ íƒœìŠ¤í¬ ì ìˆ˜ (50%)
        classification_score = (
            classification_metrics['accuracy'] * 100 * 0.4 +
            classification_metrics['weighted_f1'] * 100 * 0.3 +
            classification_metrics['bottleneck_recall'] * 100 * 0.3
        ) * 0.5
        
        # í†µí•© ì ìˆ˜
        integrated_score = regression_score + classification_score
        
        # ë“±ê¸‰ íŒì •
        if integrated_score >= 90:
            grade = "A+ (íƒì›”í•¨)"
        elif integrated_score >= 85:
            grade = "A (ìš°ìˆ˜í•¨)"
        elif integrated_score >= 80:
            grade = "B+ (ë§¤ìš° ì¢‹ìŒ)"
        elif integrated_score >= 75:
            grade = "B (ì¢‹ìŒ)"
        elif integrated_score >= 70:
            grade = "C+ (ì–‘í˜¸)"
        elif integrated_score >= 65:
            grade = "C (ë³´í†µ)"
        else:
            grade = "D (ê°œì„  í•„ìš”)"
        
        return integrated_score, grade, regression_score, classification_score
    
    def visualize_results(self, y_true_reg, y_pred_reg, y_true_cls, y_pred_cls,
                         regression_metrics, classification_metrics, class_names):
        """í‰ê°€ ê²°ê³¼ ì‹œê°í™”"""
        fig = plt.figure(figsize=(20, 15))
        
        # 1. ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ë¹„êµ (ì‹œê³„ì—´)
        ax1 = plt.subplot(3, 3, 1)
        sample_size = min(300, len(y_true_reg))
        ax1.plot(y_true_reg[:sample_size], label='ì‹¤ì œê°’', color='blue', linewidth=2)
        ax1.plot(y_pred_reg[:sample_size], label='ì˜ˆì¸¡ê°’', color='red', alpha=0.7)
        ax1.set_title('ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ê²°ê³¼ (ì‹œê³„ì—´)', fontsize=14)
        ax1.set_xlabel('ì‹œê°„')
        ax1.set_ylabel('ë¬¼ë¥˜ëŸ‰')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ì‚°ì ë„
        ax2 = plt.subplot(3, 3, 2)
        ax2.scatter(y_true_reg, y_pred_reg, alpha=0.5, s=10)
        ax2.plot([y_true_reg.min(), y_true_reg.max()],
                [y_true_reg.min(), y_true_reg.max()],
                'r--', lw=2)
        ax2.set_title('ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ì‚°ì ë„', fontsize=14)
        ax2.set_xlabel('ì‹¤ì œê°’')
        ax2.set_ylabel('ì˜ˆì¸¡ê°’')
        ax2.text(0.05, 0.95, f'RÂ² = {regression_metrics["r2"]:.3f}',
                transform=ax2.transAxes, verticalalignment='top')
        ax2.grid(True, alpha=0.3)
        
        # 3. ì˜¤ì°¨ ë¶„í¬
        ax3 = plt.subplot(3, 3, 3)
        errors = y_true_reg - y_pred_reg
        ax3.hist(errors, bins=50, color='green', alpha=0.7, edgecolor='black')
        ax3.axvline(x=0, color='red', linestyle='--')
        ax3.set_title('ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬', fontsize=14)
        ax3.set_xlabel('ì˜¤ì°¨ (ì‹¤ì œê°’ - ì˜ˆì¸¡ê°’)')
        ax3.set_ylabel('ë¹ˆë„')
        ax3.text(0.05, 0.95, f'MAE = {regression_metrics["mae"]:.2f}',
                transform=ax3.transAxes, verticalalignment='top')
        
        # 4. ë³‘ëª© ì˜ˆì¸¡ í˜¼ë™ í–‰ë ¬
        ax4 = plt.subplot(3, 3, 4)
        y_pred_cls_labels = np.argmax(y_pred_cls, axis=1)
        cm = classification_metrics['confusion_matrix']
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4)
        ax4.set_title('ë³‘ëª© ìœ„ì¹˜ ì˜ˆì¸¡ í˜¼ë™ í–‰ë ¬', fontsize=14)
        ax4.set_xlabel('ì˜ˆì¸¡ê°’')
        ax4.set_ylabel('ì‹¤ì œê°’')
        ax4.set_xticklabels(class_names, rotation=45)
        ax4.set_yticklabels(class_names, rotation=0)
        
        # 5. í´ë˜ìŠ¤ë³„ F1 Score
        ax5 = plt.subplot(3, 3, 5)
        f1_scores = classification_metrics['f1']
        bars = ax5.bar(class_names, f1_scores, color=['green', 'orange', 'red', 'purple'][:len(f1_scores)])
        ax5.set_title('í´ë˜ìŠ¤ë³„ F1 Score', fontsize=14)
        ax5.set_ylabel('F1 Score')
        ax5.set_ylim(0, 1)
        
        # ê°’ í‘œì‹œ
        for bar, score in zip(bars, f1_scores):
            height = bar.get_height()
            ax5.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{score:.2f}', ha='center', va='bottom')
        
        # 6. ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ ì •í™•ë„
        ax6 = plt.subplot(3, 3, 6)
        # ì˜¤ì°¨ë¥¼ ì‹œê°„ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™” (ì˜ˆ: 100ê°œì”©)
        chunk_size = 100
        num_chunks = len(errors) // chunk_size
        chunk_mae = []
        
        for i in range(num_chunks):
            chunk_errors = errors[i*chunk_size:(i+1)*chunk_size]
            chunk_mae.append(np.mean(np.abs(chunk_errors)))
        
        ax6.plot(chunk_mae)
        ax6.set_title('ì‹œê°„ëŒ€ë³„ MAE ë³€í™”', fontsize=14)
        ax6.set_xlabel('ì‹œê°„ êµ¬ê°„')
        ax6.set_ylabel('MAE')
        ax6.grid(True, alpha=0.3)
        
        # 7. ë³‘ëª© ì˜ˆì¸¡ í™•ë¥  ë¶„í¬
        ax7 = plt.subplot(3, 3, 7)
        # ë³‘ëª© í´ë˜ìŠ¤(1,2,3)ì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥ ì˜ ìµœëŒ€ê°’
        bottleneck_probs = np.max(y_pred_cls[:, 1:], axis=1) if y_pred_cls.shape[1] > 1 else y_pred_cls[:, 0]
        ax7.hist(bottleneck_probs, bins=50, color='orange', alpha=0.7, edgecolor='black')
        ax7.set_title('ë³‘ëª© ì˜ˆì¸¡ í™•ë¥  ë¶„í¬', fontsize=14)
        ax7.set_xlabel('ë³‘ëª© ì˜ˆì¸¡ í™•ë¥ ')
        ax7.set_ylabel('ë¹ˆë„')
        ax7.axvline(x=0.5, color='red', linestyle='--', label='ì„ê³„ê°’ 0.5')
        ax7.legend()
        
        # 8. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìš”ì•½
        ax8 = plt.subplot(3, 3, 8)
        ax8.axis('off')
        
        summary_text = f"""
        ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ì„±ëŠ¥:
        â€¢ MAE: {regression_metrics['mae']:.2f}
        â€¢ RMSE: {regression_metrics['rmse']:.2f}
        â€¢ RÂ² Score: {regression_metrics['r2']:.3f}
        â€¢ MAPE: {regression_metrics['mape']:.1f}%
        â€¢ 10% ì •í™•ë„: {regression_metrics['acc_10']:.1f}%
        
        ë³‘ëª© ì˜ˆì¸¡ ì„±ëŠ¥:
        â€¢ ì •í™•ë„: {classification_metrics['accuracy']:.1%}
        â€¢ F1 Score: {classification_metrics['weighted_f1']:.1%}
        â€¢ ë³‘ëª© ì¬í˜„ìœ¨: {classification_metrics['bottleneck_recall']:.1%}
        """
        
        ax8.text(0.1, 0.9, summary_text, transform=ax8.transAxes,
                fontsize=12, verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        # 9. ì‹¤ì œ vs ì˜ˆì¸¡ ë³‘ëª© ì‹œì 
        ax9 = plt.subplot(3, 3, 9)
        sample_size = min(500, len(y_true_cls))
        
        # ì‹¤ì œ ë³‘ëª©
        actual_bottleneck = y_true_cls[:sample_size] > 0
        ax9.scatter(np.where(actual_bottleneck)[0], 
                   y_true_reg[:sample_size][actual_bottleneck],
                   color='blue', s=50, alpha=0.6, label='ì‹¤ì œ ë³‘ëª©')
        
        # ì˜ˆì¸¡ ë³‘ëª©
        pred_bottleneck = y_pred_cls_labels[:sample_size] > 0
        ax9.scatter(np.where(pred_bottleneck)[0],
                   y_pred_reg[:sample_size][pred_bottleneck],
                   color='red', s=30, alpha=0.6, label='ì˜ˆì¸¡ ë³‘ëª©')
        
        ax9.plot(y_true_reg[:sample_size], color='gray', alpha=0.3, linewidth=1)
        ax9.set_title('ë³‘ëª© íƒì§€ ê²°ê³¼', fontsize=14)
        ax9.set_xlabel('ì‹œê°„')
        ax9.set_ylabel('ë¬¼ë¥˜ëŸ‰')
        ax9.legend()
        ax9.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        plt.savefig(f'multitask_evaluation_{timestamp}.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def save_evaluation_results(self, regression_metrics, classification_metrics,
                               integrated_score, grade):
        """í‰ê°€ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        results = {
            'evaluation_time': timestamp,
            'integrated_score': integrated_score,
            'grade': grade,
            'regression_metrics': regression_metrics,
            'classification_metrics': {
                k: v.tolist() if isinstance(v, np.ndarray) else v
                for k, v in classification_metrics.items()
            }
        }
        
        # JSON ì €ì¥
        json_path = f'multitask_evaluation_{timestamp}.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=4)
        
        logger.info(f"í‰ê°€ ê²°ê³¼ ì €ì¥: {json_path}")
        
        # í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ì €ì¥
        report_path = f'multitask_evaluation_report_{timestamp}.txt'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("CNN-LSTM Multi-Task ëª¨ë¸ í‰ê°€ ë³´ê³ ì„œ\n")
            f.write(f"í‰ê°€ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*70 + "\n\n")
            
            f.write(f"í†µí•© ì„±ëŠ¥ ì ìˆ˜: {integrated_score:.1f}%\n")
            f.write(f"ì„±ëŠ¥ ë“±ê¸‰: {grade}\n\n")
            
            f.write("ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ì„±ëŠ¥:\n")
            f.write(f"  - MAE: {regression_metrics['mae']:.2f}\n")
            f.write(f"  - MAPE: {regression_metrics['mape']:.1f}%\n")
            f.write(f"  - RÂ² Score: {regression_metrics['r2']:.3f}\n")
            f.write(f"  - 10% ì •í™•ë„: {regression_metrics['acc_10']:.1f}%\n\n")
            
            f.write("ë³‘ëª© ì˜ˆì¸¡ ì„±ëŠ¥:\n")
            f.write(f"  - ì •í™•ë„: {classification_metrics['accuracy']:.1%}\n")
            f.write(f"  - F1 Score: {classification_metrics['weighted_f1']:.1%}\n")
            f.write(f"  - ë³‘ëª© ì¬í˜„ìœ¨: {classification_metrics['bottleneck_recall']:.1%}\n")
        
        logger.info(f"í‰ê°€ ë³´ê³ ì„œ ì €ì¥: {report_path}")
    
    def evaluate(self, data_path='data/0730to31.csv'):
        """ì „ì²´ í‰ê°€ ì‹¤í–‰"""
        try:
            # ëª¨ë¸ ë° ì„¤ì • ë¡œë“œ
            self.load_model_and_config()
            
            # í‰ê°€ ë°ì´í„° ì¤€ë¹„
            X_test, y_true_reg, y_true_cls, original_data, thresholds = self.prepare_evaluation_data(data_path)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            logger.info("\nëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
            predictions = self.model.predict(X_test, verbose=1)
            y_pred_reg = predictions[0].flatten()
            y_pred_cls = predictions[1]
            
            # íšŒê·€ íƒœìŠ¤í¬ í‰ê°€
            regression_metrics = self.evaluate_regression_task(y_true_reg, y_pred_reg)
            
            # ë¶„ë¥˜ íƒœìŠ¤í¬ í‰ê°€
            classification_metrics, class_names = self.evaluate_classification_task(y_true_cls, y_pred_cls)
            
            # í†µí•© ì ìˆ˜ ê³„ì‚°
            integrated_score, grade, reg_score, cls_score = self.calculate_integrated_score(
                regression_metrics, classification_metrics
            )
            
            # ìµœì¢… ê²°ê³¼ ì¶œë ¥
            logger.info("\n" + "="*70)
            logger.info("ì¢…í•© í‰ê°€ ê²°ê³¼")
            logger.info("="*70)
            print(f"\nâ­ í†µí•© ì„±ëŠ¥ ì ìˆ˜: {integrated_score:.1f}%")
            print(f"   - ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ ì ìˆ˜: {reg_score*2:.1f}% (50% ê°€ì¤‘ì¹˜)")
            print(f"   - ë³‘ëª© ì˜ˆì¸¡ ì ìˆ˜: {cls_score*2:.1f}% (50% ê°€ì¤‘ì¹˜)")
            print(f"\nğŸ“Š ì„±ëŠ¥ ë“±ê¸‰: {grade}")
            
            # ë³‘ëª© ì„ê³„ê°’ ì •ë³´
            print(f"\nğŸš¨ ë³‘ëª© íŒì • ì„ê³„ê°’:")
            print(f"   - ì „ì²´ ë¬¼ë¥˜ëŸ‰: {thresholds['total']:.0f}")
            print(f"   - M14A-M10A ê²½ë¡œ: {thresholds['m14a_m10a']:.0f}")
            print(f"   - M14A-M14B ê²½ë¡œ: {thresholds['m14a_m14b']:.0f}")
            print(f"   - M14A-M16 ê²½ë¡œ: {thresholds['m14a_m16']:.0f}")
            
            # ì‹œê°í™”
            logger.info("\nê²°ê³¼ ì‹œê°í™” ìƒì„± ì¤‘...")
            self.visualize_results(
                y_true_reg, y_pred_reg, y_true_cls, y_pred_cls,
                regression_metrics, classification_metrics, class_names
            )
            
            # ê²°ê³¼ ì €ì¥
            self.save_evaluation_results(
                regression_metrics, classification_metrics,
                integrated_score, grade
            )
            
            logger.info("\n" + "="*70)
            logger.info("í‰ê°€ ì™„ë£Œ!")
            logger.info("="*70)
            
            return {
                'integrated_score': integrated_score,
                'grade': grade,
                'regression_metrics': regression_metrics,
                'classification_metrics': classification_metrics
            }
            
        except Exception as e:
            logger.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

# ===================================
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ===================================

def main(data_path='data/0730to31.csv'):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "="*70)
    print("CNN-LSTM Multi-Task ëª¨ë¸ í‰ê°€ ì‹œìŠ¤í…œ")
    print("="*70)
    
    # í‰ê°€ê¸° ì´ˆê¸°í™”
    evaluator = MultiTaskModelEvaluator()
    
    # ë°ì´í„° íŒŒì¼ í™•ì¸
    if not os.path.exists(data_path):
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        return None
    
    # í‰ê°€ ì‹¤í–‰
    results = evaluator.evaluate(data_path)
    
    if results:
        print("\nâœ… í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nìƒì„±ëœ íŒŒì¼:")
        print("  - multitask_evaluation_YYYYMMDD_HHMMSS.png (ì‹œê°í™”)")
        print("  - multitask_evaluation_YYYYMMDD_HHMMSS.json (ê²°ê³¼ ë°ì´í„°)")
        print("  - multitask_evaluation_report_YYYYMMDD_HHMMSS.txt (ë³´ê³ ì„œ)")
        
        return results
    else:
        print("\nâŒ í‰ê°€ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print("\ní™•ì¸ ì‚¬í•­:")
        print("  1. model/cnn_lstm_multitask_final.keras íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸")
        print("  2. scaler/multitask_scaler.pkl íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸")
        print("  3. ë°ì´í„° íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        return None

# ===================================
# 5. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
# ===================================

if __name__ == "__main__":
    import sys
    
    # ëª…ë ¹ì¤„ ì¸ìë¡œ ë°ì´í„° ê²½ë¡œ ë°›ê¸°
    if len(sys.argv) > 1:
        data_path = sys.argv[1]
        print(f"ì‚¬ìš©ì ì§€ì • ë°ì´í„°: {data_path}")
        main(data_path)
    else:
        # ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
        main('data/0730to31.csv')