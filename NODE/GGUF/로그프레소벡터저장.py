#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ì‚¬ìš©ë²• ì „ìš© ë²¡í„° ì €ì¥ ì‹œìŠ¤í…œ
"""

import os
from typing import List
from datetime import datetime
import time
import json

# LangChain ê´€ë ¨
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

class LogpressoQueryVectorBuilder:
    """ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ì‚¬ìš©ë²• ì „ìš© ë²¡í„° ì €ì¥ì†Œ"""
    
    def __init__(self, embedding_model_path: str = "./models/paraphrase-multilingual-MiniLM-L12-v2"):
        print("ğŸ”„ ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”...")
        
        try:
            import torch
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            print(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {device}")
        except ImportError:
            device = 'cpu'
        
        self.embeddings = HuggingFaceEmbeddings(
            model_name=embedding_model_path,
            model_kwargs={'device': device, 'trust_remote_code': True},
            encode_kwargs={'normalize_embeddings': True}
        )
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        
    def get_logpresso_query_docs(self) -> str:
        """ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ì‚¬ìš©ë²• ë¬¸ì„œ"""
        return """# ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ì‚¬ìš©ë²•

## ê¸°ë³¸ ì¿¼ë¦¬ êµ¬ì¡°
ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ëŠ” íŒŒì´í”„(|)ë¡œ ì—°ê²°ëœ ëª…ë ¹ì–´ë“¤ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
ë°ì´í„° ì†ŒìŠ¤ â†’ ë³€í™˜ â†’ í•„í„°ë§ â†’ ì¶œë ¥ ìˆœì„œë¡œ ì§„í–‰ë©ë‹ˆë‹¤.

## ë°ì´í„° ì†ŒìŠ¤ ëª…ë ¹ì–´

### table ëª…ë ¹ì–´
í…Œì´ë¸”ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
```
table í…Œì´ë¸”ëª…
table logs
table access_log
```

### csvfile ëª…ë ¹ì–´
CSV íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.
```
csvfile /path/to/file.csv
csvfile tab=t /path/to/file.tsv  // TSV íŒŒì¼ìš© (íƒ­ êµ¬ë¶„ì)
csvfile encoding=utf-8 /path/to/korean.csv  // ì¸ì½”ë”© ì§€ì •
```

### jsonfile ëª…ë ¹ì–´
JSON íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.
```
jsonfile /path/to/file.json
jsonfile overlay=t /path/to/file.json  // ì›ë³¸ ë¼ì¸ë„ í•¨ê»˜ ì¶œë ¥
```

### logger ëª…ë ¹ì–´
ì‹¤ì‹œê°„ ë¡œê·¸ ìˆ˜ì§‘ê¸° ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
```
logger ë¡œê±°ëª…
logger window=1h syslog_logger  // 1ì‹œê°„ ë™ì•ˆì˜ ë°ì´í„°
logger window=1d web_logger     // 1ì¼ ë™ì•ˆì˜ ë°ì´í„°
```

## ë°ì´í„° ë³€í™˜ ëª…ë ¹ì–´

### parse ëª…ë ¹ì–´
ë¡œê·¸ë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ í•„ë“œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
```
table raw_log | parse apache_log
table syslog | parse syslog
table iis_log | parse iis
```

### eval ëª…ë ¹ì–´
ìƒˆë¡œìš´ í•„ë“œë¥¼ ìƒì„±í•˜ê±°ë‚˜ ê¸°ì¡´ í•„ë“œë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.
```
table logs | eval status_group = if(status < 400, "success", "error")
table logs | eval timestamp = dateformat(_time, "yyyy-MM-dd HH:mm:ss")
table logs | eval size_mb = bytes / 1024 / 1024
```

### rename ëª…ë ¹ì–´
í•„ë“œëª…ì„ ë³€ê²½í•©ë‹ˆë‹¤.
```
table logs | rename src_ip as source_ip, dst_ip as dest_ip
table logs | rename "old name" as new_name
```

### fields ëª…ë ¹ì–´
íŠ¹ì • í•„ë“œë§Œ ì„ íƒí•˜ê±°ë‚˜ ì œì™¸í•©ë‹ˆë‹¤.
```
table logs | fields _time, src_ip, dst_ip, status
table logs | fields - _raw, _id  // _raw, _id í•„ë“œ ì œì™¸
```

## í•„í„°ë§ ëª…ë ¹ì–´

### where ëª…ë ¹ì–´
ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
```
table logs | where status >= 400
table logs | where src_ip == "192.168.1.100"
table logs | where method == "POST" and status != 200
table logs | where len(url) > 100
```

### search ëª…ë ¹ì–´
í…ìŠ¤íŠ¸ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
```
table logs | search "error"
table logs | search src_ip="192.168.1.*"
table logs | search NOT status=200
```

### limit ëª…ë ¹ì–´
ê²°ê³¼ ê°œìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.
```
table logs | limit 100
table logs | sort _time desc | limit 10  // ìµœì‹  10ê±´
```

### head / tail ëª…ë ¹ì–´
ì²˜ìŒ ë˜ëŠ” ë§ˆì§€ë§‰ Nê°œ ë ˆì½”ë“œë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.
```
table logs | head 50
table logs | tail 20
```

## í†µê³„ ë° ì§‘ê³„ ëª…ë ¹ì–´

### stats ëª…ë ¹ì–´
í†µê³„ ì •ë³´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
```
table logs | stats count
table logs | stats count by status
table logs | stats avg(response_time), max(bytes) by method
table logs | stats dc(src_ip) as unique_ips  // distinct count
table logs | stats sum(bytes) as total_bytes by date_trunc("1h", _time)
```

#### í†µê³„ í•¨ìˆ˜ë“¤
- count: ê°œìˆ˜
- sum: í•©ê³„
- avg: í‰ê· 
- min: ìµœì†Ÿê°’
- max: ìµœëŒ“ê°’
- dc: ìœ ë‹ˆí¬ ê°œìˆ˜ (distinct count)
- stdev: í‘œì¤€í¸ì°¨
- var: ë¶„ì‚°
- first: ì²« ë²ˆì§¸ ê°’
- last: ë§ˆì§€ë§‰ ê°’

### timechart ëª…ë ¹ì–´
ì‹œê°„ëŒ€ë³„ í†µê³„ ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
```
table logs | timechart span=1h count by status
table logs | timechart span=5m avg(response_time)
table logs | timechart span=1d sum(bytes) as daily_traffic
```

### sort ëª…ë ¹ì–´
ë°ì´í„°ë¥¼ ì •ë ¬í•©ë‹ˆë‹¤.
```
table logs | sort _time desc
table logs | sort status asc, _time desc
table logs | stats count by src_ip | sort count desc
```

## ì‹œê°„ ê´€ë ¨ í•¨ìˆ˜

### ì‹œê°„ í•„í„°ë§
```
table logs | where _time >= "2025-01-01 00:00:00"
table logs | where _time between "2025-01-01" and "2025-01-31"
```

### ë‚ ì§œ í•¨ìˆ˜ë“¤
```
// í˜„ì¬ ì‹œê°„
table logs | eval now_time = now()

// ë‚ ì§œ í¬ë§· ë³€ê²½
table logs | eval formatted_time = dateformat(_time, "yyyy-MM-dd")

// ë‚ ì§œ íŒŒì‹±
table logs | eval parsed_time = dateparse("dd/MMM/yyyy:HH:mm:ss", log_time)

// ë‚ ì§œ ìë¥´ê¸° (ì‹œê°„ ë‹¨ìœ„ë¡œ ê·¸ë£¹í•‘ìš©)
table logs | eval hour_group = date_trunc("1h", _time)
```

## ë¬¸ìì—´ ì²˜ë¦¬ í•¨ìˆ˜

### ë¬¸ìì—´ í•¨ìˆ˜ë“¤
```
// ê¸¸ì´
table logs | eval url_length = len(url)

// ë¶€ë¶„ ë¬¸ìì—´
table logs | eval domain = substr(url, 8, 20)

// ëŒ€ì†Œë¬¸ì ë³€í™˜
table logs | eval upper_method = upper(method)
table logs | eval lower_url = lower(url)

// ë¬¸ìì—´ ë¶„í• 
table logs | eval url_parts = split(url, "/")

// ì •ê·œì‹ ë§¤ì¹­
table logs | eval ip_match = match(src_ip, "192\.168\.\d+\.\d+")

// ë¬¸ìì—´ ì¹˜í™˜
table logs | eval clean_url = replace(url, "%20", " ")
```

## ì¡°ê±´ë¬¸ê³¼ ë…¼ë¦¬ ì—°ì‚°

### if í•¨ìˆ˜
```
table logs | eval status_category = if(status < 300, "success", if(status < 400, "redirect", "error"))
```

### case í•¨ìˆ˜
```
table logs | eval status_type = case(
    status < 300, "Success",
    status < 400, "Redirect", 
    status < 500, "Client Error",
    "Server Error"
)
```

### ë…¼ë¦¬ ì—°ì‚°ì
```
table logs | where status == 200 and method == "GET"
table logs | where status == 404 or status == 500
table logs | where not (method == "OPTIONS")
```

## ë°ì´í„° ì¶œë ¥ ë° ì €ì¥

### import ëª…ë ¹ì–´
ë°ì´í„°ë¥¼ í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.
```
table source_logs | parse apache_log | import processed_logs
csvfile /path/data.csv | import csv_table
```

### outputcsv ëª…ë ¹ì–´
CSV íŒŒì¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
```
table logs | stats count by status | outputcsv /path/result.csv
```

## ê³ ê¸‰ ì¿¼ë¦¬ ì˜ˆì‹œ

### ì›¹ ë¡œê·¸ ë¶„ì„
```sql
// ì‹œê°„ëŒ€ë³„ HTTP ìƒíƒœì½”ë“œ ë¶„í¬
table web_logs 
| parse apache_log 
| timechart span=1h count by status

// ìƒìœ„ 10ê°œ IPë³„ ìš”ì²­ ìˆ˜
table web_logs 
| parse apache_log 
| stats count by src_ip 
| sort count desc 
| limit 10

// 404 ì—ëŸ¬ í˜ì´ì§€ ë¶„ì„
table web_logs 
| parse apache_log 
| where status == 404 
| stats count by url 
| sort count desc
```

### ì‹œìŠ¤í…œ ë¡œê·¸ ë¶„ì„
```sql
// ì—ëŸ¬ ë¡œê·¸ ì¶”ì¶œ
table system_logs 
| search "ERROR" or "FATAL" 
| fields _time, host, message

// ì‹œê°„ëŒ€ë³„ ë¡œê·¸ ë ˆë²¨ ë¶„í¬
table system_logs 
| parse syslog 
| timechart span=1h count by level
```

### ë³´ì•ˆ ë¡œê·¸ ë¶„ì„
```sql
// ì‹¤íŒ¨í•œ ë¡œê·¸ì¸ ì‹œë„ ë¶„ì„
table auth_logs 
| where event_type == "login_failed" 
| stats count by src_ip, user 
| where count > 10 
| sort count desc

// ë¹„ì •ìƒ ì ‘ê·¼ íŒ¨í„´ íƒì§€
table access_logs 
| parse apache_log 
| where status == 401 or status == 403 
| stats count by src_ip, date_trunc("1h", _time) as hour 
| where count > 100
```

## ì¿¼ë¦¬ ìµœì í™” íŒ

### ì„±ëŠ¥ í–¥ìƒ ë°©ë²•
1. where ì¡°ê±´ì„ ê°€ëŠ¥í•œ ì•ìª½ì— ë°°ì¹˜
2. ì‹œê°„ ë²”ìœ„ë¥¼ ëª…ì‹œí•˜ì—¬ ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œ
3. í•„ìš”í•œ í•„ë“œë§Œ fields ëª…ë ¹ìœ¼ë¡œ ì„ íƒ
4. ì¸ë±ìŠ¤ê°€ ìˆëŠ” í•„ë“œ í™œìš©

### ì¢‹ì€ ì¿¼ë¦¬ ì˜ˆì‹œ
```sql
// ì¢‹ì€ ì˜ˆ: ì¡°ê±´ì„ ë¨¼ì € ì ìš©
table logs 
| where _time >= "2025-01-01" and status >= 400 
| parse apache_log 
| fields _time, src_ip, url, status 
| stats count by src_ip

// ë‚˜ìœ ì˜ˆ: ëª¨ë“  ë°ì´í„° íŒŒì‹± í›„ í•„í„°ë§
table logs 
| parse apache_log 
| stats count by src_ip 
| where _time >= "2025-01-01" and status >= 400
```

## ìì£¼ ì‚¬ìš©í•˜ëŠ” ì¿¼ë¦¬ íŒ¨í„´

### ê¸°ë³¸ ë¡œê·¸ ì¡°íšŒ
```sql
table logs | limit 100
table logs | where _time >= "2025-01-01" | limit 100
```

### ì—ëŸ¬ ë¡œê·¸ ì°¾ê¸°
```sql
table logs | search "error" or "exception" or "fail"
table web_logs | parse apache_log | where status >= 400
```

### í†µê³„ ë¶„ì„
```sql
table logs | stats count by host, level
table logs | timechart span=1h count
```

### ìƒìœ„ Nê°œ ë¶„ì„
```sql
table logs | stats count by src_ip | sort count desc | limit 10
```

ì´ ë¬¸ì„œëŠ” ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ì˜ í•µì‹¬ ì‚¬ìš©ë²•ì„ ë‹¤ë£¨ë©°, 
ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒ¨í„´ë“¤ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤."""

    def build_vector_store(self, output_dir: str = "./vector_stores"):
        """ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ë¬¸ì„œ ë²¡í„° ì €ì¥ì†Œ ìƒì„±"""
        print("\nğŸ”„ ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì‹œì‘...")
        
        # 1. ë¬¸ì„œ ë‚´ìš© ìƒì„±
        docs_content = self.get_logpresso_query_docs()
        
        # 2. ì„¹ì…˜ë³„ë¡œ ë¶„í• í•˜ì—¬ Document ê°ì²´ ìƒì„±
        sections = docs_content.split('\n## ')
        documents = []
        
        for i, section in enumerate(sections):
            if i == 0:
                title = "ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ì‚¬ìš©ë²•"
                content = section
            else:
                lines = section.split('\n', 1)
                title = lines[0].strip()
                content = f"## {section}"
            
            doc = Document(
                page_content=content,
                metadata={
                    "source": "ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ë¬¸ì„œ",
                    "section": title,
                    "section_index": i
                }
            )
            documents.append(doc)
        
        print(f"ğŸ“„ ì´ {len(documents)}ê°œ ì„¹ì…˜ ìƒì„±")
        
        # 3. í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=100,
            separators=["\n\n", "\n### ", "\n```", "\n", "```", ". ", " "],
            length_function=len
        )
        
        split_docs = text_splitter.split_documents(documents)
        print(f"âœ‚ï¸  ì´ {len(split_docs)}ê°œ ì²­í¬ ìƒì„±")
        
        # 4. ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        print("ğŸ” ë²¡í„° ì„ë² ë”© ìƒì„± ì¤‘...")
        vector_store = FAISS.from_documents(split_docs, self.embeddings)
        
        # 5. ì €ì¥
        os.makedirs(output_dir, exist_ok=True)
        save_path = os.path.join(output_dir, "logpresso_query")
        vector_store.save_local(save_path)
        
        # 6. ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_documents": len(documents),
            "total_chunks": len(split_docs),
            "doc_type": "logpresso_query_docs"
        }
        
        with open(os.path.join(output_dir, "logpresso_metadata.json"), "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ: {save_path}")
        print(f"ğŸ“Š ë©”íƒ€ë°ì´í„° ì €ì¥: {os.path.join(output_dir, 'logpresso_metadata.json')}")
        return save_path

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ë²¡í„° ì €ì¥ì†Œ ìƒì„±")
    parser.add_argument("--output-dir", default="./vector_stores", help="ë²¡í„° ì €ì¥ì†Œ ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--embedding-model", default="./models/paraphrase-multilingual-MiniLM-L12-v2", help="ì„ë² ë”© ëª¨ë¸ ê²½ë¡œ")
    
    args = parser.parse_args()
    
    # ë²¡í„° ì €ì¥ì†Œ ë¹Œë” ìƒì„±
    builder = LogpressoQueryVectorBuilder(embedding_model_path=args.embedding_model)
    
    # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    save_path = builder.build_vector_store(args.output_dir)
    
    print(f"\nğŸ‰ ì™„ë£Œ! ë²¡í„° ì €ì¥ì†Œ ìœ„ì¹˜: {save_path}")
    print("\nì‚¬ìš©ë²•:")
    print("1. LLM ì„œë¹„ìŠ¤ì—ì„œ ì´ ë²¡í„° ì €ì¥ì†Œë¥¼ ë¡œë“œí•˜ì—¬ ì‚¬ìš©")
    print("2. ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì œê³µ")

if __name__ == "__main__":
    main()