#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ë¡œê·¸í”„ë ˆì†Œ LLM ì„œë¹„ìŠ¤ (ëª¨ë¸ë§Œ)
Qwen2.5 + ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤
"""

import os
import json
from typing import List, Dict, Any, Optional

from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.llms.base import LLM
from langchain.callbacks.manager import CallbackManagerForLLMRun
from llama_cpp import Llama

class QwenLLM(LLM):
    """Qwen2.5 LLM ë˜í¼"""
    
    llama_model: Optional[Any] = None
    model_path: str = ""
    
    def __init__(self, model_path: str, **kwargs):
        super().__init__(**kwargs)
        self.model_path = model_path
        self.llama_model = Llama(
            model_path=model_path,
            n_gpu_layers=0,  # CPU ì‚¬ìš©
            n_ctx=4096,
            n_threads=8,
            verbose=False
        )
    
    @property
    def _llm_type(self) -> str:
        return "qwen2.5"
    
    def _call(
        self, 
        prompt: str, 
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None, 
        **kwargs: Any
    ) -> str:
        """LLM í˜¸ì¶œ"""
        response = self.llama_model(
            prompt,
            max_tokens=512,
            temperature=0.7,
            stop=stop if stop else ["Human:", "\n\n"],
            echo=False
        )
        return response['choices'][0]['text'].strip()

class LogpressoLLMService:
    """ë¡œê·¸í”„ë ˆì†Œ LLM ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    def __init__(self, llm_path: str, embedding_path: str, vector_store_path: str):
        # LLM ë¡œë“œ
        print("ğŸ”„ LLM ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.llm = QwenLLM(model_path=llm_path)
        print("âœ… LLM ë¡œë”© ì™„ë£Œ!")
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        print("ğŸ”„ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.embeddings = HuggingFaceEmbeddings(
            model_name=embedding_path,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        
        # ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
        print("ğŸ”„ ë²¡í„° ì €ì¥ì†Œ ë¡œë”© ì¤‘...")
        self.vector_store = FAISS.load_local(
            vector_store_path,
            self.embeddings,
            allow_dangerous_deserialization=True
        )
        print("âœ… ë²¡í„° ì €ì¥ì†Œ ë¡œë”© ì™„ë£Œ!")
        
        # QA ì²´ì¸ ì„¤ì •
        self._setup_qa_chain()
    
    def _setup_qa_chain(self):
        """QA ì²´ì¸ ì„¤ì •"""
        prompt_template = """ë‹¤ìŒì€ ë¡œê·¸í”„ë ˆì†Œ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤:

{context}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— í•œê¸€ë¡œ ìì„¸íˆ ë‹µë³€í•´ì£¼ì„¸ìš”:

ì§ˆë¬¸: {question}

ë‹µë³€: """
        
        prompt = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )
        
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vector_store.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 5}
            ),
            chain_type_kwargs={"prompt": prompt},
            return_source_documents=True
        )
    
    def search(self, query: str) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            result = self.qa_chain({"query": query})
            
            sources = []
            for doc in result.get("source_documents", []):
                sources.append({
                    "content": doc.page_content[:200] + "...",
                    "metadata": doc.metadata
                })
            
            return {
                "answer": result["result"],
                "sources": sources
            }
        except Exception as e:
            return {
                "answer": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                "sources": []
            }

def main():
    # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    MODEL_DIR = "./models"
    VECTOR_DIR = "./vector_stores"
    
    llm_path = os.path.join(MODEL_DIR, "Qwen2.5-14B-Instruct-Q6_K.gguf")
    embedding_path = os.path.join(MODEL_DIR, "paraphrase-multilingual-MiniLM-L12-v2")
    vector_path = os.path.join(VECTOR_DIR, "logpresso_query")
    
    # ê²½ë¡œ í™•ì¸
    if not os.path.exists(llm_path):
        print(f"âŒ LLM ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {llm_path}")
        return
    
    if not os.path.exists(vector_path):
        print(f"âŒ ë²¡í„° ì €ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {vector_path}")
        print("ë¨¼ì € ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    # ì„œë¹„ìŠ¤ ì‹œì‘
    print("ğŸš€ ë¡œê·¸í”„ë ˆì†Œ LLM ì„œë¹„ìŠ¤ ì‹œì‘...")
    
    try:
        service = LogpressoLLMService(
            llm_path=llm_path,
            embedding_path=embedding_path,
            vector_store_path=vector_path
        )
    except Exception as e:
        print(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    print("\nâœ… ì¤€ë¹„ ì™„ë£Œ! ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    print("\nğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸:")
    print("- ë¡œê·¸í”„ë ˆì†Œ ì¿¼ë¦¬ ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”")
    print("- table ëª…ë ¹ì–´ëŠ” ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?")
    print("- CSV íŒŒì¼ì„ ì–´ë–»ê²Œ ì½ì–´ì˜¤ë‚˜ìš”?")
    print("- stats ëª…ë ¹ì–´ë¡œ í†µê³„ë¥¼ ë‚´ëŠ” ë°©ë²•ì€?")
    print()
    
    # ëŒ€í™” ì‹œì‘
    while True:
        query = input("â“ ì§ˆë¬¸ (ì¢…ë£Œ: quit): ").strip()
        
        if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
            print("ğŸ‘‹ ì„œë¹„ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        if not query:
            continue
        
        try:
            print("\nğŸ” ê²€ìƒ‰ ì¤‘...")
            result = service.search(query)
            
            print(f"\nğŸ’¬ ë‹µë³€:")
            print(result['answer'])
            
            if result['sources']:
                print(f"\nğŸ“š ì°¸ì¡° ì†ŒìŠ¤ ({len(result['sources'])}ê°œ):")
                for idx, source in enumerate(result['sources'][:3], 1):
                    print(f"  {idx}. {source['content'][:100]}...")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        print("\n" + "="*60 + "\n")

if __name__ == "__main__":
    main()