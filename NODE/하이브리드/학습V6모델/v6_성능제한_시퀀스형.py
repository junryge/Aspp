"""
ensemble_fixed_v6.py - ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„± (ë¡œë”© ì˜¤ë¥˜ ìˆ˜ì •)
ëª¨ë¸ ë¡œë“œ ì‹œ ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
TensorFlow 2.15.0
"""

import tensorflow as tf
import numpy as np
import json
import os
import gc
import warnings
import matplotlib.pyplot as plt
warnings.filterwarnings('ignore')

print("="*60)
print("ğŸ¯ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„± - ë¡œë”© ì˜¤ë¥˜ ìˆ˜ì • ë²„ì „")
print(f"ğŸ“¦ TensorFlow ë²„ì „: {tf.__version__}")
print("="*60)

# GPU ë©”ëª¨ë¦¬ ì„¤ì •
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

# ============================================
# 1. ì„¤ì •
# ============================================
class Config:
    # ë°ì´í„° íŒŒì¼
    SEQUENCE_FILE = './sequences_v6.npz'
    
    # ëª¨ë¸ ê²½ë¡œ
    MODEL_DIR = './models_v6/'
    
    # M14 ì„ê³„ê°’
    M14B_THRESHOLDS = {
        1400: 320,
        1500: 400,
        1600: 450,
        1700: 500
    }
    
    RATIO_THRESHOLDS = {
        1400: 4,
        1500: 5,
        1600: 6,
        1700: 7
    }
    
    # ì•™ìƒë¸” í•™ìŠµ ì„¤ì •
    BATCH_SIZE = 16
    ENSEMBLE_EPOCHS = 30
    LEARNING_RATE = 0.0005

# ============================================
# 2. ì»¤ìŠ¤í…€ ê°ì²´ ì •ì˜ (ë¡œë“œìš©)
# ============================================
class WeightedLoss(tf.keras.losses.Loss):
    """ë ˆë²¨ë³„ ê°€ì¤‘ ì†ì‹¤ í•¨ìˆ˜"""
    def __init__(self):
        super().__init__()
        
    def call(self, y_true, y_pred):
        # ë ˆë²¨ë³„ ê°€ì¤‘ì¹˜
        weights = tf.where(y_true < 1400, 1.0,
                 tf.where(y_true < 1500, 3.0,
                 tf.where(y_true < 1600, 5.0,
                 tf.where(y_true < 1700, 8.0, 10.0))))
        
        # ê°€ì¤‘ MAE
        mae = tf.abs(y_true - y_pred)
        weighted_mae = mae * weights
        
        return tf.reduce_mean(weighted_mae)

class M14RuleCorrection(tf.keras.layers.Layer):
    """M14 ê·œì¹™ ê¸°ë°˜ ë³´ì • ë ˆì´ì–´"""
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
    def call(self, inputs):
        pred, m14_features = inputs
        
        # M14 íŠ¹ì§• ë¶„í•´
        m14b = m14_features[:, 0:1]
        m10a = m14_features[:, 1:2]
        ratio = m14_features[:, 3:4] if m14_features.shape[1] > 3 else tf.ones_like(m14b)
        
        # ê·œì¹™ ê¸°ë°˜ ë³´ì •
        condition_1700 = tf.logical_and(
            tf.greater_equal(m14b, Config.M14B_THRESHOLDS[1700]),
            tf.greater_equal(ratio, Config.RATIO_THRESHOLDS[1700])
        )
        pred = tf.where(condition_1700, tf.maximum(pred, 1700), pred)
        
        condition_1600 = tf.logical_and(
            tf.greater_equal(m14b, Config.M14B_THRESHOLDS[1600]),
            tf.greater_equal(ratio, Config.RATIO_THRESHOLDS[1600])
        )
        pred = tf.where(condition_1600, tf.maximum(pred, 1600), pred)
        
        condition_1500 = tf.logical_and(
            tf.greater_equal(m14b, Config.M14B_THRESHOLDS[1500]),
            tf.greater_equal(ratio, Config.RATIO_THRESHOLDS[1500])
        )
        pred = tf.where(condition_1500, tf.maximum(pred, 1500), pred)
        
        condition_1400 = tf.greater_equal(m14b, Config.M14B_THRESHOLDS[1400])
        pred = tf.where(condition_1400, tf.maximum(pred, 1400), pred)
        
        condition_inverse = tf.logical_and(
            tf.less(m10a, 70),
            tf.greater_equal(m14b, 250)
        )
        pred = tf.where(condition_inverse, pred * 1.08, pred)
        
        return pred
    
    def get_config(self):
        return super().get_config()

# ============================================
# 3. ì•ˆì „í•œ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
# ============================================
def safe_load_model(model_path, model_name):
    """ì•ˆì „í•˜ê²Œ ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ë°©ë²• 1: ì»¤ìŠ¤í…€ ê°ì²´ì™€ í•¨ê»˜ ë¡œë“œ
        custom_objects = {
            'WeightedLoss': WeightedLoss,
            'M14RuleCorrection': M14RuleCorrection
        }
        
        model = tf.keras.models.load_model(
            model_path, 
            custom_objects=custom_objects,
            compile=False  # ì»´íŒŒì¼ ê±´ë„ˆë›°ê¸°
        )
        print(f"  âœ… {model_name} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ë°©ë²• 1)")
        return model
        
    except Exception as e1:
        print(f"  âš ï¸ {model_name} ë¡œë“œ ë°©ë²• 1 ì‹¤íŒ¨: {str(e1)[:50]}...")
        
        try:
            # ë°©ë²• 2: weightsë§Œ ë¡œë“œ
            print(f"  ğŸ”„ {model_name} weights ë¡œë“œ ì‹œë„...")
            
            # ëª¨ë¸ êµ¬ì¡°ë¥¼ ì•Œì•„ì•¼ í•¨ - ê°„ë‹¨í•œ ì¶”ì •
            if 'lstm' in model_name.lower():
                model = create_simple_lstm_model()
            elif 'gru' in model_name.lower():
                model = create_simple_gru_model()
            elif 'cnn' in model_name.lower():
                model = create_simple_cnn_model()
            elif 'spike' in model_name.lower():
                model = create_spike_model()
            else:
                raise ValueError(f"Unknown model type: {model_name}")
            
            # weights íŒŒì¼ ê²½ë¡œ
            weights_path = model_path.replace('.h5', '_weights.h5')
            if os.path.exists(weights_path):
                model.load_weights(weights_path)
                print(f"  âœ… {model_name} weights ë¡œë“œ ì„±ê³µ")
                return model
            else:
                print(f"  âŒ {model_name} weights íŒŒì¼ë„ ì—†ìŒ")
                return None
                
        except Exception as e2:
            print(f"  âŒ {model_name} ë¡œë“œ ì™„ì „ ì‹¤íŒ¨: {str(e2)[:50]}...")
            return None

# ============================================
# 4. ê°„ë‹¨í•œ ëª¨ë¸ êµ¬ì¡° ì •ì˜ (weights ë¡œë“œìš©)
# ============================================
def create_simple_lstm_model(input_shape=(100, 47)):
    """LSTM ëª¨ë¸ êµ¬ì¡°"""
    model = tf.keras.Sequential([
        tf.keras.layers.LSTM(128, return_sequences=True, input_shape=input_shape),
        tf.keras.layers.LSTM(128, return_sequences=True),
        tf.keras.layers.LSTM(64),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(1)
    ], name='LSTM_Model')
    return model

def create_simple_gru_model(input_shape=(100, 47)):
    """GRU ëª¨ë¸ êµ¬ì¡°"""
    model = tf.keras.Sequential([
        tf.keras.layers.GRU(128, return_sequences=True, input_shape=input_shape),
        tf.keras.layers.GRU(128, return_sequences=True),
        tf.keras.layers.GRU(64),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(1)
    ], name='GRU_Model')
    return model

def create_simple_cnn_model(input_shape=(100, 47)):
    """CNN-LSTM ëª¨ë¸ êµ¬ì¡°"""
    inputs = tf.keras.Input(shape=input_shape)
    
    conv1 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(inputs)
    conv2 = tf.keras.layers.Conv1D(64, 5, activation='relu', padding='same')(inputs)
    conv3 = tf.keras.layers.Conv1D(64, 7, activation='relu', padding='same')(inputs)
    
    concat = tf.keras.layers.Concatenate()([conv1, conv2, conv3])
    norm = tf.keras.layers.BatchNormalization()(concat)
    
    lstm = tf.keras.layers.LSTM(128, return_sequences=True)(norm)
    lstm2 = tf.keras.layers.LSTM(64)(lstm)
    
    dense = tf.keras.layers.Dense(128, activation='relu')(lstm2)
    dropout = tf.keras.layers.Dropout(0.3)(dense)
    output = tf.keras.layers.Dense(1)(dropout)
    
    model = tf.keras.Model(inputs=inputs, outputs=output, name='CNN_LSTM_Model')
    return model

def create_spike_model(input_shape=(100, 47)):
    """Spike Detector ëª¨ë¸ êµ¬ì¡°"""
    inputs = tf.keras.Input(shape=input_shape)
    
    conv1 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(inputs)
    conv2 = tf.keras.layers.Conv1D(64, 5, activation='relu', padding='same')(inputs)
    conv3 = tf.keras.layers.Conv1D(64, 7, activation='relu', padding='same')(inputs)
    
    concat = tf.keras.layers.Concatenate()([conv1, conv2, conv3])
    norm = tf.keras.layers.BatchNormalization()(concat)
    
    # Attention ëŒ€ì‹  ê°„ë‹¨í•œ ì²˜ë¦¬
    lstm = tf.keras.layers.Bidirectional(
        tf.keras.layers.LSTM(128, return_sequences=True)
    )(norm)
    
    pooled = tf.keras.layers.GlobalAveragePooling1D()(lstm)
    
    dense1 = tf.keras.layers.Dense(256, activation='relu')(pooled)
    dropout1 = tf.keras.layers.Dropout(0.3)(dense1)
    dense2 = tf.keras.layers.Dense(128, activation='relu')(dropout1)
    dropout2 = tf.keras.layers.Dropout(0.2)(dense2)
    
    regression_output = tf.keras.layers.Dense(1, name='spike_value')(dropout2)
    classification_output = tf.keras.layers.Dense(1, activation='sigmoid', name='spike_prob')(dropout2)
    
    model = tf.keras.Model(
        inputs=inputs,
        outputs=[regression_output, classification_output],
        name='Spike_Detector'
    )
    return model

# ============================================
# 5. ë°ì´í„° ë¡œë“œ
# ============================================
print("\nğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")

# ì „ì²´ ë°ì´í„°ê°€ ì•„ë‹Œ ê²€ì¦ìš© ì¼ë¶€ë§Œ ë¡œë“œ
data = np.load(Config.SEQUENCE_FILE)
X_val = data['X'][-10000:].astype(np.float32)
y_val = data['y'][-10000:].astype(np.float32)
m14_val = data['m14_features'][-10000:].astype(np.float32)

print(f"  ê²€ì¦ ë°ì´í„° shape: {X_val.shape}")
print(f"  1400+ ë¹„ìœ¨: {(y_val >= 1400).mean():.1%}")

# ============================================
# 6. ëª¨ë¸ ë¡œë“œ (ìˆ˜ì •ëœ ë°©ì‹)
# ============================================
print("\nğŸ“¥ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì¤‘...")

models = {}

# ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
model_files = {
    'lstm': 'lstm_model.h5',
    'gru': 'gru_model.h5',
    'cnn_lstm': 'cnn_lstm_model.h5',
    'spike': 'spike_model.h5'
}

# ê° ëª¨ë¸ ë¡œë“œ ì‹œë„
for model_name, file_name in model_files.items():
    model_path = os.path.join(Config.MODEL_DIR, file_name)
    
    if os.path.exists(model_path):
        model = safe_load_model(model_path, model_name.upper())
        if model is not None:
            models[model_name] = model
    else:
        print(f"  âš ï¸ {model_name.upper()} ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")

print(f"\nğŸ’¡ ë¡œë“œëœ ëª¨ë¸ ìˆ˜: {len(models)}ê°œ")
print(f"  ë¡œë“œëœ ëª¨ë¸: {list(models.keys())}")

if len(models) == 0:
    print("\nâŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    print("ğŸ’¡ í•´ê²° ë°©ë²•:")
    print("  1. ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸: ./models_v6/")
    print("  2. ëª¨ë¸ íŒŒì¼ëª… í™•ì¸: lstm_model.h5, gru_model.h5 ë“±")
    print("  3. ê°œë³„ ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµí•´ì£¼ì„¸ìš”.")
    exit(1)

# ============================================
# 7. ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±
# ============================================
print("\nğŸ”§ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„± ì¤‘...")

# ì…ë ¥ ì •ì˜
input_shape = X_val.shape[1:]
time_series_input = tf.keras.Input(shape=input_shape, name='ensemble_input')
m14_input = tf.keras.Input(shape=(4,), name='m14_features')

# ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ìˆ˜ì§‘
predictions = []
model_names = []

# ê° ëª¨ë¸ ì˜ˆì¸¡ê°’ ìˆ˜ì§‘
for name, model in models.items():
    try:
        if name == 'spike':
            outputs = model(time_series_input)
            if isinstance(outputs, list):
                pred = outputs[0]
                spike_prob = outputs[1]
            else:
                pred = outputs
                spike_prob = None
        else:
            pred = model(time_series_input)
            spike_prob = None
            
        predictions.append(pred)
        model_names.append(name)
        print(f"  âœ… {name} ì˜ˆì¸¡ ë ˆì´ì–´ ì¶”ê°€")
        
    except Exception as e:
        print(f"  âŒ {name} ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)[:50]}...")

print(f"\n  ì•™ìƒë¸”ì— í¬í•¨ëœ ëª¨ë¸: {model_names}")

# ì•™ìƒë¸” êµ¬ì„± ê³„ì†...
if len(predictions) == 0:
    print("âŒ ì•™ìƒë¸”ì— ì‚¬ìš©í•  ì˜ˆì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
    exit(1)

# ê°€ì¤‘ í‰ê·  ê³„ì‚°
if len(predictions) > 1:
    # ë™ì¼ ê°€ì¤‘ì¹˜ë¡œ ì‹œì‘
    ensemble_pred = tf.keras.layers.Average()(predictions)
    print("  ğŸ“Š í‰ê·  ì•™ìƒë¸” ì‚¬ìš©")
else:
    ensemble_pred = predictions[0]
    print("  ğŸ“Š ë‹¨ì¼ ëª¨ë¸ ì‚¬ìš©")

# M14 ê·œì¹™ ë³´ì •
final_pred = M14RuleCorrection()([ensemble_pred, m14_input])

# ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
ensemble_model = tf.keras.Model(
    inputs=[time_series_input, m14_input],
    outputs=final_pred,
    name='Ensemble_Model'
)

print("  âœ… ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„± ì™„ë£Œ")

# ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
print("\nğŸ“‹ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì¡°:")
print(f"  ì…ë ¥: ì‹œê³„ì—´ {input_shape} + M14 íŠ¹ì§• (4,)")
print(f"  í¬í•¨ ëª¨ë¸: {len(model_names)}ê°œ")
print(f"  ì¶œë ¥: ë¬¼ë¥˜ëŸ‰ ì˜ˆì¸¡ê°’")

# ============================================
# 8. ê°„ë‹¨í•œ í‰ê°€ (ì»´íŒŒì¼ ì—†ì´)
# ============================================
print("\nğŸ“Š ë¹ ë¥¸ í‰ê°€...")

# 100ê°œ ìƒ˜í”Œë§Œ í…ŒìŠ¤íŠ¸
test_size = min(100, len(X_val))
X_test = X_val[:test_size]
y_test = y_val[:test_size]
m14_test = m14_val[:test_size]

# ì˜ˆì¸¡
try:
    y_pred = ensemble_model.predict([X_test, m14_test], verbose=0)
    y_pred = y_pred.flatten()
    
    # MAE ê³„ì‚°
    mae = np.mean(np.abs(y_test - y_pred))
    print(f"  í…ŒìŠ¤íŠ¸ MAE: {mae:.2f}")
    
    # 1400+ Recall
    mask_1400 = y_test >= 1400
    if np.any(mask_1400):
        recall_1400 = np.sum((y_pred >= 1400) & mask_1400) / np.sum(mask_1400)
        print(f"  1400+ Recall: {recall_1400:.2%}")
        
except Exception as e:
    print(f"  âš ï¸ í‰ê°€ ì‹¤íŒ¨: {str(e)[:100]}...")

# ============================================
# 9. ëª¨ë¸ ì €ì¥
# ============================================
print("\nğŸ’¾ ì•™ìƒë¸” ëª¨ë¸ ì €ì¥ ì¤‘...")

# ì €ì¥ ì‹œë„
ensemble_path = os.path.join(Config.MODEL_DIR, 'ensemble_model_fixed.h5')

try:
    # ëª¨ë¸ êµ¬ì¡°ì™€ ê°€ì¤‘ì¹˜ ì €ì¥
    ensemble_model.save(ensemble_path, save_traces=False)
    print(f"  âœ… ì•™ìƒë¸” ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {ensemble_path}")
except Exception as e:
    print(f"  âŒ ì „ì²´ ì €ì¥ ì‹¤íŒ¨: {str(e)[:50]}...")
    
    # weightsë§Œ ì €ì¥
    try:
        weights_path = os.path.join(Config.MODEL_DIR, 'ensemble_weights_fixed.h5')
        ensemble_model.save_weights(weights_path)
        print(f"  âœ… ê°€ì¤‘ì¹˜ë§Œ ì €ì¥ ì™„ë£Œ: {weights_path}")
    except Exception as e2:
        print(f"  âŒ ê°€ì¤‘ì¹˜ ì €ì¥ë„ ì‹¤íŒ¨: {str(e2)[:50]}...")

# ============================================
# 10. ìš”ì•½
# ============================================
print("\n" + "="*60)
print("ğŸ‰ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„± ì™„ë£Œ!")
print("="*60)
print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {Config.MODEL_DIR}")
print(f"ğŸ”§ í¬í•¨ëœ ëª¨ë¸: {', '.join(model_names)}")
print(f"ğŸ’¾ ì €ì¥ íŒŒì¼: ensemble_model_fixed.h5")
print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
print("  1. ê°œë³„ ëª¨ë¸ë“¤ì´ ì œëŒ€ë¡œ í•™ìŠµë˜ì—ˆëŠ”ì§€ í™•ì¸")
print("  2. ëª¨ë¸ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸")
print("  3. í•„ìš”ì‹œ weights íŒŒì¼ë„ í•¨ê»˜ ì €ì¥")
print("="*60)