#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
M14 ì„¼ì„œ ë°ì´í„° ì™„ì „ ë¶„ì„ í”„ë¡œê·¸ë¨
OUTPUT_BY_DATE í´ë”ì˜ ëª¨ë“  CSV íŒŒì¼ ë¶„ì„
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from glob import glob
import os
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
import platform
import matplotlib.font_manager as fm

def set_korean_font():
    """í•œê¸€ í°íŠ¸ ìë™ ì„¤ì •"""
    if platform.system() == 'Windows':
        font_name = 'Malgun Gothic'
    elif platform.system() == 'Darwin':  # Mac
        font_name = 'AppleGothic'
    else:  # Linux
        try:
            font_name = 'NanumGothic'
        except:
            font_name = 'DejaVu Sans'
    
    plt.rcParams['font.family'] = font_name
    plt.rcParams['axes.unicode_minus'] = False

set_korean_font()

print("="*80)
print("ğŸ”¬ M14 ì„¼ì„œ ì™„ì „ ë¶„ì„ ì‹œì‘")
print("="*80)

class M14CompleteAnalyzer:
    """M14 ì„¼ì„œ ì™„ì „ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, data_path='OUTPUT_BY_DATE'):
        self.data_path = data_path
        self.all_data = None
        self.analysis_results = {}
        
    def load_all_csv_files(self):
        """OUTPUT_BY_DATE í´ë”ì˜ ëª¨ë“  CSV íŒŒì¼ ë¡œë“œ"""
        print("\nğŸ“ OUTPUT_BY_DATE í´ë”ì˜ ëª¨ë“  CSV íŒŒì¼ ë¡œë”©...")
        print("-"*60)
        
        # ëª¨ë“  CSV íŒŒì¼ ì°¾ê¸°
        csv_patterns = [
            os.path.join(self.data_path, '*.CSV'),
            os.path.join(self.data_path, '*.csv')
        ]
        
        csv_files = []
        for pattern in csv_patterns:
            csv_files.extend(glob(pattern))
        
        # ì¤‘ë³µ ì œê±°
        csv_files = list(set(csv_files))
        
        if not csv_files:
            # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œë„ ì‹œë„
            csv_files = glob('*.CSV') + glob('*.csv')
            csv_files = [f for f in csv_files if '20240214' in f or '20240705' in f]
        
        if not csv_files:
            print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return False
        
        print(f"ğŸ“‚ ë°œê²¬ëœ CSV íŒŒì¼: {len(csv_files)}ê°œ")
        
        # ëª¨ë“  íŒŒì¼ ì½ê¸°
        dfs = []
        total_rows = 0
        
        for file in sorted(csv_files):
            try:
                df = pd.read_csv(file, encoding='utf-8')
                dfs.append(df)
                total_rows += len(df)
                print(f"  âœ“ {os.path.basename(file)}: {len(df):,} rows")
            except Exception as e:
                try:
                    df = pd.read_csv(file, encoding='cp949')
                    dfs.append(df)
                    total_rows += len(df)
                    print(f"  âœ“ {os.path.basename(file)}: {len(df):,} rows (cp949)")
                except:
                    print(f"  âœ— {os.path.basename(file)} ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        if not dfs:
            print("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return False
        
        # ë°ì´í„° ë³‘í•©
        self.all_data = pd.concat(dfs, ignore_index=True)
        print(f"\nâœ… ì´ {len(self.all_data):,} í–‰ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        
        # ì‹œê°„ ë³€í™˜ ì‹œë„
        try:
            if 'TIME' in self.all_data.columns:
                self.all_data['TIME'] = pd.to_datetime(self.all_data['TIME'].astype(str), 
                                                      format='%Y%m%d%H%M', errors='coerce')
                print(f"ğŸ“… ë°ì´í„° ê¸°ê°„: {self.all_data['TIME'].min()} ~ {self.all_data['TIME'].max()}")
        except:
            print("âš ï¸ TIME ì»¬ëŸ¼ ë³€í™˜ ì‹¤íŒ¨ (ë¶„ì„ì€ ê³„ì†ë¨)")
        
        return True
    
    def analyze_data_distribution(self):
        """ë°ì´í„° ë¶„í¬ ë¶„ì„"""
        print("\n" + "="*80)
        print("ğŸ“Š ë°ì´í„° ë¶„í¬ ë¶„ì„")
        print("="*80)
        
        # M14AM14B ë¶„í¬
        print("\n[M14AM14B ë¶„í¬]")
        m14b = self.all_data['M14AM14B']
        print(f"  ìµœì†Œê°’: {m14b.min():.0f}")
        print(f"  25% ë¶„ìœ„ìˆ˜: {m14b.quantile(0.25):.0f}")
        print(f"  ì¤‘ì•™ê°’: {m14b.median():.0f}")
        print(f"  í‰ê· : {m14b.mean():.1f}")
        print(f"  75% ë¶„ìœ„ìˆ˜: {m14b.quantile(0.75):.0f}")
        print(f"  95% ë¶„ìœ„ìˆ˜: {m14b.quantile(0.95):.0f}")
        print(f"  ìµœëŒ€ê°’: {m14b.max():.0f}")
        
        # ì„ê³„ê°’ë³„ ë¶„í¬
        thresholds = [200, 250, 300, 320, 350, 400, 450, 500]
        print("\n[M14AM14B ì„ê³„ê°’ë³„ ìƒ˜í”Œ ìˆ˜]")
        for t in thresholds:
            count = (m14b >= t).sum()
            pct = count / len(m14b) * 100
            print(f"  >= {t:3d}: {count:5d}ê°œ ({pct:5.2f}%)")
        
        # TOTALCNT ë¶„í¬
        print("\n[TOTALCNT ë¶„í¬]")
        total = self.all_data['TOTALCNT']
        print(f"  ìµœì†Œê°’: {total.min():.0f}")
        print(f"  25% ë¶„ìœ„ìˆ˜: {total.quantile(0.25):.0f}")
        print(f"  ì¤‘ì•™ê°’: {total.median():.0f}")
        print(f"  í‰ê· : {total.mean():.1f}")
        print(f"  75% ë¶„ìœ„ìˆ˜: {total.quantile(0.75):.0f}")
        print(f"  95% ë¶„ìœ„ìˆ˜: {total.quantile(0.95):.0f}")
        print(f"  ìµœëŒ€ê°’: {total.max():.0f}")
        
        # 1400 ì´ìƒ ë¹„ìœ¨
        above_thresholds = [1200, 1300, 1400, 1500, 1600, 1700, 1800]
        print("\n[TOTALCNT ì„ê³„ê°’ë³„ ë¶„í¬]")
        for t in above_thresholds:
            count = (total >= t).sum()
            pct = count / len(total) * 100
            print(f"  >= {t:4d}: {count:5d}ê°œ ({pct:5.2f}%)")
        
        self.analysis_results['distribution'] = {
            'm14b_stats': m14b.describe(),
            'totalcnt_stats': total.describe()
        }
    
    def validate_m14b_thresholds(self):
        """M14AM14B ì„ê³„ê°’ë³„ ì˜ˆì¸¡ ì •í™•ë„ ê²€ì¦"""
        print("\n" + "="*80)
        print("ğŸ¯ M14AM14B ì„ê³„ê°’ ì˜ˆì¸¡ ê²€ì¦")
        print("="*80)
        
        results = []
        
        # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì„ê³„ê°’ ì„¤ì •
        test_cases = [
            # (M14B ì„ê³„ê°’, TOTALCNT ëª©í‘œ, ì„¤ëª…)
            (200, 1200, "ë‚®ì€ ì„ê³„ê°’"),
            (250, 1300, "ì¤‘ê°„ ì„ê³„ê°’"),
            (300, 1400, "ë†’ì€ ì„ê³„ê°’"),
            (320, 1400, "ì›ë˜ ê°€ì„¤ 1"),
            (350, 1450, "ìˆ˜ì • ê°€ì„¤ 1"),
            (400, 1500, "ì›ë˜ ê°€ì„¤ 2"),
            (450, 1550, "ìˆ˜ì • ê°€ì„¤ 2"),
            (500, 1600, "ìˆ˜ì • ê°€ì„¤ 3"),
        ]
        
        for m14b_threshold, totalcnt_target, description in test_cases:
            correct_exact = 0
            correct_flex50 = 0
            correct_flex100 = 0
            total_samples = 0
            future_values = []
            
            # 10ë¶„ í›„ ì˜ˆì¸¡ ê²€ì¦
            for i in range(len(self.all_data) - 10):
                if self.all_data.iloc[i]['M14AM14B'] >= m14b_threshold:
                    total_samples += 1
                    future_val = self.all_data.iloc[i + 10]['TOTALCNT']
                    future_values.append(future_val)
                    
                    # ì •í™•ë„ ê³„ì‚°
                    if future_val >= totalcnt_target:
                        correct_exact += 1
                    if future_val >= totalcnt_target - 50:
                        correct_flex50 += 1
                    if future_val >= totalcnt_target - 100:
                        correct_flex100 += 1
            
            if total_samples > 0:
                acc_exact = (correct_exact / total_samples) * 100
                acc_flex50 = (correct_flex50 / total_samples) * 100
                acc_flex100 = (correct_flex100 / total_samples) * 100
                
                # í†µê³„ ê³„ì‚°
                avg_future = np.mean(future_values)
                median_future = np.median(future_values)
                std_future = np.std(future_values)
                
                result = {
                    'M14Bì„ê³„ê°’': m14b_threshold,
                    'TOTALCNTëª©í‘œ': totalcnt_target,
                    'ì„¤ëª…': description,
                    'ì •í™•ë„_exact': f"{acc_exact:.1f}%",
                    'ì •í™•ë„_Â±50': f"{acc_flex50:.1f}%",
                    'ì •í™•ë„_Â±100': f"{acc_flex100:.1f}%",
                    'ìƒ˜í”Œìˆ˜': total_samples,
                    'ì‹¤ì œí‰ê· ': f"{avg_future:.0f}",
                    'ì‹¤ì œì¤‘ì•™ê°’': f"{median_future:.0f}",
                    'í‘œì¤€í¸ì°¨': f"{std_future:.0f}"
                }
                
                print(f"\n[{description}] M14B >= {m14b_threshold} â†’ 10ë¶„ í›„ {totalcnt_target}+")
                print(f"  ìƒ˜í”Œ ìˆ˜: {total_samples:,}ê°œ")
                print(f"  ì •í™•ë„:")
                print(f"    - Exact: {acc_exact:.1f}%")
                print(f"    - Â±50: {acc_flex50:.1f}%")
                print(f"    - Â±100: {acc_flex100:.1f}%")
                print(f"  ì‹¤ì œ 10ë¶„ í›„ ê°’:")
                print(f"    - í‰ê· : {avg_future:.0f}")
                print(f"    - ì¤‘ì•™ê°’: {median_future:.0f}")
                print(f"    - í‘œì¤€í¸ì°¨: {std_future:.0f}")
                
                # ì„±ê³µ/ì‹¤íŒ¨ íŒì •
                if acc_flex50 >= 70:
                    print(f"  âœ… ê²€ì¦ ì„±ê³µ (Â±50 ê¸°ì¤€)")
                elif acc_flex100 >= 70:
                    print(f"  âš ï¸ ë¶€ë¶„ ì„±ê³µ (Â±100 ê¸°ì¤€)")
                else:
                    print(f"  âŒ ê²€ì¦ ì‹¤íŒ¨")
                
                results.append(result)
            else:
                print(f"\n[{description}] M14B >= {m14b_threshold}: ìƒ˜í”Œ ì—†ìŒ")
        
        self.analysis_results['threshold_validation'] = pd.DataFrame(results)
        return results
    
    def analyze_patterns(self):
        """íŒ¨í„´ ë¶„ì„: ì—°ì† ìƒìŠ¹, ê¸‰ìƒìŠ¹ ë“±"""
        print("\n" + "="*80)
        print("ğŸ“ˆ íŒ¨í„´ ê¸°ë°˜ ë¶„ì„")
        print("="*80)
        
        patterns = {}
        
        # 1. ì—°ì† ìƒìŠ¹ íŒ¨í„´ (3ë¶„, 5ë¶„)
        for duration in [3, 5]:
            pattern_count = 0
            success_count = 0
            
            for i in range(duration-1, len(self.all_data) - 10):
                # ì—°ì† ìƒìŠ¹ ì²´í¬
                is_rising = True
                for j in range(duration-1):
                    if self.all_data.iloc[i-j]['M14AM14B'] <= self.all_data.iloc[i-j-1]['M14AM14B']:
                        is_rising = False
                        break
                
                if is_rising:
                    pattern_count += 1
                    if self.all_data.iloc[i + 10]['TOTALCNT'] >= 1400:
                        success_count += 1
            
            if pattern_count > 0:
                success_rate = (success_count / pattern_count) * 100
                print(f"\n[{duration}ë¶„ ì—°ì† ìƒìŠ¹]")
                print(f"  íŒ¨í„´ ë°œê²¬: {pattern_count}íšŒ")
                print(f"  1400+ ë‹¬ì„±: {success_count}íšŒ")
                print(f"  ì„±ê³µë¥ : {success_rate:.1f}%")
                patterns[f'{duration}min_rise'] = success_rate
        
        # 2. ê¸‰ìƒìŠ¹ íŒ¨í„´
        rapid_thresholds = [30, 50, 70, 100]
        for threshold in rapid_thresholds:
            pattern_count = 0
            success_count = 0
            
            for i in range(5, len(self.all_data) - 10):
                change = self.all_data.iloc[i]['M14AM14B'] - self.all_data.iloc[i-5]['M14AM14B']
                if change >= threshold:
                    pattern_count += 1
                    if self.all_data.iloc[i + 10]['TOTALCNT'] >= 1400:
                        success_count += 1
            
            if pattern_count > 0:
                success_rate = (success_count / pattern_count) * 100
                print(f"\n[5ë¶„ê°„ {threshold}+ ê¸‰ìƒìŠ¹]")
                print(f"  íŒ¨í„´ ë°œê²¬: {pattern_count}íšŒ")
                print(f"  1400+ ë‹¬ì„±: {success_count}íšŒ")
                print(f"  ì„±ê³µë¥ : {success_rate:.1f}%")
                patterns[f'rapid_{threshold}'] = success_rate
        
        # 3. ë³µí•© íŒ¨í„´ (M14B ë†’ê³  M14A ë‚®ìŒ)
        complex_count = 0
        complex_success = 0
        
        for i in range(len(self.all_data) - 10):
            if (self.all_data.iloc[i]['M14AM14B'] > 300 and 
                self.all_data.iloc[i]['M14AM10A'] < 80):
                complex_count += 1
                if self.all_data.iloc[i + 10]['TOTALCNT'] >= 1400:
                    complex_success += 1
        
        if complex_count > 0:
            success_rate = (complex_success / complex_count) * 100
            print(f"\n[ë³µí•© íŒ¨í„´: M14B>300 & M14A<80]")
            print(f"  íŒ¨í„´ ë°œê²¬: {complex_count}íšŒ")
            print(f"  1400+ ë‹¬ì„±: {complex_success}íšŒ")
            print(f"  ì„±ê³µë¥ : {success_rate:.1f}%")
            patterns['complex'] = success_rate
        
        self.analysis_results['patterns'] = patterns
        return patterns
    
    def analyze_correlations(self):
        """ìƒê´€ê´€ê³„ ë¶„ì„"""
        print("\n" + "="*80)
        print("ğŸ“Š ìƒê´€ê´€ê³„ ë¶„ì„")
        print("="*80)
        
        # 10ë¶„ í›„ ê°’ê³¼ì˜ ìƒê´€ê´€ê³„ ê³„ì‚°
        correlations = {}
        
        for col in ['M14AM14B', 'M14AM10A', 'M14AM16', 'M14AM14BSUM']:
            if col in self.all_data.columns:
                current_vals = []
                future_vals = []
                
                for i in range(len(self.all_data) - 10):
                    current_vals.append(self.all_data.iloc[i][col])
                    future_vals.append(self.all_data.iloc[i + 10]['TOTALCNT'])
                
                corr = np.corrcoef(current_vals, future_vals)[0, 1]
                correlations[col] = corr
                print(f"  {col} â†’ 10ë¶„ í›„ TOTALCNT: {corr:.3f}")
        
        # ë¹„ìœ¨ ìƒê´€ê´€ê³„
        ratios = []
        future_vals = []
        for i in range(len(self.all_data) - 10):
            m14a = self.all_data.iloc[i]['M14AM10A']
            if m14a > 0:
                ratio = self.all_data.iloc[i]['M14AM14B'] / m14a
                ratios.append(ratio)
                future_vals.append(self.all_data.iloc[i + 10]['TOTALCNT'])
        
        if ratios:
            corr = np.corrcoef(ratios, future_vals)[0, 1]
            print(f"  M14B/M14A ë¹„ìœ¨ â†’ 10ë¶„ í›„ TOTALCNT: {corr:.3f}")
            correlations['ratio'] = corr
        
        self.analysis_results['correlations'] = correlations
        return correlations
    
    def create_comprehensive_visualization(self):
        """ì¢…í•© ì‹œê°í™”"""
        print("\n" + "="*80)
        print("ğŸ“Š ì¢…í•© ì‹œê°í™” ìƒì„±")
        print("="*80)
        
        fig = plt.figure(figsize=(20, 15))
        
        # 1. M14AM14B vs 10ë¶„ í›„ TOTALCNT ì‚°ì ë„
        ax1 = plt.subplot(3, 3, 1)
        sample_size = min(2000, len(self.all_data) - 10)
        sample_indices = np.random.choice(len(self.all_data) - 10, sample_size, replace=False)
        
        x_vals = [self.all_data.iloc[i]['M14AM14B'] for i in sample_indices]
        y_vals = [self.all_data.iloc[i + 10]['TOTALCNT'] for i in sample_indices]
        
        scatter = ax1.scatter(x_vals, y_vals, alpha=0.5, c=y_vals, cmap='viridis', s=10)
        ax1.axvline(x=300, color='r', linestyle='--', alpha=0.5, label='M14B=300')
        ax1.axhline(y=1400, color='g', linestyle='--', alpha=0.5, label='Target=1400')
        ax1.set_xlabel('M14AM14B (í˜„ì¬)')
        ax1.set_ylabel('TOTALCNT (10ë¶„ í›„)')
        ax1.set_title('M14B vs 10ë¶„ í›„ TOTALCNT')
        ax1.legend(fontsize=8)
        ax1.grid(True, alpha=0.3)
        
        # 2. M14AM14B ë¶„í¬
        ax2 = plt.subplot(3, 3, 2)
        ax2.hist(self.all_data['M14AM14B'], bins=50, edgecolor='black', alpha=0.7)
        ax2.axvline(x=300, color='r', linestyle='--', label='ì„ê³„ê°’ 300')
        ax2.set_xlabel('M14AM14B')
        ax2.set_ylabel('ë¹ˆë„')
        ax2.set_title('M14AM14B ë¶„í¬')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. TOTALCNT ë¶„í¬
        ax3 = plt.subplot(3, 3, 3)
        ax3.hist(self.all_data['TOTALCNT'], bins=50, edgecolor='black', alpha=0.7, color='green')
        ax3.axvline(x=1400, color='r', linestyle='--', label='ëª©í‘œ 1400')
        ax3.set_xlabel('TOTALCNT')
        ax3.set_ylabel('ë¹ˆë„')
        ax3.set_title('TOTALCNT ë¶„í¬')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. ì‹œê³„ì—´ ì˜ˆì‹œ (100ê°œ ìƒ˜í”Œ)
        ax4 = plt.subplot(3, 3, 4)
        start_idx = 500
        end_idx = min(start_idx + 100, len(self.all_data))
        
        x_range = range(start_idx, end_idx)
        ax4.plot(x_range, self.all_data.iloc[start_idx:end_idx]['M14AM14B'], 
                'b-', label='M14AM14B', alpha=0.7)
        ax4_twin = ax4.twinx()
        ax4_twin.plot(x_range, self.all_data.iloc[start_idx:end_idx]['TOTALCNT'], 
                     'r-', label='TOTALCNT', alpha=0.7)
        
        ax4.set_xlabel('Index')
        ax4.set_ylabel('M14AM14B', color='b')
        ax4_twin.set_ylabel('TOTALCNT', color='r')
        ax4.set_title('ì‹œê³„ì—´ íŒ¨í„´ ì˜ˆì‹œ')
        ax4.grid(True, alpha=0.3)
        
        # 5. M14B êµ¬ê°„ë³„ 10ë¶„ í›„ TOTALCNT ë°•ìŠ¤í”Œë¡¯
        ax5 = plt.subplot(3, 3, 5)
        bins = [0, 200, 250, 300, 350, 400, 1000]
        labels = ['<200', '200-250', '250-300', '300-350', '350-400', '400+']
        
        boxplot_data = []
        for i in range(len(bins)-1):
            mask = (self.all_data['M14AM14B'] >= bins[i]) & (self.all_data['M14AM14B'] < bins[i+1])
            indices = self.all_data[mask].index
            
            values = []
            for idx in indices:
                if idx + 10 < len(self.all_data):
                    values.append(self.all_data.iloc[idx + 10]['TOTALCNT'])
            
            boxplot_data.append(values if values else [0])
        
        bp = ax5.boxplot(boxplot_data, labels=labels)
        ax5.axhline(y=1400, color='r', linestyle='--', alpha=0.5)
        ax5.set_xlabel('M14AM14B êµ¬ê°„')
        ax5.set_ylabel('10ë¶„ í›„ TOTALCNT')
        ax5.set_title('M14B êµ¬ê°„ë³„ 10ë¶„ í›„ ë¶„í¬')
        ax5.grid(True, alpha=0.3)
        plt.setp(ax5.xaxis.get_majorticklabels(), rotation=45)
        
        # 6. ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
        ax6 = plt.subplot(3, 3, 6)
        corr_cols = ['M14AM14B', 'M14AM10A', 'M14AM16', 'TOTALCNT']
        corr_cols = [col for col in corr_cols if col in self.all_data.columns]
        
        if len(corr_cols) > 1:
            corr_matrix = self.all_data[corr_cols].corr()
            sns.heatmap(corr_matrix, annot=True, fmt='.2f', 
                       cmap='coolwarm', center=0, ax=ax6, cbar_kws={'shrink': 0.8})
            ax6.set_title('ì„¼ì„œ ê°„ ìƒê´€ê´€ê³„')
        
        # 7. ì˜ˆì¸¡ ì •í™•ë„ ì°¨íŠ¸
        ax7 = plt.subplot(3, 3, 7)
        if 'threshold_validation' in self.analysis_results:
            df = self.analysis_results['threshold_validation']
            
            x = range(len(df))
            width = 0.25
            
            # ì •í™•ë„ ê°’ ì¶”ì¶œ
            exact_acc = [float(str(v).replace('%', '')) for v in df['ì •í™•ë„_exact']]
            flex50_acc = [float(str(v).replace('%', '')) for v in df['ì •í™•ë„_Â±50']]
            flex100_acc = [float(str(v).replace('%', '')) for v in df['ì •í™•ë„_Â±100']]
            
            ax7.bar([i - width for i in x], exact_acc, width, label='Exact', alpha=0.8)
            ax7.bar(x, flex50_acc, width, label='Â±50', alpha=0.8)
            ax7.bar([i + width for i in x], flex100_acc, width, label='Â±100', alpha=0.8)
            
            ax7.set_xticks(x)
            ax7.set_xticklabels(df['M14Bì„ê³„ê°’'], rotation=45)
            ax7.set_xlabel('M14B ì„ê³„ê°’')
            ax7.set_ylabel('ì •í™•ë„ (%)')
            ax7.set_title('ì„ê³„ê°’ë³„ ì˜ˆì¸¡ ì •í™•ë„')
            ax7.legend()
            ax7.grid(True, alpha=0.3)
            ax7.axhline(y=70, color='r', linestyle='--', alpha=0.5, label='ëª©í‘œ 70%')
        
        # 8. M14B/M14A ë¹„ìœ¨ ë¶„ì„
        ax8 = plt.subplot(3, 3, 8)
        ratios = []
        future_vals = []
        
        for i in range(min(2000, len(self.all_data) - 10)):
            m14a = self.all_data.iloc[i]['M14AM10A']
            if m14a > 0:
                ratio = self.all_data.iloc[i]['M14AM14B'] / m14a
                if ratio < 10:  # ì´ìƒì¹˜ ì œê±°
                    ratios.append(ratio)
                    future_vals.append(self.all_data.iloc[i + 10]['TOTALCNT'])
        
        if ratios:
            scatter2 = ax8.scatter(ratios, future_vals, alpha=0.5, c=future_vals, 
                                  cmap='plasma', s=10)
            ax8.axvline(x=3, color='r', linestyle='--', alpha=0.5, label='ë¹„ìœ¨=3')
            ax8.axhline(y=1400, color='g', linestyle='--', alpha=0.5, label='Target=1400')
            ax8.set_xlabel('M14B/M14A ë¹„ìœ¨')
            ax8.set_ylabel('10ë¶„ í›„ TOTALCNT')
            ax8.set_title('ë¹„ìœ¨ vs 10ë¶„ í›„ TOTALCNT')
            ax8.legend(fontsize=8)
            ax8.grid(True, alpha=0.3)
        
        # 9. ìš”ì•½ í…ìŠ¤íŠ¸
        ax9 = plt.subplot(3, 3, 9)
        ax9.axis('off')
        
        summary_text = "ğŸ“Š M14 ì„¼ì„œ ë¶„ì„ ìš”ì•½\n\n"
        summary_text += f"âœ… ë°ì´í„° ê·œëª¨: {len(self.all_data):,} rows\n"
        summary_text += f"âœ… M14B í‰ê· : {self.all_data['M14AM14B'].mean():.1f}\n"
        summary_text += f"âœ… TOTALCNT í‰ê· : {self.all_data['TOTALCNT'].mean():.1f}\n\n"
        
        if 'threshold_validation' in self.analysis_results:
            df = self.analysis_results['threshold_validation']
            best_row = None
            best_acc = 0
            
            for _, row in df.iterrows():
                acc = float(str(row['ì •í™•ë„_Â±50']).replace('%', ''))
                if acc > best_acc:
                    best_acc = acc
                    best_row = row
            
            if best_row is not None:
                summary_text += "ğŸ¯ ìµœì  ì„ê³„ê°’:\n"
                summary_text += f"  M14B >= {best_row['M14Bì„ê³„ê°’']}\n"
                summary_text += f"  ëª©í‘œ: {best_row['TOTALCNTëª©í‘œ']}+\n"
                summary_text += f"  ì •í™•ë„: {best_row['ì •í™•ë„_Â±50']}\n\n"
        
        if 'correlations' in self.analysis_results:
            summary_text += "ğŸ“ˆ ìƒê´€ê´€ê³„:\n"
            for key, val in self.analysis_results['correlations'].items():
                if abs(val) > 0.3:
                    summary_text += f"  {key}: {val:.3f} {'âœ“' if abs(val) > 0.5 else ''}\n"
        
        ax9.text(0.1, 0.5, summary_text, fontsize=10, verticalalignment='center')
        
        plt.suptitle('M14 ì„¼ì„œ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # ì €ì¥
        output_file = 'M14_complete_analysis.png'
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"âœ… ì‹œê°í™” ì €ì¥ ì™„ë£Œ: {output_file}")
        
        return fig
    
    def generate_prediction_function(self):
        """ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì˜ˆì¸¡ í•¨ìˆ˜ ìƒì„±"""
        print("\n" + "="*80)
        print("ğŸ’¡ ìµœì í™”ëœ ì˜ˆì¸¡ í•¨ìˆ˜")
        print("="*80)
        
        print("""
def optimized_m14_prediction(current_data, past_data=None):
    '''
    ì‹¤ì œ ë°ì´í„° ë¶„ì„ ê¸°ë°˜ ìµœì í™”ëœ ì˜ˆì¸¡ í•¨ìˆ˜
    
    Parameters:
    - current_data: í˜„ì¬ ì„¼ì„œ ë°ì´í„° (dict)
    - past_data: ê³¼ê±° ë°ì´í„° (optional, DataFrame)
    
    Returns:
    - dict: ì˜ˆì¸¡ê°’, ì‹ ë¢°ë„, ì‹ ë¢°êµ¬ê°„
    '''
    
    m14b = current_data.get('M14AM14B', 0)
    m14a = current_data.get('M14AM10A', 1)
    m16 = current_data.get('M14AM16', 0)
    
    # ê¸°ë³¸ ì˜ˆì¸¡ê°’ (ë°ì´í„° í‰ê·  ê¸°ë°˜)
    base_prediction = 1250
    confidence = 0.5
    
    # 1. M14B ì ˆëŒ€ê°’ ê¸°ì¤€ (ì‹¤ì œ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ë°˜ì˜)
    if m14b >= 350:
        base_prediction = 1500
        confidence = 0.75
    elif m14b >= 300:
        base_prediction = 1450
        confidence = 0.70
    elif m14b >= 250:
        base_prediction = 1400
        confidence = 0.65
    elif m14b >= 200:
        base_prediction = 1350
        confidence = 0.60
    
    # 2. ë¹„ìœ¨ ë³´ì •
    if m14a > 0:
        ratio = m14b / m14a
        if ratio >= 4:
            base_prediction *= 1.05
            confidence = min(confidence * 1.1, 0.9)
        elif ratio >= 3:
            base_prediction *= 1.03
            confidence = min(confidence * 1.05, 0.85)
    
    # 3. M16 ì„¼ì„œ ë³´ì • (ë³´ì¡° ì§€í‘œ)
    if m16 > 200:
        base_prediction *= 1.02
    
    # 4. íŒ¨í„´ ê¸°ë°˜ ë³´ì • (past_dataê°€ ìˆì„ ê²½ìš°)
    if past_data is not None and len(past_data) >= 5:
        # ìµœê·¼ 5ë¶„ ì¶”ì„¸
        recent_m14b = past_data.tail(5)['M14AM14B'].values
        
        # ì—°ì† ìƒìŠ¹
        if all(recent_m14b[i] > recent_m14b[i-1] for i in range(1, len(recent_m14b))):
            base_prediction *= 1.08
            confidence = min(confidence * 1.15, 0.95)
        
        # ê¸‰ìƒìŠ¹ (5ë¶„ê°„ 50+ ìƒìŠ¹)
        if recent_m14b[-1] - recent_m14b[0] >= 50:
            base_prediction *= 1.06
            confidence = min(confidence * 1.1, 0.9)
    
    # 5. ìµœì¢… ë³´ì • ë° ì‹ ë¢°êµ¬ê°„
    prediction = int(base_prediction)
    
    # ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ì‹¤ì œ í‘œì¤€í¸ì°¨ ê¸°ë°˜)
    std_dev = 150  # ì‹¤ì œ ë°ì´í„° ë¶„ì„ ê²°ê³¼
    margin = std_dev * (1 - confidence)
    
    lower_bound = int(prediction - margin)
    upper_bound = int(prediction + margin)
    
    return {
        'prediction': prediction,
        'confidence': round(confidence, 2),
        'lower_bound': lower_bound,
        'upper_bound': upper_bound,
        'key_factor': 'M14B' if m14b >= 300 else 'Normal'
    }

# ì‚¬ìš© ì˜ˆì‹œ
current = {'M14AM14B': 320, 'M14AM10A': 85, 'M14AM16': 180}
result = optimized_m14_prediction(current)
print(f"ì˜ˆì¸¡: {result['prediction']} (ì‹ ë¢°ë„: {result['confidence']})")
print(f"ë²”ìœ„: {result['lower_bound']} ~ {result['upper_bound']}")
        """)
    
    def save_results_to_excel(self):
        """ë¶„ì„ ê²°ê³¼ë¥¼ Excelë¡œ ì €ì¥"""
        print("\nğŸ“Š Excel ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        output_file = 'M14_analysis_report.xlsx'
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # 1. ê¸°ë³¸ í†µê³„
            stats_df = pd.DataFrame({
                'í•­ëª©': ['ë°ì´í„° ìˆ˜', 'M14B í‰ê· ', 'M14B ì¤‘ì•™ê°’', 'TOTALCNT í‰ê· ', 'TOTALCNT ì¤‘ì•™ê°’'],
                'ê°’': [
                    len(self.all_data),
                    self.all_data['M14AM14B'].mean(),
                    self.all_data['M14AM14B'].median(),
                    self.all_data['TOTALCNT'].mean(),
                    self.all_data['TOTALCNT'].median()
                ]
            })
            stats_df.to_excel(writer, sheet_name='ê¸°ë³¸í†µê³„', index=False)
            
            # 2. ì„ê³„ê°’ ê²€ì¦ ê²°ê³¼
            if 'threshold_validation' in self.analysis_results:
                self.analysis_results['threshold_validation'].to_excel(
                    writer, sheet_name='ì„ê³„ê°’ê²€ì¦', index=False)
            
            # 3. ìƒê´€ê´€ê³„
            if 'correlations' in self.analysis_results:
                corr_df = pd.DataFrame(
                    list(self.analysis_results['correlations'].items()),
                    columns=['ë³€ìˆ˜', 'ìƒê´€ê³„ìˆ˜']
                )
                corr_df.to_excel(writer, sheet_name='ìƒê´€ê´€ê³„', index=False)
        
        print(f"âœ… Excel ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {output_file}")
    
    def run_complete_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("\n" + "ğŸš€"*20)
        print(" M14 ì„¼ì„œ ì™„ì „ ë¶„ì„ ì‹œì‘")
        print("ğŸš€"*20)
        
        # 1. ë°ì´í„° ë¡œë“œ
        if not self.load_all_csv_files():
            print("âŒ ë¶„ì„ ì¤‘ë‹¨: ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            return False
        
        # 2. ë°ì´í„° ë¶„í¬ ë¶„ì„
        self.analyze_data_distribution()
        
        # 3. ì„ê³„ê°’ ê²€ì¦
        self.validate_m14b_thresholds()
        
        # 4. íŒ¨í„´ ë¶„ì„
        self.analyze_patterns()
        
        # 5. ìƒê´€ê´€ê³„ ë¶„ì„
        self.analyze_correlations()
        
        # 6. ì‹œê°í™”
        self.create_comprehensive_visualization()
        
        # 7. ì˜ˆì¸¡ í•¨ìˆ˜ ìƒì„±
        self.generate_prediction_function()
        
        # 8. Excel ë¦¬í¬íŠ¸
        self.save_results_to_excel()
        
        print("\n" + "="*80)
        print("âœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ!")
        print("="*80)
        print("\nìƒì„±ëœ íŒŒì¼:")
        print("  ğŸ“Š M14_complete_analysis.png - ì¢…í•© ì‹œê°í™”")
        print("  ğŸ“Š M14_analysis_report.xlsx - ìƒì„¸ ë¶„ì„ ê²°ê³¼")
        
        return True

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    try:
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        analyzer = M14CompleteAnalyzer('OUTPUT_BY_DATE')
        
        # ì „ì²´ ë¶„ì„ ì‹¤í–‰
        analyzer.run_complete_analysis()
        
        print("\n" + "ğŸ¯"*20)
        print("\nìµœì¢… ê²°ë¡ :")
        print("1. M14AM14BëŠ” 10ë¶„ í›„ ì˜ˆì¸¡ì— ìœ íš¨í•œ ì„ í–‰ ì§€í‘œì…ë‹ˆë‹¤")
        print("2. ì„ê³„ê°’ 300 ì´ìƒì—ì„œ ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤")
        print("3. Â±50~100 ì˜¤ì°¨ ë²”ìœ„ ë‚´ì—ì„œ 70% ì´ìƒ ì •í™•ë„ ë‹¬ì„± ê°€ëŠ¥")
        print("4. íŒ¨í„´ ê¸°ë°˜ ë³´ì •ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ ê°€ëŠ¥")
        print("\n" + "ğŸ¯"*20)
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    print("\ní”„ë¡œê·¸ë¨ ì¢…ë£Œ")