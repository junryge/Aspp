"""
V6 ëª¨ë¸ í‰ê°€ ì‹œìŠ¤í…œ (ìµœì¢… ìˆ˜ì •íŒ)
- íŠ¹ì§• ê°œìˆ˜ ì¼ì¹˜ ë¬¸ì œ í•´ê²°
- ì§ì ‘ ê°€ì¤‘ì¹˜ ë¡œë“œ ë°©ì‹
- ëª¨ë¸ êµ¬ì¡° ì •í™•íˆ ì¬ìƒì„±
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import RobustScaler
import matplotlib.pyplot as plt
import json
import warnings
from datetime import datetime
import os
import h5py
warnings.filterwarnings('ignore')

# TensorFlow ê²½ê³  ì–µì œ
import logging
logging.getLogger('tensorflow').setLevel(logging.ERROR)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

print("="*60)
print("ğŸ“Š V6 ëª¨ë¸ í‰ê°€ ì‹œìŠ¤í…œ (ìµœì¢… ìˆ˜ì •íŒ)")
print(f"ğŸ“¦ TensorFlow: {tf.__version__}")
print("="*60)

# ============================================
# ì„¤ì •
# ============================================
class Config:
    # í‰ê°€ ë°ì´í„° íŒŒì¼
    EVAL_DATA_FILE = './data/20250731_to20250806.CSV'
    
    # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    MODEL_DIR = './models_v6_full_train/'
    
    # ì‹œí€€ìŠ¤ ì„¤ì •
    LOOKBACK = 100  # ê³¼ê±° 100ë¶„ ë°ì´í„°
    FORECAST = 10   # 10ë¶„ í›„ ì˜ˆì¸¡
    
    # í‰ê°€ ê²°ê³¼ ì €ì¥ ê²½ë¡œ
    EVAL_RESULT_DIR = './evaluation_results/'
    
    # ì‹œê°í™” ì €ì¥ ê²½ë¡œ
    PLOT_DIR = './evaluation_plots/'
    
    # CPU ëª¨ë“œ ë°°ì¹˜ í¬ê¸°
    BATCH_SIZE = 32
    
    # íŠ¹ì§• ê°œìˆ˜ (í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ)
    NUM_FEATURES = 47  # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ íŠ¹ì§• ê°œìˆ˜

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(Config.EVAL_RESULT_DIR, exist_ok=True)
os.makedirs(Config.PLOT_DIR, exist_ok=True)

# ============================================
# ëª¨ë¸ êµ¬ì¡° í™•ì¸ í•¨ìˆ˜
# ============================================
def check_model_structure():
    """ì €ì¥ëœ ëª¨ë¸ì˜ êµ¬ì¡° í™•ì¸"""
    print("\nğŸ” ëª¨ë¸ êµ¬ì¡° í™•ì¸ ì¤‘...")
    
    model_files = [
        'lstm_final.keras',
        'gru_final.keras',
        'cnn_lstm_final.keras',
        'spike_final.keras',
        'rule_final.keras',
        'ensemble_final.keras'
    ]
    
    for model_file in model_files:
        model_path = os.path.join(Config.MODEL_DIR, model_file)
        if os.path.exists(model_path):
            try:
                # H5 íŒŒì¼ë¡œ ì§ì ‘ ì½ê¸°
                with h5py.File(model_path, 'r') as f:
                    if 'model_config' in f.attrs:
                        import json
                        config = json.loads(f.attrs['model_config'])
                        
                        # ì…ë ¥ shape ì°¾ê¸°
                        if 'config' in config:
                            layers = config['config'].get('layers', [])
                            if layers and len(layers) > 0:
                                first_layer = layers[0]
                                if 'batch_shape' in first_layer.get('config', {}):
                                    batch_shape = first_layer['config']['batch_shape']
                                    print(f"  {model_file}: ì…ë ¥ shape = {batch_shape}")
                                    Config.NUM_FEATURES = batch_shape[2] if len(batch_shape) > 2 else 47
                                    break
            except Exception as e:
                print(f"  {model_file} í™•ì¸ ì‹¤íŒ¨: {str(e)[:50]}...")
    
    print(f"  âœ… íŠ¹ì§• ê°œìˆ˜ ì„¤ì •: {Config.NUM_FEATURES}")

# ============================================
# ì»¤ìŠ¤í…€ ë ˆì´ì–´ ì •ì˜
# ============================================
@tf.keras.utils.register_keras_serializable()
class M14RuleCorrection(tf.keras.layers.Layer):
    """M14 ê·œì¹™ ê¸°ë°˜ ë³´ì • ë ˆì´ì–´"""
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
    
    def call(self, inputs, training=None):
        if isinstance(inputs, list):
            pred, m14_features = inputs
        else:
            return inputs
        
        pred = tf.cast(pred, tf.float32)
        m14_features = tf.cast(m14_features, tf.float32)
        
        if len(m14_features.shape) == 1:
            m14_features = tf.expand_dims(m14_features, axis=0)
        
        # M14 íŠ¹ì§• ì¶”ì¶œ
        m14b = m14_features[:, 0:1] if m14_features.shape[-1] >= 1 else tf.zeros_like(pred)
        m10a = m14_features[:, 1:2] if m14_features.shape[-1] >= 2 else tf.ones_like(pred)
        m16 = m14_features[:, 2:3] if m14_features.shape[-1] >= 3 else tf.ones_like(pred)
        ratio = m14_features[:, 3:4] if m14_features.shape[-1] >= 4 else \
                tf.where(m10a > 0, m14b / (m10a + 1e-7), tf.zeros_like(pred))
        
        # ê·œì¹™ ì ìš©
        pred = tf.where(m14b >= 420, tf.maximum(pred, 1550.0), pred)
        pred = tf.where(m14b >= 380, tf.maximum(pred, 1500.0), pred)
        pred = tf.where(m14b >= 350, tf.maximum(pred, 1450.0), pred)
        pred = tf.where(m14b >= 300, tf.maximum(pred, 1400.0), pred)
        
        pred = tf.clip_by_value(pred, 1200.0, 2000.0)
        
        return pred
    
    def get_config(self):
        return super().get_config()

# ============================================
# ê°„ë‹¨í•œ ì˜ˆì¸¡ ëª¨ë¸ (ë¡œë“œ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ìš©)
# ============================================
def create_simple_predictor(X_test, y_test, m14_test):
    """ê·œì¹™ ê¸°ë°˜ ê°„ë‹¨í•œ ì˜ˆì¸¡ê¸°"""
    print("\nğŸ”§ ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡ê¸° ìƒì„±...")
    
    predictions = []
    
    for i in range(len(X_test)):
        # ìµœê·¼ 10ê°œ ê°’ì˜ í‰ê· 
        recent_avg = np.mean(X_test[i, -10:, 0])  # TOTALCNT ì»¬ëŸ¼
        
        # M14 ê¸°ë°˜ ì¡°ì •
        m14b = m14_test[i, 0] if m14_test.shape[1] > 0 else 0
        m10a = m14_test[i, 1] if m14_test.shape[1] > 1 else 1
        
        # ê¸°ë³¸ ì˜ˆì¸¡
        pred = recent_avg
        
        # M14 ê·œì¹™ ì ìš©
        if m14b >= 400:
            pred = max(pred, 1500)
        elif m14b >= 350:
            pred = max(pred, 1450)
        elif m14b >= 300:
            pred = max(pred, 1400)
        
        # ë¹„ìœ¨ ê¸°ë°˜ ì¡°ì •
        if m10a > 0:
            ratio = m14b / m10a
            if ratio > 5:
                pred *= 1.1
            elif ratio > 4:
                pred *= 1.05
        
        predictions.append(pred)
    
    predictions = np.array(predictions)
    
    # ì„±ëŠ¥ ê³„ì‚°
    mae = np.mean(np.abs(y_test - predictions))
    accuracy_50 = np.mean(np.abs(y_test - predictions) <= 50) * 100
    accuracy_100 = np.mean(np.abs(y_test - predictions) <= 100) * 100
    
    print(f"  MAE: {mae:.2f}")
    print(f"  ì •í™•ë„(Â±50): {accuracy_50:.1f}%")
    print(f"  ì •í™•ë„(Â±100): {accuracy_100:.1f}%")
    
    return {
        'rule_simple': predictions
    }, {
        'rule_simple': {
            'mae': mae,
            'accuracy_50': accuracy_50,
            'accuracy_100': accuracy_100
        }
    }

# ============================================
# ë°ì´í„° ì „ì²˜ë¦¬ (í•™ìŠµê³¼ ë™ì¼í•˜ê²Œ)
# ============================================
def prepare_evaluation_data(file_path):
    """í‰ê°€ ë°ì´í„° ì¤€ë¹„ - í•™ìŠµê³¼ ë™ì¼í•œ íŠ¹ì§• ìƒì„±"""
    print(f"\nğŸ“‚ í‰ê°€ ë°ì´í„° ë¡œë“œ: {file_path}")
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(file_path)
    print(f"  ì›ë³¸ ë°ì´í„°: {len(df)}í–‰")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_columns = ['M14AM10A', 'M14AM14B', 'M14AM16', 'TOTALCNT']
    for col in required_columns:
        if col not in df.columns:
            print(f"  âš ï¸ {col} ì»¬ëŸ¼ ì—†ìŒ - 0ìœ¼ë¡œ ì´ˆê¸°í™”")
            df[col] = 0
    
    # M14AM14BSUM ìƒì„±
    if 'M14AM14BSUM' not in df.columns:
        df['M14AM14BSUM'] = df['M14AM14B'] + df['M14AM10A']
    
    # íƒ€ê²Ÿ ìƒì„±
    df['target'] = df['TOTALCNT'].shift(-Config.FORECAST)
    
    print("\nğŸ”§ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§ (í•™ìŠµê³¼ ë™ì¼í•˜ê²Œ)...")
    
    # ê¸°ë³¸ íŠ¹ì§•
    df['ratio_14B_10A'] = df['M14AM14B'] / (df['M14AM10A'] + 1)
    df['ratio_14B_16'] = df['M14AM14B'] / (df['M14AM16'] + 1)
    df['ratio_10A_16'] = df['M14AM10A'] / (df['M14AM16'] + 1)
    
    # ì‹œê³„ì—´ íŠ¹ì§• (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ)
    for col in ['TOTALCNT', 'M14AM14B', 'M14AM10A', 'M14AM16']:
        if col in df.columns:
            df[f'{col}_diff_1'] = df[col].diff(1)
            df[f'{col}_diff_5'] = df[col].diff(5)
            df[f'{col}_diff_10'] = df[col].diff(10)
            df[f'{col}_ma_5'] = df[col].rolling(5, min_periods=1).mean()
            df[f'{col}_ma_10'] = df[col].rolling(10, min_periods=1).mean()
            df[f'{col}_ma_20'] = df[col].rolling(20, min_periods=1).mean()
            df[f'{col}_std_5'] = df[col].rolling(5, min_periods=1).std()
            df[f'{col}_std_10'] = df[col].rolling(10, min_periods=1).std()
    
    # í™©ê¸ˆ íŒ¨í„´
    df['golden_pattern'] = ((df['M14AM14B'] >= 350) & (df['M14AM10A'] < 70)).astype(float)
    
    # ê¸‰ì¦ ì‹ í˜¸
    for threshold in [250, 300, 350, 400, 450]:
        df[f'signal_{threshold}'] = (df['M14AM14B'] >= threshold).astype(float)
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df = df.fillna(0)
    df = df.dropna(subset=['target'])
    
    # íŠ¹ì§• ê°œìˆ˜ ì¡°ì • (í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ)
    print(f"  í˜„ì¬ íŠ¹ì§• ê°œìˆ˜: {len(df.columns)}ê°œ")
    
    # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ íŠ¹ì§•ë§Œ ì„ íƒ (ë˜ëŠ” íŠ¹ì§• ê°œìˆ˜ ë§ì¶”ê¸°)
    if len(df.columns) > Config.NUM_FEATURES:
        # ì¤‘ìš”í•œ ì»¬ëŸ¼ ìš°ì„  ì„ íƒ
        important_cols = ['TOTALCNT', 'M14AM14B', 'M14AM10A', 'M14AM16', 'M14AM14BSUM',
                         'ratio_14B_10A', 'ratio_14B_16', 'ratio_10A_16', 'golden_pattern']
        
        # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ ì¶”ê°€
        other_cols = [col for col in df.columns if col not in important_cols and col != 'target']
        
        # ì´ NUM_FEATURES ê°œë§Œ ì„ íƒ
        selected_cols = important_cols[:min(len(important_cols), Config.NUM_FEATURES)]
        remaining = Config.NUM_FEATURES - len(selected_cols)
        if remaining > 0:
            selected_cols.extend(other_cols[:remaining])
        
        # target ì»¬ëŸ¼ ì¶”ê°€
        selected_cols.append('target')
        df = df[selected_cols]
    
    elif len(df.columns) < Config.NUM_FEATURES + 1:  # +1 for target
        # ë¶€ì¡±í•œ íŠ¹ì§• ì¶”ê°€ (0ìœ¼ë¡œ ì±„ì›€)
        while len(df.columns) < Config.NUM_FEATURES + 1:
            df[f'dummy_{len(df.columns)}'] = 0
    
    print(f"  ì¡°ì •ëœ íŠ¹ì§• ê°œìˆ˜: {len(df.columns)-1}ê°œ (target ì œì™¸)")
    
    return df

def create_sequences(df, lookback=100, forecast=10):
    """ì‹œí€€ìŠ¤ ìƒì„±"""
    print("\nâš¡ í‰ê°€ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
    
    X, y = [], []
    
    # target ì»¬ëŸ¼ ì œì™¸í•œ ë°ì´í„°
    feature_cols = [col for col in df.columns if col != 'target']
    data_array = df[feature_cols].values
    target_array = df['target'].values
    
    for i in range(len(data_array) - lookback):
        if i + lookback < len(target_array) and not np.isnan(target_array[i + lookback]):
            X.append(data_array[i:i+lookback])
            y.append(target_array[i + lookback])
    
    X = np.array(X, dtype=np.float32)
    y = np.array(y, dtype=np.float32)
    
    print(f"  X shape: {X.shape}")
    print(f"  y shape: {y.shape}")
    print(f"  y ë²”ìœ„: {y.min():.0f} ~ {y.max():.0f}")
    
    # íŠ¹ì§• ê°œìˆ˜ í™•ì¸
    if X.shape[2] != Config.NUM_FEATURES:
        print(f"  âš ï¸ íŠ¹ì§• ê°œìˆ˜ ë¶ˆì¼ì¹˜: {X.shape[2]} vs {Config.NUM_FEATURES}")
        print(f"  íŠ¹ì§• ê°œìˆ˜ ì¡°ì • ì¤‘...")
        
        if X.shape[2] > Config.NUM_FEATURES:
            X = X[:, :, :Config.NUM_FEATURES]
        else:
            # ë¶€ì¡±í•œ íŠ¹ì§• 0ìœ¼ë¡œ ì±„ì›€
            padding = np.zeros((X.shape[0], X.shape[1], Config.NUM_FEATURES - X.shape[2]))
            X = np.concatenate([X, padding], axis=2)
        
        print(f"  ì¡°ì •ëœ X shape: {X.shape}")
    
    return X, y, df

# ============================================
# ì§ì ‘ ì˜ˆì¸¡ í•¨ìˆ˜
# ============================================
def direct_prediction(X_test, m14_test):
    """í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•œ ì§ì ‘ ì˜ˆì¸¡"""
    print("\nğŸ”® ì§ì ‘ ì˜ˆì¸¡ ì‹œë„...")
    
    predictions = {}
    results = {}
    
    # LSTM ê°€ì¤‘ì¹˜ë¡œ ì˜ˆì¸¡ ì‹œë„
    lstm_path = os.path.join(Config.MODEL_DIR, 'lstm_final.keras')
    if os.path.exists(lstm_path):
        try:
            # ê°„ë‹¨í•œ LSTM ëª¨ë¸ ìƒì„±
            model = tf.keras.Sequential([
                tf.keras.layers.InputLayer(input_shape=(100, Config.NUM_FEATURES)),
                tf.keras.layers.LSTM(256, return_sequences=True),
                tf.keras.layers.LSTM(128, return_sequences=True),
                tf.keras.layers.LSTM(64),
                tf.keras.layers.Dense(256, activation='relu'),
                tf.keras.layers.Dropout(0.3),
                tf.keras.layers.Dense(128, activation='relu'),
                tf.keras.layers.Dropout(0.2),
                tf.keras.layers.Dense(64, activation='relu'),
                tf.keras.layers.Dense(1)
            ])
            
            # ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹œë„
            model.load_weights(lstm_path)
            
            # ì˜ˆì¸¡
            pred = model.predict(X_test, batch_size=Config.BATCH_SIZE, verbose=0).flatten()
            predictions['lstm_direct'] = pred
            
            print("  âœ… LSTM ì§ì ‘ ì˜ˆì¸¡ ì„±ê³µ")
            
        except Exception as e:
            print(f"  âŒ LSTM ì§ì ‘ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)[:100]}")
    
    return predictions, results

# ============================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ============================================
def main():
    """ë©”ì¸ í‰ê°€ í”„ë¡œì„¸ìŠ¤"""
    
    try:
        # 0. ëª¨ë¸ êµ¬ì¡° í™•ì¸
        check_model_structure()
        
        # 1. í‰ê°€ ë°ì´í„° ì¤€ë¹„
        df = prepare_evaluation_data(Config.EVAL_DATA_FILE)
        
        # 2. ì‹œí€€ìŠ¤ ìƒì„±
        X, y, df_processed = create_sequences(df, Config.LOOKBACK, Config.FORECAST)
        
        if len(X) == 0:
            print("\nâŒ ì‹œí€€ìŠ¤ ìƒì„± ì‹¤íŒ¨ - ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return
        
        # 3. M14 íŠ¹ì§• ì¶”ì¶œ
        print("\nğŸ“Š M14 íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
        m14_features = np.zeros((len(X), 4), dtype=np.float32)
        
        # M14 ì»¬ëŸ¼ ì°¾ê¸°
        if 'M14AM14B' in df_processed.columns:
            m14b_idx = df_processed.columns.get_loc('M14AM14B')
            m10a_idx = df_processed.columns.get_loc('M14AM10A') if 'M14AM10A' in df_processed.columns else -1
            m16_idx = df_processed.columns.get_loc('M14AM16') if 'M14AM16' in df_processed.columns else -1
            ratio_idx = df_processed.columns.get_loc('ratio_14B_10A') if 'ratio_14B_10A' in df_processed.columns else -1
            
            for i in range(len(X)):
                if m14b_idx >= 0:
                    m14_features[i, 0] = X[i, -1, m14b_idx]  # ë§ˆì§€ë§‰ ì‹œì ì˜ M14B
                if m10a_idx >= 0:
                    m14_features[i, 1] = X[i, -1, m10a_idx]
                if m16_idx >= 0:
                    m14_features[i, 2] = X[i, -1, m16_idx]
                if ratio_idx >= 0:
                    m14_features[i, 3] = X[i, -1, ratio_idx]
        
        # 4. ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        print("\nğŸ“ ë°ì´í„° ìŠ¤ì¼€ì¼ë§...")
        
        X_scaled = np.zeros_like(X)
        for i in range(X.shape[2]):
            scaler = RobustScaler()
            feature = X[:, :, i].reshape(-1, 1)
            X_scaled[:, :, i] = scaler.fit_transform(feature).reshape(X[:, :, i].shape)
        
        m14_scaler = RobustScaler()
        m14_features_scaled = m14_scaler.fit_transform(m14_features)
        
        print("  âœ… ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ")
        
        # 5. ì˜ˆì¸¡ ì‹œë„
        print("\n" + "="*60)
        print("ğŸ“Š í‰ê°€ ì‹œì‘")
        print("="*60)
        
        # 5-1. ì§ì ‘ ì˜ˆì¸¡ ì‹œë„
        predictions_direct, results_direct = direct_prediction(X_scaled, m14_features_scaled)
        
        # 5-2. ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡
        predictions_simple, results_simple = create_simple_predictor(X_scaled, y, m14_features)
        
        # ê²°ê³¼ í†µí•©
        all_predictions = {**predictions_direct, **predictions_simple}
        all_results = {**results_direct, **results_simple}
        
        # 6. ì„±ëŠ¥ í‰ê°€
        if all_predictions:
            print("\nğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼:")
            print("-"*60)
            
            for name, pred in all_predictions.items():
                mae = np.mean(np.abs(y - pred))
                rmse = np.sqrt(np.mean((y - pred) ** 2))
                accuracy_50 = np.mean(np.abs(y - pred) <= 50) * 100
                accuracy_100 = np.mean(np.abs(y - pred) <= 100) * 100
                
                print(f"\n{name.upper()}:")
                print(f"  MAE: {mae:.2f}")
                print(f"  RMSE: {rmse:.2f}")
                print(f"  ì •í™•ë„(Â±50): {accuracy_50:.1f}%")
                print(f"  ì •í™•ë„(Â±100): {accuracy_100:.1f}%")
                
                all_results[name] = {
                    'mae': float(mae),
                    'rmse': float(rmse),
                    'accuracy_50': float(accuracy_50),
                    'accuracy_100': float(accuracy_100)
                }
            
            # 7. ê²°ê³¼ ì €ì¥
            json_path = f"{Config.EVAL_RESULT_DIR}evaluation_results.json"
            with open(json_path, 'w') as f:
                json.dump(all_results, f, indent=2)
            print(f"\nğŸ“ ê²°ê³¼ ì €ì¥: {json_path}")
        
        else:
            print("\nâš ï¸ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
            print("  1. ëª¨ë¸ì„ ë‹¤ì‹œ í•™ìŠµì‹œí‚¤ì„¸ìš”")
            print("  2. TensorFlow ë²„ì „ì„ í™•ì¸í•˜ì„¸ìš” (2.15.0 ê¶Œì¥)")
            print("  3. í•™ìŠµê³¼ í‰ê°€ ì½”ë“œì˜ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§ì´ ë™ì¼í•œì§€ í™•ì¸í•˜ì„¸ìš”")
        
        print("\n" + "="*60)
        print("âœ… í‰ê°€ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()