"""
V6 ëª¨ë¸ í‰ê°€ ì‹œìŠ¤í…œ - ì‹¤ì „ ë²„ì „
- TensorFlow 2.16.1 ì™„ë²½ í˜¸í™˜
- ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡ + ë”¥ëŸ¬ë‹ ëª¨ë¸ í‰ê°€
- ì‹¤ì œ ì‘ë™ ê²€ì¦ë¨
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import json
import warnings
from datetime import datetime
import os
warnings.filterwarnings('ignore')

print("="*60)
print("ğŸ”¬ V6 ëª¨ë¸ í‰ê°€ ì‹œìŠ¤í…œ - ì‹¤ì „ ë²„ì „")
print(f"ğŸ“¦ TensorFlow: {tf.__version__}")
print("="*60)

# ============================================
# ì„¤ì •
# ============================================
class Config:
    # í‰ê°€ ë°ì´í„°
    EVAL_DATA_FILE = './data/20250731_to_20250826.csv'
    
    # ëª¨ë¸ ê²½ë¡œ
    MODEL_DIR = './models_v6_full_train/'
    
    # ì‹œí€€ìŠ¤ ì„¤ì •
    LOOKBACK = 100  # ê³¼ê±° 100ë¶„
    FORECAST = 10   # 10ë¶„ í›„ ì˜ˆì¸¡
    
    # ê²°ê³¼ ì €ì¥
    OUTPUT_DIR = './evaluation_results/'
    PLOT_DIR = './evaluation_plots/'
    
    # ë°°ì¹˜ í¬ê¸°
    BATCH_SIZE = 32
    
    # íŠ¹ì§• ê°œìˆ˜ (í•™ìŠµê³¼ ë™ì¼)
    NUM_FEATURES = 47

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(Config.OUTPUT_DIR, exist_ok=True)
os.makedirs(Config.PLOT_DIR, exist_ok=True)

# ============================================
# ê°•ë ¥í•œ ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡ê¸°
# ============================================
class RuleBasedPredictor:
    """M14 ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡ê¸°"""
    
    def __init__(self):
        self.thresholds = {
            'M14B': [250, 300, 350, 400, 450],
            'predictions': [1350, 1400, 1450, 1500, 1550],
            'ratios': [3.0, 4.0, 4.5, 5.0, 5.5],
            'adjustments': [1.02, 1.05, 1.08, 1.10, 1.15]
        }
    
    def predict(self, X, m14_features):
        """ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡"""
        predictions = []
        
        for i in range(len(X)):
            # ìµœê·¼ TOTALCNT ê°’ë“¤ (4ë²ˆì§¸ ì»¬ëŸ¼)
            try:
                recent_values = X[i, -20:, 4]  # TOTALCNT ìœ„ì¹˜
            except:
                recent_values = X[i, -20:, 3]  # ë‹¤ë¥¸ ìœ„ì¹˜ ì‹œë„
            
            current_value = recent_values[-1]
            recent_avg = np.mean(recent_values)
            recent_trend = np.polyfit(range(len(recent_values)), recent_values, 1)[0]
            
            # M14 íŠ¹ì§•
            m14b = m14_features[i, 0] if len(m14_features[i]) > 0 else 0
            m10a = m14_features[i, 1] if len(m14_features[i]) > 1 else 1
            m16 = m14_features[i, 2] if len(m14_features[i]) > 2 else 0
            
            # ê¸°ë³¸ ì˜ˆì¸¡ (íŠ¸ë Œë“œ ê¸°ë°˜)
            base_pred = recent_avg + recent_trend * Config.FORECAST
            
            # M14B ì„ê³„ê°’ ê¸°ë°˜ ì¡°ì •
            for j, threshold in enumerate(self.thresholds['M14B']):
                if m14b >= threshold:
                    base_pred = max(base_pred, self.thresholds['predictions'][j])
            
            # ë¹„ìœ¨ ê¸°ë°˜ ì¡°ì •
            if m10a > 0:
                ratio = m14b / m10a
                for j, ratio_threshold in enumerate(self.thresholds['ratios']):
                    if ratio >= ratio_threshold:
                        base_pred *= self.thresholds['adjustments'][j]
            
            # í™©ê¸ˆ íŒ¨í„´
            if m14b >= 350 and m10a < 70:
                base_pred *= 1.2
            
            # ë²”ìœ„ ì œí•œ
            base_pred = np.clip(base_pred, 1200, 2000)
            
            predictions.append(base_pred)
        
        return np.array(predictions)

# ============================================
# ëª¨ë¸ êµ¬ì¡° ì¬ìƒì„± (TF 2.16.1ìš©)
# ============================================
def create_model_structures():
    """TF 2.16.1ìš© ëª¨ë¸ êµ¬ì¡°ë§Œ ìƒì„±"""
    
    models = {}
    
    # 1. LSTM
    lstm = tf.keras.Sequential([
        tf.keras.layers.InputLayer(shape=(Config.LOOKBACK, Config.NUM_FEATURES)),
        tf.keras.layers.LSTM(256, return_sequences=True, dropout=0.2),
        tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.2),
        tf.keras.layers.LSTM(64, dropout=0.2),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(1)
    ], name='LSTM_Model_v216')
    models['lstm'] = lstm
    
    # 2. GRU  
    gru = tf.keras.Sequential([
        tf.keras.layers.InputLayer(shape=(Config.LOOKBACK, Config.NUM_FEATURES)),
        tf.keras.layers.GRU(256, return_sequences=True, dropout=0.15),
        tf.keras.layers.GRU(128, return_sequences=True, dropout=0.15),
        tf.keras.layers.GRU(64, dropout=0.15),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(1)
    ], name='GRU_Model_v216')
    models['gru'] = gru
    
    print("âœ… ëª¨ë¸ êµ¬ì¡° ìƒì„± ì™„ë£Œ")
    
    return models

# ============================================
# ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹œë„
# ============================================
def try_load_weights(models):
    """ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹œë„"""
    
    loaded_models = {}
    
    for name, model in models.items():
        weight_files = [
            f"{Config.MODEL_DIR}{name}_final.keras",
            f"{Config.MODEL_DIR}{name}_best.keras",
            f"{Config.MODEL_DIR}{name}.weights.h5",
        ]
        
        loaded = False
        for weight_file in weight_files:
            if os.path.exists(weight_file):
                try:
                    model.load_weights(weight_file)
                    loaded_models[name] = model
                    loaded = True
                    print(f"âœ… {name} ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ: {weight_file}")
                    break
                except Exception as e:
                    print(f"âš ï¸ {name} ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {str(e)[:50]}")
        
        if not loaded:
            print(f"âš ï¸ {name} - ëœë¤ ì´ˆê¸°í™” ì‚¬ìš©")
            loaded_models[name] = model
    
    return loaded_models

# ============================================
# ë°ì´í„° ì¤€ë¹„
# ============================================
def prepare_data(file_path):
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    print(f"\nğŸ“‚ ë°ì´í„° ë¡œë“œ: {file_path}")
    
    df = pd.read_csv(file_path)
    print(f"  ì›ë³¸: {len(df)}í–‰")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required = ['M14AM10A', 'M14AM14B', 'M14AM16', 'TOTALCNT']
    for col in required:
        if col not in df.columns:
            print(f"  âš ï¸ {col} ì—†ìŒ - 0ìœ¼ë¡œ ì´ˆê¸°í™”")
            df[col] = 0
    
    if 'M14AM14BSUM' not in df.columns:
        df['M14AM14BSUM'] = df['M14AM14B'] + df['M14AM10A']
    
    print(f"  TOTALCNT ë²”ìœ„: {df['TOTALCNT'].min():.0f} ~ {df['TOTALCNT'].max():.0f}")
    
    # íŠ¹ì§• ìƒì„± (í•™ìŠµê³¼ ë™ì¼í•˜ê²Œ)
    print("  íŠ¹ì§• ìƒì„± ì¤‘...")
    
    # ë¹„ìœ¨
    df['ratio_14B_10A'] = df['M14AM14B'] / (df['M14AM10A'] + 1)
    df['ratio_14B_16'] = df['M14AM14B'] / (df['M14AM16'] + 1)
    df['ratio_10A_16'] = df['M14AM10A'] / (df['M14AM16'] + 1)
    
    # ì‹œê³„ì—´ íŠ¹ì§•
    feature_columns = ['M14AM10A', 'M14AM14B', 'M14AM16', 'M14AM14BSUM', 'TOTALCNT']
    for col in feature_columns:
        # ë³€í™”ëŸ‰
        df[f'{col}_diff_1'] = df[col].diff(1)
        df[f'{col}_diff_5'] = df[col].diff(5)
        df[f'{col}_diff_10'] = df[col].diff(10)
        
        # ì´ë™í‰ê· 
        df[f'{col}_ma_5'] = df[col].rolling(5, min_periods=1).mean()
        df[f'{col}_ma_10'] = df[col].rolling(10, min_periods=1).mean()
        
        # í‘œì¤€í¸ì°¨
        df[f'{col}_std_5'] = df[col].rolling(5, min_periods=1).std()
        df[f'{col}_std_10'] = df[col].rolling(10, min_periods=1).std()
    
    # í™©ê¸ˆ íŒ¨í„´
    df['golden_pattern'] = ((df['M14AM14B'] >= 350) & (df['M14AM10A'] < 70)).astype(float)
    
    # ì‹ í˜¸
    thresholds = {1300: 250, 1400: 300, 1450: 350, 1500: 380}
    for level, threshold in thresholds.items():
        df[f'signal_{level}'] = (df['M14AM14B'] >= threshold).astype(float)
    
    ratio_thresholds = {1300: 3.5, 1400: 4.0, 1450: 4.5, 1500: 5.0}
    for level, ratio in ratio_thresholds.items():
        df[f'ratio_signal_{level}'] = (df['ratio_14B_10A'] >= ratio).astype(float)
    
    df = df.fillna(0)
    
    # íŠ¹ì§• ê°œìˆ˜ ë§ì¶”ê¸° (47ê°œ)
    print(f"  í˜„ì¬ íŠ¹ì§• ìˆ˜: {len(df.columns)}ê°œ")
    
    if len(df.columns) > Config.NUM_FEATURES:
        df = df.iloc[:, :Config.NUM_FEATURES]
    elif len(df.columns) < Config.NUM_FEATURES:
        for i in range(Config.NUM_FEATURES - len(df.columns)):
            df[f'pad_{i}'] = 0
    
    print(f"  ìµœì¢… íŠ¹ì§• ìˆ˜: {len(df.columns)}ê°œ")
    
    return df

def create_sequences(df):
    """ì‹œí€€ìŠ¤ ìƒì„±"""
    X, y = [], []
    
    data = df.values
    
    for i in range(len(data) - Config.LOOKBACK - Config.FORECAST):
        X.append(data[i:i+Config.LOOKBACK])
        # TOTALCNT ìœ„ì¹˜ ì°¾ê¸°
        totalcnt_idx = 4  # ê¸°ë³¸ ìœ„ì¹˜
        y.append(data[i+Config.LOOKBACK+Config.FORECAST-1, totalcnt_idx])
    
    X = np.array(X, dtype=np.float32)
    y = np.array(y, dtype=np.float32)
    
    return X, y

# ============================================
# í‰ê°€ í•¨ìˆ˜
# ============================================
def evaluate(y_true, y_pred, name):
    """ì„±ëŠ¥ í‰ê°€"""
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    
    # ì •í™•ë„
    acc_50 = np.mean(np.abs(y_true - y_pred) <= 50) * 100
    acc_100 = np.mean(np.abs(y_true - y_pred) <= 100) * 100
    
    # ê¸‰ì¦ ê°ì§€
    spike_performance = {}
    for level in [1400, 1450, 1500]:
        actual_spike = y_true >= level
        pred_spike = y_pred >= level
        
        if np.sum(actual_spike) > 0:
            recall = np.sum(actual_spike & pred_spike) / np.sum(actual_spike)
            precision = np.sum(actual_spike & pred_spike) / max(np.sum(pred_spike), 1)
            f1 = 2 * (precision * recall) / max(precision + recall, 1e-10)
            
            spike_performance[level] = {
                'recall': recall * 100,
                'precision': precision * 100,
                'f1': f1 * 100
            }
    
    print(f"\nğŸ“Š {name} ì„±ëŠ¥:")
    print(f"  MAE: {mae:.2f}")
    print(f"  RMSE: {rmse:.2f}")
    print(f"  RÂ²: {r2:.4f}")
    print(f"  ì •í™•ë„(Â±50): {acc_50:.1f}%")
    print(f"  ì •í™•ë„(Â±100): {acc_100:.1f}%")
    
    for level, perf in spike_performance.items():
        print(f"  {level}+ ê°ì§€: F1={perf['f1']:.1f}%, Recall={perf['recall']:.1f}%")
    
    return {
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'acc_50': acc_50,
        'acc_100': acc_100,
        'spike': spike_performance
    }

# ============================================
# ì‹œê°í™”
# ============================================
def visualize_results(y_true, predictions, results):
    """ê²°ê³¼ ì‹œê°í™”"""
    
    plt.figure(figsize=(15, 10))
    
    # 1. ì˜ˆì¸¡ vs ì‹¤ì œ
    plt.subplot(2, 3, 1)
    best_model = min(results.keys(), key=lambda x: results[x]['mae'])
    sample_size = min(500, len(y_true))
    plt.scatter(y_true[:sample_size], predictions[best_model][:sample_size], alpha=0.5)
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')
    plt.xlabel('Actual')
    plt.ylabel('Predicted')
    plt.title(f'{best_model} - Predictions')
    
    # 2. MAE ë¹„êµ
    plt.subplot(2, 3, 2)
    names = list(results.keys())
    maes = [results[n]['mae'] for n in names]
    plt.bar(names, maes)
    plt.ylabel('MAE')
    plt.title('Model Comparison')
    plt.xticks(rotation=45)
    
    # 3. ì‹œê³„ì—´
    plt.subplot(2, 3, 3)
    sample = min(200, len(y_true))
    plt.plot(y_true[:sample], label='Actual', linewidth=2)
    plt.plot(predictions[best_model][:sample], label=f'{best_model}', alpha=0.7)
    plt.legend()
    plt.title('Time Series')
    
    # 4. ì˜¤ì°¨ ë¶„í¬
    plt.subplot(2, 3, 4)
    errors = predictions[best_model] - y_true
    plt.hist(errors, bins=50, alpha=0.7)
    plt.axvline(0, color='red', linestyle='--')
    plt.xlabel('Error')
    plt.ylabel('Frequency')
    plt.title('Error Distribution')
    
    # 5. ì •í™•ë„ ë¹„êµ
    plt.subplot(2, 3, 5)
    acc_50 = [results[n]['acc_50'] for n in names]
    acc_100 = [results[n]['acc_100'] for n in names]
    x = np.arange(len(names))
    plt.bar(x - 0.2, acc_50, 0.4, label='Â±50')
    plt.bar(x + 0.2, acc_100, 0.4, label='Â±100')
    plt.xticks(x, names, rotation=45)
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.title('Prediction Accuracy')
    
    # 6. RÂ² ë¹„êµ
    plt.subplot(2, 3, 6)
    r2_scores = [results[n]['r2'] for n in names]
    plt.bar(names, r2_scores)
    plt.ylabel('RÂ² Score')
    plt.title('Model RÂ² Comparison')
    plt.xticks(rotation=45)
    plt.ylim(-0.1, 1.0)
    
    plt.tight_layout()
    save_path = f'{Config.PLOT_DIR}evaluation_results.png'
    plt.savefig(save_path, dpi=150)
    print(f"\nğŸ“ˆ ì‹œê°í™” ì €ì¥: {save_path}")
    plt.close()

# ============================================
# ë©”ì¸ ì‹¤í–‰
# ============================================
def main():
    print("\nğŸš€ í‰ê°€ ì‹œì‘...")
    
    try:
        # 1. ë°ì´í„° ì¤€ë¹„
        df = prepare_data(Config.EVAL_DATA_FILE)
        X, y = create_sequences(df)
        
        print(f"\nğŸ“Š ë°ì´í„° shape:")
        print(f"  X: {X.shape}")
        print(f"  y: {y.shape}")
        print(f"  y ë²”ìœ„: {y.min():.0f} ~ {y.max():.0f}")
        
        # 2. M14 íŠ¹ì§• ì¶”ì¶œ
        m14_features = np.zeros((len(X), 4))
        m14_features[:, 0] = X[:, -1, 1]  # M14AM14B
        m14_features[:, 1] = X[:, -1, 0]  # M14AM10A
        m14_features[:, 2] = X[:, -1, 2]  # M14AM16
        m14_features[:, 3] = X[:, -1, 1] / (X[:, -1, 0] + 1)  # ë¹„ìœ¨
        
        # 3. ìŠ¤ì¼€ì¼ë§
        print("\nğŸ“ ìŠ¤ì¼€ì¼ë§...")
        X_scaled = np.zeros_like(X)
        for i in range(X.shape[2]):
            scaler = RobustScaler()
            feature = X[:, :, i].reshape(-1, 1)
            X_scaled[:, :, i] = scaler.fit_transform(feature).reshape(X[:, :, i].shape)
        
        m14_scaler = RobustScaler()
        m14_scaled = m14_scaler.fit_transform(m14_features)
        
        # 4. ì˜ˆì¸¡
        predictions = {}
        results = {}
        
        # 4-1. ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡ (í•µì‹¬!)
        print("\nğŸ¯ ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡...")
        rule_predictor = RuleBasedPredictor()
        rule_pred = rule_predictor.predict(X, m14_features)
        predictions['rule_based'] = rule_pred
        results['rule_based'] = evaluate(y, rule_pred, 'Rule-Based')
        
        # 4-2. ë² ì´ìŠ¤ë¼ì¸ (ë‹¨ìˆœ í‰ê· )
        print("\nğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ì˜ˆì¸¡...")
        baseline_pred = np.array([np.mean(X[i, -10:, 4]) for i in range(len(X))])
        predictions['baseline'] = baseline_pred
        results['baseline'] = evaluate(y, baseline_pred, 'Baseline')
        
        # 4-3. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì‹œë„ (ì˜µì…˜)
        print("\nğŸ¤– ë”¥ëŸ¬ë‹ ëª¨ë¸ ì‹œë„...")
        models = create_model_structures()
        loaded_models = try_load_weights(models)
        
        for name, model in loaded_models.items():
            try:
                pred = model.predict(X_scaled, batch_size=Config.BATCH_SIZE, verbose=0)
                predictions[name] = pred.flatten()
                results[name] = evaluate(y, predictions[name], name.upper())
            except Exception as e:
                print(f"  âŒ {name} ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)[:100]}")
        
        # 5. ìµœê³  ëª¨ë¸ ì„ íƒ
        if results:
            best = min(results.keys(), key=lambda x: results[x]['mae'])
            print("\n" + "="*60)
            print(f"ğŸ† ìµœê³  ì„±ëŠ¥: {best.upper()}")
            print(f"   MAE: {results[best]['mae']:.2f}")
            print(f"   RMSE: {results[best]['rmse']:.2f}")
            print(f"   RÂ²: {results[best]['r2']:.4f}")
            print(f"   ì •í™•ë„(Â±50): {results[best]['acc_50']:.1f}%")
            print(f"   ì •í™•ë„(Â±100): {results[best]['acc_100']:.1f}%")
            print("="*60)
            
            # ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”
            print("\nğŸ“Š ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ:")
            print("-"*70)
            print(f"{'ëª¨ë¸':<15} {'MAE':<10} {'RMSE':<10} {'RÂ²':<10} {'Â±50(%)':<10} {'Â±100(%)':<10}")
            print("-"*70)
            
            for name, result in sorted(results.items(), key=lambda x: x[1]['mae']):
                print(f"{name:<15} {result['mae']:<10.2f} {result['rmse']:<10.2f} "
                      f"{result['r2']:<10.4f} {result['acc_50']:<10.1f} {result['acc_100']:<10.1f}")
            print("-"*70)
        
        # 6. ì˜ˆì¸¡ ê²°ê³¼ CSV ì €ì¥
        print("\nğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥...")
        
        results_df = pd.DataFrame({
            'ì‹¤ì œê°’': y,
            'Rule_Based_ì˜ˆì¸¡': predictions['rule_based'],
            'Baseline_ì˜ˆì¸¡': predictions['baseline'],
            'Rule_ì˜¤ì°¨': predictions['rule_based'] - y,
            'Baseline_ì˜¤ì°¨': predictions['baseline'] - y,
            'Rule_ì ˆëŒ€ì˜¤ì°¨': np.abs(predictions['rule_based'] - y),
            'Baseline_ì ˆëŒ€ì˜¤ì°¨': np.abs(predictions['baseline'] - y),
            '50ì´ë‚´_ì •í™•': np.abs(predictions['rule_based'] - y) <= 50,
            '100ì´ë‚´_ì •í™•': np.abs(predictions['rule_based'] - y) <= 100,
        })
        
        # ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        for name in ['lstm', 'gru']:
            if name in predictions:
                results_df[f'{name.upper()}_ì˜ˆì¸¡'] = predictions[name]
                results_df[f'{name.upper()}_ì˜¤ì°¨'] = np.abs(predictions[name] - y)
        
        csv_path = f'{Config.OUTPUT_DIR}prediction_results.csv'
        results_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"  âœ… CSV ì €ì¥: {csv_path}")
        
        # ìš”ì•½ í†µê³„
        print("\nğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½:")
        print(f"  ì „ì²´ ìƒ˜í”Œ: {len(results_df):,}ê°œ")
        print(f"  Rule MAE: {results_df['Rule_ì ˆëŒ€ì˜¤ì°¨'].mean():.2f}")
        print(f"  Baseline MAE: {results_df['Baseline_ì ˆëŒ€ì˜¤ì°¨'].mean():.2f}")
        print(f"  50 ì´ë‚´: {results_df['50ì´ë‚´_ì •í™•'].sum():,}ê°œ ({results_df['50ì´ë‚´_ì •í™•'].mean()*100:.1f}%)")
        print(f"  100 ì´ë‚´: {results_df['100ì´ë‚´_ì •í™•'].sum():,}ê°œ ({results_df['100ì´ë‚´_ì •í™•'].mean()*100:.1f}%)")
        
        # ê¸‰ì¦ ë¶„ì„
        print("\nğŸ¯ ê¸‰ì¦ êµ¬ê°„(1400+) ë¶„ì„:")
        spike_mask = y >= 1400
        if spike_mask.sum() > 0:
            spike_actual = y[spike_mask]
            spike_rule = predictions['rule_based'][spike_mask]
            spike_mae = np.mean(np.abs(spike_actual - spike_rule))
            spike_detected = (spike_rule >= 1400).sum()
            
            print(f"  ì‹¤ì œ ê¸‰ì¦: {spike_mask.sum()}íšŒ")
            print(f"  ì˜ˆì¸¡ ì„±ê³µ: {spike_detected}íšŒ ({spike_detected/spike_mask.sum()*100:.1f}%)")
            print(f"  ê¸‰ì¦ MAE: {spike_mae:.2f}")
        
        # 7. ê²°ê³¼ JSON ì €ì¥
        json_path = f'{Config.OUTPUT_DIR}evaluation_results.json'
        with open(json_path, 'w') as f:
            json.dump(results, f, indent=2, default=float)
        print(f"\n  âœ… JSON ì €ì¥: {json_path}")
        
        # 8. ì‹œê°í™”
        if len(predictions) > 0:
            visualize_results(y, predictions, results)
        
        print("\nâœ… í‰ê°€ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {Config.OUTPUT_DIR}")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()