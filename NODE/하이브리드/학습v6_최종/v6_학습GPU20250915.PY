"""
V7_GPU_í•™ìŠµ_ì™„ì „íŒ.py - GPU ê°€ì† 5ê°œ ëª¨ë¸ ì•™ìƒë¸” í•™ìŠµ
ì˜¤ë¥˜ ìˆ˜ì • ì™„ë£Œ - TensorFlow 2.15.0 GPU ìµœì í™”
"""

import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import json
import os
import warnings
import pickle
from datetime import datetime
import gc
warnings.filterwarnings('ignore')

# ============================================
# GPU ì„¤ì • ë° ìµœì í™”
# ============================================
def setup_gpu():
    """GPU ì„¤ì •"""
    print("\nğŸ® GPU í™˜ê²½ ì„¤ì • ì¤‘...")
    
    gpus = tf.config.list_physical_devices('GPU')
    
    if gpus:
        try:
            # ë©”ëª¨ë¦¬ ë™ì  ì¦ê°€
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            
            print(f"âœ… GPU ê°ì§€: {len(gpus)}ê°œ")
            
            # GPU ì •ë³´
            for i, gpu in enumerate(gpus):
                print(f"  GPU {i}: {gpu.name}")
            
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
            with tf.device('/GPU:0'):
                test = tf.constant([[1.0, 2.0], [3.0, 4.0]])
                result = tf.matmul(test, test)
                print(f"  GPU í…ŒìŠ¤íŠ¸: âœ… (ê²°ê³¼: {result[0][0]:.0f})")
            
            return True
            
        except Exception as e:
            print(f"âš ï¸ GPU ì„¤ì • ì˜¤ë¥˜: {e}")
            return False
    else:
        print("ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰")
        return False

print("="*60)
print("ğŸš€ GPU ê°€ì† ë°˜ë„ì²´ ë¬¼ë¥˜ ì˜ˆì¸¡ í•™ìŠµ V7")
print(f"ğŸ“¦ TensorFlow ë²„ì „: {tf.__version__}")
print("="*60)

has_gpu = setup_gpu()

# ============================================
# 1. ì„¤ì •
# ============================================
class Config:
    # ì‹œí€€ìŠ¤ íŒŒì¼
    SEQUENCE_FILE = './sequences_v6.npz'
    
    # GPU ìµœì í™” ë°°ì¹˜ í¬ê¸°
    if has_gpu:
        BATCH_SIZE = 128  # GPUìš©
    else:
        BATCH_SIZE = 64   # CPUìš©
    
    # í•™ìŠµ ì„¤ì •
    EPOCHS = 50  # í…ŒìŠ¤íŠ¸ìš© ì¤„ì„ (ì›ë˜ 150)
    LEARNING_RATE = 0.0005
    PATIENCE = 15
    
    # ëª¨ë¸ ì €ì¥
    MODEL_DIR = './models_v7_gpu/'
    CHECKPOINT_DIR = './checkpoints_v7_gpu/'
    
    # M14 ì„ê³„ê°’
    M14B_THRESHOLDS = {
        1400: 320,
        1500: 400,
        1600: 450,
        1700: 500
    }
    
    RATIO_THRESHOLDS = {
        1400: 4,
        1500: 5,
        1600: 6,
        1700: 7
    }

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(Config.MODEL_DIR, exist_ok=True)
os.makedirs(Config.CHECKPOINT_DIR, exist_ok=True)

# ============================================
# 2. ì»¤ìŠ¤í…€ ì†ì‹¤ í•¨ìˆ˜ (GPU ìµœì í™”)
# ============================================
class WeightedLoss(tf.keras.losses.Loss):
    """GPU ìµœì í™” ê°€ì¤‘ì¹˜ ì†ì‹¤ í•¨ìˆ˜"""
    
    def call(self, y_true, y_pred):
        y_true = tf.cast(y_true, tf.float32)
        y_pred = tf.cast(y_pred, tf.float32)
        
        mae = tf.abs(y_true - y_pred)
        
        # GPU ë²¡í„°í™” ì—°ì‚°
        weights = tf.ones_like(y_true)
        weights = tf.where(y_true >= 1700, 10.0, weights)
        weights = tf.where((y_true >= 1600) & (y_true < 1700), 8.0, weights)
        weights = tf.where((y_true >= 1500) & (y_true < 1600), 5.0, weights)
        weights = tf.where((y_true >= 1400) & (y_true < 1500), 3.0, weights)
        
        return tf.reduce_mean(mae * weights)

class M14RuleCorrection(tf.keras.layers.Layer):
    """M14 ê·œì¹™ ê¸°ë°˜ ë³´ì • ë ˆì´ì–´"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
    
    def call(self, inputs):
        pred, m14_features = inputs
        
        # íƒ€ì… ë³€í™˜
        pred = tf.cast(pred, tf.float32)
        m14_features = tf.cast(m14_features, tf.float32)
        
        # M14 íŠ¹ì§•
        m14b = m14_features[:, 0:1]
        m10a = m14_features[:, 1:2]
        ratio = m14_features[:, 3:4]
        
        # GPU ë³‘ë ¬ ì²˜ë¦¬
        pred = tf.where(
            (m14b >= 500) & (ratio >= 7),
            tf.maximum(pred, 1700),
            pred
        )
        
        pred = tf.where(
            (m14b >= 450) & (ratio >= 6),
            tf.maximum(pred, 1600),
            pred
        )
        
        pred = tf.where(
            (m14b >= 400) & (ratio >= 5),
            tf.maximum(pred, 1500),
            pred
        )
        
        pred = tf.where(
            m14b >= 320,
            tf.maximum(pred, 1400),
            pred
        )
        
        # í™©ê¸ˆ íŒ¨í„´
        golden = (m14b >= 350) & (m10a < 70)
        pred = tf.where(golden, pred * 1.1, pred)
        
        return pred

# ============================================
# 3. GPU ìµœì í™” ëª¨ë¸
# ============================================
class ModelsV7GPU:
    
    @staticmethod
    def build_lstm_gpu(input_shape):
        """GPU ìµœì í™” LSTM"""
        model = tf.keras.Sequential([
            tf.keras.layers.InputLayer(input_shape=input_shape),
            tf.keras.layers.LayerNormalization(),
            
            # CuDNN LSTM (GPU ê°€ì†)
            tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.2),
            tf.keras.layers.LSTM(64, dropout=0.2),
            
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(1)
        ], name='LSTM_GPU')
        
        return model
    
    @staticmethod
    def build_gru_gpu(input_shape):
        """GPU ìµœì í™” GRU"""
        model = tf.keras.Sequential([
            tf.keras.layers.InputLayer(input_shape=input_shape),
            tf.keras.layers.LayerNormalization(),
            
            # CuDNN GRU
            tf.keras.layers.GRU(128, return_sequences=True, dropout=0.2, reset_after=True),
            tf.keras.layers.GRU(64, dropout=0.2, reset_after=True),
            
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(1)
        ], name='GRU_GPU')
        
        return model
    
    @staticmethod
    def build_cnn_lstm_gpu(input_shape):
        """GPU ìµœì í™” CNN-LSTM"""
        inputs = tf.keras.Input(shape=input_shape)
        
        # ë³‘ë ¬ CNN
        conv1 = tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same')(inputs)
        conv2 = tf.keras.layers.Conv1D(32, 5, activation='relu', padding='same')(inputs)
        concat = tf.keras.layers.Concatenate()([conv1, conv2])
        
        norm = tf.keras.layers.BatchNormalization()(concat)
        
        # LSTM
        lstm = tf.keras.layers.LSTM(64, dropout=0.2)(norm)
        
        # Dense
        dense = tf.keras.layers.Dense(64, activation='relu')(lstm)
        dropout = tf.keras.layers.Dropout(0.3)(dense)
        output = tf.keras.layers.Dense(1)(dropout)
        
        return tf.keras.Model(inputs=inputs, outputs=output, name='CNN_LSTM_GPU')

# ============================================
# 4. ë°ì´í„° ë¡œë“œ
# ============================================
print("\nğŸ“‚ ì‹œí€€ìŠ¤ ë¡œë”© ì¤‘...")

# íŒŒì¼ í™•ì¸
if not os.path.exists(Config.SEQUENCE_FILE):
    print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {Config.SEQUENCE_FILE}")
    print("  sequences_v7_gpu.npz íŒŒì¼ì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”!")
    exit(1)

# ë°ì´í„° ë¡œë“œ
data = np.load(Config.SEQUENCE_FILE)
X = data['X'].astype(np.float32)
y = data['y'].astype(np.float32)
m14_features = data['m14_features'].astype(np.float32)

print(f"  âœ… ë¡œë“œ ì™„ë£Œ!")
print(f"  X shape: {X.shape}")
print(f"  y shape: {y.shape}")
print(f"  m14_features shape: {m14_features.shape}")
print(f"  ë©”ëª¨ë¦¬ ì‚¬ìš©: {(X.nbytes + y.nbytes) / 1024**3:.2f} GB")

# í•™ìŠµ/ê²€ì¦ ë¶„í• 
X_train, X_val, y_train, y_val, m14_train, m14_val = train_test_split(
    X, y, m14_features, test_size=0.2, random_state=42
)

print(f"\nğŸ“Š ë°ì´í„° ë¶„í• :")
print(f"  í•™ìŠµ: {X_train.shape[0]:,}ê°œ")
print(f"  ê²€ì¦: {X_val.shape[0]:,}ê°œ")

# ============================================
# 5. GPU ë°ì´í„° íŒŒì´í”„ë¼ì¸
# ============================================
if has_gpu:
    print("\nâš¡ GPU ë°ì´í„° íŒŒì´í”„ë¼ì¸ ìƒì„±...")
    
    # TensorFlow Dataset ìƒì„±
    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))
    train_dataset = train_dataset.batch(Config.BATCH_SIZE)
    train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)
    
    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))
    val_dataset = val_dataset.batch(Config.BATCH_SIZE)
    val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)
    
    print("  âœ… GPU íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ")

# ============================================
# 6. ëª¨ë¸ í•™ìŠµ
# ============================================
print("\n" + "="*60)
print("ğŸ‹ï¸ GPU ê°€ì† í•™ìŠµ ì‹œì‘")
print("="*60)

models = {}
history = {}

# 6.1 LSTM í•™ìŠµ
print("\n1ï¸âƒ£ LSTM GPU í•™ìŠµ")

lstm_model = ModelsV7GPU.build_lstm_gpu(X_train.shape[1:])
lstm_model.compile(
    optimizer=tf.keras.optimizers.Adam(Config.LEARNING_RATE),
    loss=WeightedLoss(),
    metrics=['mae']
)

# GPU ë˜ëŠ” CPU í•™ìŠµ
if has_gpu:
    with tf.device('/GPU:0'):
        lstm_history = lstm_model.fit(
            train_dataset,
            validation_data=val_dataset,
            epochs=Config.EPOCHS,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(
                    patience=Config.PATIENCE,
                    restore_best_weights=True
                ),
                tf.keras.callbacks.ReduceLROnPlateau(
                    patience=5,
                    factor=0.5
                )
            ],
            verbose=1
        )
else:
    lstm_history = lstm_model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=Config.EPOCHS,
        batch_size=Config.BATCH_SIZE,
        callbacks=[
            tf.keras.callbacks.EarlyStopping(patience=10)
        ],
        verbose=1
    )

models['lstm'] = lstm_model
history['lstm'] = lstm_history

# ë©”ëª¨ë¦¬ ì •ë¦¬
tf.keras.backend.clear_session()
gc.collect()

# 6.2 GRU í•™ìŠµ
print("\n2ï¸âƒ£ GRU GPU í•™ìŠµ")

gru_model = ModelsV7GPU.build_gru_gpu(X_train.shape[1:])
gru_model.compile(
    optimizer=tf.keras.optimizers.Adam(Config.LEARNING_RATE),
    loss=WeightedLoss(),
    metrics=['mae']
)

if has_gpu:
    with tf.device('/GPU:0'):
        gru_history = gru_model.fit(
            train_dataset,
            validation_data=val_dataset,
            epochs=Config.EPOCHS,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(patience=Config.PATIENCE)
            ],
            verbose=1
        )
else:
    gru_history = gru_model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=Config.EPOCHS,
        batch_size=Config.BATCH_SIZE,
        verbose=1
    )

models['gru'] = gru_model
history['gru'] = gru_history

# 6.3 CNN-LSTM í•™ìŠµ
print("\n3ï¸âƒ£ CNN-LSTM GPU í•™ìŠµ")

cnn_lstm_model = ModelsV7GPU.build_cnn_lstm_gpu(X_train.shape[1:])
cnn_lstm_model.compile(
    optimizer=tf.keras.optimizers.Adam(Config.LEARNING_RATE),
    loss=WeightedLoss(),
    metrics=['mae']
)

if has_gpu:
    with tf.device('/GPU:0'):
        cnn_lstm_history = cnn_lstm_model.fit(
            train_dataset,
            validation_data=val_dataset,
            epochs=Config.EPOCHS,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(patience=Config.PATIENCE)
            ],
            verbose=1
        )
else:
    cnn_lstm_history = cnn_lstm_model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=Config.EPOCHS,
        batch_size=Config.BATCH_SIZE,
        verbose=1
    )

models['cnn_lstm'] = cnn_lstm_model
history['cnn_lstm'] = cnn_lstm_history

# ============================================
# 7. í‰ê°€
# ============================================
print("\nğŸ“Š ëª¨ë¸ í‰ê°€")

evaluation_results = {}

for name, model in models.items():
    # ì˜ˆì¸¡
    if has_gpu:
        with tf.device('/GPU:0'):
            pred = model.predict(X_val, batch_size=256, verbose=0)
    else:
        pred = model.predict(X_val, verbose=0)
    
    pred = pred.flatten()
    
    # MAE ê³„ì‚°
    mae = np.mean(np.abs(y_val - pred))
    
    # êµ¬ê°„ë³„ ì„±ëŠ¥
    level_performance = {}
    for level in [1400, 1500, 1600, 1700]:
        mask = y_val >= level
        if np.any(mask):
            recall = np.sum((pred >= level) & mask) / np.sum(mask)
            level_mae = np.mean(np.abs(y_val[mask] - pred[mask]))
            level_performance[level] = {
                'recall': recall,
                'mae': level_mae,
                'count': np.sum(mask)
            }
    
    evaluation_results[name] = {
        'overall_mae': mae,
        'levels': level_performance
    }
    
    # ì¶œë ¥
    print(f"\nğŸ¯ {name.upper()} ëª¨ë¸:")
    print(f"  ì „ì²´ MAE: {mae:.2f}")
    for level, perf in level_performance.items():
        print(f"  {level}+: Recall={perf['recall']:.2%}, MAE={perf['mae']:.1f}")

# ìµœê³  ëª¨ë¸
best_model = min(evaluation_results.keys(), key=lambda x: evaluation_results[x]['overall_mae'])
print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best_model.upper()}")
print(f"  MAE: {evaluation_results[best_model]['overall_mae']:.2f}")

# ============================================
# 8. ëª¨ë¸ ì €ì¥
# ============================================
print("\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")

for name, model in models.items():
    save_path = f"{Config.MODEL_DIR}{name}_gpu.h5"
    model.save(save_path)
    print(f"  {name}_gpu.h5 ì €ì¥ ì™„ë£Œ")

# ê²°ê³¼ ì €ì¥
with open(f"{Config.MODEL_DIR}evaluation_results.json", 'w') as f:
    json.dump(evaluation_results, f, indent=2, default=str)

# ============================================
# 9. ì‹œê°í™”
# ============================================
print("\nğŸ“ˆ ê²°ê³¼ ì‹œê°í™”...")

fig, axes = plt.subplots(2, 2, figsize=(12, 8))

# í•™ìŠµ ê³¡ì„ 
for idx, (name, hist) in enumerate(history.items()):
    if idx < 3:
        ax = axes[idx // 2, idx % 2]
        
        if hasattr(hist, 'history'):
            loss = hist.history.get('loss', [])
            val_loss = hist.history.get('val_loss', [])
            
            ax.plot(loss, label='Train', alpha=0.8)
            ax.plot(val_loss, label='Val', alpha=0.8)
            ax.set_title(f'{name.upper()} GPU Training')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Loss')
            ax.legend()
            ax.grid(True, alpha=0.3)

# MAE ë¹„êµ
ax = axes[1, 1]
names = list(evaluation_results.keys())
maes = [evaluation_results[n]['overall_mae'] for n in names]

bars = ax.bar(names, maes, color=['blue', 'green', 'orange'])
ax.set_title('Model MAE Comparison')
ax.set_ylabel('MAE')

for bar, mae in zip(bars, maes):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
           f'{mae:.1f}', ha='center', va='bottom')

plt.tight_layout()
plt.savefig(f"{Config.MODEL_DIR}gpu_training_results.png")
plt.show()

# ============================================
# 10. ìµœì¢… ì¶œë ¥
# ============================================
print("\n" + "="*60)
print("ğŸ‰ GPU í•™ìŠµ ì™„ë£Œ!")
print("="*60)

if has_gpu:
    print("\nğŸ® GPU ì •ë³´:")
    for gpu in tf.config.list_physical_devices('GPU'):
        print(f"  {gpu.name}")
    print(f"\nâš¡ GPU ê°€ì† íš¨ê³¼:")
    print(f"  - ë°°ì¹˜ í¬ê¸°: {Config.BATCH_SIZE} (CPU ëŒ€ë¹„ 2x)")
    print(f"  - í•™ìŠµ ì†ë„: ì•½ 5-10x í–¥ìƒ")
else:
    print("\nğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰ë¨")

print(f"\nğŸ“ ëª¨ë¸ ì €ì¥: {Config.MODEL_DIR}")
print(f"ğŸ“Š ìµœê³  ëª¨ë¸: {best_model.upper()} (MAE: {evaluation_results[best_model]['overall_mae']:.2f})")

# ë©”ëª¨ë¦¬ ì •ë¦¬
tf.keras.backend.clear_session()
gc.collect()

print("\nâœ… ì™„ë£Œ! ë‹¤ìŒ: ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
print("="*60)