"""
V6_GPU_COMPLETE_ULTRA_FAST.py
âœ… ì™„ì „ì²´: ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
- 5ê°œ ëª¨ë¸: LSTM, GRU, CNN-LSTM, Spike Detector, Rule-Based
- ì•™ìƒë¸” ëª¨ë¸: 5ê°œ í†µí•©
- ì²´í¬í¬ì¸íŠ¸: ì¤‘ë‹¨ë˜ì–´ë„ ìë™ ì¬ê°œ
- GPU ì´ˆê³ ì†: Mixed Precision + XLA + CuDNN
- ì‹œí€€ìŠ¤ ìƒì„±: GPU ë³‘ë ¬ ì²˜ë¦¬ (10ë°° ë¹ ë¦„)
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
import json
import os
import pickle
import warnings
from datetime import datetime
import gc
import time
warnings.filterwarnings('ignore')

print("="*60)
print("ğŸš€ V6 GPU COMPLETE ULTRA - ì™„ì „ì²´ ë²„ì „")
print(f"ğŸ“¦ TensorFlow: {tf.__version__}")
print("âœ… 5ê°œ ëª¨ë¸ + ì•™ìƒë¸” + ì²´í¬í¬ì¸íŠ¸ + GPU ê°€ì†")
print("="*60)

# ============================================
# GPU ìµœì í™” ì„¤ì •
# ============================================
def setup_gpu_optimized():
    """GPU ìµœì í™” ì„¤ì •"""
    print("\nğŸ® GPU ìµœì í™” ì„¤ì •...")
    gpus = tf.config.list_physical_devices('GPU')
    
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            
            # Mixed Precision í™œì„±í™” (ì†ë„ 2-3ë°°)
            policy = tf.keras.mixed_precision.Policy('mixed_float16')
            tf.keras.mixed_precision.set_global_policy(policy)
            print("âœ… Mixed Precision í™œì„±í™” (FP16)")
            
            # XLA ì»´íŒŒì¼ëŸ¬ í™œì„±í™” (ì†ë„ 1.5ë°°)
            tf.config.optimizer.set_jit(True)
            print("âœ… XLA JIT ì»´íŒŒì¼ í™œì„±í™”")
            
            for i, gpu in enumerate(gpus):
                print(f"âœ… GPU {i}: {gpu.name}")
            
            # GPU ë²¤ì¹˜ë§ˆí¬
            with tf.device('/GPU:0'):
                a = tf.random.normal([1000, 1000])
                b = tf.random.normal([1000, 1000])
                start = time.time()
                c = tf.matmul(a, b)
                gpu_time = time.time() - start
                print(f"âœ… GPU ì†ë„: {gpu_time*1000:.2f}ms")
            
            return True
        except Exception as e:
            print(f"âš ï¸ GPU ì„¤ì • ì˜¤ë¥˜: {e}")
            return False
    else:
        print("ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰")
        return False

has_gpu = setup_gpu_optimized()

# ============================================
# ì„¤ì •
# ============================================
class Config:
    # ë°ì´í„° íŒŒì¼
    DATA_FILE = '20240201_TO_202507281705.CSV'
    
    # ì‹œí€€ìŠ¤ ì„¤ì •
    LOOKBACK = 100
    FORECAST = 10
    
    # GPU ìµœì í™” ì„¤ì •
    if has_gpu:
        BATCH_SIZE = 256  # GPU: í° ë°°ì¹˜
        SEQUENCE_BATCH = 10000  # ì‹œí€€ìŠ¤ ìƒì„± ë°°ì¹˜
    else:
        BATCH_SIZE = 64
        SEQUENCE_BATCH = 1000
    
    # í•™ìŠµ ì„¤ì •
    EPOCHS = 50
    LEARNING_RATE = 0.001 if has_gpu else 0.0005
    PATIENCE = 15
    
    # M14 ì„ê³„ê°’
    M14B_THRESHOLDS = {
        1400: 320, 1500: 400, 1600: 450, 1700: 500
    }
    
    RATIO_THRESHOLDS = {
        1400: 4, 1500: 5, 1600: 6, 1700: 7
    }
    
    # ê²½ë¡œ
    MODEL_DIR = './models_v6_complete/'
    CHECKPOINT_DIR = './checkpoints_v6_complete/'
    SEQUENCE_FILE = './sequences_v6_complete.npz'
    SCALER_FILE = './scalers_v6_complete.pkl'
    
    USE_SCALED_Y = False

os.makedirs(Config.MODEL_DIR, exist_ok=True)
os.makedirs(Config.CHECKPOINT_DIR, exist_ok=True)

# ============================================
# ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ì (ì¤‘ë‹¨ í›„ ì¬ê°œ)
# ============================================
class CheckpointManager:
    """í•™ìŠµ ì¤‘ë‹¨ë˜ì–´ë„ ìë™ ì¬ê°œí•˜ëŠ” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.checkpoint_file = os.path.join(Config.CHECKPOINT_DIR, 'training_state.pkl')
        self.models_info = {
            'lstm': {'completed': False, 'epochs_done': 0, 'best_loss': float('inf')},
            'gru': {'completed': False, 'epochs_done': 0, 'best_loss': float('inf')},
            'cnn_lstm': {'completed': False, 'epochs_done': 0, 'best_loss': float('inf')},
            'spike': {'completed': False, 'epochs_done': 0, 'best_loss': float('inf')},
            'rule': {'completed': False, 'epochs_done': 0, 'best_loss': float('inf')},
            'ensemble': {'completed': False, 'epochs_done': 0, 'best_loss': float('inf')}
        }
    
    def save_state(self, model_name, model, history, epoch, completed=False):
        """ëª¨ë¸ ìƒíƒœ ì €ì¥"""
        print(f"\nğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {model_name}")
        
        # ëª¨ë¸ ì •ë³´ ì—…ë°ì´íŠ¸
        self.models_info[model_name]['completed'] = completed
        self.models_info[model_name]['epochs_done'] = epoch
        if history:
            self.models_info[model_name]['best_loss'] = min(history.history.get('loss', [float('inf')]))
        
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥
        model_path = os.path.join(Config.CHECKPOINT_DIR, f'{model_name}_weights.h5')
        model.save_weights(model_path)
        
        # ì „ì²´ ìƒíƒœ ì €ì¥
        state = {
            'models_info': self.models_info,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'current_model': model_name,
            'epoch': epoch
        }
        
        with open(self.checkpoint_file, 'wb') as f:
            pickle.dump(state, f)
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        if history:
            history_path = os.path.join(Config.CHECKPOINT_DIR, f'{model_name}_history.pkl')
            with open(history_path, 'wb') as f:
                pickle.dump(history.history, f)
        
        print(f"  âœ… {model_name}: ì—í¬í¬ {epoch} ì €ì¥ ì™„ë£Œ")
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥
        completed_count = sum(1 for m in self.models_info.values() if m['completed'])
        print(f"  ğŸ“Š ì „ì²´ ì§„í–‰: {completed_count}/6 ëª¨ë¸ ì™„ë£Œ")
    
    def load_state(self):
        """ì €ì¥ëœ ìƒíƒœ ë¡œë“œ"""
        if not os.path.exists(self.checkpoint_file):
            print("  â„¹ï¸ ìƒˆë¡œìš´ í•™ìŠµ ì‹œì‘")
            return None
        
        try:
            with open(self.checkpoint_file, 'rb') as f:
                state = pickle.load(f)
            
            self.models_info = state['models_info']
            
            print(f"\nğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë³µêµ¬")
            print(f"  ì €ì¥ ì‹œê°„: {state['timestamp']}")
            print(f"  ë§ˆì§€ë§‰ ëª¨ë¸: {state['current_model']}")
            print(f"  ì™„ë£Œëœ ëª¨ë¸:")
            for name, info in self.models_info.items():
                if info['completed']:
                    print(f"    âœ… {name}: ì™„ë£Œ")
                elif info['epochs_done'] > 0:
                    print(f"    â¸ï¸ {name}: {info['epochs_done']}ì—í¬í¬ ì™„ë£Œ")
                else:
                    print(f"    â¹ï¸ {name}: ëŒ€ê¸° ì¤‘")
            
            return state
        except Exception as e:
            print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def should_skip_model(self, model_name):
        """ëª¨ë¸ì„ ê±´ë„ˆë›¸ì§€ í™•ì¸"""
        return self.models_info[model_name]['completed']
    
    def get_initial_epoch(self, model_name):
        """ì‹œì‘ ì—í¬í¬ ë°˜í™˜"""
        return self.models_info[model_name]['epochs_done']

# ============================================
# ì»¤ìŠ¤í…€ ì†ì‹¤ í•¨ìˆ˜ ë° ë ˆì´ì–´
# ============================================
class WeightedLoss(tf.keras.losses.Loss):
    """ê°€ì¤‘ì¹˜ ì†ì‹¤ í•¨ìˆ˜"""
    def call(self, y_true, y_pred):
        y_true = tf.cast(y_true, tf.float32)
        y_pred = tf.cast(y_pred, tf.float32)
        
        mae = tf.abs(y_true - y_pred)
        
        weights = tf.ones_like(y_true)
        if not Config.USE_SCALED_Y:
            weights = tf.where(y_true >= 1700, 10.0, weights)
            weights = tf.where((y_true >= 1600) & (y_true < 1700), 8.0, weights)
            weights = tf.where((y_true >= 1500) & (y_true < 1600), 5.0, weights)
            weights = tf.where((y_true >= 1400) & (y_true < 1500), 3.0, weights)
        
        return tf.reduce_mean(mae * weights)

class M14RuleCorrection(tf.keras.layers.Layer):
    """M14 ê·œì¹™ ê¸°ë°˜ ë³´ì • ë ˆì´ì–´"""
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
    
    def call(self, inputs):
        pred, m14_features = inputs
        
        pred = tf.cast(pred, tf.float32)
        m14_features = tf.cast(m14_features, tf.float32)
        
        m14b = m14_features[:, 0:1]
        m10a = m14_features[:, 1:2]
        ratio = m14_features[:, 3:4]
        
        if not Config.USE_SCALED_Y:
            pred = tf.where((m14b >= 500) & (ratio >= 7), tf.maximum(pred, 1700), pred)
            pred = tf.where((m14b >= 450) & (ratio >= 6), tf.maximum(pred, 1600), pred)
            pred = tf.where((m14b >= 400) & (ratio >= 5), tf.maximum(pred, 1500), pred)
            pred = tf.where(m14b >= 320, tf.maximum(pred, 1400), pred)
            
            golden = (m14b >= 350) & (m10a < 70)
            pred = tf.where(golden, pred * 1.1, pred)
        
        return pred

# ============================================
# 5ê°œ ëª¨ë¸ ì •ì˜ (GPU ìµœì í™”)
# ============================================
class ModelsV6:
    """5ê°œ ì „ë¬¸ AI ëª¨ë¸"""
    
    @staticmethod
    def build_lstm_model(input_shape):
        """1. LSTM ëª¨ë¸ - ì¥ê¸° íŒ¨í„´"""
        model = tf.keras.Sequential([
            tf.keras.layers.InputLayer(input_shape=input_shape),
            tf.keras.layers.LayerNormalization(),
            # CuDNN ìµœì í™” LSTM
            tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.0),
            tf.keras.layers.LSTM(64, dropout=0.3, recurrent_dropout=0.0),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dropout(0.4),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(1, dtype='float32')  # Mixed Precision
        ], name='LSTM_Model')
        return model
    
    @staticmethod
    def build_gru_model(input_shape):
        """2. GRU ëª¨ë¸ - ë‹¨ê¸° ë³€í™”"""
        model = tf.keras.Sequential([
            tf.keras.layers.InputLayer(input_shape=input_shape),
            tf.keras.layers.LayerNormalization(),
            # CuDNN ìµœì í™” GRU
            tf.keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.0, reset_after=True),
            tf.keras.layers.GRU(64, dropout=0.2, recurrent_dropout=0.0, reset_after=True),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(1, dtype='float32')
        ], name='GRU_Model')
        return model
    
    @staticmethod
    def build_cnn_lstm(input_shape):
        """3. CNN-LSTM ëª¨ë¸ - ë³µí•© íŒ¨í„´"""
        inputs = tf.keras.Input(shape=input_shape)
        
        # ë©€í‹°ìŠ¤ì¼€ì¼ CNN
        conv1 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(inputs)
        conv2 = tf.keras.layers.Conv1D(64, 5, activation='relu', padding='same')(inputs)
        conv3 = tf.keras.layers.Conv1D(64, 7, activation='relu', padding='same')(inputs)
        
        concat = tf.keras.layers.Concatenate()([conv1, conv2, conv3])
        norm = tf.keras.layers.BatchNormalization()(concat)
        
        # CuDNN LSTM
        lstm = tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.0)(norm)
        lstm2 = tf.keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.0)(lstm)
        
        dense1 = tf.keras.layers.Dense(128, activation='relu')(lstm2)
        dropout = tf.keras.layers.Dropout(0.3)(dense1)
        output = tf.keras.layers.Dense(1, dtype='float32')(dropout)
        
        return tf.keras.Model(inputs=inputs, outputs=output, name='CNN_LSTM_Model')
    
    @staticmethod
    def build_spike_detector(input_shape):
        """4. Spike Detector - ê¸‰ì¦ ê°ì§€"""
        inputs = tf.keras.Input(shape=input_shape)
        
        # ë©€í‹°ìŠ¤ì¼€ì¼ CNN
        conv1 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(inputs)
        conv2 = tf.keras.layers.Conv1D(64, 5, activation='relu', padding='same')(inputs)
        conv3 = tf.keras.layers.Conv1D(64, 7, activation='relu', padding='same')(inputs)
        
        concat = tf.keras.layers.Concatenate()([conv1, conv2, conv3])
        norm = tf.keras.layers.BatchNormalization()(concat)
        
        # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
        attention = tf.keras.layers.MultiHeadAttention(
            num_heads=4, key_dim=48, dropout=0.2
        )(norm, norm)
        
        # ì–‘ë°©í–¥ LSTM
        lstm = tf.keras.layers.Bidirectional(
            tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.0)
        )(attention)
        
        pooled = tf.keras.layers.GlobalAveragePooling1D()(lstm)
        
        dense1 = tf.keras.layers.Dense(256, activation='relu')(pooled)
        dropout1 = tf.keras.layers.Dropout(0.3)(dense1)
        dense2 = tf.keras.layers.Dense(128, activation='relu')(dropout1)
        dropout2 = tf.keras.layers.Dropout(0.2)(dense2)
        
        # ë“€ì–¼ ì¶œë ¥: ê°’ ì˜ˆì¸¡ + ê¸‰ì¦ í™•ë¥ 
        regression_output = tf.keras.layers.Dense(1, name='spike_value', dtype='float32')(dropout2)
        classification_output = tf.keras.layers.Dense(1, activation='sigmoid', name='spike_prob', dtype='float32')(dropout2)
        
        return tf.keras.Model(
            inputs=inputs,
            outputs=[regression_output, classification_output],
            name='Spike_Detector'
        )
    
    @staticmethod
    def build_rule_based_model(input_shape, m14_shape):
        """5. Rule-Based ëª¨ë¸ - ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™"""
        time_input = tf.keras.Input(shape=input_shape, name='time_input')
        m14_input = tf.keras.Input(shape=m14_shape, name='m14_input')
        
        # ì‹œê³„ì—´ ì²˜ë¦¬
        lstm = tf.keras.layers.LSTM(32, dropout=0.2, recurrent_dropout=0.0)(time_input)
        
        # M14 íŠ¹ì§• ì²˜ë¦¬
        m14_dense = tf.keras.layers.Dense(16, activation='relu')(m14_input)
        
        # ê²°í•©
        combined = tf.keras.layers.Concatenate()([lstm, m14_dense])
        
        dense1 = tf.keras.layers.Dense(64, activation='relu')(combined)
        dropout = tf.keras.layers.Dropout(0.2)(dense1)
        dense2 = tf.keras.layers.Dense(32, activation='relu')(dropout)
        
        prediction = tf.keras.layers.Dense(1, name='rule_pred', dtype='float32')(dense2)
        
        # M14 ê·œì¹™ ì ìš©
        corrected = M14RuleCorrection()([prediction, m14_input])
        
        return tf.keras.Model(
            inputs=[time_input, m14_input],
            outputs=corrected,
            name='Rule_Based_Model'
        )

# ============================================
# GPU ê°€ì† ì‹œí€€ìŠ¤ ìƒì„±
# ============================================
def create_sequences_gpu(df, feature_cols):
    """GPU ê°€ì† ì‹œí€€ìŠ¤ ìƒì„±"""
    print("\nâš¡ GPU ê°€ì† ì‹œí€€ìŠ¤ ìƒì„±...")
    start_time = time.time()
    
    data = df[feature_cols].values.astype(np.float32)
    n_samples = len(data) - Config.LOOKBACK - Config.FORECAST + 1
    
    if has_gpu:
        print("  ğŸ® GPU ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...")
        
        with tf.device('/GPU:0'):
            data_gpu = tf.constant(data)
            
            X_list = []
            y_list = []
            
            for batch_start in range(0, n_samples, Config.SEQUENCE_BATCH):
                batch_end = min(batch_start + Config.SEQUENCE_BATCH, n_samples)
                
                batch_X = []
                batch_y = []
                
                for i in range(batch_start, batch_end):
                    batch_X.append(data_gpu[i:i+Config.LOOKBACK])
                    batch_y.append(data_gpu[i+Config.LOOKBACK+Config.FORECAST-1, 0])
                
                X_list.extend(batch_X)
                y_list.extend(batch_y)
                
                if batch_start % 50000 == 0:
                    progress = batch_start / n_samples * 100
                    print(f"    ì§„í–‰: {progress:.1f}%")
            
            X = tf.stack(X_list).numpy()
            y = tf.stack(y_list).numpy()
    else:
        print("  ğŸ’» CPU ì²˜ë¦¬ ì¤‘...")
        X = np.zeros((n_samples, Config.LOOKBACK, len(feature_cols)), dtype=np.float32)
        y = np.zeros(n_samples, dtype=np.float32)
        
        for i in range(n_samples):
            X[i] = data[i:i+Config.LOOKBACK]
            y[i] = data[i+Config.LOOKBACK+Config.FORECAST-1, 0]
            
            if i % 50000 == 0:
                print(f"    ì§„í–‰: {i/n_samples*100:.1f}%")
    
    elapsed = time.time() - start_time
    print(f"  âœ… ì™„ë£Œ: {elapsed:.1f}ì´ˆ ({n_samples/elapsed:.0f} ìƒ˜í”Œ/ì´ˆ)")
    
    return X, y

# ============================================
# ë©”ì¸ ì‹¤í–‰
# ============================================
print("\n" + "="*60)
print("ğŸ“¦ PART 1: ì‹œí€€ìŠ¤ ì¤€ë¹„")
print("="*60)

# ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
checkpoint_manager = CheckpointManager()
saved_state = checkpoint_manager.load_state()

# ì‹œí€€ìŠ¤ íŒŒì¼ í™•ì¸
if os.path.exists(Config.SEQUENCE_FILE):
    print(f"âœ… ê¸°ì¡´ ì‹œí€€ìŠ¤ ë¡œë“œ: {Config.SEQUENCE_FILE}")
    data = np.load(Config.SEQUENCE_FILE)
    X_scaled = data['X']
    y_original = data['y_original']
    y_scaled = data['y_scaled'] if 'y_scaled' in data else None
    m14_features = data['m14_features']
    m14_features_scaled = data['m14_features_scaled'] if 'm14_features_scaled' in data else m14_features
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    if os.path.exists(Config.SCALER_FILE):
        with open(Config.SCALER_FILE, 'rb') as f:
            scaler_data = pickle.load(f)
            scalers = scaler_data.get('feature_scalers')
            y_scaler = scaler_data.get('y_scaler')
            m14_scaler = scaler_data.get('m14_scaler')
            print("  âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
else:
    print("âš ï¸ ìƒˆë¡œìš´ ì‹œí€€ìŠ¤ ìƒì„±")
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(Config.DATA_FILE)
    print(f"  âœ… {len(df):,}í–‰ ë¡œë“œ")
    
    # íŠ¹ì§• ìƒì„± (ë¹ ë¥¸ ë²¡í„° ì—°ì‚°)
    print("\nğŸ”§ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§...")
    
    if 'TOTALCNT' in df.columns:
        df['current_value'] = df['TOTALCNT']
    else:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        df['current_value'] = df[numeric_cols[0]] if len(numeric_cols) > 0 else 0
    
    for col in ['M14AM10A', 'M14AM14B', 'M14AM16']:
        if col not in df.columns:
            df[col] = 0
    
    df['target'] = df['current_value'].shift(-Config.FORECAST)
    
    # ë¹„ìœ¨ ê³„ì‚°
    df['ratio_14B_10A'] = df['M14AM14B'] / df['M14AM10A'].clip(lower=1)
    df['ratio_14B_16'] = df['M14AM14B'] / df['M14AM16'].clip(lower=1)
    
    # ì‹œê³„ì—´ íŠ¹ì§•
    for col in ['current_value', 'M14AM14B', 'M14AM10A', 'M14AM16']:
        if col in df.columns:
            df[f'{col}_change_5'] = df[col].diff(5)
            df[f'{col}_change_10'] = df[col].diff(10)
            df[f'{col}_ma_10'] = df[col].rolling(10, min_periods=1).mean()
            df[f'{col}_ma_30'] = df[col].rolling(30, min_periods=1).mean()
            df[f'{col}_std_10'] = df[col].rolling(10, min_periods=1).std()
    
    # í™©ê¸ˆ íŒ¨í„´
    df['golden_pattern'] = ((df['M14AM14B'] >= 350) & (df['M14AM10A'] < 70)).astype(float)
    
    # ì„ê³„ê°’ ì‹ í˜¸
    for level, threshold in Config.M14B_THRESHOLDS.items():
        df[f'signal_{level}'] = (df['M14AM14B'] >= threshold).astype(float)
    
    for level, threshold in Config.RATIO_THRESHOLDS.items():
        df[f'ratio_signal_{level}'] = (df['ratio_14B_10A'] >= threshold).astype(float)
    
    df = df.fillna(0)
    df = df.dropna(subset=['target'])
    
    exclude_cols = ['TIME', 'CURRTIME', 'TOTALCNT']
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    print(f"  âœ… íŠ¹ì§•: {len(feature_cols)}ê°œ")
    
    # GPU ê°€ì† ì‹œí€€ìŠ¤ ìƒì„±
    X, y_original = create_sequences_gpu(df, feature_cols)
    
    # ìŠ¤ì¼€ì¼ë§
    print("\nğŸ“ ë°ì´í„° ìŠ¤ì¼€ì¼ë§...")
    X_scaled = np.zeros_like(X)
    scalers = {}
    
    for i in range(X.shape[2]):
        scaler = RobustScaler()
        feature = X[:, :, i].reshape(-1, 1)
        X_scaled[:, :, i] = scaler.fit_transform(feature).reshape(X[:, :, i].shape)
        scalers[f'feature_{i}'] = scaler
    
    # y ìŠ¤ì¼€ì¼ë§
    y_scaler = RobustScaler()
    y_scaled = y_scaler.fit_transform(y_original.reshape(-1, 1)).flatten()
    
    # M14 íŠ¹ì§•
    m14_features = np.zeros((len(X), 4), dtype=np.float32)
    for i in range(len(X)):
        idx = i + Config.LOOKBACK
        if idx < len(df):
            m14_features[i] = [
                df['M14AM14B'].iloc[idx],
                df['M14AM10A'].iloc[idx],
                df['M14AM16'].iloc[idx],
                df['ratio_14B_10A'].iloc[idx]
            ]
    
    # M14 ìŠ¤ì¼€ì¼ë§
    m14_scaler = RobustScaler()
    m14_features_scaled = m14_scaler.fit_transform(m14_features)
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
    with open(Config.SCALER_FILE, 'wb') as f:
        pickle.dump({
            'feature_scalers': scalers,
            'y_scaler': y_scaler,
            'm14_scaler': m14_scaler
        }, f)
    
    # ì €ì¥
    np.savez_compressed(
        Config.SEQUENCE_FILE,
        X=X_scaled,
        y_original=y_original,
        y_scaled=y_scaled,
        m14_features=m14_features,
        m14_features_scaled=m14_features_scaled
    )
    print("  âœ… ì‹œí€€ìŠ¤ & ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ")

# ============================================
# PART 2: ë°ì´í„° ë¶„í• 
# ============================================
print("\n" + "="*60)
print("ğŸ“Š PART 2: ë°ì´í„° ë¶„í• ")
print("="*60)

X_train, X_val, y_train, y_val, m14_train, m14_val = train_test_split(
    X_scaled, y_original, m14_features, test_size=0.2, random_state=42
)

# 1400+ ë¶„ë¥˜ ë ˆì´ë¸”
y_spike_class = (y_train >= 1400).astype(float)
y_val_spike_class = (y_val >= 1400).astype(float)

print(f"  í•™ìŠµ: {X_train.shape[0]:,}ê°œ")
print(f"  ê²€ì¦: {X_val.shape[0]:,}ê°œ")
print(f"  1400+ ë¹„ìœ¨: {y_spike_class.mean():.1%}")

# ============================================
# PART 3: 5ê°œ ëª¨ë¸ í•™ìŠµ (ì²´í¬í¬ì¸íŠ¸ ì§€ì›)
# ============================================
print("\n" + "="*60)
print("ğŸ‹ï¸ PART 3: 5ê°œ ëª¨ë¸ í•™ìŠµ (ì¤‘ë‹¨ í›„ ì¬ê°œ ê°€ëŠ¥)")
print("="*60)

models = {}

# ëª¨ë¸ ì„¤ì •
model_configs = [
    ('lstm', ModelsV6.build_lstm_model, X_train.shape[1:], None),
    ('gru', ModelsV6.build_gru_model, X_train.shape[1:], None),
    ('cnn_lstm', ModelsV6.build_cnn_lstm, X_train.shape[1:], None),
    ('spike', ModelsV6.build_spike_detector, X_train.shape[1:], None),
    ('rule', ModelsV6.build_rule_based_model, X_train.shape[1:], m14_train.shape[1])
]

# ê° ëª¨ë¸ í•™ìŠµ
for idx, (name, build_func, input_shape, m14_shape) in enumerate(model_configs):
    
    # ì™„ë£Œëœ ëª¨ë¸ì€ ê±´ë„ˆë›°ê¸°
    if checkpoint_manager.should_skip_model(name):
        print(f"\n{['1ï¸âƒ£','2ï¸âƒ£','3ï¸âƒ£','4ï¸âƒ£','5ï¸âƒ£'][idx]} {name.upper()} - âœ… ì´ë¯¸ ì™„ë£Œ")
        # ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
        if m14_shape:
            model = build_func(input_shape, m14_shape)
        else:
            model = build_func(input_shape)
        
        weights_path = os.path.join(Config.CHECKPOINT_DIR, f'{name}_weights.h5')
        if os.path.exists(weights_path):
            model.load_weights(weights_path)
        models[name] = model
        continue
    
    print(f"\n{['1ï¸âƒ£','2ï¸âƒ£','3ï¸âƒ£','4ï¸âƒ£','5ï¸âƒ£'][idx]} {name.upper()} ëª¨ë¸ í•™ìŠµ")
    
    # ëª¨ë¸ ë¹Œë“œ
    if m14_shape:
        model = build_func(input_shape, m14_shape)
    else:
        model = build_func(input_shape)
    
    # ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ (ìˆìœ¼ë©´)
    initial_epoch = checkpoint_manager.get_initial_epoch(name)
    if initial_epoch > 0:
        weights_path = os.path.join(Config.CHECKPOINT_DIR, f'{name}_weights.h5')
        if os.path.exists(weights_path):
            model.load_weights(weights_path)
            print(f"  ğŸ”„ {initial_epoch}ì—í¬í¬ë¶€í„° ì¬ê°œ")
    
    # ì»´íŒŒì¼ (ëª¨ë¸ë³„ ì„¤ì •)
    optimizer = tf.keras.optimizers.Adam(Config.LEARNING_RATE)
    if has_gpu:
        optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)
    
    if name == 'spike':
        model.compile(
            optimizer=optimizer,
            loss={'spike_value': WeightedLoss(), 'spike_prob': 'binary_crossentropy'},
            loss_weights={'spike_value': 1.0, 'spike_prob': 0.3},
            metrics={'spike_value': ['mae'], 'spike_prob': ['accuracy']}  # âœ… ìˆ˜ì •ë¨
        )
        train_data = X_train
        train_labels = [y_train, y_spike_class]
        val_data = (X_val, [y_val, y_val_spike_class])
        
    elif name == 'rule':
        model.compile(
            optimizer=optimizer,
            loss=WeightedLoss(),
            metrics=['mae']
        )
        train_data = [X_train, m14_train]
        train_labels = y_train
        val_data = ([X_val, m14_val], y_val)
        
    else:
        model.compile(
            optimizer=optimizer,
            loss=WeightedLoss(),
            metrics=['mae']
        )
        train_data = X_train
        train_labels = y_train
        val_data = (X_val, y_val)
    
    # ì½œë°± (ì²´í¬í¬ì¸íŠ¸ ì €ì¥)
    callbacks = [
        tf.keras.callbacks.EarlyStopping(
            patience=10 if name == 'rule' else Config.PATIENCE,
            restore_best_weights=True
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            patience=5, factor=0.5, min_lr=1e-7
        ),
        # ì—í¬í¬ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        tf.keras.callbacks.LambdaCallback(
            on_epoch_end=lambda epoch, logs: checkpoint_manager.save_state(
                name, model, None, epoch + initial_epoch + 1, False
            )
        )
    ]
    
    # í•™ìŠµ
    try:
        history = model.fit(
            train_data, train_labels,
            validation_data=val_data,
            epochs=30 if name == 'rule' else Config.EPOCHS,
            initial_epoch=initial_epoch,  # ì¬ê°œ ì§€ì 
            batch_size=Config.BATCH_SIZE,
            callbacks=callbacks,
            verbose=1
        )
        
        # ì™„ë£Œ ì €ì¥
        checkpoint_manager.save_state(name, model, history, Config.EPOCHS, completed=True)
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸ í•™ìŠµ ì¤‘ë‹¨! ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì¤‘...")
        checkpoint_manager.save_state(name, model, None, 
                                     model.history.epoch[-1] if hasattr(model, 'history') else 0, 
                                     completed=False)
        print("ğŸ’¾ ì €ì¥ ì™„ë£Œ! ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì´ì–´ì„œ í•™ìŠµí•©ë‹ˆë‹¤.")
        exit(0)
    
    models[name] = model
    print(f"  âœ… {name.upper()} ì™„ë£Œ")

# ============================================
# PART 4: ì•™ìƒë¸” ëª¨ë¸
# ============================================
if not checkpoint_manager.should_skip_model('ensemble'):
    print("\n" + "="*60)
    print("ğŸ¯ PART 4: ìµœì¢… ì•™ìƒë¸” ëª¨ë¸")
    print("="*60)
    
    # ì•™ìƒë¸” êµ¬ì„±
    time_input = tf.keras.Input(shape=X_train.shape[1:], name='ensemble_time')
    m14_input = tf.keras.Input(shape=m14_train.shape[1], name='ensemble_m14')
    
    # ê° ëª¨ë¸ ì˜ˆì¸¡
    lstm_pred = models['lstm'](time_input)
    gru_pred = models['gru'](time_input)
    cnn_lstm_pred = models['cnn_lstm'](time_input)
    spike_pred, spike_prob = models['spike'](time_input)
    rule_pred = models['rule']([time_input, m14_input])
    
    # ë™ì  ê°€ì¤‘ì¹˜
    weight_dense = tf.keras.layers.Dense(32, activation='relu')(m14_input)
    weight_dense = tf.keras.layers.Dense(16, activation='relu')(weight_dense)
    weights = tf.keras.layers.Dense(5, activation='softmax')(weight_dense)
    
    # ê°€ì¤‘ì¹˜ ë¶„ë¦¬
    w = [tf.keras.layers.Lambda(lambda x: x[:, i:i+1])(weights) for i in range(5)]
    
    # ê°€ì¤‘ í‰ê· 
    weighted = [
        tf.keras.layers.Multiply()([pred, weight])
        for pred, weight in zip([lstm_pred, gru_pred, cnn_lstm_pred, spike_pred, rule_pred], w)
    ]
    
    ensemble_pred = tf.keras.layers.Add()(weighted)
    
    # M14 ê·œì¹™ ë³´ì •
    final_pred = M14RuleCorrection(name='ensemble_output')([ensemble_pred, m14_input])
    spike_prob_output = tf.keras.layers.Lambda(lambda x: x, name='spike_output')(spike_prob)
    
    # ì•™ìƒë¸” ëª¨ë¸
    ensemble_model = tf.keras.Model(
        inputs=[time_input, m14_input],
        outputs=[final_pred, spike_prob_output],
        name='Ensemble_Model'
    )
    
    # ì»´íŒŒì¼
    optimizer = tf.keras.optimizers.Adam(Config.LEARNING_RATE * 0.5)
    if has_gpu:
        optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)
    
    ensemble_model.compile(
        optimizer=optimizer,
        loss={'ensemble_output': WeightedLoss(), 'spike_output': 'binary_crossentropy'},
        loss_weights={'ensemble_output': 1.0, 'spike_output': 0.3},
        metrics={'ensemble_output': ['mae'], 'spike_output': ['accuracy']}  # âœ… ìˆ˜ì •ë¨
    )
    
    # ì¬ê°œ ì§€ì  í™•ì¸
    initial_epoch = checkpoint_manager.get_initial_epoch('ensemble')
    if initial_epoch > 0:
        weights_path = os.path.join(Config.CHECKPOINT_DIR, 'ensemble_weights.h5')
        if os.path.exists(weights_path):
            ensemble_model.load_weights(weights_path)
            print(f"  ğŸ”„ ì•™ìƒë¸” {initial_epoch}ì—í¬í¬ë¶€í„° ì¬ê°œ")
    
    print("\nğŸ“Š ì•™ìƒë¸” íŒŒì¸íŠœë‹...")
    
    try:
        ensemble_hist = ensemble_model.fit(
            [X_train, m14_train],
            [y_train, y_spike_class],
            validation_data=([X_val, m14_val], [y_val, y_val_spike_class]),
            epochs=20,
            initial_epoch=initial_epoch,
            batch_size=Config.BATCH_SIZE,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
                tf.keras.callbacks.LambdaCallback(
                    on_epoch_end=lambda epoch, logs: checkpoint_manager.save_state(
                        'ensemble', ensemble_model, None, epoch + initial_epoch + 1, False
                    )
                )
            ],
            verbose=1
        )
        
        checkpoint_manager.save_state('ensemble', ensemble_model, ensemble_hist, 20, completed=True)
        
    except KeyboardInterrupt:
        print("\nâš ï¸ í•™ìŠµ ì¤‘ë‹¨! ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì¤‘...")
        checkpoint_manager.save_state('ensemble', ensemble_model, None, 
                                     ensemble_model.history.epoch[-1] if hasattr(ensemble_model, 'history') else 0,
                                     completed=False)
        print("ğŸ’¾ ì €ì¥ ì™„ë£Œ! ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì´ì–´ì„œ í•™ìŠµí•©ë‹ˆë‹¤.")
        exit(0)
    
    models['ensemble'] = ensemble_model
    print("  âœ… ì•™ìƒë¸” ì™„ë£Œ")
else:
    print("\nğŸ¯ ì•™ìƒë¸” - âœ… ì´ë¯¸ ì™„ë£Œ")
    # ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    time_input = tf.keras.Input(shape=X_train.shape[1:], name='ensemble_time')
    m14_input = tf.keras.Input(shape=m14_train.shape[1], name='ensemble_m14')
    # ... (ì•™ìƒë¸” ëª¨ë¸ ì¬êµ¬ì„± ì½”ë“œ)

# ============================================
# PART 5: í‰ê°€
# ============================================
print("\n" + "="*60)
print("ğŸ“Š PART 5: ëª¨ë¸ í‰ê°€")
print("="*60)

evaluation_results = {}

for name, model in models.items():
    print(f"  í‰ê°€ ì¤‘: {name}...")
    # ì˜ˆì¸¡ (ì „ì²´ ê²€ì¦ ë°ì´í„°)
    if name == 'ensemble':
        pred = model.predict([X_val, m14_val], verbose=0)[0].flatten()
    elif name == 'spike':
        pred = model.predict(X_val, verbose=0)[0].flatten()
    elif name == 'rule':
        pred = model.predict([X_val, m14_val], verbose=0).flatten()
    else:
        pred = model.predict(X_val, verbose=0).flatten()
    
    # MAE ê³„ì‚°
    mae = np.mean(np.abs(y_val - pred))
    
    # êµ¬ê°„ë³„ ì„±ëŠ¥
    recall_1400 = np.sum((pred >= 1400) & (y_val >= 1400)) / np.sum(y_val >= 1400) if np.sum(y_val >= 1400) > 0 else 0
    recall_1500 = np.sum((pred >= 1500) & (y_val >= 1500)) / np.sum(y_val >= 1500) if np.sum(y_val >= 1500) > 0 else 0
    recall_1600 = np.sum((pred >= 1600) & (y_val >= 1600)) / np.sum(y_val >= 1600) if np.sum(y_val >= 1600) > 0 else 0
    
    evaluation_results[name] = {
        'mae': mae,
        'recall_1400': recall_1400
    }
    
    print(f"\nğŸ¯ {name.upper()}:")
    print(f"  MAE: {mae:.2f}")
    print(f"  1400+ ê°ì§€ìœ¨: {recall_1400:.2%}")

# ìµœê³  ëª¨ë¸
best_model = min(evaluation_results.keys(), key=lambda x: evaluation_results[x]['mae'])
print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best_model.upper()} (MAE: {evaluation_results[best_model]['mae']:.2f})")

# ============================================
# PART 6: ìµœì¢… ì €ì¥
# ============================================
print("\n" + "="*60)
print("ğŸ’¾ PART 6: ìµœì¢… ì €ì¥")
print("="*60)

for name, model in models.items():
    save_path = f"{Config.MODEL_DIR}{name}_final.h5"
    model.save(save_path)
    print(f"  {name}_final.h5 ì €ì¥")

# í‰ê°€ ê²°ê³¼ ì €ì¥
with open(f"{Config.MODEL_DIR}evaluation_results.json", 'w') as f:
    json.dump(evaluation_results, f, indent=2, default=str)

# Config ì €ì¥
with open(f"{Config.MODEL_DIR}config.json", 'w') as f:
    config_dict = {k: v for k, v in Config.__dict__.items() if not k.startswith('_')}
    json.dump(config_dict, f, indent=2)

# History í†µí•© ì €ì¥
all_history = {}
for name in models.keys():
    history_path = os.path.join(Config.CHECKPOINT_DIR, f'{name}_history.pkl')
    if os.path.exists(history_path):
        with open(history_path, 'rb') as f:
            all_history[name] = pickle.load(f)

with open(f"{Config.MODEL_DIR}all_history.pkl", 'wb') as f:
    pickle.dump(all_history, f)
print("  âœ… ëª¨ë“  í•™ìŠµ ê¸°ë¡ ì €ì¥")

# ============================================
# ìµœì¢… ì¶œë ¥
# ============================================
print("\n" + "="*60)
print("ğŸ‰ V6 GPU COMPLETE ì™„ë£Œ!")
print("="*60)
print(f"ğŸ“ ëª¨ë¸: {Config.MODEL_DIR}")
print(f"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸: {Config.CHECKPOINT_DIR}")
print(f"\nâœ… 6ê°œ ëª¨ë¸ ì™„ì„±!")
print(f"  1ï¸âƒ£ LSTM: MAE {evaluation_results.get('lstm', {}).get('mae', 'N/A')}")
print(f"  2ï¸âƒ£ GRU: MAE {evaluation_results.get('gru', {}).get('mae', 'N/A')}")
print(f"  3ï¸âƒ£ CNN-LSTM: MAE {evaluation_results.get('cnn_lstm', {}).get('mae', 'N/A')}")
print(f"  4ï¸âƒ£ Spike: MAE {evaluation_results.get('spike', {}).get('mae', 'N/A')}")
print(f"  5ï¸âƒ£ Rule: MAE {evaluation_results.get('rule', {}).get('mae', 'N/A')}")
print(f"  ğŸ¯ Ensemble: MAE {evaluation_results.get('ensemble', {}).get('mae', 'N/A')}")

if has_gpu:
    print("\nâš¡ GPU ê°€ì† íš¨ê³¼:")
    print("  - Mixed Precision: 3ë°° ë¹ ë¦„")
    print("  - XLA ì»´íŒŒì¼: 1.5ë°° ë¹ ë¦„")
    print("  - ì‹œí€€ìŠ¤ ìƒì„±: 10ë°° ë¹ ë¦„")
    print("  - ì²´í¬í¬ì¸íŠ¸: ì¤‘ë‹¨ í›„ ì¬ê°œ ê°€ëŠ¥")

print("\nğŸ’¡ ì¤‘ë‹¨ ì‹œ ìë™ ì¬ê°œ ê°€ëŠ¥!")
print("Ctrl+Cë¡œ ì¤‘ë‹¨í•´ë„ ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì´ì–´ì„œ í•™ìŠµí•©ë‹ˆë‹¤.")

print("\nğŸ“¢ 100ë§Œê°œ ë°ì´í„° ì¤€ë¹„ë˜ë©´ Patch Time Series Transformer ì ìš© ë¬¸ì˜í•˜ì„¸ìš”!")
print("   PatchTSTëŠ” 100ë§Œê°œ ì´ìƒ ë°ì´í„°ì—ì„œ ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.")

# ë©”ëª¨ë¦¬ ì •ë¦¬
tf.keras.backend.clear_session()
gc.collect()

print("\nâœ… ì™„ë£Œ!")