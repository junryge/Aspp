"""
ì˜¤í”„ë¼ì¸ GGUF CSV RAG ì‹œìŠ¤í…œ
ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•œ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
ğŸ“‹ ì‚¬ì „ ì¤€ë¹„ì‚¬í•­

ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì¸í„°ë„· ìˆëŠ” PCì—ì„œ)

https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/tree/main
ëª¨ë“  íŒŒì¼ì„ ./offline_models/all-MiniLM-L6-v2/ í´ë”ì— ì €ì¥


í´ë” êµ¬ì¡°
í”„ë¡œì íŠ¸/
â”œâ”€â”€ output_by_date/
â”‚   â”œâ”€â”€ 20240201_data.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ offline_models/
â”‚   â””â”€â”€ all-MiniLM-L6-v2/
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ pytorch_model.bin
â”‚       â””â”€â”€ ...
â”œâ”€â”€ phi-4-mini-instruct-q4_k_m.gguf
â””â”€â”€ offline_gguf_rag.py

í•„ìš” íŒ¨í‚¤ì§€ (ì˜¤í”„ë¼ì¸ ì„¤ì¹˜)
bashpip install pandas langchain langchain-community faiss-cpu sentence-transformers llama-cpp-python --no-deps


ì´ì œ ì¸í„°ë„· ì—°ê²° ì—†ì´ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤!
"""

import os
import glob
import pandas as pd
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.llms import LlamaCpp
from langchain.chains import RetrievalQA
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

def main():
    print("=" * 60)
    print("ğŸ“Š ì˜¤í”„ë¼ì¸ GGUF CSV RAG ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    # 1. ì˜¤í”„ë¼ì¸ ì„ë² ë”© ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    local_model_path = "./offline_models/all-MiniLM-L6-v2"
    
    # ëª¨ë¸ ê²½ë¡œ í™•ì¸
    if not os.path.exists(local_model_path):
        print(f"âŒ ì„ë² ë”© ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {local_model_path}")
        print("\në‹¤ìŒ ë°©ë²•ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
        print("1. https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/tree/main")
        print("2. ëª¨ë“  íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ì„œ ìœ„ ê²½ë¡œì— ì €ì¥")
        return
    
    # 2. CSV íŒŒì¼ë“¤ ë¡œë“œ
    folder_path = "./output_by_date"
    print(f"\nğŸ“ CSV í´ë”: {folder_path}")
    
    csv_files = glob.glob(os.path.join(folder_path, "*.csv"))
    if not csv_files:
        print("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    print(f"âœ… ë°œê²¬ëœ íŒŒì¼: {len(csv_files)}ê°œ")
    
    # ë°ì´í„° ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì¼ë¶€ë§Œ)
    all_data = []
    for i, file in enumerate(csv_files[:30]):  # ì²˜ìŒ 30ê°œë§Œ
        try:
            df = pd.read_csv(file)
            all_data.append(df)
        except:
            pass
    
    df = pd.concat(all_data, ignore_index=True)
    print(f"âœ… ë¡œë“œëœ ë°ì´í„°: {len(df)}í–‰")
    
    # 3. ë¬¸ì„œ ìƒì„±
    print("\nğŸ“„ ë¬¸ì„œ ìƒì„± ì¤‘...")
    documents = []
    
    # ì „ì²´ í†µê³„
    doc_text = f"""ì „ì²´ ë°ì´í„° ì •ë³´:
ì´ í–‰ ìˆ˜: {len(df)}
ì»¬ëŸ¼: {', '.join(df.columns)}
"""
    
    # TOTALCNT í†µê³„
    if 'TOTALCNT' in df.columns:
        doc_text += f"""
TOTALCNT í†µê³„:
- í‰ê· : {df['TOTALCNT'].mean():.0f}
- ìµœëŒ€: {df['TOTALCNT'].max()}
- ìµœì†Œ: {df['TOTALCNT'].min()}
- 1400 ì´ìƒ: {(df['TOTALCNT'] >= 1400).sum()}ê±´
- 1500 ì´ìƒ: {(df['TOTALCNT'] >= 1500).sum()}ê±´
"""
    
    documents.append(Document(page_content=doc_text))
    
    # ê° í–‰ì„ ë¬¸ì„œë¡œ (ìƒ˜í”Œ)
    for idx, row in df.head(500).iterrows():
        row_text = f"ë°ì´í„° {idx}: "
        for col in ['CURRTIME', 'TOTALCNT', 'M14AM14B', 'M14AM10A']:
            if col in df.columns:
                row_text += f"{col}={row[col]}, "
        documents.append(Document(page_content=row_text))
    
    print(f"âœ… ìƒì„±ëœ ë¬¸ì„œ: {len(documents)}ê°œ")
    
    # 4. í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50
    )
    texts = text_splitter.split_documents(documents)
    
    # 5. ì˜¤í”„ë¼ì¸ ì„ë² ë”© ìƒì„±
    print("\nğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘ (ì˜¤í”„ë¼ì¸)...")
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name=local_model_path,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # 6. ë²¡í„° ìŠ¤í† ì–´
    print("ğŸ”„ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
    vectorstore = FAISS.from_documents(texts, embeddings)
    print("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")
    
    # 7. GGUF ëª¨ë¸ ë¡œë“œ
    print("\nğŸ¤– Phi-4 GGUF ëª¨ë¸ ë¡œë”© ì¤‘...")
    model_path = "./phi-4-mini-instruct-q4_k_m.gguf"
    
    if not os.path.exists(model_path):
        print(f"âŒ GGUF ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return
    
    llm = LlamaCpp(
        model_path=model_path,
        n_ctx=2048,
        max_tokens=256,
        temperature=0.1,
        n_threads=8,
        verbose=False
    )
    print("âœ… GGUF ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # 8. QA ì²´ì¸
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3})
    )
    
    print("\n" + "=" * 60)
    print("âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
    print("ì§ˆë¬¸ ì˜ˆì‹œ:")
    print("- ì „ì²´ ë°ì´í„°ëŠ” ëª‡ ê°œì•¼?")
    print("- TOTALCNT í‰ê· ì€?")
    print("- 1500 ì´ìƒì¸ ë°ì´í„°ëŠ” ëª‡ ê°œ?")
    print("=" * 60)
    
    # 9. ì§ˆì˜ì‘ë‹µ
    while True:
        question = input("\nğŸ’¬ ì§ˆë¬¸: ")
        if question.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
            
        try:
            print("\nğŸ¤” ìƒê° ì¤‘...")
            result = qa_chain({"query": question})
            print("\nğŸ¤– ë‹µë³€:")
            print(result['result'])
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()