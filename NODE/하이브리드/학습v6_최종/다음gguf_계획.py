"""
íì‡„ë§ CSV RAG ì‹œìŠ¤í…œ - ë‹¨ìˆœ ë²„ì „
phi-4-mini-instruct-q4_k_m.gguf ì‚¬ìš©
"""

import os
import glob
import pandas as pd
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.llms import LlamaCpp
from langchain.chains import RetrievalQA

def main():
    print("=" * 60)
    print("ğŸ“Š CSV RAG ì‹œìŠ¤í…œ (Phi-4 ì‚¬ìš©)")
    print("=" * 60)
    
    # 1. CSV íŒŒì¼ë“¤ ë¡œë“œ
    folder_path = "./output_by_date"
    print(f"\nğŸ“ í´ë” ê²€ìƒ‰ ì¤‘: {folder_path}")
    
    csv_files = glob.glob(os.path.join(folder_path, "*.csv"))
    if not csv_files:
        print("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    print(f"âœ… ë°œê²¬ëœ íŒŒì¼: {len(csv_files)}ê°œ")
    
    # ëª¨ë“  CSV ì½ê¸°
    all_data = []
    for file in csv_files:
        try:
            df = pd.read_csv(file)
            all_data.append(df)
        except:
            pass
    
    # ë°ì´í„° í•©ì¹˜ê¸°
    df = pd.concat(all_data, ignore_index=True)
    print(f"âœ… ì „ì²´ ë°ì´í„°: {len(df)}í–‰")
    
    # 2. ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
    documents = []
    
    # ê¸°ë³¸ ì •ë³´
    doc_text = f"ì „ì²´ ë°ì´í„° ìˆ˜: {len(df)}ê°œ\n"
    doc_text += f"ì»¬ëŸ¼: {', '.join(df.columns)}\n\n"
    
    # ê° í–‰ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì²˜ìŒ 1000í–‰ë§Œ)
    for idx, row in df.head(1000).iterrows():
        row_text = f"ë°ì´í„° {idx}: "
        for col in df.columns:
            row_text += f"{col}={row[col]}, "
        row_text += "\n"
        
        # 500ìì”© ë¬¶ì–´ì„œ ë¬¸ì„œ ìƒì„±
        if len(doc_text) > 500:
            documents.append(Document(page_content=doc_text))
            doc_text = ""
        doc_text += row_text
    
    if doc_text:
        documents.append(Document(page_content=doc_text))
    
    print(f"âœ… ë¬¸ì„œ ìƒì„±: {len(documents)}ê°œ")
    
    # 3. ì„ë² ë”© ìƒì„±
    print("\nğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘...")
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={'device': 'cpu'}
    )
    
    # 4. ë²¡í„° ìŠ¤í† ì–´
    print("ğŸ”„ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
    vectorstore = FAISS.from_documents(documents, embeddings)
    
    # 5. Phi-4 ëª¨ë¸ ë¡œë“œ
    print("\nğŸ¤– Phi-4 ëª¨ë¸ ë¡œë”© ì¤‘...")
    model_path = "./phi-4-mini-instruct-q4_k_m.gguf"
    
    llm = LlamaCpp(
        model_path=model_path,
        n_ctx=2048,
        max_tokens=256,
        temperature=0.1,
        verbose=False
    )
    
    # 6. QA ì²´ì¸
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever()
    )
    
    print("\nâœ… ì¤€ë¹„ ì™„ë£Œ! ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    print("=" * 60)
    
    # 7. ì§ˆì˜ì‘ë‹µ
    while True:
        question = input("\nğŸ’¬ ì§ˆë¬¸: ")
        if question.lower() in ['quit', 'exit']:
            break
            
        try:
            result = qa_chain({"query": question})
            print("\nğŸ¤– ë‹µë³€:", result['result'])
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()