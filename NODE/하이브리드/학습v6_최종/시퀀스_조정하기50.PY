"""
data_reducer_for_v6.py - V6 ì‹œí€€ìŠ¤ ìƒì„±ê¸° ì „ìš© ë°ì´í„° ì¶•ì†Œ
ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ìµœì í™”
"""

import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ============================================
# ì„¤ì • (V6ì™€ ë™ì¼í•˜ê²Œ ìœ ì§€)
# ============================================
# íŒŒì¼ ê²½ë¡œ
INPUT_FILE = './data/20240201_TO_202507281705.CSV'  # ì›ë³¸ (V6ì™€ ë™ì¼)
OUTPUT_FILE = './data/20240201_TO_202507281705_reduced.CSV'  # ì¶•ì†Œ ë²„ì „

# V6 ì„¤ì •ê°’ ê·¸ëŒ€ë¡œ
LOOKBACK = 100  # ê³¼ê±° 100ë¶„
FORECAST = 10   # 10ë¶„ í›„ ì˜ˆì¸¡

# M14 ì„ê³„ê°’ (V6ì™€ ë™ì¼)
M14B_THRESHOLDS = {
    1400: 320,
    1500: 400,
    1600: 450,
    1700: 500
}

RATIO_THRESHOLDS = {
    1400: 4,
    1500: 5,
    1600: 6,
    1700: 7
}

# ì¶•ì†Œ ì„¤ì •
REDUCTION_CONFIG = {
    'target_rows': 100000,      # ëª©í‘œ: 10ë§Œí–‰ (ì›ë³¸ì˜ ì•½ 13%)
    'method': 'smart',           # ì¤‘ìš” íŒ¨í„´ ìš°ì„  ë³´ì¡´
    'keep_critical_patterns': True,  # í•µì‹¬ íŒ¨í„´ 100% ë³´ì¡´
}

# ============================================
# ë©”ì¸ ì²˜ë¦¬
# ============================================
def main():
    print("="*60)
    print("ğŸš€ V6 ì‹œí€€ìŠ¤ ìƒì„±ê¸°ìš© ë°ì´í„° ì¶•ì†Œ")
    print("="*60)
    
    # 1. ë°ì´í„° ë¡œë“œ
    print(f"\nğŸ“‚ ì›ë³¸ ë°ì´í„° ë¡œë”©: {INPUT_FILE}")
    try:
        df = pd.read_csv(INPUT_FILE)
    except:
        print("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None
    
    original_size = len(df)
    print(f"âœ… ì›ë³¸ í¬ê¸°: {original_size:,}í–‰")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ (V6ì™€ ë™ì¼)
    required_cols = ['TOTALCNT'] if 'TOTALCNT' in df.columns else []
    m14_cols = ['M14AM10A', 'M14AM14B', 'M14AM16']
    
    for col in m14_cols:
        if col not in df.columns:
            print(f"  âš ï¸ {col} ì—†ìŒ â†’ 0ìœ¼ë¡œ ì´ˆê¸°í™”")
            df[col] = 0
    
    # 2. ì‹œê°„ ê¸°ë°˜ ì—°ì†ì„± í™•ì¸
    print("\nğŸ” ì—°ì† êµ¬ê°„ ë¶„ì„ ì¤‘...")
    
    # TIME ë˜ëŠ” CURRTIME ì»¬ëŸ¼ í™•ì¸
    time_col = None
    if 'TIME' in df.columns:
        time_col = 'TIME'
    elif 'CURRTIME' in df.columns:
        time_col = 'CURRTIME'
    
    if time_col:
        # ì‹œê°„ ìˆœì„œë¡œ ì •ë ¬
        df = df.sort_values(time_col).reset_index(drop=True)
        
        # datetime ë³€í™˜
        df['datetime'] = pd.to_datetime(df[time_col].astype(str), 
                                       format='%Y%m%d%H%M', 
                                       errors='coerce')
        
        # ì‹œê°„ ì°¨ì´ ê³„ì‚°
        df['time_diff'] = df['datetime'].diff().dt.total_seconds() / 60
        
        # 5ë¶„ ì´ìƒ ëŠì–´ì§„ êµ¬ê°„ ì°¾ê¸°
        df['segment_id'] = (df['time_diff'] > 5).cumsum()
        
        # ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸°
        segment_sizes = df.groupby('segment_id').size()
        min_size = LOOKBACK + FORECAST + 10  # ì—¬ìœ  ìˆê²Œ
        valid_segments = segment_sizes[segment_sizes >= min_size]
        
        print(f"  â€¢ ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸: {len(segment_sizes)}ê°œ")
        print(f"  â€¢ ìœ íš¨ ì„¸ê·¸ë¨¼íŠ¸ (>={min_size}ë¶„): {len(valid_segments)}ê°œ")
        print(f"  â€¢ ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸: {segment_sizes.max():,}ë¶„")
    else:
        # ì‹œê°„ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í•˜ë‚˜ë¡œ
        df['segment_id'] = 0
        valid_segments = pd.Series([len(df)], index=[0])
        print("  â€¢ TIME ì»¬ëŸ¼ ì—†ìŒ - ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì²˜ë¦¬")
    
    # 3. ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°
    print("\nğŸ“Š ì¤‘ìš” íŒ¨í„´ ë¶„ì„ ì¤‘...")
    
    segment_scores = {}
    critical_indices = []  # ë°˜ë“œì‹œ ë³´ì¡´í•  ì¸ë±ìŠ¤
    
    for seg_id in valid_segments.index:
        seg_df = df[df['segment_id'] == seg_id]
        score = 0
        
        # TOTALCNT ê¸°ë°˜ ì ìˆ˜
        if 'TOTALCNT' in seg_df.columns:
            # 1500 ì´ìƒì¸ í–‰ë“¤ì€ ë°˜ë“œì‹œ ë³´ì¡´
            critical_mask = seg_df['TOTALCNT'] >= 1500
            critical_indices.extend(seg_df[critical_mask].index.tolist())
            
            # í‰ê· ê°’ ì ìˆ˜
            avg_total = seg_df['TOTALCNT'].mean()
            score += avg_total / 10
            
            # ë³€ë™ì„± ì ìˆ˜
            std_total = seg_df['TOTALCNT'].std()
            score += std_total / 20
        
        # M14AM14B ê¸°ë°˜ ì ìˆ˜
        if 'M14AM14B' in seg_df.columns:
            # 400 ì´ìƒì¸ í–‰ë“¤ì€ ë°˜ë“œì‹œ ë³´ì¡´
            critical_m14b = seg_df['M14AM14B'] >= M14B_THRESHOLDS[1500]
            critical_indices.extend(seg_df[critical_m14b].index.tolist())
            
            # ì„ê³„ê°’ë³„ ê°€ì¤‘ì¹˜
            for threshold_val, m14b_threshold in M14B_THRESHOLDS.items():
                count = (seg_df['M14AM14B'] >= m14b_threshold).sum()
                score += count * (threshold_val / 1000)
        
        # í™©ê¸ˆ íŒ¨í„´ (M14B ë†’ê³  M10A ë‚®ìŒ)
        if 'M14AM14B' in seg_df.columns and 'M14AM10A' in seg_df.columns:
            golden_pattern = (seg_df['M14AM14B'] >= 300) & (seg_df['M14AM10A'] < 80)
            critical_indices.extend(seg_df[golden_pattern].index.tolist())
            score += golden_pattern.sum() * 20
            
            # ë¹„ìœ¨ íŒ¨í„´
            seg_df['temp_ratio'] = seg_df['M14AM14B'] / seg_df['M14AM10A'].clip(lower=1)
            for threshold_val, ratio_threshold in RATIO_THRESHOLDS.items():
                ratio_count = (seg_df['temp_ratio'] >= ratio_threshold).sum()
                score += ratio_count * (threshold_val / 1000)
        
        # ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ë³´ë„ˆìŠ¤
        score += len(seg_df) / 1000
        
        segment_scores[seg_id] = score
    
    # ì¤‘ë³µ ì œê±°
    critical_indices = list(set(critical_indices))
    print(f"  â€¢ í•„ìˆ˜ ë³´ì¡´ í–‰: {len(critical_indices):,}ê°œ")
    
    # 4. ìŠ¤ë§ˆíŠ¸ ìƒ˜í”Œë§
    print("\nğŸ¯ ìŠ¤ë§ˆíŠ¸ ìƒ˜í”Œë§ ì‹œì‘...")
    
    target_rows = REDUCTION_CONFIG['target_rows']
    
    # í•„ìˆ˜ ë³´ì¡´ ë°ì´í„°
    if REDUCTION_CONFIG['keep_critical_patterns']:
        sampled_indices = critical_indices.copy()
        remaining_quota = target_rows - len(sampled_indices)
        print(f"  â€¢ í•„ìˆ˜ íŒ¨í„´ ë³´ì¡´: {len(sampled_indices):,}ê°œ")
    else:
        sampled_indices = []
        remaining_quota = target_rows
    
    # ì„¸ê·¸ë¨¼íŠ¸ë³„ë¡œ ì¶”ê°€ ìƒ˜í”Œë§
    if remaining_quota > 0:
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_segments = sorted(segment_scores.items(), key=lambda x: x[1], reverse=True)
        
        for seg_id, score in sorted_segments:
            if remaining_quota <= 0:
                break
            
            seg_df = df[df['segment_id'] == seg_id]
            
            # ì´ë¯¸ ì„ íƒëœ ê²ƒ ì œì™¸
            unselected = seg_df[~seg_df.index.isin(sampled_indices)]
            
            if len(unselected) == 0:
                continue
            
            # ì´ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ìƒ˜í”Œë§í•  ê°œìˆ˜
            seg_quota = min(remaining_quota, len(unselected) // 2)
            
            if seg_quota > 0:
                # ê· ë“± ê°„ê²© ìƒ˜í”Œë§
                step = max(1, len(unselected) // seg_quota)
                seg_samples = unselected.iloc[::step].index.tolist()
                sampled_indices.extend(seg_samples[:seg_quota])
                remaining_quota -= len(seg_samples[:seg_quota])
        
        print(f"  â€¢ ì¶”ê°€ ìƒ˜í”Œë§: {target_rows - remaining_quota:,}ê°œ")
    
    # 5. ìµœì¢… ë°ì´í„° ìƒì„±
    print("\nğŸ“¦ ìµœì¢… ë°ì´í„° ìƒì„± ì¤‘...")
    
    # ì„ íƒëœ ì¸ë±ìŠ¤ë¡œ ë°ì´í„° ì¶”ì¶œ
    sampled_indices = sorted(list(set(sampled_indices)))
    df_reduced = df.loc[sampled_indices].copy()
    
    # ì„ì‹œ ì»¬ëŸ¼ ì œê±°
    temp_cols = ['datetime', 'time_diff', 'segment_id', 'temp_ratio']
    for col in temp_cols:
        if col in df_reduced.columns:
            df_reduced = df_reduced.drop(col, axis=1)
    
    # ì¸ë±ìŠ¤ ë¦¬ì…‹
    df_reduced = df_reduced.reset_index(drop=True)
    
    # 6. ê²€ì¦
    print("\nâœ… ê²°ê³¼ ê²€ì¦")
    print("="*60)
    
    print(f"ì¶•ì†Œ ê²°ê³¼:")
    print(f"  â€¢ ì›ë³¸: {original_size:,}í–‰")
    print(f"  â€¢ ì¶•ì†Œ: {len(df_reduced):,}í–‰")
    print(f"  â€¢ ì¶•ì†Œìœ¨: {(1 - len(df_reduced)/original_size)*100:.1f}%")
    
    # ì‹œí€€ìŠ¤ ìƒì„± ê°€ëŠ¥ í™•ì¸
    max_sequences = max(0, len(df_reduced) - LOOKBACK - FORECAST)
    print(f"\nìƒì„± ê°€ëŠ¥ ì‹œí€€ìŠ¤: {max_sequences:,}ê°œ")
    
    # ì¤‘ìš” íŒ¨í„´ ë³´ì¡´ë¥ 
    if 'TOTALCNT' in df_reduced.columns:
        orig_1500 = (df['TOTALCNT'] >= 1500).sum()
        redu_1500 = (df_reduced['TOTALCNT'] >= 1500).sum()
        if orig_1500 > 0:
            print(f"\nTOTALCNT â‰¥ 1500 ë³´ì¡´ë¥ : {redu_1500/orig_1500*100:.1f}%")
    
    if 'M14AM14B' in df_reduced.columns:
        orig_400 = (df['M14AM14B'] >= 400).sum()
        redu_400 = (df_reduced['M14AM14B'] >= 400).sum()
        if orig_400 > 0:
            print(f"M14AM14B â‰¥ 400 ë³´ì¡´ë¥ : {redu_400/orig_400*100:.1f}%")
    
    # 7. ì €ì¥
    print(f"\nğŸ’¾ ì €ì¥ ì¤‘: {OUTPUT_FILE}")
    df_reduced.to_csv(OUTPUT_FILE, index=False)
    print(f"âœ… ì €ì¥ ì™„ë£Œ!")
    
    # 8. ì‚¬ìš© ì•ˆë‚´
    print("\n" + "="*60)
    print("âœ¨ ì™„ë£Œ! V6 ì‹œí€€ìŠ¤ ìƒì„±ê¸° ì‚¬ìš© ë°©ë²•:")
    print("="*60)
    print("\n1. V6 ì½”ë“œì—ì„œ ê²½ë¡œë§Œ ë³€ê²½:")
    print(f"   DATA_FILE = '{OUTPUT_FILE}'")
    print("\n2. ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ì‹¤í–‰:")
    print("   python sequence_generator_v6_parallel.py")
    print("\nğŸ’¡ ì¶”ê°€ ì˜µì…˜:")
    print("  â€¢ ë” ì‘ê²Œ: target_rows = 50000")
    print("  â€¢ ë” í¬ê²Œ: target_rows = 200000")
    print("  â€¢ ëª¨ë“  íŒ¨í„´: keep_critical_patterns = True (ê¶Œì¥)")
    
    return df_reduced

if __name__ == '__main__':
    result = main()