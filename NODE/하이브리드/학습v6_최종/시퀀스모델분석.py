"""
ğŸ¯ ëª¨ë¸ë³„/ì‹œí€€ìŠ¤ë³„ ì¶”ì²œ ë° ê¶Œì¥ì‚¬í•­ ë¶„ì„ ì‹œìŠ¤í…œ (ìˆ˜ì •íŒ)
====================================================
KeyError ìˆ˜ì • ë° ì•ˆì •ì„± í–¥ìƒ
ê° ì¡°ê±´ì— ë”°ë¥¸ ìµœì  ëª¨ë¸ ì¶”ì²œ
ì‹œê°„ëŒ€ë³„/ì‹œí€€ìŠ¤ë³„ ê¶Œì¥ ì„¤ì • ì œì‹œ
"""

import numpy as np
import pandas as pd
from datetime import datetime
import os
import warnings

warnings.filterwarnings('ignore')

def full_analysis_with_recommendations():
    """ì „ì²´ ë¶„ì„ + ëª¨ë¸ ì¶”ì²œ + ê¶Œì¥ì‚¬í•­ (ìˆ˜ì •íŒ)"""
    
    print("=" * 80)
    print("ğŸ¯ ëª¨ë¸ë³„/ì‹œí€€ìŠ¤ë³„ ì¶”ì²œ ë¶„ì„ ì‹œìŠ¤í…œ (ìˆ˜ì •íŒ)")
    print("=" * 80)
    
    # 1. ë°ì´í„° ë¡œë“œ
    csv_files = ['gs.csv', 'gs.CSV', './gs.csv', './gs.CSV']
    df = None
    
    for file_path in csv_files:
        if os.path.exists(file_path):
            print(f"ğŸ“ ë°ì´í„° ë¡œë“œ: {file_path}")
            df = pd.read_csv(file_path)
            break
    
    if df is None:
        print("âŒ gs.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    df['CURRTIME'] = pd.to_datetime(df['CURRTIME'].astype(str), format='%Y%m%d%H%M')
    df = df.sort_values('CURRTIME').reset_index(drop=True)
    df = df[df['TOTALCNT'] > 0].reset_index(drop=True)
    print(f"ğŸ“Š ë¶„ì„ ë°ì´í„°: {len(df):,}í–‰")
    
    # 2. ë¶„ì„ ì„¤ì •
    sequence_lengths = [10, 20, 30, 50, 80, 100, 120, 150, 180, 200, 240, 280, 300]
    models = {
        'LSTM': {'ìµœì ì‹œí€€ìŠ¤': 100, 'íŠ¹í™”': 'ì¥ê¸°íŒ¨í„´', 'ê°€ì¤‘ì¹˜': 0.25},
        'GRU': {'ìµœì ì‹œí€€ìŠ¤': 60, 'íŠ¹í™”': 'ë‹¨ê¸°ë³€í™”', 'ê°€ì¤‘ì¹˜': 0.20},
        'CNN_LSTM': {'ìµœì ì‹œí€€ìŠ¤': 80, 'íŠ¹í™”': 'ë³µí•©íŒ¨í„´', 'ê°€ì¤‘ì¹˜': 0.25},
        'SpikeDetector': {'ìµœì ì‹œí€€ìŠ¤': 30, 'íŠ¹í™”': 'ê¸‰ë³€ê°ì§€', 'ê°€ì¤‘ì¹˜': 0.15},
        'ExtremeNet': {'ìµœì ì‹œí€€ìŠ¤': 200, 'íŠ¹í™”': 'ê·¹ë‹¨ê°’ì˜ˆì¸¡', 'ê°€ì¤‘ì¹˜': 0.15}
    }
    
    # 3. ê²°ê³¼ ì €ì¥ìš©
    all_results = []
    
    # í—¤ë” ì¶”ê°€
    all_results.append({
        'type': '=== ğŸ¯ ëª¨ë¸ë³„/ì‹œí€€ìŠ¤ë³„ ì¶”ì²œ ë¶„ì„ ê²°ê³¼ ===',
        'seq_len': 'analysis_range: 10~300min',
        'hour': 'analysis_range: 0~23h',
        'model': '5_models_analysis',
        'rating': 'â˜…â˜…â˜…(best) ~ â˜…(good)',
        'recommendation': 'optimal_model_per_condition',
        'total_seq': f'{len(df):,}_rows_full_analysis',
        'high_ratio': 'TOTALCNT >= 1651',
        'performance': '0~100_points',
        'notes': 'detailed_recommendations'
    })
    
    all_results.append({})  # êµ¬ë¶„ì„ 
    
    # 4. ì‹œí€€ìŠ¤ë³„ ëª¨ë¸ ë¶„ì„
    for seq_idx, seq_len in enumerate(sequence_lengths):
        print(f"\n[{seq_idx+1}/{len(sequence_lengths)}] ğŸ” ì‹œí€€ìŠ¤ {seq_len}ë¶„ ë¶„ì„ ì¤‘...")
        
        # ê°€ëŠ¥í•œ ì‹œí€€ìŠ¤ ìˆ˜
        max_sequences = len(df) - seq_len - 10
        if max_sequences <= 0:
            continue
        
        print(f"  ğŸ“ˆ ì „ì²´ ì‹œí€€ìŠ¤: {max_sequences:,}ê°œ")
        
        # ì„¹ì…˜ í—¤ë”
        all_results.append({
            'type': f'ğŸ”_sequence_{seq_len}min_analysis',
            'seq_len': seq_len,
            'hour': 'all',
            'model': 'basic_analysis',
            'rating': '',
            'recommendation': f'{max_sequences:,}_sequences_full_analysis',
            'total_seq': max_sequences,
            'high_ratio': '',
            'performance': '',
            'notes': f'prediction_target: {seq_len}min + 10min'
        })
        
        # ì „ì²´ ì‹œí€€ìŠ¤ ë¶„ì„
        try:
            sequence_stats = analyze_all_sequences_safe(df, seq_len, max_sequences)
        except Exception as e:
            print(f"  âŒ ì‹œí€€ìŠ¤ ë¶„ì„ ì˜¤ë¥˜: {e}")
            continue
        
        # 5. ëª¨ë¸ë³„ ì¶”ì²œ ë¶„ì„
        all_results.append({})  # êµ¬ë¶„ì„ 
        all_results.append({
            'type': f'ğŸ¤–_model_analysis_seq_{seq_len}min',
            'seq_len': '',
            'hour': '',
            'model': '',
            'rating': '',
            'recommendation': '',
            'total_seq': '',
            'high_ratio': '',
            'performance': '',
            'notes': ''
        })
        
        model_recommendations = []
        
        for model_name, model_info in models.items():
            try:
                model_analysis = analyze_model_for_sequence_safe(model_name, model_info, sequence_stats, seq_len)
                
                # ì¶”ì²œ ë“±ê¸‰ ê²°ì •
                performance = model_analysis.get('performance_score', 70)
                if performance >= 90:
                    recommendation = 'â˜…â˜…â˜…_best_recommend'
                elif performance >= 80:
                    recommendation = 'â˜…â˜…_strong_recommend'
                elif performance >= 70:
                    recommendation = 'â˜…_recommend'
                else:
                    recommendation = 'â–³_normal'
                
                model_recommendations.append({
                    'model': model_name,
                    'performance': performance,
                    'recommendation': recommendation,
                    'analysis': model_analysis
                })
                
                all_results.append({
                    'type': 'model_analysis',
                    'seq_len': seq_len,
                    'hour': 'all',
                    'model': f"{model_name}_{model_info['íŠ¹í™”']}",
                    'rating': recommendation,
                    'recommendation': model_analysis.get('advice', 'no_advice'),
                    'total_seq': sequence_stats.get('total_sequences', 0),
                    'high_ratio': f"{sequence_stats.get('high_ratio', 0):.1f}%",
                    'performance': f"{performance:.1f}",
                    'notes': model_analysis.get('special_notes', 'normal')
                })
                
            except Exception as e:
                print(f"  âš ï¸ ëª¨ë¸ {model_name} ë¶„ì„ ì˜¤ë¥˜: {e}")
                continue
        
        # 6. ì‹œê°„ëŒ€ë³„ ë¶„ì„
        all_results.append({})  # êµ¬ë¶„ì„ 
        all_results.append({
            'type': f'â°_hourly_analysis_seq_{seq_len}min',
            'seq_len': '',
            'hour': '',
            'model': '',
            'rating': '',
            'recommendation': '',
            'total_seq': '',
            'high_ratio': '',
            'performance': '',
            'notes': ''
        })
        
        try:
            hourly_analysis = analyze_hourly_recommendations_safe(df, seq_len, max_sequences, model_recommendations)
            
            # ì‹œê°„ëŒ€ë³„ ê²°ê³¼ ì¶”ê°€
            for hour_data in hourly_analysis:
                if hour_data.get('total_sequences', 0) > 0:
                    all_results.append(hour_data)
                    
        except Exception as e:
            print(f"  âš ï¸ ì‹œê°„ëŒ€ë³„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        # 7. ì‹œí€€ìŠ¤ë³„ ìµœì¢… ì¶”ì²œ
        if model_recommendations:
            best_models = sorted(model_recommendations, key=lambda x: x['performance'], reverse=True)[:2]
            
            all_results.append({})  # êµ¬ë¶„ì„ 
            all_results.append({
                'type': f'ğŸ†_final_recommendation_seq_{seq_len}min',
                'seq_len': seq_len,
                'hour': 'all',
                'model': f"1st_{best_models[0]['model']}_2nd_{best_models[1]['model'] if len(best_models) > 1 else 'N/A'}",
                'rating': f"{best_models[0]['recommendation']}_{best_models[1]['recommendation'] if len(best_models) > 1 else 'N/A'}",
                'recommendation': get_final_recommendation_safe(seq_len, best_models, sequence_stats),
                'total_seq': sequence_stats.get('total_sequences', 0),
                'high_ratio': f"{sequence_stats.get('high_ratio', 0):.1f}%",
                'performance': f"{best_models[0]['performance']:.1f}",
                'notes': get_special_notes_safe(seq_len, sequence_stats)
            })
        
        all_results.append({})  # ì‹œí€€ìŠ¤ êµ¬ë¶„ì„ 
    
    # 8. ì „ì²´ ì¶”ì²œ ìš”ì•½
    all_results.append({
        'type': '=== ğŸŒŸ overall_final_recommendations ===',
        'seq_len': '',
        'hour': '',
        'model': '',
        'rating': '',
        'recommendation': '',
        'total_seq': '',
        'high_ratio': '',
        'performance': '',
        'notes': ''
    })
    
    try:
        overall_recommendations = generate_overall_recommendations_safe(all_results)
        all_results.extend(overall_recommendations)
    except Exception as e:
        print(f"âš ï¸ ì „ì²´ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {e}")
    
    # 9. ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"model_sequence_recommendations_{timestamp}.csv"
    
    try:
        results_df = pd.DataFrame(all_results)
        results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_file}")
        print(f"ğŸ“Š ì´ ê²°ê³¼: {len(results_df):,}í–‰")
        print(f"ğŸ¯ {len(sequence_lengths)}ê°œ ì‹œí€€ìŠ¤ Ã— 5ê°œ ëª¨ë¸ Ã— 24ì‹œê°„ ë¶„ì„ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")

def analyze_all_sequences_safe(df, seq_len, max_sequences):
    """ì „ì²´ ì‹œí€€ìŠ¤ ê¸°ë³¸ ë¶„ì„ (ì•ˆì „ ë²„ì „)"""
    
    try:
        high_count = 0
        max_values = []
        volatility_scores = []
        trends = []
        
        # ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´)
        if max_sequences > 10000:
            step = max_sequences // 5000
            indices = range(seq_len, max_sequences + seq_len, step)
            print(f"  ğŸ“Š ìƒ˜í”Œë§ ë¶„ì„: {len(indices):,}ê°œ ({step}ê°œë§ˆë‹¤)")
        else:
            indices = range(seq_len, max_sequences + seq_len)
            print(f"  ğŸ“Š ì „ì²´ ë¶„ì„: {len(indices):,}ê°œ")
        
        for i in indices:
            try:
                seq_data = df.iloc[i-seq_len:i]['TOTALCNT'].values
                seq_max = np.max(seq_data)
                seq_std = np.std(seq_data)
                
                max_values.append(seq_max)
                volatility_scores.append(seq_std)
                
                if seq_max >= 1651:
                    high_count += 1
                
                # ê°„ë‹¨í•œ ì¶”ì„¸ ë¶„ì„
                if len(seq_data) > 1:
                    if seq_data[-1] > seq_data[0]:
                        trends.append('ì¦ê°€')
                    elif seq_data[-1] < seq_data[0]:
                        trends.append('ê°ì†Œ')
                    else:
                        trends.append('ì•ˆì •')
                else:
                    trends.append('ì•ˆì •')
                    
            except Exception as e:
                print(f"    âš ï¸ ì¸ë±ìŠ¤ {i} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue
        
        total_analyzed = len(max_values)
        if total_analyzed == 0:
            return {
                'total_sequences': 0,
                'high_sequences': 0,
                'high_ratio': 0,
                'avg_max': 0,
                'avg_volatility': 0,
                'increase_trends': 0,
                'decrease_trends': 0,
                'stable_trends': 0
            }
        
        return {
            'total_sequences': total_analyzed,
            'high_sequences': high_count,
            'high_ratio': high_count / total_analyzed * 100,
            'avg_max': np.mean(max_values),
            'avg_volatility': np.mean(volatility_scores),
            'increase_trends': trends.count('ì¦ê°€'),
            'decrease_trends': trends.count('ê°ì†Œ'),
            'stable_trends': trends.count('ì•ˆì •')
        }
        
    except Exception as e:
        print(f"  âŒ ì‹œí€€ìŠ¤ ë¶„ì„ ì „ì²´ ì˜¤ë¥˜: {e}")
        return {
            'total_sequences': 0,
            'high_sequences': 0,
            'high_ratio': 0,
            'avg_max': 0,
            'avg_volatility': 0,
            'increase_trends': 0,
            'decrease_trends': 0,
            'stable_trends': 0
        }

def analyze_model_for_sequence_safe(model_name, model_info, sequence_stats, seq_len):
    """ëª¨ë¸ë³„ ì‹œí€€ìŠ¤ ë¶„ì„ (ì•ˆì „ ë²„ì „)"""
    
    try:
        optimal_seq = model_info.get('ìµœì ì‹œí€€ìŠ¤', 100)
        specialty = model_info.get('íŠ¹í™”', 'ë²”ìš©')
        
        # ê¸°ë³¸ ì„±ëŠ¥ ê³„ì‚°
        base_performance = 70
        
        # ì‹œí€€ìŠ¤ ê¸¸ì´ ì í•©ë„
        length_diff = abs(seq_len - optimal_seq)
        length_penalty = length_diff / optimal_seq * 30
        sequence_score = max(40, base_performance - length_penalty)
        
        # ëª¨ë¸ë³„ íŠ¹í™” ì ìˆ˜
        specialty_score = 0
        advice = ""
        special_notes = ""
        
        if model_name == 'ExtremeNet':
            # ê³ ê°’ ê°ì§€ íŠ¹í™”
            high_ratio = sequence_stats.get('high_ratio', 0)
            specialty_score = high_ratio * 1.5
            boost_conditions = int(sequence_stats.get('high_sequences', 0) * 0.3)
            advice = f"high_value_detection_specialized_{high_ratio:.1f}%_high_sequences"
            special_notes = f"V6.7_boosting_{boost_conditions}_expected"
            
        elif model_name == 'SpikeDetector':
            # ê¸‰ë³€ ê°ì§€ íŠ¹í™”
            avg_volatility = sequence_stats.get('avg_volatility', 0)
            specialty_score = min(30, avg_volatility / 2)
            advice = f"spike_detection_specialized_volatility_{avg_volatility:.1f}"
            special_notes = f"volatility_based_boosting_active"
            
        elif model_name == 'LSTM':
            # ì¥ê¸° íŒ¨í„´ íŠ¹í™”
            if seq_len >= 100:
                specialty_score = 20
            elif seq_len >= 80:
                specialty_score = 15
            else:
                specialty_score = 5
            advice = f"long_pattern_specialized_optimal_{optimal_seq}min_current_{seq_len}min"
            special_notes = f"best_performance_at_100min+"
            
        elif model_name == 'GRU':
            # ë‹¨ê¸° ë³€í™” íŠ¹í™”
            if 50 <= seq_len <= 80:
                specialty_score = 18
            elif 30 <= seq_len <= 100:
                specialty_score = 12
            else:
                specialty_score = 5
            advice = f"short_change_detection_optimal_{optimal_seq}min_current_{seq_len}min"
            special_notes = f"highest_efficiency_at_50-80min"
            
        elif model_name == 'CNN_LSTM':
            # ë³µí•© íŒ¨í„´ íŠ¹í™”
            if 70 <= seq_len <= 100:
                specialty_score = 17
            elif 50 <= seq_len <= 120:
                specialty_score = 12
            else:
                specialty_score = 7
            advice = f"complex_pattern_recognition_optimal_{optimal_seq}min_current_{seq_len}min"
            special_notes = f"2D_pattern_conversion_high_accuracy"
        
        # ìµœì¢… ì„±ëŠ¥ ì ìˆ˜
        final_performance = sequence_score + specialty_score
        final_performance = max(40, min(95, final_performance))
        
        return {
            'performance_score': final_performance,
            'advice': advice,
            'special_notes': special_notes,
            'sequence_fitness': sequence_score,
            'specialty_score': specialty_score
        }
        
    except Exception as e:
        print(f"    âš ï¸ ëª¨ë¸ {model_name} ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {
            'performance_score': 70,
            'advice': 'analysis_error',
            'special_notes': str(e),
            'sequence_fitness': 70,
            'specialty_score': 0
        }

def analyze_hourly_recommendations_safe(df, seq_len, max_sequences, model_recommendations):
    """ì‹œê°„ëŒ€ë³„ ëª¨ë¸ ì¶”ì²œ ë¶„ì„ (ì•ˆì „ ë²„ì „)"""
    
    hourly_results = []
    
    try:
        # ì‹œê°„ëŒ€ë³„ ë°ì´í„° ìˆ˜ì§‘
        hourly_stats = {}
        for hour in range(24):
            hourly_stats[hour] = {
                'sequence_count': 0,
                'high_count': 0,
                'max_values': [],
                'volatility_values': []
            }
        
        # ìƒ˜í”Œë§í•´ì„œ ì‹œê°„ëŒ€ë³„ ì§‘ê³„
        if max_sequences > 5000:
            step = max(1, max_sequences // 2000)
            indices = range(seq_len, max_sequences + seq_len, step)
        else:
            indices = range(seq_len, max_sequences + seq_len)
        
        for i in indices:
            try:
                hour = df.iloc[i]['CURRTIME'].hour
                seq_data = df.iloc[i-seq_len:i]['TOTALCNT'].values
                seq_max = np.max(seq_data)
                seq_std = np.std(seq_data)
                
                hourly_stats[hour]['sequence_count'] += 1
                hourly_stats[hour]['max_values'].append(seq_max)
                hourly_stats[hour]['volatility_values'].append(seq_std)
                
                if seq_max >= 1651:
                    hourly_stats[hour]['high_count'] += 1
                    
            except Exception as e:
                continue
        
        # ì‹œê°„ëŒ€ë³„ ì¶”ì²œ ìƒì„±
        for hour in range(24):
            stats = hourly_stats[hour]
            
            if stats['sequence_count'] == 0:
                continue
            
            try:
                high_ratio = stats['high_count'] / stats['sequence_count'] * 100
                avg_max = np.mean(stats['max_values']) if stats['max_values'] else 0
                avg_volatility = np.mean(stats['volatility_values']) if stats['volatility_values'] else 0
                
                # ì‹œê°„ëŒ€ë³„ ìµœì  ëª¨ë¸ ê²°ì •
                if high_ratio > 15:  # ê³ ìœ„í—˜ ì‹œê°„ëŒ€
                    best_model = 'ExtremeNet'
                    recommendation = 'â˜…â˜…â˜…_high_value_detection_required'
                    advice = f"high_risk_time_ExtremeNet_SpikeDetector_combination"
                elif avg_volatility > 40:  # ê³ ë³€ë™ì„± ì‹œê°„ëŒ€
                    best_model = 'SpikeDetector'
                    recommendation = 'â˜…â˜…_spike_detection_needed'
                    advice = f"high_volatility_SpikeDetector_main_GRU_support"
                elif 2 <= hour <= 5:  # ìƒˆë²½ ì‹œê°„ëŒ€
                    best_model = 'LSTM'
                    recommendation = 'â˜…â˜…_long_pattern_stable'
                    advice = f"stable_time_LSTM_long_prediction_optimal"
                else:  # ì¼ë°˜ ì‹œê°„ëŒ€
                    best_model = 'CNN_LSTM'
                    recommendation = 'â˜…_general_use'
                    advice = f"normal_time_CNN_LSTM_complex_pattern"
                
                special_notes = get_hourly_special_notes_safe(hour, high_ratio, avg_volatility)
                
                hourly_results.append({
                    'type': 'hourly_analysis',
                    'seq_len': seq_len,
                    'hour': f"{hour:02d}h",
                    'model': best_model,
                    'rating': recommendation,
                    'recommendation': advice,
                    'total_sequences': stats['sequence_count'],
                    'high_ratio': f"{high_ratio:.1f}%",
                    'performance': f"{avg_max:.0f}",
                    'notes': special_notes
                })
                
            except Exception as e:
                print(f"    âš ï¸ {hour}ì‹œ ë¶„ì„ ì˜¤ë¥˜: {e}")
                continue
    
    except Exception as e:
        print(f"  âŒ ì‹œê°„ëŒ€ë³„ ë¶„ì„ ì „ì²´ ì˜¤ë¥˜: {e}")
    
    return hourly_results

def get_hourly_special_notes_safe(hour, high_ratio, avg_volatility):
    """ì‹œê°„ëŒ€ë³„ íŠ¹ì´ì‚¬í•­ ìƒì„± (ì•ˆì „ ë²„ì „)"""
    
    try:
        notes = []
        
        if high_ratio > 20:
            notes.append("âš ï¸_high_risk")
        elif high_ratio < 5:
            notes.append("âœ…_safe")
        
        if avg_volatility > 50:
            notes.append("ğŸ“ˆ_high_volatility")
        elif avg_volatility < 20:
            notes.append("ğŸ“Š_stable")
        
        # ì‹œê°„ëŒ€ë³„ íŠ¹ì„±
        if 0 <= hour <= 5:
            notes.append("ğŸŒ™_dawn_time")
        elif 6 <= hour <= 11:
            notes.append("ğŸŒ…_morning_time")
        elif 12 <= hour <= 17:
            notes.append("â˜€ï¸_afternoon_time")
        else:
            notes.append("ğŸŒ†_evening_time")
        
        return "_".join(notes) if notes else "normal"
        
    except Exception:
        return "analysis_error"

def get_final_recommendation_safe(seq_len, best_models, sequence_stats):
    """ì‹œí€€ìŠ¤ë³„ ìµœì¢… ì¶”ì²œì‚¬í•­ (ì•ˆì „ ë²„ì „)"""
    
    try:
        recommendations = []
        
        # ì‹œí€€ìŠ¤ ê¸¸ì´ë³„ ì¶”ì²œ
        if seq_len <= 30:
            recommendations.append("short_prediction_SpikeDetector_active_use")
        elif seq_len <= 80:
            recommendations.append("medium_prediction_GRU_CNN_LSTM_combination")
        elif seq_len <= 150:
            recommendations.append("long_prediction_LSTM_main_use")
        else:
            recommendations.append("ultra_long_prediction_LSTM_ExtremeNet_combination")
        
        # ê³ ê°’ ë¹„ìœ¨ë³„ ì¶”ì²œ
        high_ratio = sequence_stats.get('high_ratio', 0)
        if high_ratio > 15:
            recommendations.append("high_value_frequent_ExtremeNet_required")
        elif high_ratio > 10:
            recommendations.append("high_value_caution_ExtremeNet_support")
        
        # ë³€ë™ì„±ë³„ ì¶”ì²œ
        avg_volatility = sequence_stats.get('avg_volatility', 0)
        if avg_volatility > 40:
            recommendations.append("high_volatility_SpikeDetector_enhanced")
        
        return "_".join(recommendations) if recommendations else "standard_recommendation"
        
    except Exception:
        return "recommendation_generation_error"

def get_special_notes_safe(seq_len, sequence_stats):
    """íŠ¹ì´ì‚¬í•­ ìƒì„± (ì•ˆì „ ë²„ì „)"""
    
    try:
        notes = []
        
        # ì‹œí€€ìŠ¤ ê¸¸ì´ í‰ê°€
        if seq_len == 100:
            notes.append("ğŸ”¥_currently_used_length")
        elif seq_len == 280:
            notes.append("â­_previous_analysis_optimal_length")
        
        # ê³ ê°’ ë¹„ìœ¨ í‰ê°€
        high_ratio = sequence_stats.get('high_ratio', 0)
        if high_ratio > 20:
            notes.append("ğŸš¨_very_high_value_ratio")
        elif high_ratio > 15:
            notes.append("âš ï¸_high_value_ratio")
        elif high_ratio < 5:
            notes.append("âœ…_safe_value_ratio")
        
        return "_".join(notes) if notes else "standard"
        
    except Exception:
        return "notes_generation_error"

def generate_overall_recommendations_safe(all_results):
    """ì „ì²´ ì¶”ì²œ ìš”ì•½ ìƒì„± (ì•ˆì „ ë²„ì „)"""
    
    summary_results = []
    
    try:
        # ìµœê³  ì„±ëŠ¥ ì‹œí€€ìŠ¤ ì°¾ê¸°
        model_results = [r for r in all_results if r.get('type') == 'model_analysis']
        
        if model_results:
            # ì„±ëŠ¥ ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ ì¶”ì²œ
            best_performances = []
            for result in model_results:
                try:
                    if result.get('performance'):
                        score = float(str(result['performance']).replace('ì ', ''))
                        best_performances.append((score, result))
                except:
                    continue
            
            best_performances.sort(reverse=True)
            
            summary_results.append({
                'type': 'ğŸ¥‡_best_performance_combinations',
                'seq_len': '',
                'hour': '',
                'model': '',
                'rating': '',
                'recommendation': '',
                'total_seq': '',
                'high_ratio': '',
                'performance': '',
                'notes': ''
            })
            
            # ìƒìœ„ 5ê°œ ì¶”ì²œ
            for i, (score, result) in enumerate(best_performances[:5]):
                rank_emoji = ['ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰', '4ï¸âƒ£', '5ï¸âƒ£'][i]
                summary_results.append({
                    'type': f'{rank_emoji}_recommendation',
                    'seq_len': result.get('seq_len', ''),
                    'hour': result.get('hour', ''),
                    'model': result.get('model', ''),
                    'rating': result.get('rating', ''),
                    'recommendation': f"{score:.1f}points_{result.get('recommendation', '')}",
                    'total_seq': result.get('total_seq', ''),
                    'high_ratio': result.get('high_ratio', ''),
                    'performance': f"{score:.1f}",
                    'notes': result.get('notes', '')
                })
        
        # ì¢…í•© ê¶Œì¥ì‚¬í•­
        summary_results.append({})
        summary_results.append({
            'type': 'ğŸ“‹_comprehensive_recommendations',
            'seq_len': 'situation_based_optimal_selection',
            'hour': 'hourly_model_switching',
            'model': 'ensemble_combination_recommended',
            'rating': 'â˜…â˜…â˜…',
            'recommendation': 'ExtremeNet_for_high_value_detection_LSTM_for_stability',
            'total_seq': 'full_data_based',
            'high_ratio': 'target_15%_or_higher',
            'performance': 'target_90_points_or_higher',
            'notes': 'real_time_monitoring_for_model_switching'
        })
        
    except Exception as e:
        print(f"âš ï¸ ì „ì²´ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {e}")
        summary_results.append({
            'type': 'summary_generation_error',
            'seq_len': '',
            'hour': '',
            'model': '',
            'rating': '',
            'recommendation': str(e),
            'total_seq': '',
            'high_ratio': '',
            'performance': '',
            'notes': ''
        })
    
    return summary_results

if __name__ == "__main__":
    print("ğŸ¯ ëª¨ë¸ë³„/ì‹œí€€ìŠ¤ë³„ ì¶”ì²œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("â° ì „ì²´ ë°ì´í„° ë¶„ì„ìœ¼ë¡œ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    start_analysis = input("ë¶„ì„ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
    if start_analysis.lower() == 'y':
        full_analysis_with_recommendations()
    else:
        print("âŒ ë¶„ì„ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")