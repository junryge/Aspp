"""
ğŸ“Š ë°˜ë„ì²´ ë¬¼ë¥˜ ì˜ˆì¸¡ ëª¨ë¸ í‰ê°€
================================
ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ë¹„êµ ë° ì‹œê°í™”
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle
import json
import os
import warnings
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns

warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class ModelEvaluator:
    def __init__(self, model_path, scaler_path='scalers/'):
        """ëª¨ë¸ í‰ê°€ê¸° ì´ˆê¸°í™”"""
        print("="*80)
        print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì‹œìŠ¤í…œ")
        print("="*80)
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = tf.keras.models.load_model(model_path)
        self.model_name = os.path.basename(model_path).split('.')[0]
        print(f"âœ… ëª¨ë¸ ë¡œë“œ: {self.model_name}")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        with open(f'{scaler_path}feature_scaler.pkl', 'rb') as f:
            self.feature_scaler = pickle.load(f)
        with open(f'{scaler_path}target_scaler.pkl', 'rb') as f:
            self.target_scaler = pickle.load(f)
        with open(f'{scaler_path}config.json', 'r') as f:
            config = json.load(f)
            self.seq_len = config['seq_len']
            self.pred_len = config['pred_len']
            self.feature_columns = config['feature_columns']
        print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
        
    def load_test_data(self, filepath):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
        print(f"\nğŸ“‚ í‰ê°€ ë°ì´í„° ë¡œë”©: {filepath}")
        df = pd.read_csv(filepath)
        print(f"  ì›ë³¸: {df.shape[0]:,}í–‰")
        
        # 0ê°’ ì œê±°
        df = df[df['TOTALCNT'] > 0].reset_index(drop=True)
        
        # ì‹œê°„ ë³€í™˜
        df['CURRTIME'] = pd.to_datetime(df['CURRTIME'].astype(str), 
                                       format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('CURRTIME').reset_index(drop=True)
        
        print(f"  ìœ íš¨: {df.shape[0]:,}í–‰")
        return df
    
    def create_features(self, df):
        """íŠ¹ì„± ìƒì„±"""
        # ê¸°ë³¸ íŠ¹ì„±
        df['RATIO'] = df['M14AM14B'] / (df['M14AM10A'] + 1)
        df['GOLDEN'] = ((df['M14AM14B'] > 300) & (df['M14AM10A'] < 80)).astype(float)
        
        # ì‹œê°„
        df['HOUR'] = df['CURRTIME'].dt.hour
        df['HOUR_SIN'] = np.sin(2 * np.pi * df['HOUR'] / 24)
        df['HOUR_COS'] = np.cos(2 * np.pi * df['HOUR'] / 24)
        
        # ì´ë™í‰ê· 
        for w in [10, 30]:
            df[f'MA_{w}'] = df['TOTALCNT'].rolling(w, min_periods=1).mean()
            df[f'STD_{w}'] = df['TOTALCNT'].rolling(w, min_periods=1).std().fillna(0)
        
        # ë³€í™”ìœ¨
        df['CHANGE_1'] = df['TOTALCNT'].diff(1).fillna(0)
        df['CHANGE_10'] = df['TOTALCNT'].diff(10).fillna(0)
        
        return df
    
    def evaluate(self, test_file):
        """í‰ê°€ ì‹¤í–‰"""
        # ë°ì´í„° ë¡œë“œ
        df = self.load_test_data(test_file)
        df = self.create_features(df)
        
        # ê²°ê³¼ ì €ì¥ìš©
        results = []
        
        print("\nğŸ”® ì˜ˆì¸¡ ì‹œì‘...")
        print(f"  ì‹œí€€ìŠ¤: {self.seq_len}ë¶„")
        print(f"  ì˜ˆì¸¡: {self.pred_len}ë¶„ í›„")
        
        # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë²”ìœ„
        start_idx = self.seq_len
        end_idx = len(df) - self.pred_len
        
        total = end_idx - start_idx
        print(f"  ì˜ˆì¸¡ ê°œìˆ˜: {total:,}ê°œ")
        
        predictions = []
        actuals = []
        timestamps = []
        
        # ë°°ì¹˜ ì˜ˆì¸¡
        batch_size = 1000
        for i in range(start_idx, end_idx, batch_size):
            batch_end = min(i + batch_size, end_idx)
            
            # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
            X_batch = []
            for j in range(i, batch_end):
                # 100ë¶„ ë°ì´í„°
                seq_data = df.iloc[j-self.seq_len:j][self.feature_columns].values
                X_batch.append(seq_data)
            
            if len(X_batch) == 0:
                continue
                
            # ìŠ¤ì¼€ì¼ë§
            X_batch = np.array(X_batch)
            X_batch_scaled = []
            for seq in X_batch:
                seq_scaled = self.feature_scaler.transform(seq)
                X_batch_scaled.append(seq_scaled)
            X_batch_scaled = np.array(X_batch_scaled)
            
            # ì˜ˆì¸¡
            preds = self.model.predict(X_batch_scaled, verbose=0)
            y_pred_scaled = preds[0].flatten()
            
            # ì—­ë³€í™˜
            y_pred = self.target_scaler.inverse_transform(
                y_pred_scaled.reshape(-1, 1)).flatten()
            
            # ì‹¤ì œê°’
            for k, j in enumerate(range(i, batch_end)):
                actual_time = df.iloc[j]['CURRTIME']
                pred_time = actual_time + timedelta(minutes=self.pred_len)
                
                # 10ë¶„ í›„ ì‹¤ì œê°’
                actual_idx = j + self.pred_len
                if actual_idx < len(df):
                    actual_value = df.iloc[actual_idx]['TOTALCNT']
                    pred_value = y_pred[k]
                    
                    predictions.append(pred_value)
                    actuals.append(actual_value)
                    timestamps.append(pred_time)
                    
                    results.append({
                        'ì˜ˆì¸¡ì‹œì ': actual_time.strftime('%Y-%m-%d %H:%M'),
                        'ì˜ˆì¸¡ëŒ€ìƒì‹œê°„': pred_time.strftime('%Y-%m-%d %H:%M'),
                        'ì‹¤ì œê°’': actual_value,
                        'ì˜ˆì¸¡ê°’': round(pred_value),
                        'ì˜¤ì°¨': round(pred_value - actual_value),
                        'ì˜¤ì°¨ìœ¨(%)': round(abs(pred_value - actual_value) / actual_value * 100, 2)
                    })
            
            if len(predictions) % 10000 == 0:
                print(f"    ì²˜ë¦¬: {len(predictions):,}/{total:,}")
        
        print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions):,}ê°œ")
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        predictions = np.array(predictions)
        actuals = np.array(actuals)
        
        mae = mean_absolute_error(actuals, predictions)
        rmse = np.sqrt(mean_squared_error(actuals, predictions))
        r2 = r2_score(actuals, predictions)
        mape = np.mean(np.abs((actuals - predictions) / actuals)) * 100
        
        print("\nğŸ“Š ì „ì²´ ì„±ëŠ¥:")
        print(f"  MAE: {mae:.2f}")
        print(f"  RMSE: {rmse:.2f}")
        print(f"  RÂ²: {r2:.4f}")
        print(f"  MAPE: {mape:.2f}%")
        print(f"  í‰ê·  ì •í™•ë„: {100-mape:.2f}%")
        
        # ê²°ê³¼ DataFrame
        results_df = pd.DataFrame(results)
        
        # ì‹œê°„ëŒ€ë³„ ì„±ëŠ¥
        results_df['ì‹œê°„ëŒ€'] = pd.to_datetime(results_df['ì˜ˆì¸¡ëŒ€ìƒì‹œê°„']).dt.hour
        hourly_stats = results_df.groupby('ì‹œê°„ëŒ€').agg({
            'ì˜¤ì°¨ìœ¨(%)': ['mean', 'std'],
            'ì˜¤ì°¨': ['mean', 'std']
        }).round(2)
        
        print("\nâ° ì‹œê°„ëŒ€ë³„ ì„±ëŠ¥:")
        print(hourly_stats.head(5))
        
        # êµ¬ê°„ë³„ ì„±ëŠ¥
        results_df['êµ¬ê°„'] = pd.cut(results_df['ì‹¤ì œê°’'], 
                                   bins=[0, 1400, 1700, 999999],
                                   labels=['ì •ìƒ', 'ì£¼ì˜', 'ì‹¬ê°'])
        
        level_stats = results_df.groupby('êµ¬ê°„').agg({
            'ì˜¤ì°¨ìœ¨(%)': ['mean', 'count'],
            'ì˜¤ì°¨': ['mean', 'std']
        }).round(2)
        
        print("\nğŸ“Š êµ¬ê°„ë³„ ì„±ëŠ¥:")
        print(level_stats)
        
        # CSV ì €ì¥
        output_file = f'evaluation_{self.model_name}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
        
        # ìƒ˜í”Œ ì¶œë ¥
        print("\nğŸ“ ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ (ìµœê·¼ 20ê°œ):")
        print("="*100)
        print(f"{'ì˜ˆì¸¡ì‹œì ':^19} | {'ëŒ€ìƒì‹œê°„':^19} | {'ì‹¤ì œê°’':>8} | {'ì˜ˆì¸¡ê°’':>8} | {'ì˜¤ì°¨':>8} | {'ì˜¤ì°¨ìœ¨':>8}")
        print("-"*100)
        
        for _, row in results_df.tail(20).iterrows():
            print(f"{row['ì˜ˆì¸¡ì‹œì ']:^19} | {row['ì˜ˆì¸¡ëŒ€ìƒì‹œê°„']:^19} | "
                  f"{row['ì‹¤ì œê°’']:8.0f} | {row['ì˜ˆì¸¡ê°’']:8.0f} | "
                  f"{row['ì˜¤ì°¨']:8.0f} | {row['ì˜¤ì°¨ìœ¨(%)']:7.1f}%")
        
        # ì‹œê°í™”
        self.visualize_results(results_df, timestamps, actuals, predictions)
        
        return results_df
    
    def visualize_results(self, results_df, timestamps, actuals, predictions):
        """ê²°ê³¼ ì‹œê°í™”"""
        print("\nğŸ“ˆ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. ì‹œê³„ì—´ ë¹„êµ (ìµœê·¼ 1000ê°œ)
        n_plot = min(1000, len(timestamps))
        axes[0, 0].plot(timestamps[-n_plot:], actuals[-n_plot:], 
                       label='Actual', alpha=0.7)
        axes[0, 0].plot(timestamps[-n_plot:], predictions[-n_plot:], 
                       label='Predicted', alpha=0.7)
        axes[0, 0].set_title(f'Actual vs Predicted (Last {n_plot} points)')
        axes[0, 0].set_xlabel('Time')
        axes[0, 0].set_ylabel('TOTALCNT')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ì‚°ì ë„
        axes[0, 1].scatter(actuals, predictions, alpha=0.5, s=1)
        axes[0, 1].plot([actuals.min(), actuals.max()], 
                       [actuals.min(), actuals.max()], 
                       'r--', lw=2)
        axes[0, 1].set_title(f'Scatter Plot (RÂ² = {r2_score(actuals, predictions):.4f})')
        axes[0, 1].set_xlabel('Actual')
        axes[0, 1].set_ylabel('Predicted')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. ì˜¤ì°¨ ë¶„í¬
        errors = predictions - actuals
        axes[1, 0].hist(errors, bins=50, edgecolor='black', alpha=0.7)
        axes[1, 0].axvline(x=0, color='r', linestyle='--')
        axes[1, 0].set_title(f'Error Distribution (MAE = {np.mean(np.abs(errors)):.2f})')
        axes[1, 0].set_xlabel('Prediction Error')
        axes[1, 0].set_ylabel('Frequency')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. ì‹œê°„ëŒ€ë³„ ì˜¤ì°¨ìœ¨
        hourly = results_df.groupby('ì‹œê°„ëŒ€')['ì˜¤ì°¨ìœ¨(%)'].mean()
        axes[1, 1].bar(hourly.index, hourly.values, alpha=0.7)
        axes[1, 1].set_title('Error Rate by Hour')
        axes[1, 1].set_xlabel('Hour')
        axes[1, 1].set_ylabel('Error Rate (%)')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plot_file = f'evaluation_{self.model_name}_plot.png'
        plt.savefig(plot_file, dpi=100, bbox_inches='tight')
        print(f"ğŸ“Š ê·¸ë˜í”„ ì €ì¥: {plot_file}")
        plt.show()

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    # ëª¨ë¸ ì„ íƒ
    model_files = [f for f in os.listdir('models') if f.endswith('.keras')]
    
    if not model_files:
        print("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    print("\nğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
    for i, model in enumerate(model_files):
        print(f"  {i+1}. {model}")
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìë™ ì„ íƒ (PatchTST)
    if 'PatchTST.keras' in model_files:
        model_path = 'models/PatchTST.keras'
        print(f"\nâœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ: PatchTST")
    else:
        model_path = f'models/{model_files[0]}'
        print(f"\nâœ… ëª¨ë¸ ì„ íƒ: {model_files[0]}")
    
    # í‰ê°€ê¸° ìƒì„±
    evaluator = ModelEvaluator(model_path)
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼
    test_files = [
        'data/20250731_to20250806.csv',
        'data/test_data.csv',
        '/mnt/user-data/uploads/test.csv'
    ]
    
    test_file = None
    for file in test_files:
        if os.path.exists(file):
            test_file = file
            break
    
    if not test_file:
        print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print("  ì˜ˆìƒ ê²½ë¡œ: data/20250731_to20250806.csv")
        return
    
    # í‰ê°€ ì‹¤í–‰
    results = evaluator.evaluate(test_file)
    
    print("\nâœ… í‰ê°€ ì™„ë£Œ!")
    print("="*80)

if __name__ == "__main__":
    main()