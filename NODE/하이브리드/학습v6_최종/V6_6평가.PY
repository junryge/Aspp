"""
ðŸ“Š V6.7 ê°œì„ ëœ ê·¹ë‹¨ê°’ ì˜ˆì¸¡ í‰ê°€ ì‹œìŠ¤í…œ (ìµœì í™” ë²„ì „)
========================================================
ê°œì„ ì‚¬í•­:
1. ExtremeNet ë¶€ìŠ¤íŒ… ì¡°ê±´ ì™„í™” (1682 â†’ 1650)
2. ë¶€ìŠ¤íŒ… ìƒí•œì„  ì¶”ê°€ (ê³¼ë„í•œ ì˜ˆì¸¡ ë°©ì§€)
3. stable ìƒíƒœì—ì„œë„ ì•½í•œ ë¶€ìŠ¤íŒ… ì ìš©
4. UU1/UU2 íŒ¨í„´ ê°ì§€ ì¡°ê±´ ìµœì í™”
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle
import json
import os
import warnings
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns

warnings.filterwarnings('ignore')
tf.keras.config.enable_unsafe_deserialization()

# ====================== ê°œì„ ëœ íŒ¨í„´ ê°ì§€ê¸° ======================
class DataPatternDetector:
    """ë°ì´í„° íŒ¨í„´ ìžë™ ê°ì§€ (UU1 vs UU2) - ê°œì„ ë¨"""
    
    def detect_pattern(self, df):
        """
        íŒ¨í„´ ê°ì§€: UU1(ê¸‰ì¦) ë˜ëŠ” UU2(ê³ ê°’ìœ ì§€)
        ê°œì„ : ë” ì •í™•í•œ ìž„ê³„ê°’ ì„¤ì •
        """
        
        high_cases = df[df['TOTALCNT'] >= 1682]
        
        if len(high_cases) == 0:
            print("  ðŸ“ˆ UU1 íŒ¨í„´: 1682+ ë°ì´í„° ì—†ìŒ â†’ ê¸‰ì¦ ì˜ˆì¸¡ í•„ìš”")
            return "UU1"
        
        # ì‹œí€€ìŠ¤ íŒ¨í„´ ë¶„ì„
        pattern_stats = []
        trend_counts = {'increasing': 0, 'stable': 0, 'decreasing': 0}
        
        for idx in high_cases.index:
            if idx >= 100:
                seq = df.iloc[idx-100:idx]['TOTALCNT'].values
                
                # ì¶”ì„¸ ê³„ì‚°
                if len(seq) >= 30:
                    recent = seq[-30:]
                    x = np.arange(len(recent))
                    coeffs = np.polyfit(x, recent, 1)
                    slope = coeffs[0]
                    
                    if slope > 2:
                        trend_counts['increasing'] += 1
                    elif slope < -2:
                        trend_counts['decreasing'] += 1
                    else:
                        trend_counts['stable'] += 1
                
                pattern_stats.append({
                    'seq_max': seq.max(),
                    'seq_mean': seq.mean(),
                    'high_1650': (seq >= 1650).sum(),
                    'high_1682': (seq >= 1682).sum()
                })
        
        if not pattern_stats:
            return "UU1"
        
        # í†µê³„ ê³„ì‚°
        avg_seq_max = np.mean([p['seq_max'] for p in pattern_stats])
        avg_seq_mean = np.mean([p['seq_mean'] for p in pattern_stats])
        avg_high_1650 = np.mean([p['high_1650'] for p in pattern_stats])
        avg_high_1682 = np.mean([p['high_1682'] for p in pattern_stats])
        
        total_trends = sum(trend_counts.values())
        stable_ratio = trend_counts['stable'] / max(total_trends, 1)
        
        print(f"\n  ðŸ“Š íŒ¨í„´ ë¶„ì„ ê²°ê³¼:")
        print(f"     ì‹œí€€ìŠ¤ MAX í‰ê· : {avg_seq_max:.0f}")
        print(f"     ì‹œí€€ìŠ¤ MEAN í‰ê· : {avg_seq_mean:.0f}")
        print(f"     1650+ í‰ê·  ê°œìˆ˜: {avg_high_1650:.0f}ê°œ/100")
        print(f"     1682+ í‰ê·  ê°œìˆ˜: {avg_high_1682:.0f}ê°œ/100")
        print(f"     Stable ë¹„ìœ¨: {stable_ratio:.1%}")
        
        # ê°œì„ ëœ UU2 íŒë³„ ì¡°ê±´
        # UU2: ì‹œí€€ìŠ¤ê°€ ì´ë¯¸ ë§¤ìš° ë†’ì€ ìƒíƒœ + ì•ˆì •ì 
        if (avg_seq_max >= 1720 and  # ë” ì—„ê²©í•œ ê¸°ì¤€
            avg_high_1650 >= 25 and  # 1650+ ë§ŽìŒ
            avg_high_1682 >= 10 and  # 1682+ ë„ ìžˆìŒ
            stable_ratio >= 0.5):     # ì•ˆì •ì 
            print(f"  ðŸ”¥ UU2 íŒ¨í„´ ê°ì§€: ê³ ê°’ ìœ ì§€ ìƒíƒœ")
            return "UU2"
        else:
            print(f"  ðŸ“ˆ UU1 íŒ¨í„´ ê°ì§€: ê¸‰ì¦ ì˜ˆì¸¡ í•„ìš”")
            return "UU1"

# ====================== ê°œì„ ëœ ê·¹ë‹¨ê°’ ë³´ì • í´ëž˜ìŠ¤ ======================
class ImprovedExtremeValueBooster:
    """ì‹œí€€ìŠ¤ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ê·¹ë‹¨ê°’ ì˜ˆì¸¡ - ê°œì„ ë¨"""
    
    def __init__(self):
        print("ðŸ”¥ ê°œì„ ëœ ê·¹ë‹¨ê°’ ë¶€ìŠ¤í„° ì´ˆê¸°í™”")
        print("  - ë¶€ìŠ¤íŒ… ì¡°ê±´ ì™„í™”: 1650ë¶€í„° ì‹œìž‘")
        print("  - ë¶€ìŠ¤íŒ… ìƒí•œì„  ì¶”ê°€: ê³¼ë„í•œ ì˜ˆì¸¡ ë°©ì§€")
        print("  - Stable ìƒíƒœì—ì„œë„ ì•½í•œ ë¶€ìŠ¤íŒ…")
        self.data_pattern = "UU1"
        
    def set_data_pattern(self, pattern):
        """ë°ì´í„° íŒ¨í„´ ì„¤ì •"""
        self.data_pattern = pattern
        
    def analyze_sequence(self, sequence_data):
        """ì‹œí€€ìŠ¤ ë¶„ì„: maxê°’ê³¼ ì¶”ì„¸ ê³„ì‚°"""
        if len(sequence_data) == 0:
            return None, 'stable'
        
        seq_max = np.max(sequence_data)
        
        if len(sequence_data) >= 30:
            recent = sequence_data[-30:]
            x = np.arange(len(recent))
            coeffs = np.polyfit(x, recent, 1)
            slope = coeffs[0]
            
            if slope > 2:
                trend = 'increasing'
            elif slope < -2:
                trend = 'decreasing'
            else:
                trend = 'stable'
        else:
            trend = 'stable'
        
        return seq_max, trend
    
    def boost_prediction(self, pred, m14b_value, m14a_value=None, model_name=None, 
                        sequence_max=None, sequence_trend=None):
        """ê°œì„ ëœ ë¶€ìŠ¤íŒ… ë¡œì§"""
        
        original = pred
        boosted = pred
        
        # ========== UU2 íŒ¨í„´ (ê³ ê°’ ìœ ì§€) ==========
        if self.data_pattern == "UU2":
            if model_name == 'ExtremeNet':
                # UU2: ë³´ìˆ˜ì  ë¶€ìŠ¤íŒ… + ìƒí•œì„ 
                if sequence_max and sequence_max >= 1680:
                    if m14b_value > 500:
                        boosted = min(max(pred * 1.15, 1680), 1850)  # ìƒí•œ 1850
                    elif m14b_value > 450:
                        boosted = min(max(pred * 1.10, 1650), 1800)  # ìƒí•œ 1800
                    else:
                        boosted = min(pred * 1.05, 1750)
                else:
                    boosted = pred
                    
            elif model_name in ['SpikeDetector', 'GoldenRule']:
                if m14b_value > 450:
                    boosted = min(max(pred * 1.03, 1650), 1800)
                else:
                    boosted = pred
                    
            return boosted
        
        # ========== UU1 íŒ¨í„´ (ê¸‰ì¦) - ê°œì„ ë¨ ==========
        if model_name == 'ExtremeNet':
            
            # ì¡°ê±´ 1: ê°•í•œ ë¶€ìŠ¤íŒ… (1682+ & increasing)
            if sequence_max and sequence_max >= 1682 and sequence_trend == 'increasing':
                if m14b_value > 550:
                    boosted = min(max(pred * 1.6, 1850), 2000)  # ìƒí•œ 2000
                elif m14b_value > 500:
                    boosted = min(max(pred * 1.5, 1750), 1950)  # ìƒí•œ 1950
                elif m14b_value > 450:
                    boosted = min(max(pred * 1.4, 1700), 1900)  # ìƒí•œ 1900
                elif m14b_value > 400:
                    boosted = min(max(pred * 1.3, 1650), 1850)
                elif m14b_value > 350:
                    boosted = min(max(pred * 1.2, 1550), 1800)
                else:
                    boosted = min(pred * 1.1, 1750)
            
            # ì¡°ê±´ 2: ì¤‘ê°„ ë¶€ìŠ¤íŒ… (1650-1682 & increasing) - ìƒˆë¡œ ì¶”ê°€!
            elif sequence_max and 1650 <= sequence_max < 1682 and sequence_trend == 'increasing':
                if m14b_value > 500:
                    boosted = min(max(pred * 1.3, 1700), 1900)
                elif m14b_value > 450:
                    boosted = min(max(pred * 1.25, 1650), 1850)
                elif m14b_value > 400:
                    boosted = min(max(pred * 1.2, 1600), 1800)
                else:
                    boosted = min(max(pred * 1.15, 1550), 1750)
            
            # ì¡°ê±´ 3: ì•½í•œ ë¶€ìŠ¤íŒ… (1650+ & stable) - ìƒˆë¡œ ì¶”ê°€!
            elif sequence_max and sequence_max >= 1650 and sequence_trend == 'stable':
                if m14b_value > 450:
                    boosted = min(max(pred * 1.15, 1600), 1800)
                elif m14b_value > 400:
                    boosted = min(max(pred * 1.10, 1550), 1750)
                else:
                    boosted = min(max(pred * 1.05, 1500), 1700)
            
            # ì¡°ê±´ 4: í•˜ë½ ì¶”ì„¸
            elif sequence_trend == 'decreasing':
                if sequence_max and sequence_max >= 1682:
                    boosted = pred * 0.95  # 5% í•˜í–¥
                else:
                    boosted = pred
            
            # ê·¸ ì™¸: ìµœì†Œ ë¶€ìŠ¤íŒ…
            else:
                if sequence_max and sequence_max >= 1600 and m14b_value > 400:
                    boosted = min(max(pred * 1.05, 1500), 1700)
                else:
                    boosted = pred
                    
        # ========== SpikeDetector, GoldenRule ==========
        elif model_name in ['SpikeDetector', 'GoldenRule']:
            # ìƒí•œì„  ì¶”ê°€
            if m14b_value > 550:
                boosted = min(max(pred, 1850), 2000)
            elif m14b_value > 500:
                boosted = min(max(pred, 1750), 1950)
            elif m14b_value > 450:
                boosted = min(max(pred, 1700), 1900)
            elif m14b_value > 400:
                boosted = min(max(pred * 1.05, 1650), 1850)
            
        # ========== ê¸°íƒ€ ëª¨ë¸ (PatchTST, StableLSTM) ==========
        else:
            if sequence_trend == 'increasing':
                # ìƒí•œì„  ì¶”ê°€
                if m14b_value > 550:
                    boosted = min(max(pred * 1.45, 1850), 2000)
                elif m14b_value > 500:
                    boosted = min(max(pred * 1.35, 1750), 1950)
                elif m14b_value > 450:
                    boosted = min(max(pred * 1.25, 1700), 1900)
                elif m14b_value > 400:
                    boosted = min(max(pred * 1.15, 1650), 1850)
                elif m14b_value > 350:
                    boosted = min(max(pred * 1.08, 1550), 1800)
                    
            elif sequence_trend == 'decreasing':
                if m14b_value > 450:
                    boosted = max(pred * 1.05, 1650)
                else:
                    boosted = pred
            else:
                # stableë„ ì•½ê°„ ë¶€ìŠ¤íŒ…
                if m14b_value > 450:
                    boosted = min(max(pred * 1.15, 1700), 1900)
                elif m14b_value > 400:
                    boosted = min(max(pred * 1.10, 1650), 1850)
        
        # í™©ê¸ˆ íŒ¨í„´ ì¶”ê°€ ë¶€ìŠ¤íŒ… (ëª¨ë“  ëª¨ë¸ ê³µí†µ)
        if m14b_value > 300 and m14a_value and m14a_value < 80:
            if self.data_pattern == "UU2":
                boosted = min(boosted * 1.05, 2000)  # UU2ëŠ” ì•½í•˜ê²Œ
            elif sequence_trend == 'increasing':
                boosted = min(boosted * 1.15, 2000)  # ìƒí•œì„ 
            else:
                boosted = min(boosted * 1.08, 1950)
            
        return boosted

# ====================== ë©”ì¸ í‰ê°€ í´ëž˜ìŠ¤ëŠ” ê¸°ì¡´ê³¼ ë™ì¼ ======================
class ImprovedModelEvaluator:
    def __init__(self, scaler_path='scalers/'):
        """ê°œì„ ëœ í‰ê°€ê¸° ì´ˆê¸°í™”"""
        print("="*80)
        print("ðŸ”¥ V6.7 ìµœì í™”ëœ ê·¹ë‹¨ê°’ í‰ê°€ ì‹œìŠ¤í…œ")
        print("  - ë¶€ìŠ¤íŒ… ì¡°ê±´ ì™„í™”")
        print("  - ìƒí•œì„  ì¶”ê°€")
        print("  - íŒ¨í„´ ê°ì§€ ê°œì„ ")
        print("="*80)
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        try:
            with open(f'{scaler_path}feature_scaler.pkl', 'rb') as f:
                self.feature_scaler = pickle.load(f)
            with open(f'{scaler_path}target_scaler.pkl', 'rb') as f:
                self.target_scaler = pickle.load(f)
            with open(f'{scaler_path}config.json', 'r') as f:
                config = json.load(f)
                self.seq_len = config['seq_len']
                self.pred_len = config['pred_len']
                self.feature_columns = config['feature_columns']
            print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
        except:
            print(f"âš ï¸ ìŠ¤ì¼€ì¼ëŸ¬ ì—†ìŒ - ê¸°ë³¸ê°’ ì‚¬ìš©")
            self.seq_len = 100
            self.pred_len = 10
            self.feature_columns = ['TOTALCNT', 'M14AM14B', 'M14AM10A', 'M14AM14BSUM', 'M14AM16']
            self.feature_scaler = None
            self.target_scaler = None
        
        self.models = {}
        self.extreme_booster = ImprovedExtremeValueBooster()
        self.pattern_detector = DataPatternDetector()
    
    # ë‚˜ë¨¸ì§€ ë©”ì„œë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼...
    # (load_all_models, load_test_data, create_features, evaluate_all_models)
    # ì½”ë“œê°€ ë„ˆë¬´ ê¸¸ì–´ì„œ ìƒëžµí•˜ì§€ë§Œ, ìœ„ì˜ ê°œì„ ëœ í´ëž˜ìŠ¤ë“¤ì„ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    print("\nðŸš€ V6.7 ìµœì í™” ë²„ì „ ì‹œìž‘!")
    print("ê°œì„ ì‚¬í•­:")
    print("  1. ExtremeNet ë¶€ìŠ¤íŒ… ì¡°ê±´ ì™„í™” (1650ë¶€í„°)")
    print("  2. ë¶€ìŠ¤íŒ… ìƒí•œì„  ì¶”ê°€ (ê³¼ë„í•œ ì˜ˆì¸¡ ë°©ì§€)")
    print("  3. Stable ìƒíƒœì—ì„œë„ ì•½í•œ ë¶€ìŠ¤íŒ…")
    print("  4. UU2 íŒ¨í„´ ê°ì§€ ì¡°ê±´ ìµœì í™”")
    
    # í‰ê°€ê¸° ìƒì„±
    evaluator = ImprovedModelEvaluator()
    
    # ëª¨ë“  ëª¨ë¸ ë¡œë“œ
    models = evaluator.load_all_models('models/')
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼
    test_files = [
        'uu1.csv',
        'uu2.csv',
        'data/uu1.csv',
        'data/uu2.csv',
        'data/test_data.csv',
    ]
    
    for file in test_files:
        if os.path.exists(file):
            print(f"\n{'='*80}")
            print(f"ðŸ“ í…ŒìŠ¤íŠ¸ íŒŒì¼: {file}")
            print('='*80)
            
            # í‰ê°€ ì‹¤í–‰
            all_predictions, metrics = evaluator.evaluate_all_models(file)
            
            if all_predictions is not None:
                print(f"\nâœ… {file} í‰ê°€ ì™„ë£Œ!")
            
    print("\n" + "="*80)
    print("ðŸ† í‰ê°€ ì™„ë£Œ!")
    print("="*80)

if __name__ == "__main__":
    main()