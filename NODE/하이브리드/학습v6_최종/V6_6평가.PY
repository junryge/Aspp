"""
ğŸ“Š V6.7 ê°œì„  - ExtremeNet ë²”ìœ„ê°’ ì¶”ê°€
========================================================
í•µì‹¬: ì‹œí€€ìŠ¤ MAXì™€ ì›ë³¸ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ë²”ìœ„ ê³„ì‚°
ê³µì‹: (ì‹œí€€ìŠ¤_MAX / ExtremeNet_ì›ë³¸) = í¼ì„¼íŠ¸
      ExtremeNet_ë²”ìœ„ê°’ = ì›ë³¸ ~ (ì›ë³¸ * (1 + í¼ì„¼íŠ¸))
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle
import json
import os
import warnings
from datetime import datetime, timedelta

warnings.filterwarnings('ignore')
tf.keras.config.enable_unsafe_deserialization()

# ====================== ê°œì„ ëœ ê·¹ë‹¨ê°’ ë³´ì • í´ë˜ìŠ¤ ======================
class ImprovedExtremeValueBooster:
    """ì‹œí€€ìŠ¤ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ê·¹ë‹¨ê°’ ì˜ˆì¸¡"""
    
    def __init__(self):
        print("ğŸ”¥ ê°œì„ ëœ ê·¹ë‹¨ê°’ ë¶€ìŠ¤í„° ì´ˆê¸°í™”")
        print("  - ì‹œí€€ìŠ¤ maxê°’ 1651 ì´ìƒ ì²´í¬")
        print("  - ì¦ê°€/í•˜ë½ ì¶”ì„¸ ë¶„ì„")
        print("  - ExtremeNet ë²”ìœ„ê°’ ê³„ì‚°")
        
    def analyze_sequence(self, sequence_data):
        """ì‹œí€€ìŠ¤ ë¶„ì„"""
        if len(sequence_data) == 0:
            return {'max': 0, 'min': 0, 'trend': 'stable', 'is_high_plateau': False,
                   'consecutive_rises': 0, 'consecutive_falls': 0, 
                   'rise_strength': 0, 'fall_strength': 0, 'volatility': 0}
        
        seq_max = np.max(sequence_data)
        seq_min = np.min(sequence_data)
        seq_mean = np.mean(sequence_data[-30:]) if len(sequence_data) >= 30 else np.mean(sequence_data)
        
        is_high_plateau = seq_mean >= 1700
        
        # ì—°ì† ìƒìŠ¹ ì¹´ìš´íŠ¸
        consecutive_rises = 0
        for i in range(len(sequence_data)-1, 0, -1):
            if sequence_data[i] > sequence_data[i-1]:
                consecutive_rises += 1
            else:
                break
        
        # ì—°ì† í•˜ë½ ì¹´ìš´íŠ¸
        consecutive_falls = 0
        for i in range(len(sequence_data)-1, 0, -1):
            if sequence_data[i] < sequence_data[i-1]:
                consecutive_falls += 1
            else:
                break
        
        # ìƒìŠ¹/í•˜ë½ ê°•ë„
        rise_strength = 0
        fall_strength = 0
        if len(sequence_data) >= 10:
            recent_10 = sequence_data[-10:]
            change = recent_10[-1] - recent_10[0]
            if change > 0:
                rise_strength = change
            else:
                fall_strength = abs(change)
        
        # ì¶”ì„¸ ë¶„ì„
        if len(sequence_data) >= 30:
            recent = sequence_data[-30:]
            x = np.arange(len(recent))
            coeffs = np.polyfit(x, recent, 1)
            slope = coeffs[0]
            
            if is_high_plateau:
                if consecutive_rises >= 10 and rise_strength > 50:
                    trend = 'extreme_rising'
                elif consecutive_falls >= 10 and fall_strength > 50:
                    trend = 'extreme_falling'
                elif slope > 1 or consecutive_rises >= 5:
                    trend = 'high_increasing'
                elif slope < -1 or consecutive_falls >= 5:
                    trend = 'high_decreasing'
                else:
                    trend = 'high_stable'
            else:
                if consecutive_rises >= 10 and rise_strength > 50:
                    trend = 'strong_rising'
                elif consecutive_falls >= 10 and fall_strength > 50:
                    trend = 'strong_falling'
                elif consecutive_rises >= 7 and rise_strength > 30:
                    trend = 'rapid_increasing'
                elif consecutive_falls >= 7 and fall_strength > 30:
                    trend = 'rapid_decreasing'
                elif slope > 2:
                    trend = 'increasing'
                elif slope < -2:
                    trend = 'decreasing'
                else:
                    trend = 'stable'
        else:
            trend = 'stable'
        
        volatility = np.std(sequence_data[-10:]) if len(sequence_data) >= 10 else 0
        
        return {
            'max': seq_max,
            'min': seq_min,
            'trend': trend,
            'is_high_plateau': is_high_plateau,
            'consecutive_rises': consecutive_rises,
            'consecutive_falls': consecutive_falls,
            'rise_strength': rise_strength,
            'fall_strength': fall_strength,
            'volatility': volatility
        }
    
    def boost_prediction(self, pred, m14b_value, m14a_value=None, model_name=None, 
                        sequence_info=None):
        """ì‹œí€€ìŠ¤ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¶€ìŠ¤íŒ…"""
        if not sequence_info:
            return pred
            
        seq_max = sequence_info.get('max', 0)
        seq_trend = sequence_info.get('trend', 'stable')
        
        boosted = pred
        
        # ExtremeNet íŠ¹ë³„ ì²˜ë¦¬
        if model_name == 'ExtremeNet':
            if seq_max >= 1651 and seq_trend == 'increasing':
                if m14b_value > 200:
                    boosted = max(pred * 1.2, 1700)
                else:
                    boosted = max(pred * 1.15, 1700)
        
        # SpikeDetector, GoldenRule
        elif model_name in ['SpikeDetector', 'GoldenRule']:
            if seq_max >= 1651 and seq_trend == 'increasing':
                if m14b_value > 200:
                    boosted = max(pred * 1.15, 1700)
                else:
                    boosted = max(pred * 1.1, 1700)
        
        # ê¸°íƒ€ ëª¨ë¸
        else:
            if seq_max >= 1651 and seq_trend == 'increasing':
                if m14b_value > 200:
                    boosted = max(pred * 1.1, 1700)
                else:
                    boosted = max(pred * 1.05, 1700)
        
        return boosted
    
    def calculate_extreme_range(self, original_pred, seq_max, seq_trend):
        """ExtremeNet ë²”ìœ„ê°’ ê³„ì‚° - ì¶”ì„¸ë³„ ê³µê²©ì  ë²”ìœ„ ì„¤ì •"""
        if original_pred <= 0:
            return 0, original_pred, original_pred, "0~0"
        
        # ê¸°ë³¸ ë¹„ìœ¨ ê³„ì‚°
        base_ratio = seq_max / original_pred
        
        # ğŸ”¥ ì¶”ì„¸ë³„ ê³µê²©ì  ë²”ìœ„ ì„¤ì •
        if 'extreme_rising' in seq_trend or 'strong_rising' in seq_trend:
            # ê·¹ë‹¨ ìƒìŠ¹: ì›ë³¸ì˜ 100-150% ë²”ìœ„
            min_ratio = 1.0
            max_ratio = 1.5
            
            if seq_max >= 1800:
                max_ratio = 1.6  # 60% ìƒí–¥
            elif seq_max >= 1750:
                max_ratio = 1.5  # 50% ìƒí–¥
            elif seq_max >= 1700:
                max_ratio = 1.4  # 40% ìƒí–¥
            elif seq_max >= 1650:
                max_ratio = 1.3  # 30% ìƒí–¥
                
        elif 'rapid_increasing' in seq_trend or 'high_increasing' in seq_trend:
            # ë¹ ë¥¸ ìƒìŠ¹: ì›ë³¸ì˜ 100-140% ë²”ìœ„
            min_ratio = 1.0
            max_ratio = 1.4
            
            if seq_max >= 1700:
                max_ratio = 1.45
            elif seq_max >= 1650:
                max_ratio = 1.35
                
        elif seq_trend == 'increasing':
            # ì¼ë°˜ ìƒìŠ¹: ì›ë³¸ì˜ 100-130% ë²”ìœ„
            min_ratio = 1.0
            max_ratio = 1.3
            
            if seq_max >= 1650:
                max_ratio = 1.35
                
        elif 'extreme_falling' in seq_trend or 'strong_falling' in seq_trend:
            # ê·¹ë‹¨ í•˜ë½: ì›ë³¸ì˜ 80-100% ë²”ìœ„
            min_ratio = 0.8
            max_ratio = 1.0
            
        elif 'rapid_decreasing' in seq_trend or 'high_decreasing' in seq_trend:
            # ë¹ ë¥¸ í•˜ë½: ì›ë³¸ì˜ 85-105% ë²”ìœ„
            min_ratio = 0.85
            max_ratio = 1.05
            
        elif seq_trend == 'decreasing':
            # ì¼ë°˜ í•˜ë½: ì›ë³¸ì˜ 90-110% ë²”ìœ„
            min_ratio = 0.9
            max_ratio = 1.1
            
        elif 'high_stable' in seq_trend:
            # ê³ í‰ì›: ì›ë³¸ì˜ 95-120% ë²”ìœ„
            min_ratio = 0.95
            max_ratio = 1.2
            
            if seq_max >= 1750:
                max_ratio = 1.25
                
        else:  # stable
            # ì•ˆì •: ì›ë³¸ì˜ 95-115% ë²”ìœ„
            min_ratio = 0.95
            max_ratio = 1.15
        
        # ì‹œí€€ìŠ¤ MAXê°€ ì›ë³¸ë³´ë‹¤ í¬ë©´ ìµœëŒ€ê°’ ì¶”ê°€ ìƒí–¥
        if seq_max > original_pred:
            extra_boost = (seq_max / original_pred - 1) * 0.5
            max_ratio = max(max_ratio, 1 + extra_boost)
        
        min_value = original_pred * min_ratio
        max_value = original_pred * max_ratio
        
        # ìµœëŒ€ê°’ì´ ì‹œí€€ìŠ¤ MAXë³´ë‹¤ ë‚®ìœ¼ë©´ ì¡°ì •
        if max_value < seq_max and 'rising' in seq_trend:
            max_value = max(seq_max * 1.05, max_value)
        
        percent = (max_ratio - 1) * 100
        range_str = f"{round(min_value)}~{round(max_value)}"
        
        return percent, min_value, max_value, range_str

class ImprovedModelEvaluator:
    def __init__(self, scaler_path='scalers/'):
        """ê°œì„ ëœ í‰ê°€ê¸° ì´ˆê¸°í™”"""
        print("="*80)
        print("ğŸ”¥ V6.7 ê°œì„  - ExtremeNet ë²”ìœ„ê°’ ì‹œìŠ¤í…œ")
        print("  í•µì‹¬: ì‹œí€€ìŠ¤ MAX ê¸°ë°˜ ì˜ˆì¸¡ ë²”ìœ„ ê³„ì‚°")
        print("="*80)
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        with open(f'{scaler_path}feature_scaler.pkl', 'rb') as f:
            self.feature_scaler = pickle.load(f)
        with open(f'{scaler_path}target_scaler.pkl', 'rb') as f:
            self.target_scaler = pickle.load(f)
        with open(f'{scaler_path}config.json', 'r') as f:
            config = json.load(f)
            self.seq_len = config['seq_len']
            self.pred_len = config['pred_len']
            self.feature_columns = config['feature_columns']
        print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
        
        self.models = {}
        self.extreme_booster = ImprovedExtremeValueBooster()
        
    def load_all_models(self, model_dir='models/'):
        """ëª¨ë“  ëª¨ë¸ ë¡œë“œ"""
        print(f"\nğŸ“ ëª¨ë¸ ë¡œë”©...")
        
        model_files = [f for f in os.listdir(model_dir) if f.endswith('.keras')]
        
        for model_file in model_files:
            model_name = model_file.replace('.keras', '')
            model_path = os.path.join(model_dir, model_file)
            
            try:
                self.models[model_name] = tf.keras.models.load_model(
                    model_path, safe_mode=False
                )
                print(f"  âœ… {model_name} ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"  âŒ {model_name} ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        print(f"\nì´ {len(self.models)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        return self.models
    
    def load_test_data(self, filepath):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
        print(f"\nğŸ“‚ í‰ê°€ ë°ì´í„° ë¡œë”©: {filepath}")
        df = pd.read_csv(filepath)
        print(f"  ì›ë³¸: {df.shape[0]:,}í–‰")
        
        df = df[df['TOTALCNT'] > 0].reset_index(drop=True)
        
        df['CURRTIME'] = pd.to_datetime(df['CURRTIME'].astype(str), 
                                       format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('CURRTIME').reset_index(drop=True)
        
        print(f"  ìœ íš¨: {df.shape[0]:,}í–‰")
        
        # ê³ ê°’ í†µê³„
        high_count = (df['TOTALCNT'] >= 1700).sum()
        very_high_count = (df['TOTALCNT'] >= 1750).sum()
        extreme_count = (df['TOTALCNT'] >= 1800).sum()
        
        print(f"\nğŸ¯ ê³ ê°’ êµ¬ê°„ ë¶„í¬:")
        print(f"  1700+: {high_count}ê°œ ({high_count/len(df)*100:.1f}%)")
        print(f"  1750+: {very_high_count}ê°œ ({very_high_count/len(df)*100:.1f}%)")
        print(f"  1800+: {extreme_count}ê°œ ({extreme_count/len(df)*100:.1f}%)")
        
        return df
    
    def create_features(self, df):
        """íŠ¹ì„± ìƒì„±"""
        df['RATIO'] = df['M14AM14B'] / (df['M14AM10A'] + 1)
        df['GOLDEN'] = ((df['M14AM14B'] > 300) & (df['M14AM10A'] < 80)).astype(float)
        
        df['HOUR'] = df['CURRTIME'].dt.hour
        df['HOUR_SIN'] = np.sin(2 * np.pi * df['HOUR'] / 24)
        df['HOUR_COS'] = np.cos(2 * np.pi * df['HOUR'] / 24)
        
        for w in [10, 30]:
            df[f'MA_{w}'] = df['TOTALCNT'].rolling(w, min_periods=1).mean()
            df[f'STD_{w}'] = df['TOTALCNT'].rolling(w, min_periods=1).std().fillna(0)
        
        df['CHANGE_1'] = df['TOTALCNT'].diff(1).fillna(0)
        df['CHANGE_10'] = df['TOTALCNT'].diff(10).fillna(0)
        
        return df
    
    def evaluate_all_models(self, test_file):
        """ê°œì„ ëœ ëª¨ë¸ í‰ê°€ - ExtremeNet ë²”ìœ„ê°’ í¬í•¨"""
        
        # ë°ì´í„° ë¡œë“œ
        df = self.load_test_data(test_file)
        df = self.create_features(df)
        
        # ì˜ˆì¸¡ ê°€ëŠ¥ ë²”ìœ„
        start_idx = self.seq_len
        end_idx = len(df) - self.pred_len
        total = end_idx - start_idx
        
        print(f"\nğŸ”® ì˜ˆì¸¡ ì‹œì‘...")
        print(f"  ì‹œí€€ìŠ¤: {self.seq_len}ë¶„ â†’ ì˜ˆì¸¡: {self.pred_len}ë¶„ í›„")
        print(f"  ì˜ˆì¸¡ ê°œìˆ˜: {total:,}ê°œ")
        
        # ëª¨ë“  ì˜ˆì¸¡ì„ ì €ì¥í•  DataFrame
        all_predictions = pd.DataFrame()
        
        # ë°ì´í„° ìˆ˜ì§‘
        timestamps_pred = []
        timestamps_target = []
        actuals = []
        m14b_values = []
        m14a_values = []
        sequence_infos = []
        
        print("\nğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ë° ì‹œí€€ìŠ¤ ë¶„ì„ ì¤‘...")
        for i in range(start_idx, end_idx):
            pred_time = df.iloc[i]['CURRTIME']
            target_time = pred_time + timedelta(minutes=self.pred_len)
            
            actual_idx = i + self.pred_len
            if actual_idx < len(df):
                timestamps_pred.append(pred_time)
                timestamps_target.append(target_time)
                actuals.append(df.iloc[actual_idx]['TOTALCNT'])
                m14b_values.append(df.iloc[i]['M14AM14B'])
                m14a_values.append(df.iloc[i]['M14AM10A'])
                
                # ì‹œí€€ìŠ¤ ë¶„ì„
                seq_data = df.iloc[i-self.seq_len:i]['TOTALCNT'].values
                seq_info = self.extreme_booster.analyze_sequence(seq_data)
                sequence_infos.append(seq_info)
        
        # sequence_infosë¥¼ selfì— ì €ì¥ (ë‚˜ì¤‘ì— ì‚¬ìš©)
        self.sequence_infos = sequence_infos
        
        # ê¸°ë³¸ ì •ë³´ ì €ì¥
        all_predictions['ì˜ˆì¸¡ì‹œì '] = [t.strftime('%Y-%m-%d %H:%M') for t in timestamps_pred]
        all_predictions['ì˜ˆì¸¡ëŒ€ìƒì‹œê°„'] = [t.strftime('%Y-%m-%d %H:%M') for t in timestamps_target]
        all_predictions['ì‹¤ì œê°’'] = actuals
        all_predictions['M14AM14B'] = m14b_values
        all_predictions['M14AM10A'] = m14a_values
        all_predictions['ì‹œí€€ìŠ¤_MAX'] = [info['max'] for info in sequence_infos]
        all_predictions['ì‹œí€€ìŠ¤_ì¶”ì„¸'] = [info['trend'] for info in sequence_infos]
        
        print(f"  ì˜ˆì¸¡í•  ë°ì´í„°: {len(all_predictions)}ê°œ")
        
        # ê° ëª¨ë¸ë³„ ì˜ˆì¸¡
        model_metrics = {}
        
        for model_name, model in self.models.items():
            print(f"\nğŸ¯ {model_name} ì˜ˆì¸¡ ì¤‘...")
            predictions = []
            
            # ë°°ì¹˜ ì˜ˆì¸¡
            batch_size = 500
            for i in range(start_idx, end_idx, batch_size):
                batch_end = min(i + batch_size, end_idx)
                
                X_batch = []
                for j in range(i, batch_end):
                    seq_data = df.iloc[j-self.seq_len:j][self.feature_columns].values
                    X_batch.append(seq_data)
                
                if len(X_batch) == 0:
                    continue
                
                X_batch = np.array(X_batch)
                X_batch_scaled = []
                for seq in X_batch:
                    seq_scaled = self.feature_scaler.transform(seq)
                    X_batch_scaled.append(seq_scaled)
                X_batch_scaled = np.array(X_batch_scaled)
                
                preds = model.predict(X_batch_scaled, verbose=0)
                
                if isinstance(preds, list):
                    y_pred_scaled = preds[0].flatten()
                else:
                    y_pred_scaled = preds.flatten()
                
                y_pred = self.target_scaler.inverse_transform(
                    y_pred_scaled.reshape(-1, 1)).flatten()
                
                predictions.extend(y_pred[:batch_end - i])
            
            predictions = predictions[:len(all_predictions)]
            
            # ì›ë³¸ ì˜ˆì¸¡ê°’ ì €ì¥
            all_predictions[f'{model_name}_ì›ë³¸'] = [round(p) for p in predictions]
            
            # ğŸ”¥ ExtremeNet ë²”ìœ„ê°’ ê³„ì‚°
            if model_name == 'ExtremeNet':
                print(f"  ğŸ“Š ExtremeNet ë²”ìœ„ê°’ ê³„ì‚° ì¤‘...")
                extreme_percents = []
                extreme_min_values = []
                extreme_max_values = []
                extreme_ranges = []
                
                for i in range(len(predictions)):
                    original = predictions[i]
                    seq_max = sequence_infos[i]['max']
                    seq_trend = sequence_infos[i]['trend']
                    
                    percent, min_val, max_val, range_str = self.extreme_booster.calculate_extreme_range(
                        original, seq_max, seq_trend
                    )
                    
                    extreme_percents.append(round(percent, 2))
                    extreme_min_values.append(round(min_val))
                    extreme_max_values.append(round(max_val))
                    extreme_ranges.append(range_str)
                
                all_predictions['ExtremeNet_í¼ì„¼íŠ¸'] = extreme_percents
                all_predictions['ExtremeNet_ìµœì†Œê°’'] = extreme_min_values
                all_predictions['ExtremeNet_ìµœëŒ€ê°’'] = extreme_max_values
                all_predictions['ExtremeNet_ë²”ìœ„ê°’'] = extreme_ranges
                
                print(f"    âœ… ë²”ìœ„ê°’ ê³„ì‚° ì™„ë£Œ")
                
                # ë²”ìœ„ í†µê³„
                avg_percent = np.mean(extreme_percents)
                avg_range = np.mean([max_val - min_val for max_val, min_val in 
                                    zip(extreme_max_values, extreme_min_values)])
                
                print(f"    í‰ê·  í¼ì„¼íŠ¸: {avg_percent:.1f}%")
                print(f"    í‰ê·  ë²”ìœ„ í­: {avg_range:.0f}")
            
            # ë¶€ìŠ¤íŒ… ì ìš©
            print(f"  ğŸ”¥ {model_name} ë¶€ìŠ¤íŒ… ì ìš© ì¤‘...")
            boosted_predictions = []
            
            for i in range(len(predictions)):
                m14b = all_predictions.iloc[i]['M14AM14B']
                m14a = all_predictions.iloc[i]['M14AM10A']
                original = predictions[i]
                seq_trend = sequence_infos[i]['trend']
                consecutive_rises = sequence_infos[i]['consecutive_rises']
                consecutive_falls = sequence_infos[i]['consecutive_falls']
                
                boosted = self.extreme_booster.boost_prediction(
                    original, m14b, m14a, model_name,
                    sequence_info=sequence_infos[i]
                )
                
                # ğŸ”¥ ExtremeNetì˜ ê²½ìš° ì¶”ì„¸ë³„ ìµœëŒ€ê°’ ì ìš©
                if model_name == 'ExtremeNet':
                    min_val = all_predictions.iloc[i]['ExtremeNet_ìµœì†Œê°’']
                    max_val = all_predictions.iloc[i]['ExtremeNet_ìµœëŒ€ê°’']
                    
                    # ì¶”ì„¸ë³„ ì˜ˆì¸¡ê°’ ì¡°ì •
                    if 'extreme_rising' in seq_trend or 'strong_rising' in seq_trend:
                        # ê·¹ë‹¨ ìƒìŠ¹: ìµœëŒ€ê°’ì˜ 95-100%
                        boosted = max_val * 0.95 + (max_val - min_val) * 0.05
                        if consecutive_rises >= 15:
                            boosted = max_val  # 15íšŒ ì´ìƒ ì—°ì† ìƒìŠ¹ì‹œ ìµœëŒ€ê°’
                        elif consecutive_rises >= 10:
                            boosted = max_val * 0.98
                            
                    elif 'rapid_increasing' in seq_trend or 'high_increasing' in seq_trend:
                        # ë¹ ë¥¸ ìƒìŠ¹: ìµœëŒ€ê°’ì˜ 85-95%
                        boosted = min_val + (max_val - min_val) * 0.85
                        if consecutive_rises >= 7:
                            boosted = min_val + (max_val - min_val) * 0.90
                            
                    elif seq_trend == 'increasing':
                        # ì¼ë°˜ ìƒìŠ¹: ìµœëŒ€ê°’ì˜ 70-85%
                        boosted = min_val + (max_val - min_val) * 0.70
                        if consecutive_rises >= 5:
                            boosted = min_val + (max_val - min_val) * 0.80
                            
                    elif 'extreme_falling' in seq_trend or 'strong_falling' in seq_trend:
                        # ê·¹ë‹¨ í•˜ë½: ìµœì†Œê°’ì˜ 100-120%
                        boosted = min_val * 1.05
                        if consecutive_falls >= 15:
                            boosted = min_val  # 15íšŒ ì´ìƒ ì—°ì† í•˜ë½ì‹œ ìµœì†Œê°’
                        elif consecutive_falls >= 10:
                            boosted = min_val * 1.10
                            
                    elif 'rapid_decreasing' in seq_trend or 'high_decreasing' in seq_trend:
                        # ë¹ ë¥¸ í•˜ë½: ìµœì†Œê°’ì˜ 120-140%
                        boosted = min_val * 1.20
                        if consecutive_falls >= 7:
                            boosted = min_val * 1.15
                            
                    elif seq_trend == 'decreasing':
                        # ì¼ë°˜ í•˜ë½: ìµœì†Œê°’ì˜ 140-160%
                        boosted = min_val * 1.40
                        if consecutive_falls >= 5:
                            boosted = min_val * 1.30
                            
                    elif 'high_stable' in seq_trend:
                        # ê³ í‰ì›: ë²”ìœ„ ì¤‘ê°„ê°’
                        boosted = (min_val + max_val) / 2
                        
                    else:  # stable
                        # ì•ˆì •: ì›ë³¸ê³¼ ìµœëŒ€ê°’ì˜ ì¤‘ê°„
                        boosted = (original + max_val) / 2
                    
                    # ìµœì¢…ì ìœ¼ë¡œ ë²”ìœ„ ë‚´ë¡œ ì œí•œ
                    boosted = np.clip(boosted, min_val, max_val)
                
                boosted_predictions.append(boosted)
            
            all_predictions[f'{model_name}_ì˜ˆì¸¡'] = [round(p) for p in boosted_predictions]
            
            # ExtremeNet ë²”ìœ„ ë‚´ ì—¬ë¶€ ì²´í¬
            if model_name == 'ExtremeNet':
                in_range = []
                for i in range(len(all_predictions)):
                    pred = all_predictions.iloc[i]['ExtremeNet_ì˜ˆì¸¡']
                    min_val = all_predictions.iloc[i]['ExtremeNet_ìµœì†Œê°’']
                    max_val = all_predictions.iloc[i]['ExtremeNet_ìµœëŒ€ê°’']
                    in_range.append('O' if min_val <= pred <= max_val else 'X')
                
                all_predictions['ExtremeNet_ë²”ìœ„ë‚´'] = in_range
                
                in_range_count = in_range.count('O')
                print(f"    ë²”ìœ„ ë‚´ ì˜ˆì¸¡: {in_range_count}/{len(in_range)} "
                      f"({in_range_count/len(in_range)*100:.1f}%)")
            
            all_predictions[f'{model_name}_ì˜¤ì°¨'] = all_predictions[f'{model_name}_ì˜ˆì¸¡'] - all_predictions['ì‹¤ì œê°’']
            all_predictions[f'{model_name}_ì˜¤ì°¨ìœ¨(%)'] = round(
                abs(all_predictions[f'{model_name}_ì˜¤ì°¨']) / all_predictions['ì‹¤ì œê°’'] * 100, 2
            )
            
            # ì„±ëŠ¥ ê³„ì‚°
            mae = mean_absolute_error(all_predictions['ì‹¤ì œê°’'], boosted_predictions)
            rmse = np.sqrt(mean_squared_error(all_predictions['ì‹¤ì œê°’'], boosted_predictions))
            r2 = r2_score(all_predictions['ì‹¤ì œê°’'], boosted_predictions)
            mape = np.mean(abs(all_predictions[f'{model_name}_ì˜¤ì°¨']) / all_predictions['ì‹¤ì œê°’']) * 100
            
            model_metrics[model_name] = {
                'MAE': mae,
                'RMSE': rmse,
                'R2': r2,
                'MAPE': mape,
                'ì •í™•ë„(%)': 100 - mape
            }
            
            print(f"  âœ… {model_name} ì™„ë£Œ: MAE={mae:.2f}, ì •í™•ë„={100-mape:.2f}%")
        
        # ì•™ìƒë¸” ìƒì„±
        print("\nğŸ”¥ ê°œì„ ëœ ì•™ìƒë¸” ìƒì„±...")
        
        extreme_ensemble = []
        for i in range(len(all_predictions)):
            m14b = all_predictions.iloc[i]['M14AM14B']
            seq_max = all_predictions.iloc[i]['ì‹œí€€ìŠ¤_MAX']
            seq_trend = all_predictions.iloc[i]['ì‹œí€€ìŠ¤_ì¶”ì„¸']
            
            # ê° ëª¨ë¸ ì˜ˆì¸¡ê°’
            extreme_pred = all_predictions.iloc[i]['ExtremeNet_ì˜ˆì¸¡']
            spike_pred = all_predictions.iloc[i]['SpikeDetector_ì˜ˆì¸¡'] if 'SpikeDetector_ì˜ˆì¸¡' in all_predictions.columns else extreme_pred
            golden_pred = all_predictions.iloc[i]['GoldenRule_ì˜ˆì¸¡'] if 'GoldenRule_ì˜ˆì¸¡' in all_predictions.columns else extreme_pred
            patch_pred = all_predictions.iloc[i]['PatchTST_ì˜ˆì¸¡'] if 'PatchTST_ì˜ˆì¸¡' in all_predictions.columns else extreme_pred
            stable_pred = all_predictions.iloc[i]['StableLSTM_ì˜ˆì¸¡'] if 'StableLSTM_ì˜ˆì¸¡' in all_predictions.columns else extreme_pred
            
            # ë™ì  ê°€ì¤‘ì¹˜
            if seq_max >= 1650 and 'increasing' in seq_trend:
                weights = [0.35, 0.25, 0.20, 0.10, 0.10]  # ExtremeNet ì¤‘ì‹¬
            elif seq_max >= 1600:
                weights = [0.25, 0.20, 0.20, 0.20, 0.15]  # ê· í˜•
            else:
                if m14b > 200:
                    weights = [0.20, 0.30, 0.25, 0.15, 0.10]  # Spike/Golden ì¤‘ì‹¬
                else:
                    weights = [0.20, 0.15, 0.15, 0.30, 0.20]  # Patch/Stable ì¤‘ì‹¬
            
            ensemble_pred = (
                extreme_pred * weights[0] +
                spike_pred * weights[1] +
                golden_pred * weights[2] +
                patch_pred * weights[3] +
                stable_pred * weights[4]
            )
            
            extreme_ensemble.append(ensemble_pred)
        
        all_predictions['ì•™ìƒë¸”_ì˜ˆì¸¡'] = [round(p) for p in extreme_ensemble]
        all_predictions['ì•™ìƒë¸”_ì˜¤ì°¨'] = all_predictions['ì•™ìƒë¸”_ì˜ˆì¸¡'] - all_predictions['ì‹¤ì œê°’']
        all_predictions['ì•™ìƒë¸”_ì˜¤ì°¨ìœ¨(%)'] = round(
            abs(all_predictions['ì•™ìƒë¸”_ì˜¤ì°¨']) / all_predictions['ì‹¤ì œê°’'] * 100, 2
        )
        
        # ì•™ìƒë¸” ì„±ëŠ¥
        ensemble_mae = mean_absolute_error(all_predictions['ì‹¤ì œê°’'], extreme_ensemble)
        ensemble_rmse = np.sqrt(mean_squared_error(all_predictions['ì‹¤ì œê°’'], extreme_ensemble))
        ensemble_r2 = r2_score(all_predictions['ì‹¤ì œê°’'], extreme_ensemble)
        ensemble_mape = np.mean(abs(all_predictions['ì•™ìƒë¸”_ì˜¤ì°¨']) / all_predictions['ì‹¤ì œê°’']) * 100
        
        model_metrics['ì•™ìƒë¸”'] = {
            'MAE': ensemble_mae,
            'RMSE': ensemble_rmse,
            'R2': ensemble_r2,
            'MAPE': ensemble_mape,
            'ì •í™•ë„(%)': 100 - ensemble_mape
        }
        
        print(f"âœ… ì•™ìƒë¸”: MAE={ensemble_mae:.2f}, ì •í™•ë„={100-ensemble_mape:.2f}%")
        
        # CSV ì €ì¥
        output_file = f'v67_extreme_range_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        all_predictions.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ì˜ˆì¸¡ê°’ ì €ì¥: {output_file}")
        
        # ==================== ExtremeNet ë²”ìœ„ê°’ ë¶„ì„ ====================
        print("\n" + "="*80)
        print("ğŸ¯ ExtremeNet ë²”ìœ„ê°’ ìƒì„¸ ë¶„ì„")
        print("="*80)
        
        # ë²”ìœ„ ë‚´ ì‹¤ì œê°’ ë¶„ì„
        actual_in_range = 0
        for i in range(len(all_predictions)):
            actual = all_predictions.iloc[i]['ì‹¤ì œê°’']
            min_val = all_predictions.iloc[i]['ExtremeNet_ìµœì†Œê°’']
            max_val = all_predictions.iloc[i]['ExtremeNet_ìµœëŒ€ê°’']
            if min_val <= actual <= max_val:
                actual_in_range += 1
        
        print(f"\nğŸ“Š ë²”ìœ„ê°’ ì„±ëŠ¥:")
        print(f"  ì‹¤ì œê°’ì´ ë²”ìœ„ ë‚´: {actual_in_range}/{len(all_predictions)} "
              f"({actual_in_range/len(all_predictions)*100:.1f}%)")
        
        # ê³ ê°’ êµ¬ê°„ ë²”ìœ„ ë¶„ì„
        high_mask = all_predictions['ì‹¤ì œê°’'] >= 1700
        if high_mask.any():
            high_df = all_predictions[high_mask]
            
            print(f"\nğŸ¯ ê³ ê°’ êµ¬ê°„(1700+) ë²”ìœ„ ë¶„ì„:")
            print(f"  ìƒ˜í”Œ ìˆ˜: {len(high_df)}ê°œ")
            
            # ê³ ê°’ êµ¬ê°„ ë²”ìœ„ ë‚´ ì‹¤ì œê°’
            high_actual_in_range = 0
            for idx in high_df.index:
                actual = high_df.loc[idx, 'ì‹¤ì œê°’']
                min_val = high_df.loc[idx, 'ExtremeNet_ìµœì†Œê°’']
                max_val = high_df.loc[idx, 'ExtremeNet_ìµœëŒ€ê°’']
                if min_val <= actual <= max_val:
                    high_actual_in_range += 1
            
            print(f"  ì‹¤ì œê°’ ë²”ìœ„ ë‚´: {high_actual_in_range}/{len(high_df)} "
                  f"({high_actual_in_range/len(high_df)*100:.1f}%)")
            
            # ë²”ìœ„ í­ í†µê³„
            range_widths = high_df['ExtremeNet_ìµœëŒ€ê°’'] - high_df['ExtremeNet_ìµœì†Œê°’']
            print(f"  í‰ê·  ë²”ìœ„ í­: {range_widths.mean():.0f}")
            print(f"  ìµœëŒ€ ë²”ìœ„ í­: {range_widths.max():.0f}")
            print(f"  ìµœì†Œ ë²”ìœ„ í­: {range_widths.min():.0f}")
            
            # í¼ì„¼íŠ¸ í†µê³„
            print(f"  í‰ê·  í¼ì„¼íŠ¸: {high_df['ExtremeNet_í¼ì„¼íŠ¸'].mean():.1f}%")
            print(f"  ìµœëŒ€ í¼ì„¼íŠ¸: {high_df['ExtremeNet_í¼ì„¼íŠ¸'].max():.1f}%")
            
            # ë²”ìœ„ ì˜ˆì‹œ
            print(f"\n[ê³ ê°’ êµ¬ê°„ ExtremeNet ì¶”ì„¸ë³„ ì˜ˆì¸¡] (ì²˜ìŒ 15ê°œ)")
            print("-" * 110)
            print(f"{'ì‹¤ì œê°’':>7} {'ì›ë³¸':>7} {'ì˜ˆì¸¡':>7} {'ë²”ìœ„ê°’':>15} {'ì¶”ì„¸':>15} {'ì—°ì†â†‘':>6} {'ì—°ì†â†“':>6} {'ì ì¤‘':>6}")
            print("-" * 110)
            
            for idx in high_df.head(15).index:
                row = all_predictions.loc[idx]
                actual = row['ì‹¤ì œê°’']
                orig = row['ExtremeNet_ì›ë³¸']
                pred = row['ExtremeNet_ì˜ˆì¸¡']
                range_val = row['ExtremeNet_ë²”ìœ„ê°’']
                seq_trend = row['ì‹œí€€ìŠ¤_ì¶”ì„¸']
                
                # ì—°ì† ìƒìŠ¹/í•˜ë½ ì¹´ìš´íŠ¸ (self.sequence_infosì—ì„œ ê°€ì ¸ì˜¤ê¸°)
                idx_pos = list(all_predictions.index).index(idx)
                consecutive_rises = self.sequence_infos[idx_pos]['consecutive_rises']
                consecutive_falls = self.sequence_infos[idx_pos]['consecutive_falls']
                
                # ì ì¤‘ íŒì •
                error = abs(pred - actual)
                if error <= 50:
                    hit = 'âœ…'
                elif error <= 100:
                    hit = 'âš ï¸'
                else:
                    hit = 'âŒ'
                
                # ì¶”ì„¸ ì•„ì´ì½˜
                if 'rising' in seq_trend:
                    trend_icon = 'ğŸš€'
                elif 'increasing' in seq_trend:
                    trend_icon = 'ğŸ“ˆ'
                elif 'falling' in seq_trend:
                    trend_icon = 'ğŸ’¥'
                elif 'decreasing' in seq_trend:
                    trend_icon = 'ğŸ“‰'
                elif 'stable' in seq_trend:
                    trend_icon = 'â¡ï¸'
                else:
                    trend_icon = 'ğŸ”„'
                
                print(f"{actual:7.0f} {orig:7.0f} {pred:7.0f} {range_val:>15} "
                      f"{trend_icon} {seq_trend[:12]:>12} {consecutive_rises:6} "
                      f"{consecutive_falls:6} {hit:>6}")
            
            # ì¶”ì„¸ë³„ ì„±ëŠ¥ ë¶„ì„
            print(f"\n[ì¶”ì„¸ë³„ ExtremeNet ì„±ëŠ¥]")
            print("-" * 80)
            
            trend_types = ['extreme_rising', 'strong_rising', 'increasing', 
                          'stable', 'decreasing', 'strong_falling']
            
            for trend in trend_types:
                trend_mask = high_df['ì‹œí€€ìŠ¤_ì¶”ì„¸'] == trend
                if trend_mask.sum() > 0:
                    trend_df = high_df[trend_mask]
                    
                    # ExtremeNet ì˜ˆì¸¡ ì •í™•ë„
                    mae = mean_absolute_error(trend_df['ì‹¤ì œê°’'], trend_df['ExtremeNet_ì˜ˆì¸¡'])
                    
                    # í‰ê·  ì˜ˆì¸¡ê°’
                    avg_pred = trend_df['ExtremeNet_ì˜ˆì¸¡'].mean()
                    avg_actual = trend_df['ì‹¤ì œê°’'].mean()
                    
                    print(f"  {trend:20s}: {trend_mask.sum():3d}ê°œ, "
                          f"MAE={mae:6.1f}, í‰ê· ì˜ˆì¸¡={avg_pred:7.0f}, í‰ê· ì‹¤ì œ={avg_actual:7.0f}")
        
        # ì„±ëŠ¥ ìš”ì•½
        print("\n" + "="*80)
        print("ğŸ“Š ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½")
        print("="*80)
        
        metrics_df = pd.DataFrame(model_metrics).T
        metrics_df = metrics_df.sort_values('R2', ascending=False)
        
        print(f"\n{'ëª¨ë¸':<15} {'MAE':>8} {'RMSE':>8} {'RÂ²':>8} {'ì •í™•ë„(%)':>10}")
        print("-" * 55)
        
        for model_name, row in metrics_df.iterrows():
            if model_name == 'ì•™ìƒë¸”':
                print(f"{'ğŸ”¥ ' + model_name:<15} {row['MAE']:8.2f} {row['RMSE']:8.2f} "
                      f"{row['R2']:8.4f} {row['ì •í™•ë„(%)']:10.2f} â­")
            else:
                print(f"{model_name:<15} {row['MAE']:8.2f} {row['RMSE']:8.2f} "
                      f"{row['R2']:8.4f} {row['ì •í™•ë„(%)']:10.2f}")
        
        return all_predictions, metrics_df

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    print("\nğŸš€ V6.7 ExtremeNet ì¶”ì„¸ë³„ ìµœëŒ€ê°’ ì˜ˆì¸¡ ì‹œì‘!")
    print("="*60)
    print("ğŸ”¥ í•µì‹¬ ì „ëµ:")
    print("  - ê·¹ë‹¨ ìƒìŠ¹(15íšŒ+): ìµœëŒ€ê°’ì˜ 95-100% ì˜ˆì¸¡")
    print("  - ê°•í•œ ìƒìŠ¹(10íšŒ+): ìµœëŒ€ê°’ì˜ 85-95% ì˜ˆì¸¡")
    print("  - ì¼ë°˜ ìƒìŠ¹(5íšŒ+): ìµœëŒ€ê°’ì˜ 70-85% ì˜ˆì¸¡")
    print("  - ê·¹ë‹¨ í•˜ë½(15íšŒ+): ìµœì†Œê°’ì˜ 100-120% ì˜ˆì¸¡")
    print("  - ë²”ìœ„: ì›ë³¸ì˜ 80-160% (ì¶”ì„¸ë³„ ë™ì )")
    print("="*60)
    
    # í‰ê°€ê¸° ìƒì„±
    evaluator = ImprovedModelEvaluator()
    
    # ëª¨ë“  ëª¨ë¸ ë¡œë“œ
    models = evaluator.load_all_models('models/')
    
    if not models:
        print("âŒ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼
    test_files = [
        'data/M14_20250916_20250817.csv',
        'data/test_data.csv', 
        '/mnt/user-data/uploads/test.csv'
    ]
    
    test_file = None
    for file in test_files:
        if os.path.exists(file):
            test_file = file
            break
    
    if not test_file:
        print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # í‰ê°€ ì‹¤í–‰
    all_predictions, metrics = evaluator.evaluate_all_models(test_file)
    
    print("\n" + "="*80)
    print("ğŸ† V6.7 ExtremeNet ë²”ìœ„ê°’ í‰ê°€ ì™„ë£Œ!")
    print("="*80)
    print("\nğŸ“ ì €ì¥ëœ íŒŒì¼:")
    print(f"  1. v67_extreme_range_YYYYMMDD.csv")
    print("\nğŸ”¥ í•µì‹¬ ê¸°ëŠ¥:")
    print("  âœ… ExtremeNet_í¼ì„¼íŠ¸: ì‹œí€€ìŠ¤ MAX ëŒ€ë¹„ ì¦ê°€ìœ¨")
    print("  âœ… ExtremeNet_ë²”ìœ„ê°’: ì˜ˆì¸¡ ê°€ëŠ¥ ë²”ìœ„ (ìµœì†Œ~ìµœëŒ€)")
    print("  âœ… ExtremeNet_ë²”ìœ„ë‚´: ì˜ˆì¸¡ê°’ì´ ë²”ìœ„ ë‚´ì¸ì§€ ì²´í¬")
    print("  âœ… ì‹¤ì œê°’ ë²”ìœ„ í¬í•¨ë¥  ë¶„ì„")
    print("="*80)

if __name__ == "__main__":
    main()