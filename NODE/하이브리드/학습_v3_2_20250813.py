"""
ë°˜ë„ì²´ ë¬¼ë¥˜ ì˜ˆì¸¡ ëª¨ë¸ v3.4 - ì •ë°€ë„ ì¤‘ì‹¬ ê· í˜•ì¡íŒ ì˜ˆì¸¡ (ì™„ì „íŒ)
================================================================
ì£¼ìš” ê¸°ëŠ¥:
1. LSTM, GRU, RNN, Bidirectional LSTM ì•™ìƒë¸”
2. í•™ìŠµ ì¤‘ë‹¨ ì‹œ ì¬ì‹œì‘ ê¸°ëŠ¥
3. ì •ë°€ë„ ì¤‘ì‹¬ ì†ì‹¤ í•¨ìˆ˜
4. ë™ì  ì„ê³„ê°’ ì¡°ì •
5. ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from sklearn.utils.class_weight import compute_class_weight
from imblearn.over_sampling import SMOTE
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization, GRU, SimpleRNN, Bidirectional
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import os
import joblib
import logging
import warnings
import json
import pickle
import gc
import traceback

warnings.filterwarnings('ignore')

# í™˜ê²½ ì„¤ì •
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
tf.config.set_visible_devices([], 'GPU')
tf.keras.backend.set_floatx('float32')

RANDOM_SEED = 2079936
tf.random.set_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training_v3.4.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ===================================
# ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ (v3.3ì—ì„œ ê°€ì ¸ì˜´)
# ===================================
class CheckpointManager:
    def __init__(self, checkpoint_dir='checkpoints_v34'):
        self.checkpoint_dir = checkpoint_dir
        os.makedirs(checkpoint_dir, exist_ok=True)
        self.state_file = os.path.join(checkpoint_dir, 'training_state.json')
        self.data_file = os.path.join(checkpoint_dir, 'preprocessed_data.pkl')
        
    def save_state(self, state_dict):
        with open(self.state_file, 'w') as f:
            json.dump(state_dict, f, indent=4, default=str)
        logger.info(f"í•™ìŠµ ìƒíƒœ ì €ì¥ë¨: {self.state_file}")
        
    def load_state(self):
        if os.path.exists(self.state_file):
            with open(self.state_file, 'r') as f:
                state = json.load(f)
            logger.info(f"í•™ìŠµ ìƒíƒœ ë¡œë“œë¨: {self.state_file}")
            return state
        return None
        
    def save_data(self, data_dict):
        with open(self.data_file, 'wb') as f:
            pickle.dump(data_dict, f, protocol=4)
        logger.info(f"ë°ì´í„° ì €ì¥ë¨: {self.data_file}")
        
    def load_data(self):
        if os.path.exists(self.data_file):
            with open(self.data_file, 'rb') as f:
                data = pickle.load(f)
            logger.info(f"ë°ì´í„° ë¡œë“œë¨: {self.data_file}")
            return data
        return None
        
    def save_model_weights(self, model, model_name, epoch):
        weights_path = os.path.join(self.checkpoint_dir, f'{model_name}_weights_epoch_{epoch}.h5')
        model.save_weights(weights_path)
        return weights_path
        
    def load_model_weights(self, model, weights_path):
        if os.path.exists(weights_path):
            model.load_weights(weights_path)
            logger.info(f"ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œë¨: {weights_path}")
            return True
        return False

# ===================================
# ì •ë°€ë„ ì¤‘ì‹¬ ì†ì‹¤ í•¨ìˆ˜
# ===================================
class PrecisionFocusedLoss(tf.keras.losses.Loss):
    def __init__(self, precision_weight=2.0, name='precision_focused_loss'):
        super().__init__(name=name)
        self.precision_weight = precision_weight
        
    def call(self, y_true, y_pred):
        y_true = tf.cast(y_true, tf.float32)
        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)
        
        # ê¸°ë³¸ BCE
        bce = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)
        
        # False Positiveì— ë” í° í˜ë„í‹°
        false_positive_penalty = (1 - y_true) * y_pred * self.precision_weight
        
        return tf.reduce_mean(bce + false_positive_penalty)

# ===================================
# ë™ì  ì„ê³„ê°’ ì¡°ì • ì½œë°±
# ===================================
class DynamicThresholdCallback(Callback):
    def __init__(self, X_val, y_val_cls, target_ratio=0.025):
        super().__init__()
        self.X_val = X_val
        self.y_val_cls = y_val_cls
        self.target_ratio = target_ratio
        self.threshold_history = []
        
    def on_epoch_end(self, epoch, logs=None):
        val_pred = self.model.predict(self.X_val, verbose=0)
        spike_probs = val_pred[1].flatten()
        
        percentile = 100 - (self.target_ratio * 100)
        optimal_threshold = np.percentile(spike_probs, percentile)
        self.threshold_history.append(optimal_threshold)
        
        y_pred = (spike_probs > optimal_threshold).astype(int)
        tp = np.sum((self.y_val_cls == 1) & (y_pred == 1))
        fp = np.sum((self.y_val_cls == 0) & (y_pred == 1))
        fn = np.sum((self.y_val_cls == 1) & (y_pred == 0))
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        print(f"\nEpoch {epoch+1} - ì„ê³„ê°’: {optimal_threshold:.4f}")
        print(f"ì˜ˆì¸¡: {y_pred.sum()}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}")

# ===================================
# ì™„ì „í•œ ì•™ìƒë¸” ëª¨ë¸ í´ë˜ìŠ¤
# ===================================
class CompleteEnsembleModels:
    def __init__(self, input_shape):
        self.input_shape = input_shape
        self.models = {}
        self.histories = {}
        
    def build_precision_lstm_model(self):
        """ì •ë°€ë„ ì¤‘ì‹¬ LSTM"""
        inputs = Input(shape=self.input_shape, name='input')
        
        x = LSTM(units=96, return_sequences=True, 
                kernel_regularizer=tf.keras.regularizers.l2(0.005))(inputs)
        x = Dropout(0.3)(x)
        x = BatchNormalization()(x)
        
        x = LSTM(units=48, return_sequences=False)(x)
        x = Dropout(0.3)(x)
        
        shared_features = Dense(units=24, activation='relu')(x)
        
        regression_output = Dense(units=1, name='regression_output')(shared_features)
        
        spike_branch = Dense(units=32, activation='relu',
                           kernel_regularizer=tf.keras.regularizers.l2(0.01))(shared_features)
        spike_branch = Dropout(0.4)(spike_branch)
        spike_branch = Dense(units=16, activation='relu')(spike_branch)
        spike_branch = Dropout(0.4)(spike_branch)
        spike_output = Dense(units=1, activation='sigmoid', name='spike_output')(spike_branch)
        
        model = Model(inputs=inputs, outputs=[regression_output, spike_output])
        return model
    
    def build_precision_gru_model(self):
        """ì •ë°€ë„ ì¤‘ì‹¬ GRU"""
        inputs = Input(shape=self.input_shape, name='input')
        
        x = GRU(units=96, return_sequences=True)(inputs)
        x = Dropout(0.3)(x)
        x = BatchNormalization()(x)
        
        x = GRU(units=48, return_sequences=False)(x)
        x = Dropout(0.3)(x)
        
        shared_features = Dense(units=24, activation='relu')(x)
        
        regression_output = Dense(units=1, name='regression_output')(shared_features)
        
        spike_branch = Dense(units=32, activation='relu')(shared_features)
        spike_branch = Dropout(0.4)(spike_branch)
        spike_output = Dense(units=1, activation='sigmoid', name='spike_output')(spike_branch)
        
        model = Model(inputs=inputs, outputs=[regression_output, spike_output])
        return model
    
    def build_precision_rnn_model(self):
        """ì •ë°€ë„ ì¤‘ì‹¬ Simple RNN"""
        inputs = Input(shape=self.input_shape, name='input')
        
        x = SimpleRNN(units=100, return_sequences=True)(inputs)
        x = Dropout(0.3)(x)
        
        x = SimpleRNN(units=50, return_sequences=False)(x)
        x = Dropout(0.3)(x)
        
        shared_features = Dense(units=24, activation='relu')(x)
        
        regression_output = Dense(units=1, name='regression_output')(shared_features)
        
        spike_branch = Dense(units=32, activation='relu')(shared_features)
        spike_branch = Dropout(0.4)(spike_branch)
        spike_output = Dense(units=1, activation='sigmoid', name='spike_output')(spike_branch)
        
        model = Model(inputs=inputs, outputs=[regression_output, spike_output])
        return model
    
    def build_precision_bilstm_model(self):
        """ì •ë°€ë„ ì¤‘ì‹¬ Bidirectional LSTM"""
        inputs = Input(shape=self.input_shape, name='input')
        
        x = Bidirectional(LSTM(units=48, return_sequences=True))(inputs)
        x = Dropout(0.3)(x)
        x = BatchNormalization()(x)
        
        x = Bidirectional(LSTM(units=24, return_sequences=False))(x)
        x = Dropout(0.3)(x)
        
        shared_features = Dense(units=24, activation='relu')(x)
        
        regression_output = Dense(units=1, name='regression_output')(shared_features)
        
        spike_branch = Dense(units=32, activation='relu')(shared_features)
        spike_branch = Dropout(0.4)(spike_branch)
        spike_output = Dense(units=1, activation='sigmoid', name='spike_output')(spike_branch)
        
        model = Model(inputs=inputs, outputs=[regression_output, spike_output])
        return model

# ===================================
# ì¬ì‹œì‘ ê°€ëŠ¥í•œ í•™ìŠµ í•¨ìˆ˜
# ===================================
def train_with_checkpoint(model, model_name, X_train, y_train_reg, y_train_cls,
                         X_val, y_val_reg, y_val_cls, epochs, batch_size,
                         checkpoint_manager, start_epoch=0, initial_lr=0.0005):
    
    # ì»´íŒŒì¼
    optimizer = Adam(learning_rate=initial_lr)
    model.compile(
        optimizer=optimizer,
        loss={
            'regression_output': 'mse',
            'spike_output': PrecisionFocusedLoss(precision_weight=3.0)
        },
        loss_weights={
            'regression_output': 0.7,
            'spike_output': 5.0
        },
        metrics={
            'regression_output': 'mae',
            'spike_output': [
                tf.keras.metrics.Precision(name='precision'),
                tf.keras.metrics.Recall(name='recall'),
                tf.keras.metrics.AUC(name='auc')
            ]
        }
    )
    
    # ì½œë°±
    dynamic_threshold = DynamicThresholdCallback(X_val, y_val_cls, target_ratio=0.025)
    
    callbacks = [
        dynamic_threshold,
        ReduceLROnPlateau(
            monitor='val_spike_output_auc',
            factor=0.5,
            patience=10,
            min_lr=1e-6,
            mode='max',
            verbose=1
        ),
        EarlyStopping(
            monitor='val_spike_output_auc',
            patience=20,
            mode='max',
            restore_best_weights=True,
            verbose=1
        )
    ]
    
    # í•™ìŠµ ì´ë ¥
    history = {'loss': [], 'val_loss': []}
    
    # ê¸°ì¡´ ì´ë ¥ ë¡œë“œ
    state = checkpoint_manager.load_state()
    if state and model_name in state.get('model_histories', {}):
        history = state['model_histories'][model_name]
    
    best_val_loss = float('inf')
    patience_counter = 0
    patience = 20
    
    # ìƒ˜í”Œ ê°€ì¤‘ì¹˜
    sample_weights = np.ones(len(y_train_cls), dtype=np.float32)
    spike_indices = np.where(y_train_cls == 1)[0]
    sample_weights[spike_indices] = 2.0
    
    try:
        for epoch in range(start_epoch, epochs):
            logger.info(f"\n{model_name} - Epoch {epoch+1}/{epochs}")
            
            # ì—í­ë³„ í•™ìŠµ
            epoch_history = model.fit(
                X_train,
                {'regression_output': y_train_reg, 'spike_output': y_train_cls},
                validation_data=(X_val, {'regression_output': y_val_reg, 'spike_output': y_val_cls}),
                epochs=1,
                batch_size=batch_size,
                sample_weight=sample_weights,
                callbacks=callbacks,
                verbose=1
            )
            
            # ì´ë ¥ ì—…ë°ì´íŠ¸
            for key in ['loss', 'val_loss']:
                if key in epoch_history.history:
                    history[key].append(epoch_history.history[key][0])
            
            current_val_loss = epoch_history.history['val_loss'][0]
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
            if current_val_loss < best_val_loss:
                best_val_loss = current_val_loss
                best_weights_path = checkpoint_manager.save_model_weights(model, model_name, epoch)
                patience_counter = 0
                logger.info(f"ìµœê³  ì„±ëŠ¥ ê°±ì‹ ! Val Loss: {best_val_loss:.4f}")
            else:
                patience_counter += 1
            
            # ì¡°ê¸° ì¢…ë£Œ
            if patience_counter >= patience:
                logger.info(f"ì¡°ê¸° ì¢…ë£Œ - {patience}ì—í­ ë™ì•ˆ ê°œì„  ì—†ìŒ")
                break
            
            # ë§¤ 5ì—í­ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if (epoch + 1) % 5 == 0:
                current_state = checkpoint_manager.load_state() or {}
                current_state['current_model'] = model_name
                current_state['current_epoch'] = epoch + 1
                
                if 'model_histories' not in current_state:
                    current_state['model_histories'] = {}
                current_state['model_histories'][model_name] = history
                
                checkpoint_manager.save_state(current_state)
                checkpoint_manager.save_model_weights(model, f"{model_name}_checkpoint", epoch)
                
    except KeyboardInterrupt:
        logger.warning(f"\n{model_name} í•™ìŠµì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        # ì¤‘ë‹¨ ì‹œì  ìƒíƒœ ì €ì¥
        current_state = checkpoint_manager.load_state() or {}
        current_state['current_model'] = model_name
        current_state['current_epoch'] = epoch
        current_state['interrupted'] = True
        
        if 'model_histories' not in current_state:
            current_state['model_histories'] = {}
        current_state['model_histories'][model_name] = history
        
        checkpoint_manager.save_state(current_state)
        checkpoint_manager.save_model_weights(model, f"{model_name}_interrupted", epoch)
        raise
        
    except Exception as e:
        logger.error(f"\n{model_name} í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error(traceback.format_exc())
        # ì˜¤ë¥˜ ì‹œì  ìƒíƒœ ì €ì¥
        current_state = checkpoint_manager.load_state() or {}
        current_state['current_model'] = model_name
        current_state['current_epoch'] = epoch
        current_state['error'] = str(e)
        
        checkpoint_manager.save_state(current_state)
        raise
    
    # í•™ìŠµ ì™„ë£Œ ìƒíƒœ ì €ì¥
    current_state = checkpoint_manager.load_state() or {}
    if 'completed_models' not in current_state:
        current_state['completed_models'] = []
    if model_name not in current_state['completed_models']:
        current_state['completed_models'].append(model_name)
    
    if 'model_histories' not in current_state:
        current_state['model_histories'] = {}
    current_state['model_histories'][model_name] = history
    checkpoint_manager.save_state(current_state)
    
    # ìµœê³  ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ë¡œë“œ
    if 'best_weights_path' in locals():
        checkpoint_manager.load_model_weights(model, best_weights_path)
    
    # ìµœì  ì„ê³„ê°’ ì €ì¥
    model.optimal_threshold = dynamic_threshold.threshold_history[-1] if dynamic_threshold.threshold_history else 0.5
    
    return history

# ===================================
# ë©”ì¸ í•™ìŠµ í”„ë¡œì„¸ìŠ¤
# ===================================
def main(resume=False):
    checkpoint_manager = CheckpointManager()
    
    # ì¬ì‹œì‘ ëª¨ë“œ í™•ì¸
    if resume:
        state = checkpoint_manager.load_state()
        if state:
            logger.info("="*60)
            logger.info("ì´ì „ í•™ìŠµ ìƒíƒœì—ì„œ ì¬ì‹œì‘í•©ë‹ˆë‹¤.")
            logger.info(f"ë§ˆì§€ë§‰ ëª¨ë¸: {state.get('current_model', 'Unknown')}")
            logger.info(f"ë§ˆì§€ë§‰ ì—í­: {state.get('current_epoch', 0)}")
            logger.info(f"ì™„ë£Œëœ ëª¨ë¸: {state.get('completed_models', [])}")
            logger.info("="*60)
            
            # v3.3ì˜ ë°ì´í„° ë¡œë“œ ì‹œë„
            try:
                # ë¨¼ì € v3.4 ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì°¾ê¸°
                saved_data = checkpoint_manager.load_data()
                
                # ì—†ìœ¼ë©´ v3.3ì—ì„œ ì°¾ê¸°
                if saved_data is None:
                    v33_checkpoint = CheckpointManager(checkpoint_dir='checkpoints_v33')
                    saved_data = v33_checkpoint.load_data()
                    if saved_data:
                        logger.info("v3.3 ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                        # v3.4ë¡œ ë³µì‚¬
                        checkpoint_manager.save_data(saved_data)
                
                if saved_data:
                    X_train = saved_data['X_train'].astype(np.float32)
                    y_train_reg = saved_data['y_train_reg'].astype(np.float32)
                    y_train_cls = saved_data['y_train_cls'].astype(np.float32)
                    X_val = saved_data['X_val'].astype(np.float32)
                    y_val_reg = saved_data['y_val_reg'].astype(np.float32)
                    y_val_cls = saved_data['y_val_cls'].astype(np.float32)
                    X_test = saved_data['X_test'].astype(np.float32)
                    y_test_reg = saved_data['y_test_reg'].astype(np.float32)
                    y_test_cls = saved_data['y_test_cls'].astype(np.float32)
                    
                    scaler = saved_data['scaler']
                    input_shape = saved_data['input_shape']
                    scaling_columns = saved_data['scaling_columns']
                    
                    logger.info("ì €ì¥ëœ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                else:
                    logger.error("ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                    
            except Exception as e:
                logger.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return
        else:
            logger.info("ì €ì¥ëœ í•™ìŠµ ìƒíƒœê°€ ì—†ìŠµë‹ˆë‹¤. v3.3 ë°ì´í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.")
            # v3.3 ë°ì´í„° ë¡œë“œ
            v33_checkpoint = CheckpointManager(checkpoint_dir='checkpoints_v33')
            saved_data = v33_checkpoint.load_data()
            if saved_data:
                checkpoint_manager.save_data(saved_data)
                X_train = saved_data['X_train'].astype(np.float32)
                y_train_reg = saved_data['y_train_reg'].astype(np.float32)
                y_train_cls = saved_data['y_train_cls'].astype(np.float32)
                X_val = saved_data['X_val'].astype(np.float32)
                y_val_reg = saved_data['y_val_reg'].astype(np.float32)
                y_val_cls = saved_data['y_val_cls'].astype(np.float32)
                X_test = saved_data['X_test'].astype(np.float32)
                y_test_reg = saved_data['y_test_reg'].astype(np.float32)
                y_test_cls = saved_data['y_test_cls'].astype(np.float32)
                
                scaler = saved_data['scaler']
                input_shape = saved_data['input_shape']
                scaling_columns = saved_data['scaling_columns']
                logger.info("v3.3 ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            else:
                logger.error("v3.3 ë°ì´í„°ë„ ì—†ìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ë¶€í„° ì‹œì‘í•˜ì„¸ìš”.")
                return
    else:
        # ìƒˆë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° v3.3 ë°ì´í„° ì‚¬ìš©
        logger.info("="*60)
        logger.info("ë°˜ë„ì²´ ë¬¼ë¥˜ ì˜ˆì¸¡ ëª¨ë¸ v3.4 - ì •ë°€ë„ ì¤‘ì‹¬ ê· í˜•ì¡íŒ ì˜ˆì¸¡")
        logger.info("="*60)
        
        v33_checkpoint = CheckpointManager(checkpoint_dir='checkpoints_v33')
        saved_data = v33_checkpoint.load_data()
        
        if saved_data is None:
            logger.error("v3.3 ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. v3.3ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        # v3.4ë¡œ ë°ì´í„° ë³µì‚¬
        checkpoint_manager.save_data(saved_data)
        
        X_train = saved_data['X_train'].astype(np.float32)
        y_train_reg = saved_data['y_train_reg'].astype(np.float32)
        y_train_cls = saved_data['y_train_cls'].astype(np.float32)
        X_val = saved_data['X_val'].astype(np.float32)
        y_val_reg = saved_data['y_val_reg'].astype(np.float32)
        y_val_cls = saved_data['y_val_cls'].astype(np.float32)
        X_test = saved_data['X_test'].astype(np.float32)
        y_test_reg = saved_data['y_test_reg'].astype(np.float32)
        y_test_cls = saved_data['y_test_cls'].astype(np.float32)
        
        scaler = saved_data['scaler']
        input_shape = saved_data['input_shape']
        scaling_columns = saved_data['scaling_columns']
    
    logger.info(f"ë°ì´í„° shape: {X_train.shape}")
    logger.info(f"í›ˆë ¨ ê¸‰ì¦ ë¹„ìœ¨: {y_train_cls.mean():.2%}")
    logger.info(f"ê²€ì¦ ê¸‰ì¦ ë¹„ìœ¨: {y_val_cls.mean():.2%}")
    logger.info(f"í…ŒìŠ¤íŠ¸ ê¸‰ì¦ ë¹„ìœ¨: {y_test_cls.mean():.2%}")
    
    # ì•™ìƒë¸” ëª¨ë¸ ì´ˆê¸°í™”
    ensemble_models = CompleteEnsembleModels(input_shape)
    
    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    EPOCHS = 100
    BATCH_SIZE = 32
    LEARNING_RATE = 0.0005
    
    # ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
    model_configs = [
        ('precision_lstm', ensemble_models.build_precision_lstm_model),
        ('precision_gru', ensemble_models.build_precision_gru_model),
        ('precision_rnn', ensemble_models.build_precision_rnn_model),
        ('precision_bilstm', ensemble_models.build_precision_bilstm_model)
    ]
    
    # ì¬ì‹œì‘ ì‹œ ì™„ë£Œëœ ëª¨ë¸ í™•ì¸
    state = checkpoint_manager.load_state() if resume else {}
    completed_models = state.get('completed_models', [])
    
    # ê° ëª¨ë¸ í•™ìŠµ
    for model_name, build_func in model_configs:
        if model_name in completed_models:
            logger.info(f"\n{model_name} ëª¨ë¸ì€ ì´ë¯¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            # ì™„ë£Œëœ ëª¨ë¸ ë¡œë“œ
            model = build_func()
            model_path = os.path.join(checkpoint_manager.checkpoint_dir, f'{model_name}_final.h5')
            if os.path.exists(model_path):
                model.load_weights(model_path)
                ensemble_models.models[model_name] = model
            continue
        
        logger.info(f"\n{'='*60}")
        logger.info(f"{model_name.upper()} ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        logger.info(f"{'='*60}")
        
        # ëª¨ë¸ ë¹Œë“œ
        model = build_func()
        
        # ì¬ì‹œì‘ ì‹œ ê°€ì¤‘ì¹˜ ë¡œë“œ
        start_epoch = 0
        if resume and state.get('current_model') == model_name:
            start_epoch = state.get('current_epoch', 0)
            weights_path = os.path.join(checkpoint_manager.checkpoint_dir, 
                                       f'{model_name}_checkpoint_weights_epoch_{start_epoch-1}.h5')
            if checkpoint_manager.load_model_weights(model, weights_path):
                logger.info(f"{model_name} ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ. Epoch {start_epoch}ë¶€í„° ì¬ì‹œì‘")
        
        try:
            # í•™ìŠµ ì‹¤í–‰
            history = train_with_checkpoint(
                model, model_name, X_train, y_train_reg, y_train_cls,
                X_val, y_val_reg, y_val_cls,
                EPOCHS, BATCH_SIZE, checkpoint_manager,
                start_epoch=start_epoch, initial_lr=LEARNING_RATE
            )
            
            ensemble_models.models[model_name] = model
            ensemble_models.histories[model_name] = history
            
            # ëª¨ë¸ ì €ì¥
            model_path = os.path.join(checkpoint_manager.checkpoint_dir, f'{model_name}_final.h5')
            model.save_weights(model_path)
            
        except KeyboardInterrupt:
            logger.warning("\ní•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            logger.info("ë‹¤ì‹œ ì‹œì‘í•˜ë ¤ë©´ --resume ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return
        except Exception as e:
            logger.error(f"\n{model_name} ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.info("ë‹¤ì‹œ ì‹œì‘í•˜ë ¤ë©´ --resume ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return
    
    logger.info("\n" + "="*60)
    logger.info("ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    logger.info("="*60)
    
    # ===================================
    # ëª¨ë¸ í‰ê°€ ë° ì•™ìƒë¸”
    # ===================================
    
    logger.info("\nëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘...")
    
    # í›„ì²˜ë¦¬ í•¨ìˆ˜
    def postprocess_predictions(spike_probs, target_count=None, target_ratio=0.025):
        """ì˜ˆì¸¡ í›„ì²˜ë¦¬ - ìƒìœ„ Nê°œ ë˜ëŠ” N%ë§Œ ì„ íƒ"""
        if target_count is not None:
            if len(spike_probs) < target_count:
                target_count = len(spike_probs)
            
            threshold_idx = np.argsort(spike_probs)[-target_count]
            threshold = spike_probs[threshold_idx]
        else:
            percentile = 100 - (target_ratio * 100)
            threshold = np.percentile(spike_probs, percentile)
        
        return (spike_probs > threshold).astype(int), threshold
    
    # ê° ëª¨ë¸ í‰ê°€
    results = {}
    expected_spikes = int(y_test_cls.sum())
    
    for model_name, model in ensemble_models.models.items():
        logger.info(f"\n{model_name} í‰ê°€ ì¤‘...")
        
        pred = model.predict(X_test, verbose=0)
        y_pred_reg = pred[0].flatten()
        y_pred_spike = pred[1].flatten()
        
        # í›„ì²˜ë¦¬ ì ìš©
        y_pred_binary, used_threshold = postprocess_predictions(
            y_pred_spike, 
            target_count=int(expected_spikes * 1.2)  # 20% ë” ì˜ˆì¸¡
        )
        
        # í‰ê°€
        cm = confusion_matrix(y_test_cls, y_pred_binary)
        report = classification_report(y_test_cls, y_pred_binary, output_dict=True, zero_division=0)
        
        logger.info(f"\n{model_name} ì„±ëŠ¥:")
        logger.info(f"ì„ê³„ê°’: {used_threshold:.4f}")
        logger.info(f"ì˜ˆì¸¡ ê°œìˆ˜: {y_pred_binary.sum()} (ëª©í‘œ: {expected_spikes})")
        logger.info(f"Precision: {report.get('1', {}).get('precision', 0):.3f}")
        logger.info(f"Recall: {report.get('1', {}).get('recall', 0):.3f}")
        logger.info(f"F1-Score: {report.get('1', {}).get('f1-score', 0):.3f}")
        
        results[model_name] = {
            'threshold': used_threshold,
            'predictions': y_pred_binary.sum(),
            'precision': report.get('1', {}).get('precision', 0),
            'recall': report.get('1', {}).get('recall', 0),
            'f1': report.get('1', {}).get('f1-score', 0),
            'confusion_matrix': cm,
            'spike_probs': y_pred_spike  # ì•™ìƒë¸”ì„ ìœ„í•´ ì €ì¥
        }
    
    # ì•™ìƒë¸” ì˜ˆì¸¡
    logger.info(f"\n{'='*60}")
    logger.info("ì•™ìƒë¸” ì˜ˆì¸¡")
    logger.info(f"{'='*60}")
    
    # ê°€ì¤‘ ì•™ìƒë¸” (F1 ìŠ¤ì½”ì–´ ê¸°ë°˜)
    ensemble_weights = {}
    total_f1 = sum(r['f1'] for r in results.values())
    
    if total_f1 > 0:
        for model_name, result in results.items():
            ensemble_weights[model_name] = result['f1'] / total_f1
    else:
        # F1ì´ ëª¨ë‘ 0ì¸ ê²½ìš° ê· ë“± ê°€ì¤‘ì¹˜
        for model_name in results:
            ensemble_weights[model_name] = 1.0 / len(results)
    
    for model_name, weight in ensemble_weights.items():
        logger.info(f"{model_name} ê°€ì¤‘ì¹˜: {weight:.3f}")
    
    # ì•™ìƒë¸” ì˜ˆì¸¡
    ensemble_spike = np.zeros_like(y_test_cls, dtype=np.float32)
    
    for model_name, result in results.items():
        ensemble_spike += result['spike_probs'] * ensemble_weights[model_name]
    
    # ì•™ìƒë¸” í›„ì²˜ë¦¬
    ensemble_binary, ensemble_threshold = postprocess_predictions(
        ensemble_spike,
        target_count=int(expected_spikes * 1.1)  # 10% ë” ì˜ˆì¸¡
    )
    
    # ì•™ìƒë¸” í‰ê°€
    cm = confusion_matrix(y_test_cls, ensemble_binary)
    report = classification_report(y_test_cls, ensemble_binary, output_dict=True, zero_division=0)
    
    logger.info(f"\nì•™ìƒë¸” ì„±ëŠ¥:")
    logger.info(f"ì˜ˆì¸¡ ê°œìˆ˜: {ensemble_binary.sum()} (ëª©í‘œ: {expected_spikes})")
    logger.info(f"Precision: {report.get('1', {}).get('precision', 0):.3f}")
    logger.info(f"Recall: {report.get('1', {}).get('recall', 0):.3f}")
    logger.info(f"F1-Score: {report.get('1', {}).get('f1-score', 0):.3f}")
    
    # í˜¼ë™ í–‰ë ¬
    if cm.shape == (2, 2):
        tn, fp, fn, tp = cm.ravel()
        logger.info(f"\ní˜¼ë™ í–‰ë ¬:")
        logger.info(f"TN: {tn}, FP: {fp}")
        logger.info(f"FN: {fn}, TP: {tp}")
    
    # ===================================
    # ê²°ê³¼ ì €ì¥
    # ===================================
    
    logger.info("\nê²°ê³¼ ì €ì¥ ì¤‘...")
    
    os.makedirs('model_v34', exist_ok=True)
    os.makedirs('results_v34', exist_ok=True)
    
    # ëª¨ë¸ ì €ì¥
    for model_name, model in ensemble_models.models.items():
        model_path = f'model_v34/{model_name}_final.keras'
        model.save(model_path)
        logger.info(f"{model_name} ëª¨ë¸ ì €ì¥: {model_path}")
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
    scaler_path = 'model_v34/scaler_v34.pkl'
    joblib.dump(scaler, scaler_path)
    
    # ì„±ëŠ¥ ê²°ê³¼ ì €ì¥
    results_df = pd.DataFrame({k: v for k, v in results.items() if k != 'spike_probs'}).T
    results_df.to_csv('results_v34/model_performance.csv')
    
    # ì„¤ì • ì €ì¥
    config = {
        'ensemble_weights': ensemble_weights,
        'ensemble_threshold': float(ensemble_threshold),
        'target_spike_count': expected_spikes,
        'input_shape': input_shape,
        'scaling_columns': scaling_columns
    }
    
    with open('results_v34/config.json', 'w') as f:
        json.dump(config, f, indent=4)
    
    # ===================================
    # ìµœì¢… ìš”ì•½
    # ===================================
    
    logger.info("\n" + "="*60)
    logger.info("í•™ìŠµ ì™„ë£Œ ìš”ì•½")
    logger.info("="*60)
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
    best_model = max(results.items(), key=lambda x: x[1]['f1'])
    logger.info(f"\nìµœê³  F1-Score ëª¨ë¸: {best_model[0].upper()}")
    logger.info(f"  - F1-Score: {best_model[1]['f1']:.3f}")
    logger.info(f"  - Recall: {best_model[1]['recall']:.3f}")
    logger.info(f"  - Precision: {best_model[1]['precision']:.3f}")
    
    # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
    target_recall = 0.7
    if report.get('1', {}).get('recall', 0) >= target_recall and report.get('1', {}).get('precision', 0) >= 0.3:
        logger.info("\nğŸ¯ ëª©í‘œ ë‹¬ì„±! Recall >= 70%, Precision >= 30%")
    else:
        logger.info("\nğŸ“Š ì¶”ê°€ ì¡°ì • í•„ìš”")
        logger.info(f"í˜„ì¬: Recall={report.get('1', {}).get('recall', 0):.1%}, "
                   f"Precision={report.get('1', {}).get('precision', 0):.1%}")
    
    logger.info("\n" + "="*60)
    logger.info("ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    logger.info("ë‹¤ì‹œ ì‹œì‘í•˜ë ¤ë©´: python script.py --resume")
    logger.info("="*60)

# ===================================
# ì‹¤í–‰
# ===================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ë°˜ë„ì²´ ë¬¼ë¥˜ ì˜ˆì¸¡ ëª¨ë¸ v3.4')
    parser.add_argument('--resume', action='store_true', 
                       help='ì´ì „ í•™ìŠµì„ ì´ì–´ì„œ ì§„í–‰')
    parser.add_argument('--reset', action='store_true',
                       help='ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚­ì œí•˜ê³  ì²˜ìŒë¶€í„° ì‹œì‘')
    
    args = parser.parse_args()
    
    if args.reset:
        import shutil
        if os.path.exists('checkpoints_v34'):
            shutil.rmtree('checkpoints_v34')
            logger.info("ì²´í¬í¬ì¸íŠ¸ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
    
    try:
        main(resume=args.resume)
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()