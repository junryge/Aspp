# -*- coding: utf-8 -*-
"""
ExtraTrees ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
280ë¶„ ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡
"""

import pandas as pd
import numpy as np
import joblib
import os
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("ğŸ”¥ ExtraTrees ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
print("="*80)

# ì„¤ì •
MODEL_DIR = 'regression_classification_models_280to10'
DATA_FILE = 'data/20250807_DATA.csv'

def create_features_from_sequence(data, seq_length=280):
    """
    280ë¶„ ì‹œí€€ìŠ¤ ë°ì´í„°ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
    """
    if len(data) < seq_length:
        print(f"âš ï¸ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. í•„ìš”: {seq_length}ê°œ, í˜„ì¬: {len(data)}ê°œ")
        return None
    
    # ë§ˆì§€ë§‰ 280ë¶„ ë°ì´í„°ë§Œ ì‚¬ìš©
    seq_data = data.iloc[-seq_length:].copy()
    
    feature_cols = ['M14AM14B', 'M14AM10A', 'M14AM16', 'M14AM14BSUM', 
                   'M14AM10ASUM', 'M14AM16SUM', 'M14BM14A', 'M10AM14A', 'M16M14A', 'TOTALCNT']
    
    # íŒŒìƒ ë³€ìˆ˜ ìƒì„±
    seq_data['ratio_M14B_M14A'] = np.clip(seq_data['M14AM14B'] / (seq_data['M14AM10A'] + 1), 0, 1000)
    seq_data['ratio_M14B_M16'] = np.clip(seq_data['M14AM14B'] / (seq_data['M14AM16'] + 1), 0, 1000)
    seq_data['totalcnt_change'] = seq_data['TOTALCNT'].diff().fillna(0)
    seq_data['totalcnt_pct_change'] = np.clip(seq_data['TOTALCNT'].pct_change().fillna(0), -10, 10)
    
    seq_data = seq_data.replace([np.inf, -np.inf], 0).fillna(0)
    
    features = []
    
    # ê° ì»¬ëŸ¼ë³„ íŠ¹ì§• ì¶”ì¶œ
    for col in feature_cols:
        values = seq_data[col].values
        
        # ê¸°ë³¸ í†µê³„
        features.extend([
            np.mean(values),
            np.std(values) if len(values) > 1 else 0,
            np.min(values),
            np.max(values),
            np.percentile(values, 25),
            np.percentile(values, 50),
            np.percentile(values, 75),
            values[-1],  # í˜„ì¬ê°’
            values[-1] - values[0],  # ì „ì²´ ë³€í™”ëŸ‰
            np.mean(values[-60:]),  # ìµœê·¼ 1ì‹œê°„ í‰ê· 
            np.max(values[-60:]),   # ìµœê·¼ 1ì‹œê°„ ìµœëŒ€
            np.mean(values[-30:]),  # ìµœê·¼ 30ë¶„ í‰ê· 
            np.max(values[-30:]),   # ìµœê·¼ 30ë¶„ ìµœëŒ€
        ])
        
        # TOTALCNT íŠ¹ë³„ ì²˜ë¦¬
        if col == 'TOTALCNT':
            features.append(np.sum((values >= 1650) & (values < 1700)))
            features.append(np.sum(values >= 1700))
            features.append(np.max(values[-20:]))
            features.append(np.sum(values < 1400))
            features.append(np.sum((values >= 1400) & (values < 1700)))
            features.append(np.sum(values >= 1700))
            features.append(np.sum((values >= 1651) & (values <= 1682)))
            
            anomaly_values = values[(values >= 1651) & (values <= 1682)]
            features.append(np.max(anomaly_values) if len(anomaly_values) > 0 else 0)
            
            normal_vals = values[values < 1400]
            check_vals = values[(values >= 1400) & (values < 1700)]
            danger_vals = values[values >= 1700]
            
            features.append(np.mean(normal_vals) if len(normal_vals) > 0 else 0)
            features.append(np.mean(check_vals) if len(check_vals) > 0 else 0)
            features.append(np.mean(danger_vals) if len(danger_vals) > 0 else 0)
            
            try:
                x = np.arange(len(values))
                slope, _ = np.polyfit(x, values, 1)
                features.append(np.clip(slope, -100, 100))
            except:
                features.append(0)
            
            try:
                recent_slope = np.polyfit(np.arange(60), values[-60:], 1)[0]
                features.append(np.clip(recent_slope, -100, 100))
            except:
                features.append(0)
    
    # ë§ˆì§€ë§‰ ì‹œì  íŒŒìƒ ë³€ìˆ˜
    features.extend([
        np.clip(seq_data['ratio_M14B_M14A'].iloc[-1], 0, 1000),
        np.clip(seq_data['ratio_M14B_M16'].iloc[-1], 0, 1000),
        np.clip(seq_data['totalcnt_change'].iloc[-1], -1000, 1000),
        np.clip(seq_data['totalcnt_pct_change'].iloc[-1], -10, 10),
    ])
    
    return np.array(features)

def get_level_info(predicted_value):
    """
    ì˜ˆì¸¡ê°’ì— ë”°ë¥¸ êµ¬ê°„ ì •ë³´ ë°˜í™˜
    """
    if predicted_value < 1400:
        return "ì •ìƒ", 100, 0, 0, "ğŸŸ¢"
    elif predicted_value < 1700:
        return "ì£¼ì˜", 0, 100, 0, "ğŸŸ¡"
    else:
        # 1700 ì´ìƒì¼ ë•Œ ì„¸ë¶€ í™•ë¥  ê³„ì‚°
        if predicted_value >= 1800:
            return "ì‹¬ê°", 0, 5, 95, "ğŸ”´"
        elif predicted_value >= 1750:
            return "ì‹¬ê°", 0, 20, 80, "ğŸ”´"
        else:
            return "ì‹¬ê°", 0, 40, 60, "ğŸ”´"

def format_time(time_str):
    """
    ì‹œê°„ í˜•ì‹ ë³€í™˜ (202507310249 -> 2025-07-31 02:49)
    """
    if len(time_str) == 12:
        year = time_str[:4]
        month = time_str[4:6]
        day = time_str[6:8]
        hour = time_str[8:10]
        minute = time_str[10:12]
        return f"{year}-{month}-{day} {hour}:{minute}"
    return time_str

def predict_next_10min(data_file, model_dir):
    """
    ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹¤í–‰
    """
    # 1. ë°ì´í„° ë¡œë“œ
    print("ë°ì´í„° ë¡œë”© ì¤‘...")
    df = pd.read_csv(data_file)
    print(f"âœ“ ë°ì´í„° í¬ê¸°: {len(df)}í–‰")
    
    # TIME ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    if 'TIME' in df.columns:
        df['TIME'] = df['TIME'].astype(str)
    elif 'CURRTIME' in df.columns:
        df['TIME'] = df['CURRTIME'].astype(str)
    
    # ìµœì†Œ 280ê°œ ë°ì´í„° í•„ìš”
    if len(df) < 280:
        print(f"âŒ ë°ì´í„° ë¶€ì¡±! ìµœì†Œ 280ê°œ í•„ìš” (í˜„ì¬: {len(df)}ê°œ)")
        return None
    
    # 2. íŠ¹ì§• ì¶”ì¶œ
    print("íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    features = create_features_from_sequence(df)
    
    if features is None:
        return None
    
    # 3. ëª¨ë¸ ë¡œë“œ
    print("ëª¨ë¸ ë¡œë”© ì¤‘...")
    model_path = os.path.join(model_dir, 'ExtraTrees_regression_model.pkl')
    scaler_path = os.path.join(model_dir, 'scaler.pkl')
    
    if not os.path.exists(model_path):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return None
    
    if not os.path.exists(scaler_path):
        print(f"âŒ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scaler_path}")
        return None
    
    model = joblib.load(model_path)
    scaler = joblib.load(scaler_path)
    
    # 4. íŠ¹ì§• ì •ê·œí™”
    features_2d = features.reshape(1, -1)
    
    # íŠ¹ì§• ê°œìˆ˜ ë§ì¶”ê¸°
    expected_features = scaler.n_features_in_
    if features_2d.shape[1] < expected_features:
        features_2d = np.hstack([features_2d, np.zeros((1, expected_features - features_2d.shape[1]))])
    elif features_2d.shape[1] > expected_features:
        features_2d = features_2d[:, :expected_features]
    
    features_scaled = scaler.transform(features_2d)
    
    # 5. ì˜ˆì¸¡
    print("ì˜ˆì¸¡ ì¤‘...")
    prediction = model.predict(features_scaled)[0]
    
    # 6. ë³´ì • (1700+ êµ¬ê°„ ê°•í™”)
    current_totalcnt = df['TOTALCNT'].iloc[-1]
    seq_max = df['TOTALCNT'].iloc[-280:].max()
    
    # ë³´ì • ë¡œì§
    if current_totalcnt >= 1700 and prediction < 1700:
        prediction = prediction * 1.08  # 8% ìƒí–¥
    elif current_totalcnt >= 1650 and prediction < current_totalcnt:
        prediction = prediction * 1.05  # 5% ìƒí–¥
    elif seq_max >= 1700 and prediction < 1650:
        prediction = prediction * 1.06  # 6% ìƒí–¥
    
    # 7. ê²°ê³¼ ìƒì„±
    prediction = round(prediction)
    level, normal_prob, warning_prob, danger_prob, emoji = get_level_info(prediction)
    
    # í˜„ì¬ ì‹œê°„ê³¼ ì˜ˆì¸¡ ì‹œê°„
    current_time_str = df['TIME'].iloc[-1]
    current_time_formatted = format_time(current_time_str)
    
    # 10ë¶„ í›„ ì‹œê°„ ê³„ì‚°
    try:
        dt = datetime.strptime(current_time_str, "%Y%m%d%H%M")
        pred_time = dt + timedelta(minutes=10)
        pred_time_formatted = pred_time.strftime("%Y-%m-%d %H:%M")
    except:
        pred_time_formatted = "10ë¶„ í›„"
    
    return {
        'current_time': current_time_formatted,
        'pred_time': pred_time_formatted,
        'prediction': prediction,
        'level': level,
        'normal_prob': normal_prob,
        'warning_prob': warning_prob,
        'danger_prob': danger_prob,
        'emoji': emoji,
        'current_value': int(current_totalcnt),
        'seq_max': int(seq_max)
    }

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    result = predict_next_10min(DATA_FILE, MODEL_DIR)
    
    if result:
        print("="*80)
        print("ğŸ”¥ ExtraTrees ìµœì¢… ì˜ˆì¸¡")
        print("="*80)
        print(f"í˜„ì¬ì‹œê°„: {result['current_time']}")
        print(f"ì˜ˆì¸¡ì‹œê°„: {result['pred_time']} (10ë¶„ í›„)")
        print("-"*50)
        print(f"ì˜ˆì¸¡ê°’: {result['prediction']}")
        print(f"ğŸŸ¢ì •ìƒí™•ë¥ : {result['normal_prob']}%")
        print(f"ğŸŸ¡ì£¼ì˜í™•ë¥ : {result['warning_prob']}%")
        print(f"ğŸ”´ì‹¬ê°í™•ë¥ : {result['danger_prob']}%")
        
        # ê²°ê³¼ ë©”ì‹œì§€
        if result['level'] == "ì •ìƒ":
            message = "ì •ìƒ - ì•ˆì •ì "
        elif result['level'] == "ì£¼ì˜":
            message = "ì£¼ì˜ - ëª¨ë‹ˆí„°ë§ í•„ìš”"
        else:
            message = "ì‹¬ê° - ë¬¼ë¥˜ëŸ‰ ê¸‰ì¦!"
        
        print(f"ê²°ê³¼: {result['emoji']} {message}")
        print("-"*50)
        print(f"[ë°˜í™˜ê°’ í™•ì¸]")
        print(result['prediction'])
        
        # ì¶”ê°€ ì •ë³´
        print(f"\n[ì°¸ê³  ì •ë³´]")
        print(f"í˜„ì¬ ë¬¼ë¥˜ëŸ‰: {result['current_value']}")
        print(f"280ë¶„ ì¤‘ ìµœëŒ€ê°’: {result['seq_max']}")
        
        # CSV ê²°ê³¼ ì €ì¥
        output_file = f"prediction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        result_df = pd.DataFrame([{
            'ì˜ˆì¸¡ì‹œê°„': result['pred_time'],
            'ì˜ˆì¸¡ê°’': result['prediction'],
            'êµ¬ê°„': result['level'],
            'ì •ìƒí™•ë¥ ': result['normal_prob'],
            'ì£¼ì˜í™•ë¥ ': result['warning_prob'],
            'ì‹¬ê°í™•ë¥ ': result['danger_prob']
        }])
        result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")
    else:
        print("âŒ ì˜ˆì¸¡ ì‹¤íŒ¨")