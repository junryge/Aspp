"""
ğŸ“Š íŒ¨í„´ í†µí•© ExtremeNet í‰ê°€ ì½”ë“œ
í•™ìŠµëœ ëª¨ë¸ë¡œ data/20250731_to20250806.csv í‰ê°€
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle
import os
from datetime import datetime, timedelta
import warnings

warnings.filterwarnings('ignore')

print("="*80)
print("ğŸ“Š ExtremeNet í‰ê°€ ì‹œìŠ¤í…œ")
print("í‰ê°€ ëŒ€ìƒ: data/20250731_to20250806.csv")
print("="*80)

# ========================================
# ì»¤ìŠ¤í…€ ì†ì‹¤í•¨ìˆ˜ (ëª¨ë¸ ë¡œë“œìš©)
# ========================================
def weighted_mae_pattern(y_true, y_pred):
    """íŒ¨í„´ ê¸°ë°˜ ê°€ì¤‘ MAE"""
    signal_min_scaled = 0.65
    signal_max_scaled = 0.75
    
    weights = tf.ones_like(y_true)
    signal_mask = tf.logical_and(
        y_true >= signal_min_scaled,
        y_true <= signal_max_scaled
    )
    weights = tf.where(signal_mask, 5.0, weights)
    danger_mask = y_true > signal_max_scaled
    weights = tf.where(danger_mask, 10.0, weights)
    mae = tf.abs(y_true - y_pred)
    weighted_mae = mae * weights
    return tf.reduce_mean(weighted_mae)

# ========================================
# í‰ê°€ í´ë˜ìŠ¤
# ========================================
class ModelEvaluator:
    def __init__(self):
        self.seq_len = 100
        self.pred_len = 10
        
        # êµ¬ê°„ ì •ì˜
        self.NORMAL_MAX = 1400
        self.CAUTION_MAX = 1650
        self.SIGNAL_MIN = 1651
        self.SIGNAL_MAX = 1699
        self.DANGER_MIN = 1700
        
        # ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self.load_model_and_scalers()
        
    def load_model_and_scalers(self):
        """ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ"""
        print("\nğŸ“ ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë”©...")
        
        # Lambda ë ˆì´ì–´ í—ˆìš© ì„¤ì •
        tf.keras.config.enable_unsafe_deserialization()
        
        # ëª¨ë¸ ê²½ë¡œ í™•ì¸
        model_paths = [
            'models_pattern/pattern_extremenet_final.keras',
            'models_pattern/best_model.keras',
            'models_final/extremenet_v65_final.keras'
        ]
        
        model_loaded = False
        for path in model_paths:
            if os.path.exists(path):
                print(f"  ëª¨ë¸ ë°œê²¬: {path}")
                self.model = tf.keras.models.load_model(
                    path,
                    safe_mode=False,  # Lambda ë ˆì´ì–´ í—ˆìš©
                    custom_objects={'weighted_mae_pattern': weighted_mae_pattern}
                )
                model_loaded = True
                break
        
        if not model_loaded:
            raise FileNotFoundError("âŒ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        scaler_paths = [
            'scalers_pattern/',
            'scalers_final/',
            'scalers/'
        ]
        
        scaler_loaded = False
        for path in scaler_paths:
            if os.path.exists(path + 'scaler_X.pkl'):
                print(f"  ìŠ¤ì¼€ì¼ëŸ¬ ë°œê²¬: {path}")
                with open(path + 'scaler_X.pkl', 'rb') as f:
                    self.scaler_X = pickle.load(f)
                with open(path + 'scaler_y.pkl', 'rb') as f:
                    self.scaler_y = pickle.load(f)
                scaler_loaded = True
                break
        
        if not scaler_loaded:
            raise FileNotFoundError("âŒ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        
        print("âœ… ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
        
    def detect_pattern_for_window(self, df_window):
        """100ë¶„ ìœˆë„ìš°ì—ì„œ íŒ¨í„´ ê°ì§€"""
        m14b_mean = df_window['M14AM14B'].mean()
        high_cases = (df_window['TOTALCNT'] >= 1682).sum()
        m14b_350_ratio = (df_window['M14AM14B'] > 350).sum() / len(df_window)
        
        if high_cases > 0 and m14b_mean > 380:
            return 2  # UU2
        elif m14b_350_ratio > 0.3:
            return 2  # UU2
        else:
            return 1  # UU1
    
    def calculate_pattern_risk_score(self, df_window, pattern):
        """íŒ¨í„´ ê¸°ë°˜ ìœ„í—˜ë„ ì ìˆ˜"""
        current_val = df_window['TOTALCNT'].iloc[-1]
        m14b = df_window['M14AM14B'].iloc[-1]
        m14a = df_window['M14AM10A'].iloc[-1]
        
        consecutive_rises = 0
        for i in range(len(df_window)-1, 0, -1):
            if df_window['TOTALCNT'].iloc[i] > df_window['TOTALCNT'].iloc[i-1]:
                consecutive_rises += 1
            else:
                break
        
        risk_score = 0
        if pattern == 1:  # UU1
            if current_val >= 1650:
                risk_score += 40
            if m14b > 300 and m14a < 80:
                risk_score += 30
            if consecutive_rises >= 10:
                risk_score += 20
            if m14b >= 400:
                risk_score += 25
        else:  # UU2
            if m14b >= 450:
                risk_score += 35
            elif m14b >= 400:
                risk_score += 30
        
        return min(risk_score, 100) / 100.0
    
    def create_features(self, df):
        """íŠ¹ì„± ìƒì„±"""
        print("  íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ê¸°ë³¸ íŠ¹ì„±
        df['RATIO'] = df['M14AM14B'] / (df['M14AM10A'] + 1)
        df['GOLDEN'] = ((df['M14AM14B'] > 300) & (df['M14AM10A'] < 80)).astype(int)
        
        # êµ¬ê°„ íŠ¹ì„±
        df['SIGNAL_ZONE'] = ((df['TOTALCNT'] >= self.SIGNAL_MIN) & 
                             (df['TOTALCNT'] <= self.SIGNAL_MAX)).astype(int)
        df['PRE_SIGNAL'] = ((df['TOTALCNT'] >= 1600) & 
                            (df['TOTALCNT'] < self.SIGNAL_MIN)).astype(int)
        df['DANGER_ZONE'] = (df['TOTALCNT'] >= self.DANGER_MIN).astype(int)
        
        # ì´ë™í‰ê· 
        for w in [5, 10, 20]:
            df[f'MA_{w}'] = df['TOTALCNT'].rolling(w, min_periods=1).mean()
            df[f'STD_{w}'] = df['TOTALCNT'].rolling(w, min_periods=1).std().fillna(0)
            df[f'M14B_MA_{w}'] = df['M14AM14B'].rolling(w, min_periods=1).mean()
        
        # ë³€í™”ìœ¨
        for lag in [1, 5, 10]:
            df[f'CHANGE_{lag}'] = df['TOTALCNT'].diff(lag).fillna(0)
            df[f'M14B_CHANGE_{lag}'] = df['M14AM14B'].diff(lag).fillna(0)
        
        # ì—°ì† ìƒìŠ¹
        df['RISE'] = (df['TOTALCNT'] > df['TOTALCNT'].shift(1)).astype(int)
        df['RISE_COUNT'] = df['RISE'].rolling(10, min_periods=1).sum()
        
        # íŒ¨í„´ íŠ¹ì„±
        df['PATTERN'] = 0
        df['PATTERN_RISK'] = 0.0
        
        for i in range(100, len(df)):
            window = df.iloc[i-100:i]
            pattern = self.detect_pattern_for_window(window)
            risk = self.calculate_pattern_risk_score(window, pattern)
            df.loc[i, 'PATTERN'] = pattern
            df.loc[i, 'PATTERN_RISK'] = risk
        
        # M14B ë ˆë²¨
        df['M14B_HIGH'] = (df['M14AM14B'] >= 350).astype(int)
        df['M14B_VERY_HIGH'] = (df['M14AM14B'] >= 400).astype(int)
        df['M14B_EXTREME'] = (df['M14AM14B'] >= 450).astype(int)
        
        # ê¸‰ì¦ ì‹ í˜¸
        df['SPIKE_SIGNAL'] = ((df['CHANGE_10'] > 50) & (df['RISE_COUNT'] > 5)).astype(int)
        
        # ì¶”ì„¸
        df['TREND'] = 1
        for i in range(20, len(df)):
            recent = df['TOTALCNT'].iloc[i-20:i].values
            if len(recent) > 1:
                slope = np.polyfit(range(len(recent)), recent, 1)[0]
                if slope > 5:
                    df.loc[i, 'TREND'] = 2
                elif slope < -5:
                    df.loc[i, 'TREND'] = 0
                else:
                    df.loc[i, 'TREND'] = 1
        
        # íŠ¹ì„± ì»¬ëŸ¼ ëª©ë¡
        self.feature_columns = [
            'TOTALCNT', 'M14AM14B', 'M14AM14BSUM', 'M14AM10A', 'M14AM16',
            'RATIO', 'GOLDEN', 
            'SIGNAL_ZONE', 'PRE_SIGNAL', 'DANGER_ZONE',
            'PATTERN', 'PATTERN_RISK',
            'M14B_HIGH', 'M14B_VERY_HIGH', 'M14B_EXTREME',
            'SPIKE_SIGNAL', 
            'TREND',
            'MA_5', 'MA_10', 'MA_20',
            'STD_5', 'STD_10', 'STD_20',
            'M14B_MA_5', 'M14B_MA_10', 'M14B_MA_20',
            'CHANGE_1', 'CHANGE_5', 'CHANGE_10',
            'M14B_CHANGE_1', 'M14B_CHANGE_5', 'M14B_CHANGE_10',
            'RISE_COUNT'
        ]
        
        return df
    
    def evaluate(self, data_path):
        """í‰ê°€ ì‹¤í–‰ (ë°°ì¹˜ ì²˜ë¦¬ + í›„ì²˜ë¦¬)"""
        import time
        start_time = time.time()
        
        print(f"\nğŸ“‚ ë°ì´í„° ë¡œë”©: {data_path}")
        
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(data_path)
        df['CURRTIME'] = pd.to_datetime(df['CURRTIME'].astype(str), 
                                       format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('CURRTIME').reset_index(drop=True)
        df = df[df['TOTALCNT'] > 0].reset_index(drop=True)
        
        print(f"âœ… ë°ì´í„°: {len(df):,}í–‰")
        
        # íŠ¹ì„± ìƒì„±
        df = self.create_features(df)
        
        # ë°°ì¹˜ ì¤€ë¹„
        print("\nğŸš€ ê³ ì† ì˜ˆì¸¡ ì¤€ë¹„...")
        batch_size = 64  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
        
        # ëª¨ë“  ì‹œí€€ìŠ¤ ì¤€ë¹„
        sequences = []
        timestamps = []
        m14b_values = []  # M14B ê°’ ì €ì¥
        
        total_sequences = len(df) - self.seq_len - self.pred_len + 1
        print(f"  ì´ ì‹œí€€ìŠ¤: {total_sequences:,}ê°œ")
        print(f"  ë°°ì¹˜ í¬ê¸°: {batch_size}")
        
        for i in range(total_sequences):
            # 100ë¶„ ë°ì´í„° ì¶”ì¶œ
            seq_data = df.iloc[i:i+self.seq_len]
            X = seq_data[self.feature_columns].values
            sequences.append(X)
            timestamps.append((seq_data['CURRTIME'].iloc[-1], i))
            # í˜„ì¬ M14B ê°’ ì €ì¥
            m14b_values.append(seq_data['M14AM14B'].iloc[-1])
        
        # ë°°ì¹˜ë¡œ ë³€í™˜
        sequences = np.array(sequences)
        
        # ìŠ¤ì¼€ì¼ë§ (í•œë²ˆì—)
        print("  ìŠ¤ì¼€ì¼ë§...")
        sequences_flat = sequences.reshape(-1, len(self.feature_columns))
        sequences_scaled = self.scaler_X.transform(sequences_flat)
        sequences_scaled = sequences_scaled.reshape(sequences.shape)
        
        # ë°°ì¹˜ ì˜ˆì¸¡
        print("\nâš¡ ê³ ì† ë°°ì¹˜ ì˜ˆì¸¡...")
        all_predictions = []
        
        for i in range(0, len(sequences_scaled), batch_size):
            batch = sequences_scaled[i:i+batch_size]
            
            # ì˜ˆì¸¡
            preds = self.model.predict(batch, verbose=0)
            y_pred_scaled = preds[0]  # regression output
            
            # ì—­ë³€í™˜
            y_pred = self.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
            all_predictions.extend(y_pred)
            
            # ì§„í–‰ í‘œì‹œ
            if (i//batch_size + 1) % 10 == 0:
                elapsed = time.time() - start_time
                progress = min(i+batch_size, len(sequences_scaled))
                speed = progress / elapsed
                eta = (len(sequences_scaled) - progress) / speed if speed > 0 else 0
                print(f"  ì§„í–‰: {progress}/{len(sequences_scaled)} "
                      f"({progress/len(sequences_scaled)*100:.1f}%) "
                      f"ì†ë„: {speed:.0f}ê°œ/ì´ˆ "
                      f"ë‚¨ì€ì‹œê°„: {eta:.0f}ì´ˆ")
        
        print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(all_predictions)}ê°œ")
        
        # ========================================
        # í›„ì²˜ë¦¬: ìœ„í—˜êµ¬ê°„ ë³´ì •
        # ========================================
        print("\nğŸ”§ ìœ„í—˜êµ¬ê°„ ë³´ì • ì‹œì‘...")
        corrected_predictions = []
        corrections_count = 0
        
        for idx, (pred, m14b) in enumerate(zip(all_predictions, m14b_values)):
            original_pred = pred
            
            # 1. M14B ê¸°ë°˜ ë³´ì •
            if m14b >= 400:
                # M14Bê°€ 400 ì´ìƒì´ë©´ ìµœì†Œ 1650 ë³´ì¥
                if pred < 1650:
                    pred = 1650 + (m14b - 400) * 0.5
                else:
                    # ì´ë¯¸ ë†’ìœ¼ë©´ ë” ë†’ê²Œ
                    pred = pred * 1.15
                    
            elif m14b >= 350:
                # M14Bê°€ 350-400ì´ë©´ ìƒí–¥ ì¡°ì •
                if pred < 1600:
                    pred = 1600 + (m14b - 350) * 0.3
                else:
                    pred = pred * 1.08
                    
            elif m14b >= 300:
                # M14Bê°€ 300-350ì´ë©´ ì•½ê°„ ìƒí–¥
                if pred >= 1550:
                    pred = pred * 1.05
            
            # 2. ì˜ˆì¸¡ê°’ êµ¬ê°„ë³„ ì¶”ê°€ ë³´ì •
            if pred >= 1600:
                # 1600 ì´ìƒì€ ë” ê³¼ê°í•˜ê²Œ
                pred = pred * 1.12
                
                if pred >= 1650:
                    # 1650 ì´ìƒì€ ìµœì†Œê°’ ë³´ì¥
                    pred = max(pred, 1670)
                    
                if pred >= 1680:
                    # 1680 ì´ìƒì€ ë” ê°•í•˜ê²Œ
                    pred = min(pred * 1.08, 1900)
            
            # 3. ì—°ì†ì„± ë³´ì •
            if idx > 0:
                prev_pred = corrected_predictions[-1] if corrected_predictions else all_predictions[idx-1]
                if prev_pred >= 1650 and pred >= 1600:
                    # ì´ì „ì´ ë†’ìœ¼ë©´ í˜„ì¬ë„ ìœ ì§€
                    if pred < prev_pred * 0.92:
                        pred = prev_pred * 0.95
            
            # 4. ì‹œê°„ëŒ€ ë³´ì •
            current_time = timestamps[idx][0]
            hour = current_time.hour
            if 14 <= hour <= 18:  # ì˜¤í›„ ì‹œê°„ëŒ€
                if pred >= 1550:
                    pred = pred * 1.03
            
            # 5. ìµœì¢… ì œí•œ
            pred = max(pred, 900)  # ìµœì†Œê°’
            pred = min(pred, 2000)  # ìµœëŒ€ê°’
            
            if abs(pred - original_pred) > 10:
                corrections_count += 1
            
            corrected_predictions.append(pred)
        
        print(f"  ë³´ì •ëœ ì˜ˆì¸¡: {corrections_count}ê°œ ({corrections_count/len(all_predictions)*100:.1f}%)")
        
        # ê²°ê³¼ ì •ë¦¬
        print("\nğŸ“Š ê²°ê³¼ ì •ë¦¬ ì¤‘...")
        results = []
        
        for idx, (pred, (current_time, orig_idx)) in enumerate(zip(corrected_predictions, timestamps)):
            target_time = current_time + timedelta(minutes=10)
            
            # ì‹¤ì œê°’ (ìˆëŠ” ê²½ìš°)
            if orig_idx + self.seq_len + self.pred_len - 1 < len(df):
                actual = df['TOTALCNT'].iloc[orig_idx + self.seq_len + self.pred_len - 1]
            else:
                actual = np.nan
            
            # ë‹¹ì¼ ìµœëŒ€/ìµœì†Œ
            current_date = current_time.date()
            day_data = df[df['CURRTIME'].dt.date == current_date]
            daily_max = day_data['TOTALCNT'].max()
            daily_min = day_data['TOTALCNT'].min()
            
            # ê²°ê³¼ ì €ì¥
            results.append({
                'ë‚ ì§œ': current_date.strftime('%Y-%m-%d'),
                'ì‹œê°„ë‚ ì§œ': current_time.strftime('%Y-%m-%d %H:%M:%S'),
                'íƒ€ê²Ÿë‚ ì§œ': target_time.strftime('%Y-%m-%d %H:%M:%S'),
                'íƒ€ê²ŸMAX': daily_max,
                'íƒ€ê²ŸMIN': daily_min,
                'ì˜ˆì¸¡ê°’_ì›ë³¸': round(all_predictions[idx], 2),
                'ì˜ˆì¸¡ê°’': round(pred, 2),
                'ì‹¤ì œê°’': round(actual, 2) if not np.isnan(actual) else None,
                'ì˜¤ì°¨': round(actual - pred, 2) if not np.isnan(actual) else None,
                'M14B': m14b_values[idx]
            })
        
        # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        results_df = pd.DataFrame(results)
        
        # ì²˜ë¦¬ ì‹œê°„
        total_time = time.time() - start_time
        print(f"\nâ±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.1f}ì´ˆ")
        print(f"âš¡ ì²˜ë¦¬ ì†ë„: {len(corrected_predictions)/total_time:.0f}ê°œ/ì´ˆ")
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ì‹¤ì œê°’ì´ ìˆëŠ” ê²½ìš°)
        valid_results = results_df.dropna(subset=['ì‹¤ì œê°’'])
        if len(valid_results) > 0:
            # ì›ë³¸ ì„±ëŠ¥
            mae_orig = mean_absolute_error(valid_results['ì‹¤ì œê°’'], valid_results['ì˜ˆì¸¡ê°’_ì›ë³¸'])
            
            # ë³´ì • í›„ ì„±ëŠ¥
            mae = mean_absolute_error(valid_results['ì‹¤ì œê°’'], valid_results['ì˜ˆì¸¡ê°’'])
            rmse = np.sqrt(mean_squared_error(valid_results['ì‹¤ì œê°’'], valid_results['ì˜ˆì¸¡ê°’']))
            r2 = r2_score(valid_results['ì‹¤ì œê°’'], valid_results['ì˜ˆì¸¡ê°’'])
            
            print(f"\nğŸ“Š ì „ì²´ ì„±ëŠ¥:")
            print(f"  ì˜ˆì¸¡ ìˆ˜: {len(results)}ê°œ")
            print(f"  ê²€ì¦ ê°€ëŠ¥: {len(valid_results)}ê°œ")
            print(f"  MAE (ì›ë³¸): {mae_orig:.2f}")
            print(f"  MAE (ë³´ì •): {mae:.2f} [ê°œì„ : {mae_orig-mae:.2f}]")
            print(f"  RMSE: {rmse:.2f}")
            print(f"  RÂ²: {r2:.4f}")
            
            # êµ¬ê°„ë³„ ì„±ëŠ¥
            signal_data = valid_results[(valid_results['ì‹¤ì œê°’'] >= self.SIGNAL_MIN) & 
                                       (valid_results['ì‹¤ì œê°’'] <= self.SIGNAL_MAX)]
            danger_data = valid_results[valid_results['ì‹¤ì œê°’'] >= self.DANGER_MIN]
            
            if len(signal_data) > 0:
                signal_mae_orig = mean_absolute_error(signal_data['ì‹¤ì œê°’'], signal_data['ì˜ˆì¸¡ê°’_ì›ë³¸'])
                signal_mae = mean_absolute_error(signal_data['ì‹¤ì œê°’'], signal_data['ì˜ˆì¸¡ê°’'])
                print(f"\nğŸŸ  ì‹ í˜¸êµ¬ê°„(1651~1699):")
                print(f"  ìƒ˜í”Œ: {len(signal_data)}ê°œ")
                print(f"  MAE (ì›ë³¸): {signal_mae_orig:.2f}")
                print(f"  MAE (ë³´ì •): {signal_mae:.2f} [ê°œì„ : {signal_mae_orig-signal_mae:.2f}]")
                
                # ì ì¤‘ë¥ 
                hits = np.abs(signal_data['ì˜ˆì¸¡ê°’'] - signal_data['ì‹¤ì œê°’']) < 50
                print(f"  ì ì¤‘ë¥ (Â±50): {hits.mean()*100:.1f}%")
            
            if len(danger_data) > 0:
                danger_mae_orig = mean_absolute_error(danger_data['ì‹¤ì œê°’'], danger_data['ì˜ˆì¸¡ê°’_ì›ë³¸'])
                danger_mae = mean_absolute_error(danger_data['ì‹¤ì œê°’'], danger_data['ì˜ˆì¸¡ê°’'])
                print(f"\nğŸ”´ ìœ„í—˜êµ¬ê°„(1700+):")
                print(f"  ìƒ˜í”Œ: {len(danger_data)}ê°œ")
                print(f"  MAE (ì›ë³¸): {danger_mae_orig:.2f}")
                print(f"  MAE (ë³´ì •): {danger_mae:.2f} [ê°œì„ : {danger_mae_orig-danger_mae:.2f}]")
                
                # ì ì¤‘ë¥ 
                hits = np.abs(danger_data['ì˜ˆì¸¡ê°’'] - danger_data['ì‹¤ì œê°’']) < 50
                print(f"  ì ì¤‘ë¥ (Â±50): {hits.mean()*100:.1f}%")
                
                # M14Bë³„ ë¶„ì„
                high_m14b = danger_data[danger_data['M14B'] >= 400]
                if len(high_m14b) > 0:
                    print(f"\n  ğŸ“Œ M14Bâ‰¥400 ì¼€ì´ìŠ¤:")
                    print(f"    ìƒ˜í”Œ: {len(high_m14b)}ê°œ")
                    print(f"    MAE: {mean_absolute_error(high_m14b['ì‹¤ì œê°’'], high_m14b['ì˜ˆì¸¡ê°’']):.2f}")
        
        return results_df
    
    def save_results(self, results_df, output_path='evaluation_results.csv'):
        """ê²°ê³¼ ì €ì¥"""
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (ì˜ˆì¸¡ê°’_ì›ë³¸ì€ ì €ì¥í•˜ì§€ ì•ŠìŒ)
        output_columns = ['ë‚ ì§œ', 'ì‹œê°„ë‚ ì§œ', 'íƒ€ê²Ÿë‚ ì§œ', 'íƒ€ê²ŸMAX', 'íƒ€ê²ŸMIN', 'ì˜ˆì¸¡ê°’']
        
        if 'ì‹¤ì œê°’' in results_df.columns:
            output_columns.extend(['ì‹¤ì œê°’', 'ì˜¤ì°¨'])
        
        output_df = results_df[output_columns]
        
        # CSV ì €ì¥
        output_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
        
        # ìœ„í—˜êµ¬ê°„ ìƒ˜í”Œ ì¶œë ¥
        print("\nğŸ“‹ ê²°ê³¼ ìƒ˜í”Œ (ë†’ì€ ì˜ˆì¸¡ê°’):")
        high_preds = results_df[results_df['ì˜ˆì¸¡ê°’'] >= 1650].head(10)
        if len(high_preds) > 0:
            display_cols = ['ì‹œê°„ë‚ ì§œ', 'ì˜ˆì¸¡ê°’_ì›ë³¸', 'ì˜ˆì¸¡ê°’', 'M14B']
            if 'ì‹¤ì œê°’' in high_preds.columns:
                display_cols.append('ì‹¤ì œê°’')
            print(high_preds[display_cols].to_string(index=False))
        else:
            print(output_df.head(10))
        
        return output_path

# ========================================
# ë©”ì¸ ì‹¤í–‰
# ========================================
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # í‰ê°€ ë°ì´í„° ê²½ë¡œ
    eval_path = 'data/20250731_to20250806.csv'
    
    # íŒŒì¼ ì²´í¬
    if not os.path.exists(eval_path):
        print(f"âŒ í‰ê°€ ë°ì´í„° ì—†ìŒ: {eval_path}")
        return None
    
    # í‰ê°€ ì‹¤í–‰
    try:
        evaluator = ModelEvaluator()
        results_df = evaluator.evaluate(eval_path)
        
        # ê²°ê³¼ ì €ì¥
        output_file = evaluator.save_results(
            results_df, 
            output_path='evaluation_results_20250731_to_20250806.csv'
        )
        
        print("\n" + "="*80)
        print("âœ… í‰ê°€ ì™„ë£Œ!")
        print(f"ğŸ“Š ê²°ê³¼ íŒŒì¼: {output_file}")
        print("="*80)
        
        return results_df
        
    except Exception as e:
        print(f"\nâŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

if __name__ == "__main__":
    results = main()