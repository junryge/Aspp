# -*- coding: utf-8 -*-
"""
ExtraTrees ì™„ì „ì²´ - ëª¨ë¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
- ì €ì¥ëœ ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ë¡œë“œ
- í•™ìŠµ ì‹œì™€ ë™ì¼í•œ ë°©ë²•ìœ¼ë¡œ í‰ê°€ìš© ë°ì´í„° ì „ì²˜ë¦¬
- íšŒê·€, ë¶„ë¥˜, ì´ìƒì‹ í˜¸ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€
"""

import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, classification_report
import joblib
import os
import warnings
warnings.filterwarnings('ignore')

# --- ì„¤ì • ---
# ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì €ì¥ëœ í´ë” ê²½ë¡œ
MODEL_DIR = 'extratrees_fixed_model'
# í‰ê°€í•  ë°ì´í„° íŒŒì¼ ê²½ë¡œ
DATA_PATH = 'data/20240201_TO_202507281705.csv'
# --- ì„¤ì • ë ---


print("="*80)
print("ExtraTrees ì™„ì „ì²´ - ëª¨ë¸ í‰ê°€ ì‹œì‘")
print(f"ëª¨ë¸ ê²½ë¡œ: {MODEL_DIR}")
print(f"ë°ì´í„° ê²½ë¡œ: {DATA_PATH}")
print("="*80)


# ==============================================================================
# 1. ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
# ==============================================================================
print("\n[1] ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë”©...")
try:
    reg_model = joblib.load(os.path.join(MODEL_DIR, 'ExtraTrees_regression.pkl'))
    cls_model = joblib.load(os.path.join(MODEL_DIR, 'ExtraTrees_classifier.pkl'))
    anomaly_model = joblib.load(os.path.join(MODEL_DIR, 'ExtraTrees_anomaly.pkl'))
    scaler = joblib.load(os.path.join(MODEL_DIR, 'scaler.pkl'))
    print("âœ“ ëª¨ë¸ 4ê°œ íŒŒì¼ ë¡œë”© ì™„ë£Œ!")
except FileNotFoundError as e:
    print(f"ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”. -> {e}")
    exit()


# ==============================================================================
# 2. í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•œ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
# (ì´ í•¨ìˆ˜ë“¤ì€ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ê²ƒê³¼ ë°˜ë“œì‹œ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤)
# ==============================================================================
def assign_level(totalcnt_value):
    if totalcnt_value < 1400: return 0
    elif totalcnt_value < 1700: return 1
    else: return 2

def detect_anomaly_signal(totalcnt_value):
    return 1 if 1651 <= totalcnt_value <= 1682 else 0

def create_sequences_for_evaluation(data, seq_length=280, pred_horizon=10):
    """í‰ê°€ë¥¼ ìœ„í•œ ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜ (í•™ìŠµ ì½”ë“œì™€ 100% ë™ì¼)"""
    print("\n[2] í‰ê°€ìš© ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± ì‹œì‘...")
    
    # í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ì „ì—­ ë³€ìˆ˜ì™€ ë™ì¼í•˜ê²Œ ê³„ì‚°
    TOTALCNT_MEAN = data['TOTALCNT'].mean()
    TOTALCNT_MEDIAN = data['TOTALCNT'].median()
    
    feature_cols = ['M14AM14B', 'M14AM10A', 'M14AM16', 'M14AM14BSUM', 
                   'M14AM10ASUM', 'M14AM16SUM', 'M14BM14A', 'M10AM14A', 'M16M14A', 'TOTALCNT']
    
    data = data.copy()
    data['ratio_M14B_M14A'] = np.clip(data['M14AM14B'] / (data['M14AM10A'] + 1), 0, 100)
    data['ratio_M14B_M16'] = np.clip(data['M14AM14B'] / (data['M14AM16'] + 1), 0, 100)
    data['totalcnt_change'] = data['TOTALCNT'].diff().fillna(0)
    data['totalcnt_pct_change'] = data['TOTALCNT'].pct_change().fillna(0)
    data['totalcnt_pct_change'] = np.clip(data['totalcnt_pct_change'], -1, 1)
    
    data = data.replace([np.inf, -np.inf], np.nan)
    for col in data.columns:
        if data[col].isna().any():
            col_median = data[col].median()
            data[col].fillna(col_median, inplace=True)
    
    X_list, y_reg_list, y_cls_list, y_anomaly_list = [], [], [], []
    
    n_sequences = len(data) - seq_length - pred_horizon + 1
    print(f"âœ“ ìƒì„± ê°€ëŠ¥í•œ ì‹œí€€ìŠ¤: {n_sequences:,}ê°œ")
    
    for i in range(n_sequences):
        if i % 5000 == 0:
            print(f"  ì§„í–‰: {i}/{n_sequences} ({i/n_sequences*100:.1f}%)", end='\r')
        
        seq_data = data.iloc[i : i + seq_length]
        features = []
        
        for col in feature_cols:
            values = seq_data[col].values
            features.extend([
                np.mean(values), np.std(values), np.min(values), np.max(values),
                np.percentile(values, 25), np.percentile(values, 50), np.percentile(values, 75),
                values[-1], values[-1] - values[0],
                np.mean(values[-60:]), np.max(values[-60:]),
                np.mean(values[-30:]), np.max(values[-30:]),
            ])
            if col == 'TOTALCNT':
                features.extend([
                    np.sum((values >= 1650) & (values < 1700)),
                    np.sum(values >= 1700),
                    np.max(values[-20:]),
                    np.sum(values < 1400),
                    np.sum((values >= 1400) & (values < 1700)),
                    np.sum(values >= 1700),
                    np.sum((values >= 1651) & (values <= 1682)),
                ])
                anomaly_values = values[(values >= 1651) & (values <= 1682)]
                features.append(np.max(anomaly_values) if len(anomaly_values) > 0 else TOTALCNT_MEDIAN)
                
                normal_vals = values[values < 1400]
                check_vals = values[(values >= 1400) & (values < 1700)]
                danger_vals = values[values >= 1700]
                features.extend([
                    np.mean(normal_vals) if len(normal_vals) > 0 else TOTALCNT_MEAN,
                    np.mean(check_vals) if len(check_vals) > 0 else TOTALCNT_MEAN,
                    np.mean(danger_vals) if len(danger_vals) > 0 else TOTALCNT_MEAN,
                ])
                try:
                    features.append(np.clip(np.polyfit(np.arange(len(values)), values, 1)[0], -50, 50))
                    features.append(np.clip(np.polyfit(np.arange(60), values[-60:], 1)[0], -50, 50))
                except:
                    features.extend([0, 0])

        last_idx = i + seq_length - 1
        features.extend([
            np.clip(data['ratio_M14B_M14A'].iloc[last_idx], 0, 100),
            np.clip(data['ratio_M14B_M16'].iloc[last_idx], 0, 100),
            np.clip(data['totalcnt_change'].iloc[last_idx], -500, 500),
            np.clip(data['totalcnt_pct_change'].iloc[last_idx], -1, 1),
        ])
        
        target_idx = i + seq_length + pred_horizon - 1
        if target_idx < len(data):
            future_totalcnt = data['TOTALCNT'].iloc[target_idx]
            X_list.append(features)
            y_reg_list.append(future_totalcnt)
            y_cls_list.append(assign_level(future_totalcnt))
            y_anomaly_list.append(detect_anomaly_signal(future_totalcnt))
            
    print(f"\nâœ“ ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ! (ì´ {len(X_list):,}ê°œ)")
    return np.array(X_list), np.array(y_reg_list), np.array(y_cls_list), np.array(y_anomaly_list)


# ==============================================================================
# 3. ë°ì´í„° ë¡œë“œ ë° ì˜ˆì¸¡ ìˆ˜í–‰
# ==============================================================================
# ë°ì´í„° ë¡œë“œ
print(f"\n[3] í‰ê°€ìš© ë°ì´í„° ë¡œë”©: {DATA_PATH}")
try:
    eval_df = pd.read_csv(DATA_PATH)
    print(f"âœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(eval_df):,}í–‰")
except FileNotFoundError:
    print(f"ì˜¤ë¥˜: ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    exit()

# ì‹œí€€ìŠ¤ ìƒì„±
X_eval, y_reg_true, y_cls_true, y_anomaly_true = create_sequences_for_evaluation(eval_df)

# ë°ì´í„° ì •ê·œí™” (â˜…ë§¤ìš° ì¤‘ìš”: fit_transformì´ ì•„ë‹Œ transform ì‚¬ìš©)
print("\n[4] ë°ì´í„° ì •ê·œí™” ì ìš©...")
X_eval_scaled = scaler.transform(X_eval)
print("âœ“ ì •ê·œí™” ì™„ë£Œ!")

# ì˜ˆì¸¡ ìˆ˜í–‰
print("\n[5] ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰...")
y_reg_pred = reg_model.predict(X_eval_scaled)
y_cls_pred = cls_model.predict(X_eval_scaled)
y_anomaly_pred = anomaly_model.predict(X_eval_scaled)
print("âœ“ ì˜ˆì¸¡ ì™„ë£Œ!")


# ==============================================================================
# 4. ì„±ëŠ¥ í‰ê°€ ë° ê²°ê³¼ ì¶œë ¥
# ==============================================================================
print("\n" + "="*80)
print("ì¢…í•© í‰ê°€ ê²°ê³¼")
print("="*80)

# íšŒê·€ ëª¨ë¸ í‰ê°€
mae = mean_absolute_error(y_reg_true, y_reg_pred)
rmse = np.sqrt(mean_squared_error(y_reg_true, y_reg_pred))
r2 = r2_score(y_reg_true, y_reg_pred)

print("\n[ğŸ“ˆ íšŒê·€ ëª¨ë¸ ì„±ëŠ¥]")
print(f"  MAE:  {mae:.2f}")
print(f"  RMSE: {rmse:.2f}")
print(f"  RÂ²:   {r2:.4f}")

# 3êµ¬ê°„ ë¶„ë¥˜ ëª¨ë¸ í‰ê°€
cls_accuracy = accuracy_score(y_cls_true, y_cls_pred)
print("\n[ğŸ“Š 3êµ¬ê°„ ë¶„ë¥˜ ì„±ëŠ¥]")
print(f"  ì •í™•ë„: {cls_accuracy:.3f}")
print("\n  Classification Report:")
print(classification_report(y_cls_true, y_cls_pred, target_names=['ì •ìƒ(0)', 'í™•ì¸(1)', 'ìœ„í—˜(2)']))

# ì´ìƒì‹ í˜¸ ê°ì§€ ëª¨ë¸ í‰ê°€
print("[ğŸ”¥ ì´ìƒì‹ í˜¸(1651-1682) ê°ì§€ ì„±ëŠ¥]")
print(classification_report(y_anomaly_true, y_anomaly_pred, target_names=['ì •ìƒ', 'ì´ìƒì‹ í˜¸']))

# 1700+ ìœ„í—˜ ì˜ˆì¸¡ ì„±ëŠ¥ (íšŒê·€ ëª¨ë¸ ê¸°ë°˜)
actual_danger = y_reg_true >= 1700
pred_danger = y_reg_pred >= 1700
tp_d = np.sum(actual_danger & pred_danger)
fp_d = np.sum(~actual_danger & pred_danger)
fn_d = np.sum(actual_danger & ~pred_danger)
precision_d = tp_d / (tp_d + fp_d) if (tp_d + fp_d) > 0 else 0
recall_d = tp_d / (tp_d + fn_d) if (tp_d + fn_d) > 0 else 0
f1_d = 2 * (precision_d * recall_d) / (precision_d + recall_d) if (precision_d + recall_d) > 0 else 0

print(f"[ğŸš¨ 1700+ ìœ„í—˜ ì˜ˆì¸¡ ì„±ëŠ¥ (íšŒê·€ ê¸°ë°˜)]")
print(f"  F1-Score: {f1_d:.3f} (Precision: {precision_d:.3f}, Recall: {recall_d:.3f})")


# ==============================================================================
# 5. ì˜ˆì¸¡ ê²°ê³¼ DataFrameìœ¼ë¡œ í™•ì¸
# ==============================================================================
print("\n" + "="*80)
print("ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ í™•ì¸")
print("="*80)

results_df = pd.DataFrame({
    'ì‹¤ì œ TOTALCNT': y_reg_true,
    'ì˜ˆì¸¡ TOTALCNT': y_reg_pred,
    'ì˜¤ì°¨': y_reg_true - y_reg_pred,
    'ì‹¤ì œ êµ¬ê°„': y_cls_true,
    'ì˜ˆì¸¡ êµ¬ê°„': y_cls_pred,
    'ì‹¤ì œ ì´ìƒì‹ í˜¸': y_anomaly_true,
    'ì˜ˆì¸¡ ì´ìƒì‹ í˜¸': y_anomaly_pred
})

# ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ë³´ê¸° ì¢‹ê²Œ ì„¤ì •
pd.set_option('display.float_format', '{:.2f}'.format)
print(results_df.tail(15)) # ë§ˆì§€ë§‰ 15ê°œ ê²°ê³¼ ì¶œë ¥


print("\nâœ… í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
