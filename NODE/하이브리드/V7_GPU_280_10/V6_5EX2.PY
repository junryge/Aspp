"""
ğŸš¨ EXTREME_NET ê¸´ê¸‰ ìˆ˜ì • - RÂ² ë¬¸ì œ ì™„ì „ í•´ê²°
===========================================
ìŠ¤ì¼€ì¼ë§ê³¼ RÂ² ê³„ì‚° ë¬¸ì œ ìˆ˜ì •
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, Model, Input, backend as K
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import *
from sklearn.preprocessing import StandardScaler  # MinMaxScaler ëŒ€ì‹ !
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
import os

warnings.filterwarnings('ignore')
tf.random.set_seed(42)
np.random.seed(42)

print("="*80)
print("ğŸš¨ ê¸´ê¸‰ ìˆ˜ì • ë²„ì „ - RÂ² ë¬¸ì œ í•´ê²°")
print("="*80)

# ====================================
# ìˆ˜ì •ëœ RÂ² ë©”íŠ¸ë¦­
# ====================================
class R2Score(tf.keras.metrics.Metric):
    """ì˜¬ë°”ë¥¸ RÂ² êµ¬í˜„"""
    def __init__(self, name='r2_score', **kwargs):
        super().__init__(name=name, **kwargs)
        self.ss_res = self.add_weight(name='ss_res', initializer='zeros')
        self.ss_tot = self.add_weight(name='ss_tot', initializer='zeros')
        self.count = self.add_weight(name='count', initializer='zeros')
        self.y_sum = self.add_weight(name='y_sum', initializer='zeros')
        
    def update_state(self, y_true, y_pred, sample_weight=None):
        y_true = tf.cast(tf.reshape(y_true, [-1]), tf.float32)
        y_pred = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)
        
        # í‰ê·  ê³„ì‚°
        batch_size = tf.cast(tf.shape(y_true)[0], tf.float32)
        self.count.assign_add(batch_size)
        self.y_sum.assign_add(tf.reduce_sum(y_true))
        y_mean = self.y_sum / self.count
        
        # SS ê³„ì‚°
        ss_res = tf.reduce_sum(tf.square(y_true - y_pred))
        ss_tot = tf.reduce_sum(tf.square(y_true - y_mean))
        
        self.ss_res.assign_add(ss_res)
        self.ss_tot.assign_add(ss_tot)
    
    def result(self):
        return 1 - (self.ss_res / (self.ss_tot + 1e-7))
    
    def reset_state(self):
        self.ss_res.assign(0)
        self.ss_tot.assign(0)
        self.count.assign(0)
        self.y_sum.assign(0)

# ====================================
# ë‹¨ìˆœí™”ëœ ëª¨ë¸ (íšŒê·€ì— ì§‘ì¤‘)
# ====================================
def create_simple_model(input_shape):
    """ë‹¨ìˆœí•˜ì§€ë§Œ íš¨ê³¼ì ì¸ ëª¨ë¸"""
    
    inputs = Input(shape=input_shape)
    
    # ë‹¨ìˆœ LSTM
    x = LSTM(64, return_sequences=True)(inputs)
    x = Dropout(0.2)(x)
    x = LSTM(32)(x)
    x = Dropout(0.2)(x)
    
    # Dense
    x = Dense(32, activation='relu')(x)
    x = BatchNormalization()(x)
    
    # íšŒê·€ ì¶œë ¥ë§Œ
    output = Dense(1, activation='linear')(x)  # linear ì¤‘ìš”!
    
    model = Model(inputs, output, name='SimpleExtreme')
    
    # ì»´íŒŒì¼ (íšŒê·€ë§Œ ì§‘ì¤‘)
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='mse',
        metrics=[R2Score(), 'mae']
    )
    
    return model

# ====================================
# ë°ì´í„° ì²˜ë¦¬ (ìˆ˜ì •)
# ====================================
class DataProcessor:
    def __init__(self):
        self.scaler_X = StandardScaler()  # MinMax ëŒ€ì‹  Standard
        self.scaler_y = StandardScaler()  # íƒ€ê²Ÿë„ Standard
        
    def prepare_data(self, df):
        """ë°ì´í„° ì¤€ë¹„"""
        print("\nğŸ“Š ë°ì´í„° ì¤€ë¹„...")
        
        # 0ê°’ê³¼ ì´ìƒì¹˜ ì œê±°
        df = df[df['TOTALCNT'] > 0].reset_index(drop=True)
        df = df[df['TOTALCNT'] < 5000].reset_index(drop=True)  # ì´ìƒì¹˜ ì œê±°
        
        # ë¡œê·¸ ë³€í™˜ (ë¶„í¬ ì •ê·œí™”)
        df['TOTALCNT_LOG'] = np.log1p(df['TOTALCNT'])
        
        # ê¸°ë³¸ íŠ¹ì§•
        features = []
        if 'M14AM14B' in df.columns:
            features.append('M14AM14B')
            df['M14AM14B_LOG'] = np.log1p(df['M14AM14B'])
            features.append('M14AM14B_LOG')
        if 'M14AM10A' in df.columns:
            features.append('M14AM10A')
        
        # ì´ë™í‰ê· 
        df['MA_10'] = df['TOTALCNT'].rolling(10, min_periods=1).mean()
        df['MA_30'] = df['TOTALCNT'].rolling(30, min_periods=1).mean()
        features.extend(['MA_10', 'MA_30'])
        
        # ë³€í™”ìœ¨
        df['CHANGE_10'] = df['TOTALCNT'].diff(10).fillna(0)
        features.append('CHANGE_10')
        
        # TOTALCNTë„ íŠ¹ì§•ì— í¬í•¨
        features.insert(0, 'TOTALCNT')
        
        print(f"  íŠ¹ì§•: {features}")
        
        X = df[features].values
        y = df['TOTALCNT'].values  # ë¡œê·¸ ë³€í™˜ ì•ˆ í•¨
        
        print(f"  X shape: {X.shape}")
        print(f"  y ë²”ìœ„: {y.min():.0f} ~ {y.max():.0f}")
        print(f"  y í‰ê· : {y.mean():.0f} Â± {y.std():.0f}")
        
        return X, y
    
    def create_sequences(self, X, y, seq_len=100, pred_len=10):
        """ì‹œí€€ìŠ¤ ìƒì„±"""
        print("\nğŸ”„ ì‹œí€€ìŠ¤ ìƒì„±...")
        
        # NaN ì²˜ë¦¬
        X = np.nan_to_num(X, 0)
        
        sequences_X = []
        sequences_y = []
        
        for i in range(len(X) - seq_len - pred_len + 1):
            seq_x = X[i:i + seq_len]
            target = y[i + seq_len + pred_len - 1]
            
            sequences_X.append(seq_x)
            sequences_y.append(target)
        
        sequences_X = np.array(sequences_X)
        sequences_y = np.array(sequences_y)
        
        print(f"  ì‹œí€€ìŠ¤: {sequences_X.shape}")
        
        # ë¶„í• 
        n = len(sequences_X)
        train_size = int(n * 0.7)
        val_size = int(n * 0.15)
        
        X_train = sequences_X[:train_size]
        y_train = sequences_y[:train_size]
        
        X_val = sequences_X[train_size:train_size + val_size]
        y_val = sequences_y[train_size:train_size + val_size]
        
        X_test = sequences_X[train_size + val_size:]
        y_test = sequences_y[train_size + val_size:]
        
        # ìŠ¤ì¼€ì¼ë§ (ì¤‘ìš”!)
        print("\nâš™ï¸ ìŠ¤ì¼€ì¼ë§...")
        
        # X ìŠ¤ì¼€ì¼ë§
        n_samples, n_timesteps, n_features = X_train.shape
        X_train_2d = X_train.reshape(-1, n_features)
        X_train_scaled_2d = self.scaler_X.fit_transform(X_train_2d)
        X_train_scaled = X_train_scaled_2d.reshape(n_samples, n_timesteps, n_features)
        
        X_val_scaled = self.scaler_X.transform(X_val.reshape(-1, n_features)).reshape(X_val.shape)
        X_test_scaled = self.scaler_X.transform(X_test.reshape(-1, n_features)).reshape(X_test.shape)
        
        # y ìŠ¤ì¼€ì¼ë§
        y_train_scaled = self.scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()
        y_val_scaled = self.scaler_y.transform(y_val.reshape(-1, 1)).flatten()
        y_test_scaled = self.scaler_y.transform(y_test.reshape(-1, 1)).flatten()
        
        # ìŠ¤ì¼€ì¼ë§ ê²€ì¦
        print(f"  X_train ë²”ìœ„: [{X_train_scaled.min():.2f}, {X_train_scaled.max():.2f}]")
        print(f"  y_train ë²”ìœ„: [{y_train_scaled.min():.2f}, {y_train_scaled.max():.2f}]")
        print(f"  y_train í‰ê· : {y_train_scaled.mean():.2f} Â± {y_train_scaled.std():.2f}")
        
        return (X_train_scaled, y_train_scaled, y_train), \
               (X_val_scaled, y_val_scaled, y_val), \
               (X_test_scaled, y_test_scaled, y_test)

# ====================================
# í•™ìŠµ
# ====================================
def train_model(model, train_data, val_data, test_data, processor):
    """í•™ìŠµ"""
    X_train, y_train_scaled, y_train_orig = train_data
    X_val, y_val_scaled, y_val_orig = val_data
    X_test, y_test_scaled, y_test_orig = test_data
    
    print("\nğŸ¯ í•™ìŠµ ì‹œì‘...")
    
    # ì½œë°±
    callbacks = [
        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),
        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)
    ]
    
    # í•™ìŠµ
    history = model.fit(
        X_train, y_train_scaled,
        validation_data=(X_val, y_val_scaled),
        epochs=50,
        batch_size=32,
        callbacks=callbacks,
        verbose=1
    )
    
    # í‰ê°€
    print("\nğŸ“Š í‰ê°€...")
    
    # ì˜ˆì¸¡
    y_pred_scaled = model.predict(X_test, verbose=0).flatten()
    
    # ì—­ë³€í™˜ (ì¤‘ìš”!)
    y_pred = processor.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
    
    # ë©”íŠ¸ë¦­ (ì›ë³¸ ìŠ¤ì¼€ì¼ì—ì„œ)
    mae = mean_absolute_error(y_test_orig, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))
    r2 = r2_score(y_test_orig, y_pred)
    
    print(f"\nğŸ“ˆ ìµœì¢… ì„±ëŠ¥ (ì›ë³¸ ìŠ¤ì¼€ì¼):")
    print(f"  MAE: {mae:.2f}")
    print(f"  RMSE: {rmse:.2f}")
    print(f"  RÂ²: {r2:.4f}")
    
    # RÂ² ê²€ì¦
    if r2 < 0:
        print("\nâš ï¸ RÂ²ê°€ ìŒìˆ˜ì…ë‹ˆë‹¤! í™•ì¸ í•„ìš”:")
        print(f"  y_test í‰ê· : {y_test_orig.mean():.0f}")
        print(f"  y_pred í‰ê· : {y_pred.mean():.0f}")
        print(f"  y_test í‘œì¤€í¸ì°¨: {y_test_orig.std():.0f}")
        print(f"  y_pred í‘œì¤€í¸ì°¨: {y_pred.std():.0f}")
        
        # ìƒê´€ê³„ìˆ˜
        corr = np.corrcoef(y_test_orig, y_pred)[0, 1]
        print(f"  ìƒê´€ê³„ìˆ˜: {corr:.4f}")
    
    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}

# ====================================
# ë©”ì¸
# ====================================
def main():
    print("\nğŸš¨ ê¸´ê¸‰ ìˆ˜ì • ë²„ì „ ì‹¤í–‰")
    
    # ë°ì´í„° ì°¾ê¸°
    data_paths = [
        '/mnt/user-data/uploads/gs.CSV',
        'data/20240201_TO_202507281705.csv',
        'uu.csv',
        'data.csv'
    ]
    
    data_path = None
    for path in data_paths:
        if os.path.exists(path):
            data_path = path
            print(f"âœ… ë°ì´í„°: {path}")
            break
    
    if not data_path:
        print("âŒ ë°ì´í„° ì—†ìŒ")
        return
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(data_path)
    print(f"  ë¡œë“œ: {len(df):,}í–‰")
    
    # ì²˜ë¦¬
    processor = DataProcessor()
    X, y = processor.prepare_data(df)
    train_data, val_data, test_data = processor.create_sequences(X, y)
    
    # ëª¨ë¸ (ë‹¨ìˆœ ë²„ì „)
    input_shape = (100, X.shape[1])
    model = create_simple_model(input_shape)
    
    # í•™ìŠµ
    results = train_model(model, train_data, val_data, test_data, processor)
    
    # ê²°ê³¼
    print("\n" + "="*60)
    print("ğŸ† ìµœì¢… ê²°ê³¼")
    print("="*60)
    print(f"RÂ²: {results['R2']:.4f}")
    print(f"MAE: {results['MAE']:.2f}")
    
    if results['R2'] > 0.5:
        print("âœ… ì„±ê³µ!")
    else:
        print("âŒ ê°œì„  í•„ìš”")
    
    return results

if __name__ == "__main__":
    results = main()