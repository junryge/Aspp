"""
ExtremeNet V6.5 - ìƒˆ ë°ì´í„° í‰ê°€ ë° ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ (ì™„ì „ ìˆ˜ì •íŒ)
==================================================
data/20250732_to20250806.csv ë°ì´í„° í‰ê°€
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
import os
import pickle
from datetime import datetime, timedelta

warnings.filterwarnings('ignore')

print("="*80)
print("ğŸ”® ExtremeNet V6.5 - ìƒˆ ë°ì´í„° í‰ê°€")
print("ğŸ“Š í‰ê°€ ë°ì´í„°: data/20250732_to20250806.csv")
print("="*80)

# ========================================
# ë°ì´í„° ì²˜ë¦¬ í´ë˜ìŠ¤
# ========================================
class DataEvaluator:
    def __init__(self, model_path='models_final/extremenet_v65_final.keras',
                 scaler_path='scalers_final/'):
        """í‰ê°€ê¸° ì´ˆê¸°í™”"""
        
        # ëª¨ë¸ ì†ì„± ë¨¼ì € ì´ˆê¸°í™” (ì¤‘ìš”!)
        self.model = None
        self.scaler_X = None
        self.scaler_y = None
        
        # ëª¨ë¸ ë¡œë“œ
        print("\nğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        # custom_objects ì •ì˜
        custom_objects = {
            'weighted_mae_signal': self.weighted_mae_signal,
            'weighted_mae': self.weighted_mae
        }
        
        # ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„
        model_paths = [
            model_path,
            'models_final/best_extremenet.keras',
            'models/extremenet_v65_fixed_final.keras', 
            'models/best_extremenet_fixed.keras',
            'checkpoints_final/extremenet_final.keras',
            'extremenet_v65_final.keras',
            'best_extremenet.keras'
        ]
        
        model_loaded = False
        for path in model_paths:
            if os.path.exists(path):
                try:
                    self.model = tf.keras.models.load_model(path, custom_objects=custom_objects)
                    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {path}")
                    model_loaded = True
                    break
                except Exception as e:
                    print(f"âš ï¸ {path} ë¡œë“œ ì‹¤íŒ¨: {str(e)[:100]}")
                    continue
        
        if not model_loaded:
            print("\nâŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print("ë‹¤ìŒ ê²½ë¡œë“¤ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤:")
            for path in model_paths:
                print(f"  - {path}: {'[ì¡´ì¬]' if os.path.exists(path) else '[ì—†ìŒ]'}")
            raise FileNotFoundError("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        print("\nğŸ“¦ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë”© ì¤‘...")
        
        scaler_paths = [
            (f'{scaler_path}scaler_X.pkl', f'{scaler_path}scaler_y.pkl'),
            ('scalers/scaler_X.pkl', 'scalers/scaler_y.pkl'),
            ('scalers_final/scaler_X.pkl', 'scalers_final/scaler_y.pkl')
        ]
        
        scaler_loaded = False
        for x_path, y_path in scaler_paths:
            if os.path.exists(x_path) and os.path.exists(y_path):
                try:
                    with open(x_path, 'rb') as f:
                        self.scaler_X = pickle.load(f)
                    with open(y_path, 'rb') as f:
                        self.scaler_y = pickle.load(f)
                    print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì„±ê³µ")
                    scaler_loaded = True
                    break
                except Exception as e:
                    print(f"âš ï¸ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    continue
        
        if not scaler_loaded:
            print("âš ï¸ ìŠ¤ì¼€ì¼ëŸ¬ ì—†ìŒ, ìƒˆë¡œ ìƒì„± (ì˜ˆì¸¡ ì •í™•ë„ ë‚®ì„ ìˆ˜ ìˆìŒ)")
            self.scaler_X = StandardScaler()
            self.scaler_y = MinMaxScaler(feature_range=(0, 1))
            self.need_fit_scaler = True
        else:
            self.need_fit_scaler = False
        
        # íŠ¹ì„± ì»¬ëŸ¼ ì •ì˜
        self.feature_columns = [
            'TOTALCNT', 'M14AM14B', 'M14AM14BSUM', 'M14AM10A', 'M14AM16',
            'RATIO', 'GOLDEN', 'SIGNAL_ZONE', 'PRE_SIGNAL', 'DANGER_ZONE',
            'PATTERN', 'TREND',
            'MA_5', 'MA_10', 'MA_20',
            'STD_5', 'STD_10', 'STD_20',
            'M14B_MA_5', 'M14B_MA_10', 'M14B_MA_20',
            'CHANGE_1', 'CHANGE_5', 'CHANGE_10',
            'M14B_CHANGE_1', 'M14B_CHANGE_5', 'M14B_CHANGE_10',
            'RISE_COUNT'
        ]
        
        self.seq_len = 100
        self.pred_len = 10
        
    def weighted_mae_signal(self, y_true, y_pred):
        """ì»¤ìŠ¤í…€ ì†ì‹¤í•¨ìˆ˜ - ì‹ í˜¸êµ¬ê°„ ê°•ì¡°"""
        weights = tf.ones_like(y_true)
        signal_mask = tf.logical_and(y_true >= 0.65, y_true <= 0.75)
        weights = tf.where(signal_mask, 5.0, weights)
        danger_mask = y_true > 0.75
        weights = tf.where(danger_mask, 10.0, weights)
        mae = tf.abs(y_true - y_pred)
        weighted_mae = mae * weights
        return tf.reduce_mean(weighted_mae)
    
    def weighted_mae(self, y_true, y_pred):
        """ì»¤ìŠ¤í…€ ì†ì‹¤í•¨ìˆ˜ (ëŒ€ì²´)"""
        return self.weighted_mae_signal(y_true, y_pred)
        
    def load_and_process_data(self, filepath):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print(f"\nğŸ“‚ ë°ì´í„° ë¡œë”©: {filepath}")
        
        # CSV ë¡œë“œ
        df = pd.read_csv(filepath)
        print(f"âœ… ì›ë³¸ ë°ì´í„°: {len(df):,}í–‰")
        
        # ì‹œê°„ ì •ë ¬
        df['CURRTIME'] = pd.to_datetime(df['CURRTIME'].astype(str), 
                                       format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('CURRTIME').reset_index(drop=True)
        
        # 0ê°’ ì œê±°
        df = df[df['TOTALCNT'] > 0].reset_index(drop=True)
        print(f"âœ… ìœ íš¨ ë°ì´í„°: {len(df):,}í–‰")
        
        # êµ¬ê°„ í†µê³„
        normal = (df['TOTALCNT'] < 1400).sum()
        caution = ((df['TOTALCNT'] >= 1400) & (df['TOTALCNT'] <= 1650)).sum()
        signal = ((df['TOTALCNT'] >= 1651) & (df['TOTALCNT'] <= 1699)).sum()
        danger = (df['TOTALCNT'] >= 1700).sum()
        
        print(f"\nğŸ“Š ë°ì´í„° ë¶„í¬:")
        print(f"  ì •ìƒ(~1400): {normal:,}ê°œ ({normal/len(df)*100:.1f}%)")
        print(f"  ì£¼ì˜(1400~1650): {caution:,}ê°œ ({caution/len(df)*100:.1f}%)")
        print(f"  ì‹ í˜¸(1651~1699): {signal:,}ê°œ ({signal/len(df)*100:.1f}%)")
        print(f"  ìœ„í—˜(1700+): {danger:,}ê°œ ({danger/len(df)*100:.1f}%)")
        
        return df
    
    def create_features(self, df):
        """íŠ¹ì„± ìƒì„±"""
        print("\nâš™ï¸ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ê¸°ë³¸ íŠ¹ì„±
        df['RATIO'] = df['M14AM14B'] / (df['M14AM10A'] + 1)
        df['GOLDEN'] = ((df['M14AM14B'] > 300) & (df['M14AM10A'] < 80)).astype(int)
        
        # êµ¬ê°„ íŠ¹ì„±
        df['SIGNAL_ZONE'] = ((df['TOTALCNT'] >= 1651) & (df['TOTALCNT'] <= 1699)).astype(int)
        df['PRE_SIGNAL'] = ((df['TOTALCNT'] >= 1600) & (df['TOTALCNT'] < 1651)).astype(int)
        df['DANGER_ZONE'] = (df['TOTALCNT'] >= 1700).astype(int)
        
        # ì´ë™í‰ê· 
        for w in [5, 10, 20]:
            df[f'MA_{w}'] = df['TOTALCNT'].rolling(w, min_periods=1).mean()
            df[f'STD_{w}'] = df['TOTALCNT'].rolling(w, min_periods=1).std().fillna(0)
            df[f'M14B_MA_{w}'] = df['M14AM14B'].rolling(w, min_periods=1).mean()
        
        # ë³€í™”ìœ¨
        for lag in [1, 5, 10]:
            df[f'CHANGE_{lag}'] = df['TOTALCNT'].diff(lag).fillna(0)
            df[f'M14B_CHANGE_{lag}'] = df['M14AM14B'].diff(lag).fillna(0)
        
        # ì—°ì† ìƒìŠ¹
        df['RISE'] = (df['TOTALCNT'] > df['TOTALCNT'].shift(1)).astype(int)
        df['RISE_COUNT'] = df['RISE'].rolling(10, min_periods=1).sum()
        
        # íŒ¨í„´
        df['PATTERN'] = 0
        signal_mask = ((df['TOTALCNT'] >= 1651) & (df['TOTALCNT'] <= 1699))
        high_m14b = df['M14AM14B'].rolling(100, min_periods=1).mean() > 380
        df.loc[signal_mask, 'PATTERN'] = 1
        df.loc[high_m14b, 'PATTERN'] = 2
        
        # ì¶”ì„¸
        df['TREND'] = 1  # ê¸°ë³¸ê°’ ë³´í•©
        for i in range(20, len(df)):
            recent = df['TOTALCNT'].iloc[i-20:i].values
            if len(recent) > 1:
                slope = np.polyfit(range(len(recent)), recent, 1)[0]
                if slope > 5:
                    df.loc[i, 'TREND'] = 2  # ìƒìŠ¹
                elif slope < -5:
                    df.loc[i, 'TREND'] = 0  # í•˜ë½
        
        print(f"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: {len(self.feature_columns)}ê°œ")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ê°€ í•™ìŠµë˜ì§€ ì•Šì€ ê²½ìš° í•™ìŠµ
        if hasattr(self, 'need_fit_scaler') and self.need_fit_scaler:
            print("âš™ï¸ ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ ì¤‘...")
            X_sample = df[self.feature_columns].values[:1000]  # ìƒ˜í”Œë¡œ í•™ìŠµ
            y_sample = df['TOTALCNT'].values[:1000].reshape(-1, 1)
            self.scaler_X.fit(X_sample)
            self.scaler_y.fit(y_sample)
            print("âœ… ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ ì™„ë£Œ")
        
        return df
    
    def predict_sequences(self, df):
        """ì‹œí€€ìŠ¤ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡"""
        
        # ëª¨ë¸ ì²´í¬
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        
        print("\nğŸ”® ì˜ˆì¸¡ ì‹œì‘...")
        
        results = []
        
        # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë²”ìœ„ ê³„ì‚°
        max_idx = len(df) - self.seq_len - self.pred_len + 1
        if max_idx <= 0:
            print(f"âš ï¸ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ {self.seq_len + self.pred_len}ê°œ í•„ìš”")
            return pd.DataFrame()
        
        # 100ë¶„ ì‹œí€€ìŠ¤ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡
        for i in range(max_idx):
            # 100ë¶„ ë°ì´í„°
            seq_data = df.iloc[i:i+self.seq_len]
            
            # í˜„ì¬ ì‹œê°„
            current_time = seq_data['CURRTIME'].iloc[-1]
            
            # 10ë¶„ í›„ ì‹œê°„
            target_time = current_time + timedelta(minutes=10)
            
            # ì‹¤ì œê°’ (10ë¶„ í›„)
            if i+self.seq_len+self.pred_len-1 < len(df):
                actual_value = df['TOTALCNT'].iloc[i+self.seq_len+self.pred_len-1]
            else:
                actual_value = np.nan
            
            # íŠ¹ì„± ì¶”ì¶œ
            X = seq_data[self.feature_columns].values
            
            # ìŠ¤ì¼€ì¼ë§
            try:
                X_scaled = self.scaler_X.transform(X.reshape(-1, len(self.feature_columns)))
                X_scaled = X_scaled.reshape(1, self.seq_len, len(self.feature_columns))
            except Exception as e:
                print(f"âš ï¸ ìŠ¤ì¼€ì¼ë§ ì˜¤ë¥˜: {e}")
                X_scaled = X.reshape(1, self.seq_len, len(self.feature_columns))
            
            # ì˜ˆì¸¡
            try:
                preds = self.model.predict(X_scaled, verbose=0)
                
                # ëª¨ë¸ ì¶œë ¥ì´ ì—¬ëŸ¬ ê°œì¸ ê²½ìš° ì²« ë²ˆì§¸ ì¶œë ¥ ì‚¬ìš©
                if isinstance(preds, list):
                    y_pred_scaled = preds[0][0, 0]
                else:
                    y_pred_scaled = preds[0, 0]
                
                # ì—­ìŠ¤ì¼€ì¼ë§
                try:
                    y_pred = self.scaler_y.inverse_transform([[y_pred_scaled]])[0, 0]
                except:
                    # ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ëŠ” ê²½ìš° ëŒ€ëµì  ë³€í™˜
                    y_pred = y_pred_scaled * 900 + 900
                
            except Exception as e:
                print(f"âš ï¸ ì˜ˆì¸¡ ì˜¤ë¥˜ (ì¸ë±ìŠ¤ {i}): {e}")
                continue
            
            # í˜„ì¬ê°’
            current_value = seq_data['TOTALCNT'].iloc[-1]
            
            # ì¼ë³„ ìµœëŒ€ê°’ ê³„ì‚° (ë‹¹ì¼ ìµœëŒ€ê°’)
            current_date = current_time.date()
            day_data = df[df['CURRTIME'].dt.date == current_date]
            if len(day_data) > 0:
                daily_max = day_data['TOTALCNT'].max()
            else:
                daily_max = current_value
            
            # ê²°ê³¼ ì €ì¥
            results.append({
                'DateTime': current_time.strftime('%Y-%m-%d %H:%M'),
                'TargetDateTime': target_time.strftime('%Y-%m-%d %H:%M'),
                'CurrentValue': current_value,
                'ActualValue': actual_value,
                'PredictedValue': y_pred,
                'DailyMax': daily_max,
                'Error': abs(actual_value - y_pred) if not np.isnan(actual_value) else np.nan
            })
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            if (i+1) % 100 == 0:
                print(f"  ì§„í–‰: {i+1}/{max_idx}")
        
        print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(results)}ê°œ")
        return pd.DataFrame(results)
    
    def evaluate_results(self, results_df):
        """í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        print("\nğŸ“Š í‰ê°€ ë©”íŠ¸ë¦­:")
        
        if results_df.empty:
            print("âš ï¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # NaN ì œê±°
        valid_results = results_df.dropna(subset=['ActualValue', 'PredictedValue'])
        
        if len(valid_results) > 0:
            mae = mean_absolute_error(valid_results['ActualValue'], 
                                     valid_results['PredictedValue'])
            rmse = np.sqrt(mean_squared_error(valid_results['ActualValue'], 
                                             valid_results['PredictedValue']))
            r2 = r2_score(valid_results['ActualValue'], 
                         valid_results['PredictedValue'])
            
            print(f"  MAE: {mae:.2f}")
            print(f"  RMSE: {rmse:.2f}")
            print(f"  RÂ²: {r2:.4f}")
            
            # êµ¬ê°„ë³„ í‰ê°€
            signal_mask = (valid_results['ActualValue'] >= 1651) & \
                         (valid_results['ActualValue'] <= 1699)
            danger_mask = valid_results['ActualValue'] >= 1700
            
            if signal_mask.sum() > 0:
                signal_mae = mean_absolute_error(
                    valid_results[signal_mask]['ActualValue'],
                    valid_results[signal_mask]['PredictedValue']
                )
                print(f"\nğŸŸ  ì‹ í˜¸êµ¬ê°„(1651~1699) MAE: {signal_mae:.2f}")
                print(f"  ìƒ˜í”Œ ìˆ˜: {signal_mask.sum()}ê°œ")
            
            if danger_mask.sum() > 0:
                danger_mae = mean_absolute_error(
                    valid_results[danger_mask]['ActualValue'],
                    valid_results[danger_mask]['PredictedValue']
                )
                print(f"ğŸ”´ ìœ„í—˜êµ¬ê°„(1700+) MAE: {danger_mae:.2f}")
                print(f"  ìƒ˜í”Œ ìˆ˜: {danger_mask.sum()}ê°œ")
        else:
            print("âš ï¸ ìœ íš¨í•œ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ========================================
# ë©”ì¸ ì‹¤í–‰
# ========================================
def main():
    try:
        # í‰ê°€ê¸° ìƒì„±
        evaluator = DataEvaluator()
        
        # ë°ì´í„° ê²½ë¡œ
        data_path = 'data/20250732_to20250806.csv'
        
        # ëŒ€ì²´ ê²½ë¡œ
        if not os.path.exists(data_path):
            alt_paths = [
                '20250732_to20250806.csv', 
                'data/20250807_DATA.CSV',
                '20250807_DATA.CSV',
                'data/20240201_TO_202507281705.csv',
                '20240201_TO_202507281705.csv'
            ]
            for alt in alt_paths:
                if os.path.exists(alt):
                    data_path = alt
                    print(f"ğŸ“Œ ëŒ€ì²´ ê²½ë¡œ ì‚¬ìš©: {data_path}")
                    break
        
        if not os.path.exists(data_path):
            # í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±
            print("âš ï¸ ë°ì´í„° íŒŒì¼ì´ ì—†ì–´ì„œ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            
            # ê¸°ì¡´ ë°ì´í„°ì—ì„œ ì¼ë¶€ ì¶”ì¶œ
            original_paths = [
                'data/20240201_TO_202507281705.csv',
                '20240201_TO_202507281705.csv'
            ]
            
            for original_path in original_paths:
                if os.path.exists(original_path):
                    print(f"ğŸ“‚ ì›ë³¸ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ì¶”ì¶œ: {original_path}")
                    df_original = pd.read_csv(original_path)
                    # ë§ˆì§€ë§‰ 1000ê°œ í–‰ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ìš©
                    df_test = df_original.tail(1000)
                    df_test.to_csv('test_data.csv', index=False)
                    data_path = 'test_data.csv'
                    print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {data_path}")
                    break
            
            if not os.path.exists(data_path):
                print("âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                return None
        
        # ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬
        df = evaluator.load_and_process_data(data_path)
        df = evaluator.create_features(df)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        results_df = evaluator.predict_sequences(df)
        
        if results_df.empty:
            print("âš ï¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return results_df
        
        # í‰ê°€
        evaluator.evaluate_results(results_df)
        
        # ê²°ê³¼ ì €ì¥
        output_file = 'prediction_results.csv'
        
        # ì €ì¥í•  ì»¬ëŸ¼ ì„ íƒ
        save_columns = ['DateTime', 'TargetDateTime', 'DailyMax', 'PredictedValue']
        if 'ActualValue' in results_df.columns:
            # ì‹¤ì œê°’ì´ ìˆìœ¼ë©´ í¬í•¨
            save_columns = ['DateTime', 'TargetDateTime', 'DailyMax', 'ActualValue', 'PredictedValue', 'Error']
        
        results_df[save_columns].to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
        
        # ìƒ˜í”Œ ì¶œë ¥
        print("\nğŸ“‹ ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):")
        print(results_df[save_columns].head(10))
        
        # ìš”ì•½ í†µê³„
        print("\nğŸ“Š ì˜ˆì¸¡ê°’ ìš”ì•½:")
        print(f"  í‰ê· : {results_df['PredictedValue'].mean():.2f}")
        print(f"  í‘œì¤€í¸ì°¨: {results_df['PredictedValue'].std():.2f}")
        print(f"  ìµœì†Œ: {results_df['PredictedValue'].min():.2f}")
        print(f"  ìµœëŒ€: {results_df['PredictedValue'].max():.2f}")
        
        if 'Error' in results_df.columns:
            valid_errors = results_df['Error'].dropna()
            if len(valid_errors) > 0:
                print(f"\nğŸ“Š ì˜¤ì°¨ ë¶„í¬:")
                print(f"  í‰ê·  ì˜¤ì°¨: {valid_errors.mean():.2f}")
                print(f"  ì˜¤ì°¨ < 50: {(valid_errors < 50).sum()/len(valid_errors)*100:.1f}%")
                print(f"  ì˜¤ì°¨ < 100: {(valid_errors < 100).sum()/len(valid_errors)*100:.1f}%")
        
        print("\nâœ… í‰ê°€ ì™„ë£Œ!")
        return results_df
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    results = main()