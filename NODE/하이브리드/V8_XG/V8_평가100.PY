import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta
import os

def create_single_prediction_features_100min(seq_m14b, seq_m10a, seq_m16, seq_totalcnt):
    """
    í•˜ë‚˜ì˜ 100ë¶„ ì‹œí€€ìŠ¤ë¡œë¶€í„° Feature ìƒì„± (32ê°œ ê¸°ë³¸ í†µê³„ê°’ë§Œ)
    """
    features = {}
    
    # ========== M14AM14B ê¸°ë³¸ 8ê°œ ==========
    features['m14b_mean'] = np.mean(seq_m14b)
    features['m14b_std'] = np.std(seq_m14b)
    features['m14b_last_5_mean'] = np.mean(seq_m14b[-5:])
    features['m14b_max'] = np.max(seq_m14b)
    features['m14b_min'] = np.min(seq_m14b)
    features['m14b_slope'] = np.polyfit(np.arange(100), seq_m14b, 1)[0]
    features['m14b_last_10_mean'] = np.mean(seq_m14b[-10:])
    features['m14b_first_10_mean'] = np.mean(seq_m14b[:10])
    
    # ========== M14AM10A ê¸°ë³¸ 8ê°œ ==========
    features['m10a_mean'] = np.mean(seq_m10a)
    features['m10a_std'] = np.std(seq_m10a)
    features['m10a_last_5_mean'] = np.mean(seq_m10a[-5:])
    features['m10a_max'] = np.max(seq_m10a)
    features['m10a_min'] = np.min(seq_m10a)
    features['m10a_slope'] = np.polyfit(np.arange(100), seq_m10a, 1)[0]
    features['m10a_last_10_mean'] = np.mean(seq_m10a[-10:])
    features['m10a_first_10_mean'] = np.mean(seq_m10a[:10])
    
    # ========== M14AM16 ê¸°ë³¸ 8ê°œ ==========
    features['m16_mean'] = np.mean(seq_m16)
    features['m16_std'] = np.std(seq_m16)
    features['m16_last_5_mean'] = np.mean(seq_m16[-5:])
    features['m16_max'] = np.max(seq_m16)
    features['m16_min'] = np.min(seq_m16)
    features['m16_slope'] = np.polyfit(np.arange(100), seq_m16, 1)[0]
    features['m16_last_10_mean'] = np.mean(seq_m16[-10:])
    features['m16_first_10_mean'] = np.mean(seq_m16[:10])
    
    # ========== TOTALCNT ê¸°ë³¸ 8ê°œ ==========
    features['totalcnt_mean'] = np.mean(seq_totalcnt)
    features['totalcnt_std'] = np.std(seq_totalcnt)
    features['totalcnt_last_5_mean'] = np.mean(seq_totalcnt[-5:])
    features['totalcnt_max'] = np.max(seq_totalcnt)
    features['totalcnt_min'] = np.min(seq_totalcnt)
    features['totalcnt_slope'] = np.polyfit(np.arange(100), seq_totalcnt, 1)[0]
    features['totalcnt_last_10_mean'] = np.mean(seq_totalcnt[-10:])
    features['totalcnt_first_10_mean'] = np.mean(seq_totalcnt[:10])
    
    return features

def evaluate_all_predictions():
    """ì „ì²´ ë°ì´í„°ë¥¼ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ í‰ê°€ (100ë¶„ ì‹œí€€ìŠ¤)"""
    
    print("="*80)
    print("100ë¶„ ì‹œí€€ìŠ¤ ëª¨ë¸ í‰ê°€")
    print("="*80)
    
    # ëª¨ë¸ ë¡œë“œ
    model_file = 'xgboost_100to10_totalcnt.pkl'
    try:
        with open(model_file, 'rb') as f:
            model = pickle.load(f)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_file}")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {e}")
        print("ë¨¼ì € xgboost_100to10_simple.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
        return None
    
    # ë°ì´í„° ë¡œë“œ
    csv_file = 'data/aasf.csv'
    if not os.path.exists(csv_file):
        print(f"âŒ CSV íŒŒì¼ ì—†ìŒ: {csv_file}")
        return None
    
    df = pd.read_csv(csv_file, on_bad_lines='skip')
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ í–‰")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_cols = ['M14AM14B', 'M14AM10A', 'M14AM16', 'TOTALCNT']
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        print(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
        print(f"í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")
        return None
    
    print(f"âœ… í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ì™„ë£Œ")
    
    # CURRTIME ì²˜ë¦¬
    if 'CURRTIME' in df.columns:
        try:
            df['CURRTIME'] = pd.to_datetime(df['CURRTIME'])
            print("âœ… CURRTIME ì»¬ëŸ¼ ì‚¬ìš©")
        except:
            print("âš ï¸ CURRTIME ë³€í™˜ ì‹¤íŒ¨, ê°€ìƒ ì‹œê°„ ìƒì„±")
            base_time = datetime(2024, 1, 1, 0, 0)
            df['CURRTIME'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
    else:
        print("âš ï¸ CURRTIME ì—†ìŒ, ê°€ìƒ ì‹œê°„ ìƒì„±")
        base_time = datetime(2024, 1, 1, 0, 0)
        df['CURRTIME'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
    
    results = []
    
    print(f"\nğŸ“Š ìŠ¬ë¼ì´ë”© ìœˆë„ìš° í‰ê°€ ì‹œì‘...")
    print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(df) - 100:,}ê°œ")
    
    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°: i=100ë¶€í„° ì‹œì‘
    for i in range(100, len(df)):
        # 100ë¶„ ì‹œí€€ìŠ¤
        seq_m14b = df['M14AM14B'].iloc[i-100:i].values
        seq_m10a = df['M14AM10A'].iloc[i-100:i].values
        seq_m16 = df['M14AM16'].iloc[i-100:i].values
        seq_totalcnt = df['TOTALCNT'].iloc[i-100:i].values
        
        # ì‹œê°„ ì •ë³´
        current_time = df['CURRTIME'].iloc[i-1]  # ì‹œí€€ìŠ¤ ë§ˆì§€ë§‰
        seq_start_time = df['CURRTIME'].iloc[i-100]  # ì‹œí€€ìŠ¤ ì‹œì‘
        prediction_time = current_time + timedelta(minutes=10)
        actual_time = df['CURRTIME'].iloc[i]
        
        # ì‹¤ì œê°’
        actual_value = df['TOTALCNT'].iloc[i]
        
        # Feature ìƒì„±
        features = create_single_prediction_features_100min(seq_m14b, seq_m10a, seq_m16, seq_totalcnt)
        X_pred = pd.DataFrame([features])
        
        # ì˜ˆì¸¡
        prediction = model.predict(X_pred)[0]
        
        # í™©ê¸ˆ íŒ¨í„´ ê°ì§€
        golden_pattern = (seq_m14b[-1] > 300 and seq_m10a[-1] < 80)
        
        # ìœ„í—˜ êµ¬ê°„ ê°ì§€
        danger_in_seq = np.sum(seq_totalcnt >= 1700) > 0
        
        # ê²°ê³¼ ì €ì¥
        results.append({
            'ì‹œí€€ìŠ¤ì‹œì‘': seq_start_time.strftime('%Y-%m-%d %H:%M'),
            'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
            'ì˜ˆì¸¡ì‹œì ': prediction_time.strftime('%Y-%m-%d %H:%M'),
            'ì‹¤ì œì‹œì ': actual_time.strftime('%Y-%m-%d %H:%M'),
            'ì‹¤ì œê°’': round(actual_value, 2),
            'ì˜ˆì¸¡ê°’': round(prediction, 2),
            'ì˜¤ì°¨': round(actual_value - prediction, 2),
            'ì ˆëŒ€ì˜¤ì°¨': round(abs(actual_value - prediction), 2),
            'ì˜¤ì°¨ìœ¨(%)': round(abs(actual_value - prediction) / max(actual_value, 1) * 100, 2),
            'M14AM14B': round(seq_m14b[-1], 2),
            'M14AM10A': round(seq_m10a[-1], 2),
            'M14AM16': round(seq_m16[-1], 2),
            'ì‹œí€€ìŠ¤TOTALCNT_MAX': round(np.max(seq_totalcnt), 2),
            'ì‹œí€€ìŠ¤TOTALCNT_MIN': round(np.min(seq_totalcnt), 2),
            'ì‹œí€€ìŠ¤TOTALCNT_í‰ê· ': round(np.mean(seq_totalcnt), 2),
            'í™©ê¸ˆíŒ¨í„´': 'O' if golden_pattern else '',
            'ì‹œí€€ìŠ¤ìœ„í—˜': 'O' if danger_in_seq else '',
            'ì‹¤ì œìœ„í—˜(1700+)': 'O' if actual_value >= 1700 else '',
            'ì˜ˆì¸¡ìœ„í—˜(1700+)': 'O' if prediction >= 1650 else ''
        })
        
        # ì§„í–‰ìƒí™©
        if (i - 100) % 1000 == 0:
            progress = (i - 100) / (len(df) - 100) * 100
            print(f"  ì§„í–‰ì¤‘... {i-100}/{len(df)-100} ({progress:.1f}%)")
    
    # DataFrame ë³€í™˜
    results_df = pd.DataFrame(results)
    
    # CSV ì €ì¥
    output_file = 'aasf_evaluation_100min_results.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
    
    # ===== í†µê³„ ë¶„ì„ =====
    print("\n" + "="*80)
    print("ğŸ“Š í‰ê°€ í†µê³„")
    print("="*80)
    print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(results_df):,}ê°œ")
    print(f"í‰ê·  ì ˆëŒ€ ì˜¤ì°¨(MAE): {results_df['ì ˆëŒ€ì˜¤ì°¨'].mean():.2f}")
    print(f"í‰ê·  ì˜¤ì°¨ìœ¨: {results_df['ì˜¤ì°¨ìœ¨(%)'].mean():.2f}%")
    print(f"ìµœëŒ€ ì ˆëŒ€ ì˜¤ì°¨: {results_df['ì ˆëŒ€ì˜¤ì°¨'].max():.2f}")
    print(f"ìµœì†Œ ì ˆëŒ€ ì˜¤ì°¨: {results_df['ì ˆëŒ€ì˜¤ì°¨'].min():.2f}")
    
    print(f"\ní™©ê¸ˆ íŒ¨í„´ ë°œìƒ: {results_df['í™©ê¸ˆíŒ¨í„´'].value_counts().get('O', 0)}ê°œ")
    print(f"ì‹œí€€ìŠ¤ ìœ„í—˜ êµ¬ê°„: {results_df['ì‹œí€€ìŠ¤ìœ„í—˜'].value_counts().get('O', 0)}ê°œ")
    
    # ìœ„í—˜ êµ¬ê°„ ë¶„ì„
    actual_danger = results_df['ì‹¤ì œìœ„í—˜(1700+)'] == 'O'
    pred_danger = results_df['ì˜ˆì¸¡ìœ„í—˜(1700+)'] == 'O'
    
    actual_danger_count = actual_danger.sum()
    pred_danger_count = pred_danger.sum()
    danger_detected = (actual_danger & pred_danger).sum()
    
    print(f"\nâš ï¸ ìœ„í—˜ êµ¬ê°„ ë¶„ì„:")
    print(f"  ì‹¤ì œ ìœ„í—˜(1700+): {actual_danger_count}ê°œ")
    print(f"  ì˜ˆì¸¡ ìœ„í—˜(1650+): {pred_danger_count}ê°œ")
    print(f"  ìœ„í—˜ ê°ì§€ ì„±ê³µ: {danger_detected}ê°œ")
    if actual_danger_count > 0:
        print(f"  ìœ„í—˜ ê°ì§€ìœ¨: {danger_detected/actual_danger_count*100:.1f}%")
    
    # ì˜¤ì°¨ ìƒìœ„ 10ê°œ
    print("\n" + "="*80)
    print("âŒ ì˜¤ì°¨ ìƒìœ„ 10ê°œ êµ¬ê°„")
    print("="*80)
    top_errors = results_df.nlargest(10, 'ì ˆëŒ€ì˜¤ì°¨')
    print(top_errors[['í˜„ì¬ì‹œê°„', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’', 'ì ˆëŒ€ì˜¤ì°¨', 'ì˜¤ì°¨ìœ¨(%)', 'M14AM14B', 'í™©ê¸ˆíŒ¨í„´']].to_string(index=False))
    
    # ìœ„í—˜ êµ¬ê°„ ìƒì„¸
    if actual_danger_count > 0:
        print("\n" + "="*80)
        print("âš ï¸ ì‹¤ì œ ìœ„í—˜(1700+) êµ¬ê°„ ìƒì„¸")
        print("="*80)
        danger_cases = results_df[actual_danger]
        print(f"ì´ {len(danger_cases)}ê°œ")
        print(danger_cases[['í˜„ì¬ì‹œê°„', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’', 'ì ˆëŒ€ì˜¤ì°¨', 'M14AM14B', 'M14AM10A', 'ì˜ˆì¸¡ìœ„í—˜(1700+)']].head(20).to_string(index=False))
    
    # í™©ê¸ˆ íŒ¨í„´ ë¶„ì„
    golden_cases = results_df[results_df['í™©ê¸ˆíŒ¨í„´'] == 'O']
    if len(golden_cases) > 0:
        print("\n" + "="*80)
        print("ğŸ† í™©ê¸ˆ íŒ¨í„´ ë°œìƒ êµ¬ê°„")
        print("="*80)
        print(f"ì´ {len(golden_cases)}ê°œ")
        print(f"í‰ê·  ì‹¤ì œê°’: {golden_cases['ì‹¤ì œê°’'].mean():.2f}")
        print(f"í‰ê·  ì˜ˆì¸¡ê°’: {golden_cases['ì˜ˆì¸¡ê°’'].mean():.2f}")
        print(f"í‰ê·  ì ˆëŒ€ì˜¤ì°¨: {golden_cases['ì ˆëŒ€ì˜¤ì°¨'].mean():.2f}")
        print(golden_cases[['í˜„ì¬ì‹œê°„', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’', 'ì ˆëŒ€ì˜¤ì°¨', 'M14AM14B', 'M14AM10A']].head(10).to_string(index=False))
    
    return results_df

if __name__ == '__main__':
    print("\nğŸš€ 100ë¶„ ì‹œí€€ìŠ¤ ëª¨ë¸ ì‹¤ì‹œê°„ ì˜ˆì¸¡ í‰ê°€ ì‹œì‘...\n")
    results = evaluate_all_predictions()
    
    if results is not None:
        print(f"\nâœ… í‰ê°€ ì™„ë£Œ! ì´ {len(results):,}ê°œ ì˜ˆì¸¡ ìƒì„±")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: aasf_evaluation_100min_results.csv")