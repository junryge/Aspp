#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ› ï¸ í•™ìŠµ ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¦í­ (1:1 ë¹„ìœ¨)
ëª©í‘œ: í•™ìŠµì— í•„ìš”í•œ ì»¬ëŸ¼(Feature)ë§Œ ë”± ë§ì¶°ì„œ ìƒì„±í•˜ê³ , 
      12ì›” 11ì¼ì€ ë²„ë¦¬ê³ , 1700+ ë°ì´í„°ëŠ” ì¦í­í•´ì„œ ì €ì¥í•¨.
"""
import numpy as np
import pandas as pd
import glob
import warnings
warnings.filterwarnings('ignore')

print("="*70)
print("ğŸ›¡ï¸ í•™ìŠµ ë°ì´í„° ìƒì„± (ì»¬ëŸ¼ í†µì¼ + 1:1 ë°¸ëŸ°ì‹±)")
print("="*70)

PRED_OFFSET = 10
EXCLUDE_DATE = '2025-12-11' # ğŸ”´ í‰ê°€ìš© ë‚ ì§œ (í•™ìŠµ ì ˆëŒ€ ì œì™¸)

def load_data(path_pattern):
    print(f"\nğŸ“‚ ì›ë³¸ ë°ì´í„° ë¡œë”© ì¤‘...")
    files = glob.glob(path_pattern)
    if not files: files = glob.glob('M14_Q_*.CSV')
    dfs = []
    for f in sorted(files):
        try: dfs.append(pd.read_csv(f, on_bad_lines='skip', encoding='utf-8'))
        except: dfs.append(pd.read_csv(f, on_bad_lines='skip', encoding='cp949'))
    if not dfs: raise ValueError("íŒŒì¼ ì—†ìŒ")
    return pd.concat(dfs, ignore_index=True)

def create_training_features(df):
    """
    ğŸ”¥ í•™ìŠµ ëª¨ë¸(V11~V14)ì´ ì‚¬ìš©í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì •í™•í•˜ê²Œ ìƒì„±
    """
    df = df.copy()
    
    # 1. ê¸°ë³¸ ì»¬ëŸ¼ (ìˆ«ì ë³€í™˜)
    cols = ['TOTALCNT', 'M14AM14B', 'M14AM14BSUM', 'M10AM14A', 
            'M14.QUE.ALL.TRANSPORT4MINOVERCNT', 'M14.QUE.OHT.OHTUTIL',
            'M14.QUE.ALL.CURRENTQCREATED', 'M14.QUE.ALL.CURRENTQCOMPLETED']
    for c in cols: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
    
    # íŒŒìƒ ë³€ìˆ˜ 1: Gap
    df['Gap'] = df['M14.QUE.ALL.CURRENTQCREATED'] - df['M14.QUE.ALL.CURRENTQCOMPLETED']
    
    # íŒŒìƒ ë³€ìˆ˜ 2: Lag (ê³¼ê±° ë°ì´í„°) - 280ë¶„ê¹Œì§€
    lags = [1, 3, 5, 10, 20, 50, 100, 280]
    for lag in lags:
        df[f'Total_Lag_{lag}'] = df['TOTALCNT'].shift(lag)
        df[f'M14B_Lag_{lag}'] = df['M14AM14B'].shift(lag)
    
    # íŒŒìƒ ë³€ìˆ˜ 3: Rolling (ì´ë™í‰ê· ) - 280ë¶„ê¹Œì§€
    windows = [10, 30, 60, 100, 280]
    for w in windows:
        df[f'Total_Mean_{w}'] = df['TOTALCNT'].rolling(w).mean()
        df[f'Total_Std_{w}'] = df['TOTALCNT'].rolling(w).std()

    # íŒŒìƒ ë³€ìˆ˜ 4: ë³€í™”ëŸ‰ (Slope, Accel)
    df['Slope_1'] = df['TOTALCNT'] - df['TOTALCNT'].shift(1)
    df['Slope_3'] = df['TOTALCNT'] - df['TOTALCNT'].shift(3)
    df['Accel_1'] = df['Slope_1'] - df['Slope_1'].shift(1)

    # ğŸ”¥ íƒ€ê²Ÿ (Target) - í•™ìŠµì˜ ì •ë‹µì§€
    df['Target_Total_Future'] = df['TOTALCNT'].shift(-PRED_OFFSET)
    df['Target_Delta'] = df['Target_Total_Future'] - df['TOTALCNT']
    
    # ê²°ì¸¡ì¹˜ ì œê±° (ì•ë¶€ë¶„ 280ë¶„ + ë’·ë¶€ë¶„ 10ë¶„ì€ ê³„ì‚° ë¶ˆê°€í•˜ë¯€ë¡œ ì‚­ì œ)
    return df.dropna().reset_index(drop=True)

# --- ë©”ì¸ ì‹¤í–‰ ---
if __name__ == '__main__':
    # 1. ë°ì´í„° ë¡œë“œ
    df_raw = load_data('M14_Q_*.CSV')
    
    # 2. ë‚ ì§œ í•„í„°ë§ (12ì›” 11ì¼ ì œê±°)
    # ë‚ ì§œ íŒŒì‹±
    df_raw['datetime'] = pd.to_datetime(df_raw['CURRTIME'].astype(str), format='%Y%m%d%H%M', errors='coerce')
    # 12ì›” 11ì¼ì´ ì•„ë‹Œ ê²ƒë§Œ ë‚¨ê¹€
    mask_train = df_raw['datetime'].dt.date.astype(str) != EXCLUDE_DATE
    df_train_src = df_raw[mask_train].copy()
    
    print(f"ğŸ“‰ í‰ê°€ì¼({EXCLUDE_DATE}) ë°ì´í„° ì‚­ì œ ì™„ë£Œ.")
    
    # 3. í”¼ì²˜ ìƒì„± (í•™ìŠµì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë”±!)
    print("ğŸ”„ í•™ìŠµìš© í”¼ì²˜(280ë¶„ ì‹œí€€ìŠ¤) ìƒì„± ì¤‘...")
    df_features = create_training_features(df_train_src)
    
    # 4. 1:1 ë¹„ìœ¨ ë§ì¶”ê¸° (ë°ì´í„° ì¦í­)
    print("\nâš–ï¸ 1:1 ë¹„ìœ¨ ë°¸ëŸ°ì‹± ì‹œì‘...")
    
    # íƒ€ê²Ÿ(ë¯¸ë˜ê°’) ê¸°ì¤€ìœ¼ë¡œ ê³ ë¶€í•˜/ì •ìƒ ë¶„ë¦¬
    df_high = df_features[df_features['Target_Total_Future'] >= 1700].copy()
    df_normal = df_features[df_features['Target_Total_Future'] < 1700].copy()
    
    cnt_high = len(df_high)
    cnt_normal = len(df_normal)
    
    print(f"   - ì •ìƒ ë°ì´í„°: {cnt_normal:,}ê°œ")
    print(f"   - 1700+ ë°ì´í„°: {cnt_high:,}ê°œ")
    
    if cnt_high > 0:
        # ë¹„ìœ¨ ê³„ì‚° (ì •ìƒ ê°œìˆ˜ / ê³ ë¶€í•˜ ê°œìˆ˜)
        multiplier = int(cnt_normal / cnt_high)
        print(f"   ğŸ”¥ 1700+ ë°ì´í„°ë¥¼ {multiplier}ë°° ë³µì‚¬í•©ë‹ˆë‹¤!")
        
        # ì¦í­ ìˆ˜í–‰
        df_augmented_high = pd.concat([df_high] * multiplier, ignore_index=True)
        
        # í•©ì¹˜ê¸°
        df_balanced = pd.concat([df_normal, df_augmented_high], ignore_index=True)
        
        # ì…”í”Œ (ëœë¤ ì„ê¸° - í•™ìŠµ ì‹œ í•„ìˆ˜)
        df_final = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)
        
        # ê²°ê³¼ í™•ì¸
        final_high_cnt = (df_final['Target_Total_Future'] >= 1700).sum()
        ratio = final_high_cnt / len(df_final) * 100
        
        print(f"\nğŸ“Š ìµœì¢… í•™ìŠµ íŒŒì¼ ì •ë³´")
        print(f"   - íŒŒì¼ëª…: Final_Train_Data_1to1.csv")
        print(f"   - ì´ ë°ì´í„°: {len(df_final):,}ê°œ")
        print(f"   - 1700+ ë¹„ìœ¨: {ratio:.1f}% (ì•½ 50%)")
        
        # 5. ì €ì¥
        df_final.to_csv('Final_Train_Data_1to1.csv', index=False, encoding='utf-8-sig')
        print(f"\nâœ… ì €ì¥ ì™„ë£Œ! ì´ì œ í•™ìŠµ ì½”ë“œì—ì„œ ì´ íŒŒì¼ë§Œ ë¡œë“œí•˜ë©´ ë©ë‹ˆë‹¤.")
        
    else:
        print("âš  1700 ì´ìƒ ë°ì´í„°ê°€ ì—†ì–´ì„œ ì¦í­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")