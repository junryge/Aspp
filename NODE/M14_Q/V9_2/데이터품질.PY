#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ› ï¸ ê³ ë¶€í•˜(Over 1700) í•™ìŠµ ë°ì´í„° ì¶”ì¶œê¸° (V2 - 280ë¶„ ì‹œí€€ìŠ¤ ë°˜ì˜)
ê¸°ëŠ¥: '10ë¶„ ë’¤ 1700 ì´ìƒ'ì´ ë˜ëŠ” ì‹œì ì˜ ë°ì´í„°ë¥¼ 280ë¶„ ê³¼ê±° íë¦„ê¹Œì§€ í¬í•¨í•´ ì¶”ì¶œ
"""
import numpy as np
import pandas as pd
import glob
import warnings
warnings.filterwarnings('ignore')

print("="*70)
print("ğŸ› ï¸ ê³ ë¶€í•˜(1700+) í•™ìŠµ ë°ì´í„° ì¶”ì¶œ (280ë¶„ ì‹œí€€ìŠ¤ & 10ë¶„ ì˜ˆì¸¡)")
print("="*70)

PRED_OFFSET = 10 # 10ë¶„ ë’¤ ì˜ˆì¸¡

def load_data(path_pattern):
    print(f"\nğŸ“‚ ì›ë³¸ ë°ì´í„° ë¡œë”©: {path_pattern}")
    files = glob.glob(path_pattern)
    if not files: 
        print("âš  íŒŒì¼ì´ ì—†ì–´ ê¸°ë³¸ íŒŒì¼(M14_Q_*.CSV)ì„ ì°¾ìŠµë‹ˆë‹¤.")
        files = glob.glob('M14_Q_*.CSV')
    
    dfs = []
    for f in sorted(files):
        try: dfs.append(pd.read_csv(f, on_bad_lines='skip', encoding='utf-8'))
        except: dfs.append(pd.read_csv(f, on_bad_lines='skip', encoding='cp949'))
    
    if not dfs: raise ValueError("âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
    return pd.concat(dfs, ignore_index=True)

def create_vectorized_features(df):
    """280ë¶„ ì‹œí€€ìŠ¤ë¥¼ ë°˜ì˜í•œ í”¼ì²˜ ìƒì„±"""
    df = df.copy()
    cols = ['TOTALCNT', 'M14AM14B', 'M14AM14BSUM', 'M10AM14A', 
            'M14.QUE.ALL.TRANSPORT4MINOVERCNT', 'M14.QUE.OHT.OHTUTIL',
            'M14.QUE.ALL.CURRENTQCREATED', 'M14.QUE.ALL.CURRENTQCOMPLETED']
    for c in cols: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
    
    df['Gap'] = df['M14.QUE.ALL.CURRENTQCREATED'] - df['M14.QUE.ALL.CURRENTQCOMPLETED']
    
    # 1. Lag (ì‹œì°¨ ë³€ìˆ˜)
    # 280ë¶„ ì „ì˜ ìƒíƒœì™€ ë¹„êµí•˜ê¸° ìœ„í•´ Lag 280 ì¶”ê°€
    lags = [1, 3, 5, 10, 20, 50, 100, 280] 
    for lag in lags:
        df[f'Total_Lag_{lag}'] = df['TOTALCNT'].shift(lag)
        df[f'M14B_Lag_{lag}'] = df['M14AM14B'].shift(lag)
    
    # 2. Rolling (ì´ë™í‰ê· ) - 280ë¶„ ì¶”ê°€!
    windows = [10, 30, 60, 100, 280] 
    for w in windows:
        df[f'Total_Mean_{w}'] = df['TOTALCNT'].rolling(w).mean()
        df[f'Total_Std_{w}'] = df['TOTALCNT'].rolling(w).std()

    # 3. ë³€í™”ëŸ‰ (Delta & Slope)
    df['Slope_1'] = df['TOTALCNT'] - df['TOTALCNT'].shift(1)
    df['Slope_3'] = df['TOTALCNT'] - df['TOTALCNT'].shift(3)
    df['Accel_1'] = df['Slope_1'] - df['Slope_1'].shift(1)

    # 4. íƒ€ê²Ÿ (10ë¶„ ë’¤ ë¯¸ë˜ ê°’)
    df['Target_Total_Future'] = df['TOTALCNT'].shift(-PRED_OFFSET)
    
    return df.dropna().reset_index(drop=True)

# --- ë©”ì¸ ì‹¤í–‰ ---
df_raw = load_data('M14_Q_*.CSV')

print("\nğŸ”„ 280ë¶„ ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„± ì¤‘...")
df_features = create_vectorized_features(df_raw)

print("\nğŸ” 1700 ì´ìƒ ê³ ë¶€í•˜ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
# 1700 ì´ìƒì¸ ë°ì´í„°ë§Œ ì¶”ì¶œ
high_load_df = df_features[df_features['Target_Total_Future'] >= 1700].copy()

count = len(high_load_df)
print(f"\nğŸ“Š ì¶”ì¶œ ê²°ê³¼")
print(f"   - 1700+ ë°ì´í„°: {count:,}ê°œ ì¶”ì¶œë¨")

if count > 0:
    outfile = 'High_Load_Training_Data.csv'
    high_load_df.to_csv(outfile, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {outfile}")
    print("   (ì´ íŒŒì¼ì€ 280ë¶„ ì „ì˜ ë°ì´í„°ê¹Œì§€ í¬í•¨í•˜ê³  ìˆì–´ V11.5 í•™ìŠµì— ìµœì ì…ë‹ˆë‹¤)")
else:
    print("\nâš  1700 ì´ìƒì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
