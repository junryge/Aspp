#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ V11.5 í‰ê°€ (ìˆ˜ì •íŒ) - 280ë¶„ ì‹œí€€ìŠ¤ ì§€ì›
ê¸°ëŠ¥: í•™ìŠµ ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” '280ë¶„ ì „ ë°ì´í„°'ê¹Œì§€ ëª¨ë‘ ìƒì„±í•˜ì—¬ ì—ëŸ¬ í•´ê²°
"""
import numpy as np
import pandas as pd
import xgboost as xgb
import pickle
import warnings
from datetime import timedelta
warnings.filterwarnings('ignore')

print("="*70)
print("ğŸš€ V11.5 í‰ê°€ - 280ë¶„ ì‹œí€€ìŠ¤ ë§¤ì¹­ (ì—ëŸ¬ ìˆ˜ì •)")
print("="*70)

PRED_OFFSET = 10
# ğŸ”´ í‰ê°€í•  íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”
EVAL_FILE = '20251211_16í‰ê°€.CSV' 

def create_vectorized_features(df):
    """
    [ìˆ˜ì •] í•™ìŠµ ë•Œ ì‚¬ìš©í•œ '280ë¶„ ì‹œí€€ìŠ¤' í”¼ì²˜ë¥¼ ë˜‘ê°™ì´ ìƒì„±í•©ë‹ˆë‹¤.
    """
    df = df.copy()
    cols = ['TOTALCNT', 'M14AM14B', 'M14AM14BSUM', 'M10AM14A', 
            'M14.QUE.ALL.TRANSPORT4MINOVERCNT', 'M14.QUE.OHT.OHTUTIL',
            'M14.QUE.ALL.CURRENTQCREATED', 'M14.QUE.ALL.CURRENTQCOMPLETED']
    for c in cols: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
    
    df['Gap'] = df['M14.QUE.ALL.CURRENTQCREATED'] - df['M14.QUE.ALL.CURRENTQCOMPLETED']
    
    # ---------------------------------------------------------
    # ğŸ”¥ [ìˆ˜ì • í¬ì¸íŠ¸] í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ 280ê¹Œì§€ í™•ì¥
    # ---------------------------------------------------------
    # ê¸°ì¡´: [1, 3, 5, 10, 20] -> ìˆ˜ì •: [..., 50, 100, 280] ì¶”ê°€
    lags = [1, 3, 5, 10, 20, 50, 100, 280]
    for lag in lags:
        df[f'Total_Lag_{lag}'] = df['TOTALCNT'].shift(lag)
        df[f'M14B_Lag_{lag}'] = df['M14AM14B'].shift(lag)
    
    # ê¸°ì¡´: [10, 30, 60] -> ìˆ˜ì •: [..., 100, 280] ì¶”ê°€
    windows = [10, 30, 60, 100, 280]
    for w in windows:
        df[f'Total_Mean_{w}'] = df['TOTALCNT'].rolling(w).mean()
        df[f'Total_Std_{w}'] = df['TOTALCNT'].rolling(w).std()

    # ë³€í™”ëŸ‰ í”¼ì²˜ (V11.5 í•µì‹¬)
    df['Slope_1'] = df['TOTALCNT'] - df['TOTALCNT'].shift(1)
    df['Slope_3'] = df['TOTALCNT'] - df['TOTALCNT'].shift(3)
    df['Slope_5'] = df['TOTALCNT'] - df['TOTALCNT'].shift(5)
    df['Accel_1'] = df['Slope_1'] - df['Slope_1'].shift(1)

    df['Target_Total_Future'] = df['TOTALCNT'].shift(-PRED_OFFSET)
    return df

# 1. ëª¨ë¸ ë¡œë“œ
print("ğŸ“‚ ëª¨ë¸ ë¡œë”© (model_v11_delta_focused.pkl)...")
try:
    with open('model_v11_delta_focused.pkl', 'rb') as f:
        model = pickle.load(f)
    with open('features_v11_delta_focused.pkl', 'rb') as f:
        feature_cols = pickle.load(f)
except FileNotFoundError:
    print("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! í•™ìŠµ(train_v11_5.py)ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    exit()

# 2. ë°ì´í„° ë¡œë“œ
print(f"ğŸ“‚ í‰ê°€ ë°ì´í„°: {EVAL_FILE}")
try:
    df_raw = pd.read_csv(EVAL_FILE, on_bad_lines='skip', encoding='utf-8')
except:
    df_raw = pd.read_csv(EVAL_FILE, on_bad_lines='skip', encoding='cp949')

df_raw['CURRTIME_OBJ'] = pd.to_datetime(df_raw['CURRTIME'].astype(str), format='%Y%m%d%H%M', errors='coerce')

# 3. í”¼ì²˜ ìƒì„±
print("ğŸ”„ í”¼ì²˜ ìƒì„± ì¤‘ (280ë¶„ ì‹œí€€ìŠ¤ í¬í•¨)...")
df_feat = create_vectorized_features(df_raw)

# ìœ íš¨ ë°ì´í„° í•„í„°ë§
df_valid = df_feat.dropna(subset=feature_cols + ['Target_Total_Future', 'CURRTIME_OBJ']).copy()
print(f"âœ… ìœ íš¨ í‰ê°€ ìƒ˜í”Œ: {len(df_valid):,}ê°œ")

# 4. ì˜ˆì¸¡ ìˆ˜í–‰
print("ğŸš€ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
X_eval = df_valid[feature_cols]

# ë³€í™”ëŸ‰(Delta) ì˜ˆì¸¡
pred_delta = model.predict(X_eval)

# ìµœì¢…ê°’ = í˜„ì¬ê°’ + ì˜ˆì¸¡ëœ ë³€í™”ëŸ‰
pred_total = df_valid['TOTALCNT'] + pred_delta

# 5. ê²°ê³¼ ì •ë¦¬
results = pd.DataFrame()
current_time = df_valid['CURRTIME_OBJ']

results['í˜„ì¬ì‹œê°„'] = current_time.dt.strftime('%Y-%m-%d %H:%M')
results['í˜„ì¬TOTALCNT'] = df_valid['TOTALCNT'].round(2)
results['ì˜ˆì¸¡ì‹œì '] = (current_time + timedelta(minutes=PRED_OFFSET)).dt.strftime('%Y-%m-%d %H:%M')
results['ì‹¤ì œê°’'] = df_valid['Target_Total_Future'].round(2)
results['ì˜ˆì¸¡ê°’'] = pred_total.round(2)
results['ì˜ˆì¸¡Delta'] = pred_delta.round(2)
results['ì‹¤ì œDelta'] = (results['ì‹¤ì œê°’'] - results['í˜„ì¬TOTALCNT']).round(2)
results['ì˜¤ì°¨'] = (results['ì‹¤ì œê°’'] - results['ì˜ˆì¸¡ê°’']).round(2)
results['ì ˆëŒ€ì˜¤ì°¨'] = results['ì˜¤ì°¨'].abs()

# ìœ„í—˜ ê°ì§€ ì—¬ë¶€ (1650 ê¸°ì¤€)
results['ì‹¤ì œìœ„í—˜'] = np.where(results['ì‹¤ì œê°’'] >= 1700, 'O', '')
results['ì˜ˆì¸¡ìœ„í—˜'] = np.where(results['ì˜ˆì¸¡ê°’'] >= 1650, 'O', '')

# 6. í†µê³„ ì¶œë ¥
mae = results['ì ˆëŒ€ì˜¤ì°¨'].mean()
print(f"\nğŸ“Š ì „ì²´ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE): {mae:.2f}")

high_val_mask = results['ì‹¤ì œê°’'] >= 1650
if high_val_mask.sum() > 0:
    mae_high = results.loc[high_val_mask, 'ì ˆëŒ€ì˜¤ì°¨'].mean()
    acc_high = (results.loc[high_val_mask, 'ì ˆëŒ€ì˜¤ì°¨'] <= 20).mean() * 100
    print(f"ğŸ”¥ ê³ ë¶€í•˜ êµ¬ê°„(>=1650) MAE: {mae_high:.2f}")
    print(f"ğŸ”¥ ê³ ë¶€í•˜ êµ¬ê°„ ì •í™•ë„(Â±20): {acc_high:.1f}%")
    
    # ë³€í™”ëŸ‰ ì˜ˆì¸¡ë ¥ ì²´í¬
    print("\n[ë³€í™”ëŸ‰(Delta) ì˜ˆì¸¡ ìƒ˜í”Œ]")
    print(results.loc[high_val_mask, ['í˜„ì¬ì‹œê°„', 'í˜„ì¬TOTALCNT', 'ì˜ˆì¸¡Delta', 'ì‹¤ì œDelta', 'ì˜ˆì¸¡ê°’', 'ì‹¤ì œê°’']].head().to_string(index=False))

# CSV ì €ì¥
outfile = 'Evaluation_Result_V11_5.CSV'
results.to_csv(outfile, index=False, encoding='utf-8-sig')
print(f"\nğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {outfile}")
