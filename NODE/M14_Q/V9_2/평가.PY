#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ V13 í‰ê°€: ê°’ ì˜ˆì¸¡(Regression) ê²°ê³¼ ì¶œë ¥
ê¸°ëŠ¥: ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ 10ë¶„ ë’¤ ì˜ˆìƒ ìµœëŒ€ê°’ì„ ìˆ«ìë¡œ í‘œê¸°
"""

import pandas as pd
import numpy as np
import xgboost as xgb
import pickle
from datetime import timedelta
import warnings

warnings.filterwarnings('ignore')

# ============================================
# âš™ï¸ ì„¤ì •
# ============================================
EVAL_FILE = "UF09.CSV"    # í‰ê°€ íŒŒì¼
PRED_MINUTES = 10         # 10ë¶„ ì˜ˆì§€
DANGER_LEVEL = 1700       # ì´ ê°’ì„ ë„˜ìœ¼ë©´ 'ìœ„í—˜' í‘œì‹œ (ì°¸ê³ ìš©)

# íŒŒì¼ ì»¬ëŸ¼ëª… (í•™ìŠµê³¼ ë™ì¼)
COL_TIME  = 'CURRTIME'
COL_TOTAL = 'TOTALCNT'
COL_M14B  = 'M14AM14B'
COL_SUM   = 'M14AM14BSUM'
COL_Q_CR  = 'M14.QUE.ALL.CURRENTQCREATED'
COL_Q_CP  = 'M14.QUE.ALL.CURRENTQCOMPLETED'

print("="*70)
print(f"ğŸš€ V13 ìˆ«ì ì˜ˆì¸¡ í‰ê°€: {EVAL_FILE}")
print("="*70)

def create_features(df):
    df = df.copy()
    if COL_TIME in df.columns:
        df[COL_TIME] = pd.to_datetime(df[COL_TIME].astype(str), format='%Y%m%d%H%M', errors='coerce')

    df['Queue_Gap'] = df[COL_Q_CR] - df[COL_Q_CP]
    
    for gap in [1, 3, 5, 10]:
        df[f'Vel_Total_{gap}m'] = df[COL_TOTAL].diff(gap)
        df[f'Vel_Gap_{gap}m'] = df['Queue_Gap'].diff(gap)
        df[f'Vel_M14B_{gap}m'] = df[COL_M14B].diff(gap)
    
    df['Acc_Total'] = df['Vel_Total_3m'].diff(1)
    df['Vol_Total_10m'] = df[COL_TOTAL].rolling(10).std()
    df['Triple_Score'] = (df[COL_M14B]/500) + (df[COL_SUM]/600) + (df['Queue_Gap']/200)
    
    return df

def evaluate():
    try:
        with open('model_v13_reg.pkl', 'rb') as f: model = pickle.load(f)
        with open('features_v13_reg.pkl', 'rb') as f: features = pickle.load(f)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
    except FileNotFoundError:
        print("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. train_v13_reg.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    print("ğŸ”„ í‰ê°€ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
    df = pd.read_csv(EVAL_FILE, on_bad_lines='skip')
    df = create_features(df)
    
    # ì •ë‹µì§€ (ê²€ì¦ìš© ì‹¤ì œ ë¯¸ë˜ê°’)
    indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=PRED_MINUTES)
    df['Real_Future_Max'] = df[COL_TOTAL].rolling(window=indexer).max().shift(-1)
    
    # í‰ê°€ ë°ì´í„°ì…‹
    df_eval = df.dropna(subset=features + ['Real_Future_Max']).reset_index(drop=True)
    
    # ğŸ¯ ì˜ˆì¸¡ ì‹¤í–‰ (ìƒìŠ¹í­ ì˜ˆì¸¡)
    pred_delta = model.predict(df_eval[features])
    
    # ìµœì¢… ì˜ˆì¸¡ê°’ = í˜„ì¬ê°’ + ì˜ˆì¸¡ëœ ìƒìŠ¹í­
    df_eval['Pred_Future_Max'] = df_eval[COL_TOTAL] + pred_delta
    
    # ê²°ê³¼ ì •ë¦¬
    results = pd.DataFrame()
    results['ì‹œê°„'] = df_eval[COL_TIME]
    results['í˜„ì¬ê°’'] = df_eval[COL_TOTAL]
    
    # ğŸ”¥ ì‚¬ìš©ì ìš”ì²­: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ë¹„êµ
    results['ì‹¤ì œ_MAX'] = df_eval['Real_Future_Max']      # ì‹¤ì œ 10ë¶„ë‚´ ìµœëŒ€ê°’
    results['ì˜ˆì¸¡_MAX'] = df_eval['Pred_Future_Max'].round(1) # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’
    
    # ì˜¤ì°¨ (ì‹¤ì œ - ì˜ˆì¸¡)
    results['ì˜¤ì°¨'] = (results['ì‹¤ì œ_MAX'] - results['ì˜ˆì¸¡_MAX']).round(1)
    
    # 1700 ë„˜ëŠ”ì§€ ì—¬ë¶€ (O/X)
    results['ì‹¤ì œ_1700+'] = np.where(results['ì‹¤ì œ_MAX'] >= DANGER_LEVEL, 'O', '')
    results['ì˜ˆì¸¡_1700+'] = np.where(results['ì˜ˆì¸¡_MAX'] >= DANGER_LEVEL, 'O', '')

    # ì£¼ìš” Feature í™•ì¸ìš©
    results['M14B'] = df_eval[COL_M14B]
    results['Gap'] = df_eval['Queue_Gap']
    
    # íŒŒì¼ ì €ì¥
    results.to_csv("eval_result_v13.csv", index=False, encoding='utf-8-sig')
    print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: eval_result_v13.csv")
    print("   (ëª¨ë“  í–‰ì— ì˜ˆì¸¡ê°’ì´ ê¸°ì…ë˜ì—ˆìŠµë‹ˆë‹¤)")
    
    # ê°„ë‹¨ í†µê³„
    mae = np.mean(np.abs(results['ì˜¤ì°¨']))
    print("\n" + "="*50)
    print(f"ğŸ“Š ì˜ˆì¸¡ ì„±ëŠ¥ ìš”ì•½")
    print(f"   í‰ê·  ì˜¤ì°¨(MAE): {mae:.1f}")
    print(f"   (ì˜ˆ: ì‹¤ì œê°€ 1700ì¼ ë•Œ, ì˜ˆì¸¡ì€ {1700-mae:.0f} ~ {1700+mae:.0f} ì‚¬ì´)")

if __name__ == "__main__":
    evaluate()
