#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ðŸš€ V11.5 í‰ê°€ - 280ë¶„ ì‹œí€€ìŠ¤ & 10ë¶„ ì˜ˆì¸¡ (ìˆ˜ì •ë¨)
"""
import numpy as np
import pandas as pd
import xgboost as xgb
import pickle
import warnings
from datetime import timedelta
warnings.filterwarnings('ignore')

print("="*70)
print("ðŸš€ V11.5 í‰ê°€ - 280ë¶„ ì‹œí€€ìŠ¤ / 10ë¶„ ì˜ˆì¸¡")
print("="*70)

PRED_OFFSET = 10
EVAL_FILE = '20251211_16í‰ê°€.CSV'

def create_vectorized_features(df):
    """í•™ìŠµê³¼ ë™ì¼í•œ 280ë¶„ ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„±"""
    df = df.copy()
    
    cols = ['TOTALCNT', 'M14AM14B', 'M14AM14BSUM', 'M10AM14A', 
            'M14.QUE.ALL.TRANSPORT4MINOVERCNT', 'M14.QUE.OHT.OHTUTIL',
            'M14.QUE.ALL.CURRENTQCREATED', 'M14.QUE.ALL.CURRENTQCOMPLETED']
    for c in cols: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
    
    df['Gap'] = df['M14.QUE.ALL.CURRENTQCREATED'] - df['M14.QUE.ALL.CURRENTQCOMPLETED']
    
    # ðŸ”¥ [ìˆ˜ì •] 280ë¶„ê¹Œì§€ í™•ìž¥
    lags = [1, 3, 5, 10, 20, 50, 100, 280]
    for lag in lags:
        df[f'Total_Lag_{lag}'] = df['TOTALCNT'].shift(lag)
        df[f'M14B_Lag_{lag}'] = df['M14AM14B'].shift(lag)
    
    # ðŸ”¥ [ìˆ˜ì •] 280ë¶„ê¹Œì§€ í™•ìž¥
    windows = [10, 30, 60, 100, 280]
    for w in windows:
        df[f'Total_Mean_{w}'] = df['TOTALCNT'].rolling(w).mean()
        df[f'Total_Std_{w}'] = df['TOTALCNT'].rolling(w).std()

    # ë³€í™”ëŸ‰
    df['Slope_1'] = df['TOTALCNT'] - df['TOTALCNT'].shift(1)
    df['Slope_3'] = df['TOTALCNT'] - df['TOTALCNT'].shift(3)
    df['Accel_1'] = df['Slope_1'] - df['Slope_1'].shift(1)
    df['Total_Delta_10'] = df['TOTALCNT'] - df['Total_Lag_10']

    # íƒ€ê²Ÿ
    df['Target_Total_Future'] = df['TOTALCNT'].shift(-PRED_OFFSET)
    return df

# 1. ëª¨ë¸ ë¡œë“œ
print("ðŸ“‚ ëª¨ë¸ ë¡œë”© (model_v11_280seq.pkl)...")
try:
    with open('model_v11_280seq.pkl', 'rb') as f:
        model_base = pickle.load(f)
    with open('features_v11_280seq.pkl', 'rb') as f:
        feature_cols = pickle.load(f)
except FileNotFoundError:
    print("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# 2. ë°ì´í„° ë¡œë“œ
print(f"ðŸ“‚ í‰ê°€ ë°ì´í„°: {EVAL_FILE}")
try:
    df_raw = pd.read_csv(EVAL_FILE, on_bad_lines='skip', encoding='utf-8')
except:
    df_raw = pd.read_csv(EVAL_FILE, on_bad_lines='skip', encoding='cp949')

df_raw['CURRTIME_OBJ'] = pd.to_datetime(df_raw['CURRTIME'].astype(str), format='%Y%m%d%H%M', errors='coerce')

# 3. í”¼ì²˜ ìƒì„±
print("ðŸ”„ 280ë¶„ ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„± ì¤‘...")
df_feat = create_vectorized_features(df_raw)
df_valid = df_feat.dropna(subset=feature_cols + ['Target_Total_Future']).copy()

print(f"âœ… ìœ íš¨ ìƒ˜í”Œ: {len(df_valid):,}ê°œ")
X_eval = df_valid[feature_cols]
y_true = df_valid['Target_Total_Future']
current_total = df_valid['TOTALCNT']

# 4. ì˜ˆì¸¡ (ë³€í™”ëŸ‰)
pred_delta = model_base.predict(X_eval)
pred_total = current_total + pred_delta

# 5. ê²°ê³¼ ì €ìž¥
results = pd.DataFrame()
results['í˜„ìž¬ì‹œê°„'] = df_valid['CURRTIME_OBJ'].dt.strftime('%Y-%m-%d %H:%M')
results['í˜„ìž¬ê°’'] = current_total.round(2)
results['ì˜ˆì¸¡ì‹œì '] = (df_valid['CURRTIME_OBJ'] + timedelta(minutes=PRED_OFFSET)).dt.strftime('%Y-%m-%d %H:%M')
results['ì‹¤ì œê°’'] = y_true.round(2)
results['ì˜ˆì¸¡ê°’'] = pred_total.round(2)
results['ì˜¤ì°¨'] = (results['ì‹¤ì œê°’'] - results['ì˜ˆì¸¡ê°’']).round(2)
results['ì ˆëŒ€ì˜¤ì°¨'] = results['ì˜¤ì°¨'].abs()

# í†µê³„
mae = results['ì ˆëŒ€ì˜¤ì°¨'].mean()
print(f"\nðŸ“Š ì „ì²´ MAE: {mae:.2f}")

high_val_mask = results['ì‹¤ì œê°’'] >= 1650
if high_val_mask.sum() > 0:
    mae_high = results.loc[high_val_mask, 'ì ˆëŒ€ì˜¤ì°¨'].mean()
    print(f"ðŸ”¥ ê³ ë¶€í•˜(>=1650) MAE: {mae_high:.2f}")

# CSV ì €ìž¥
outfile = 'Evaluation_Result_V11_280seq.CSV'
results.to_csv(outfile, index=False, encoding='utf-8-sig')
print(f"\nðŸ’¾ ì €ìž¥ ì™„ë£Œ: {outfile}")