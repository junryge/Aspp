#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ V12.2 í‰ê°€ - ê²°ê³¼ ìƒì„¸ ì €ì¥ ë° êµ¬ê°„ ë¶„ì„
íŠ¹ì§•: Load_Categoryë³„ ì˜¤ì°¨ ë¶„ì„ + ì—‘ì…€ìš© ìƒì„¸ ê²°ê³¼ íŒŒì¼ ìƒì„±
"""
import numpy as np
import pandas as pd
import xgboost as xgb
import pickle
import warnings
from datetime import timedelta
warnings.filterwarnings('ignore')

print("="*70)
print("ğŸš€ V12.2 í‰ê°€ - ê²°ê³¼ ìƒì„¸ ì €ì¥ ë° êµ¬ê°„ ë¶„ì„")
print("="*70)

PRED_OFFSET = 10
EVAL_FILE = '20251211_16í‰ê°€.CSV'  # ğŸ”´ í‰ê°€í•  íŒŒì¼ëª…ì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”

# --- êµ¬ê°„ ë¶„ë¥˜ í•¨ìˆ˜ (í‰ê°€ í†µê³„ìš©) ---
def get_load_category(cnt):
    if cnt <= 1200: return 'Under_1200'
    elif 1200 < cnt <= 1300: return '1200_1300'
    elif 1300 < cnt <= 1400: return '1300_1400'
    elif 1400 < cnt <= 1500: return '1400_1500'
    elif 1500 < cnt <= 1600: return '1500_1600'
    elif 1600 < cnt < 1700: return '1600_1700'
    else: return 'Over_1700'

def create_vectorized_features(df):
    """í•™ìŠµê³¼ ë™ì¼í•œ í”¼ì²˜ ìƒì„±"""
    df = df.copy()
    cols = ['TOTALCNT', 'M14AM14B', 'M14AM14BSUM', 'M10AM14A', 
            'M14.QUE.ALL.TRANSPORT4MINOVERCNT', 'M14.QUE.OHT.OHTUTIL',
            'M14.QUE.ALL.CURRENTQCREATED', 'M14.QUE.ALL.CURRENTQCOMPLETED']
    for c in cols:
        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
        
    df['Gap'] = df['M14.QUE.ALL.CURRENTQCREATED'] - df['M14.QUE.ALL.CURRENTQCOMPLETED']
    
    lags = [1, 3, 5, 10, 20, 50, 100, 200, 280]
    for lag in lags:
        df[f'Total_Lag_{lag}'] = df['TOTALCNT'].shift(lag)
        df[f'M14B_Lag_{lag}'] = df['M14AM14B'].shift(lag)
        df[f'Sum_Lag_{lag}'] = df['M14AM14BSUM'].shift(lag)
        df[f'Gap_Lag_{lag}'] = df['Gap'].shift(lag)

    windows = [10, 30, 60, 100, 200, 280]
    for w in windows:
        df[f'Total_Mean_{w}'] = df['TOTALCNT'].rolling(w).mean()
        df[f'Total_Std_{w}'] = df['TOTALCNT'].rolling(w).std()
        df[f'M14B_Mean_{w}'] = df['M14AM14B'].rolling(w).mean()
        df[f'Gap_Mean_{w}'] = df['Gap'].rolling(w).mean()

    df['Slope_1'] = df['TOTALCNT'] - df['TOTALCNT'].shift(1)
    df['Slope_3'] = df['TOTALCNT'] - df['TOTALCNT'].shift(3)
    df['Slope_10'] = df['TOTALCNT'] - df['TOTALCNT'].shift(10)
        
    df['Target_Total_Future'] = df['TOTALCNT'].shift(-PRED_OFFSET)
    return df

# 1. ëª¨ë¸ ë° í”¼ì²˜ ë¡œë“œ
print("ğŸ“‚ ëª¨ë¸ ë¡œë”© (model_v12_weighted.pkl)...")
try:
    with open('model_v12_weighted.pkl', 'rb') as f:
        model = pickle.load(f)
    with open('features_v12_weighted.pkl', 'rb') as f:
        feature_cols = pickle.load(f)
except FileNotFoundError:
    print("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! í•™ìŠµ(train_v12_2.py)ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    exit()

# 2. í‰ê°€ ë°ì´í„° ë¡œë“œ
print(f"ğŸ“‚ í‰ê°€ ë°ì´í„° ë¡œë”©: {EVAL_FILE}")
try:
    df_raw = pd.read_csv(EVAL_FILE, on_bad_lines='skip', encoding='utf-8')
except:
    df_raw = pd.read_csv(EVAL_FILE, on_bad_lines='skip', encoding='cp949')

# ì‹œê°„ íŒŒì‹±
df_raw['CURRTIME_OBJ'] = pd.to_datetime(df_raw['CURRTIME'].astype(str), format='%Y%m%d%H%M', errors='coerce')

# 3. í”¼ì²˜ ìƒì„±
print("ğŸ”„ í”¼ì²˜ ìƒì„± ì¤‘...")
df_feat = create_vectorized_features(df_raw)

# ìœ íš¨ ë°ì´í„° í•„í„°ë§
df_valid = df_feat.dropna(subset=feature_cols + ['Target_Total_Future', 'CURRTIME_OBJ']).copy()
print(f"âœ… ìœ íš¨ í‰ê°€ ìƒ˜í”Œ: {len(df_valid):,}ê°œ")

# 4. ì˜ˆì¸¡ ìˆ˜í–‰
print("ğŸš€ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
X_eval = df_valid[feature_cols]
pred_delta = model.predict(X_eval)
pred_total = df_valid['TOTALCNT'] + pred_delta

# -------------------------------------------------------------
# 5. ìƒì„¸ ê²°ê³¼ ì €ì¥ (Results DataFrame)
# -------------------------------------------------------------
results = pd.DataFrame()
current_time = df_valid['CURRTIME_OBJ']

results['í˜„ì¬ì‹œê°„'] = current_time.dt.strftime('%Y-%m-%d %H:%M')
results['í˜„ì¬TOTALCNT'] = df_valid['TOTALCNT'].round(2)
results['ì˜ˆì¸¡ì‹œì '] = (current_time + timedelta(minutes=PRED_OFFSET)).dt.strftime('%Y-%m-%d %H:%M')
results['ì‹¤ì œê°’'] = df_valid['Target_Total_Future'].round(2)
results['ì˜ˆì¸¡ê°’'] = pred_total.round(2)
results['ì˜¤ì°¨'] = (results['ì‹¤ì œê°’'] - results['ì˜ˆì¸¡ê°’']).round(2)
results['ì ˆëŒ€ì˜¤ì°¨'] = (results['ì˜¤ì°¨'].abs()).round(2)

# ë³´ì¡° ì§€í‘œ
results['M14AM14B'] = df_valid['M14AM14B']
results['M14AM14BSUM'] = df_valid['M14AM14BSUM']
results['queue_gap'] = df_valid['Gap']
results['TRANSPORT'] = df_valid['M14.QUE.ALL.TRANSPORT4MINOVERCNT']

# ìœ„í—˜ ì—¬ë¶€ (O/X) - 1650 ê¸°ì¤€ ì ìš© (íŠœë‹)
results['ì‹¤ì œìœ„í—˜'] = np.where(results['ì‹¤ì œê°’'] >= 1700, 'O', '')
results['ì˜ˆì¸¡ìœ„í—˜'] = np.where(results['ì˜ˆì¸¡ê°’'] >= 1650, 'O', '')  # â­ï¸ ì˜ˆì¸¡ì€ 1650ìœ¼ë¡œ ê¸°ì¤€ ì™„í™”

# í†µê³„ìš© êµ¬ê°„ ì •ë³´
results['Load_Category'] = results['ì‹¤ì œê°’'].apply(get_load_category)

# -------------------------------------------------------------
# 6. ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥
# -------------------------------------------------------------
print("\nğŸ“Š [êµ¬ê°„ë³„ ì˜ˆì¸¡ ì„±ëŠ¥ ë¶„ì„]")
print("-" * 65)
print(f"{'Category':<15} | {'Count':<8} | {'MAE (ì˜¤ì°¨)':<10} | {'RMSE':<10}")
print("-" * 65)

categories = ['Under_1200', '1200_1300', '1300_1400', '1400_1500', '1500_1600', '1600_1700', 'Over_1700']

total_mae = results['ì ˆëŒ€ì˜¤ì°¨'].mean()
print(f"{'TOTAL (ì „ì²´)':<15} | {len(results):<8} | {total_mae:<10.2f} | -")
print("-" * 65)

for cat in categories:
    subset = results[results['Load_Category'] == cat]
    if len(subset) > 0:
        mae = subset['ì ˆëŒ€ì˜¤ì°¨'].mean()
        rmse = np.sqrt((subset['ì˜¤ì°¨']**2).mean())
        print(f"{cat:<15} | {len(subset):<8} | {mae:<10.2f} | {rmse:<10.2f}")
    else:
        print(f"{cat:<15} | {'0':<8} | {'-':<10} | -")
print("-" * 65)

# Over_1700 ìƒì„¸
over_1700 = results[results['Load_Category'] == 'Over_1700']
if len(over_1700) > 0:
    acc = (over_1700['ì ˆëŒ€ì˜¤ì°¨'] <= 20).mean() * 100
    print(f"\nğŸ”¥ [Over_1700 êµ¬ê°„ ìƒì„¸]")
    print(f"   - ìƒ˜í”Œ ìˆ˜: {len(over_1700)}ê°œ")
    print(f"   - í‰ê·  ì˜¤ì°¨: {over_1700['ì ˆëŒ€ì˜¤ì°¨'].mean():.2f}")
    print(f"   - Â±20 ì´ë‚´ ì •í™•ë„: {acc:.1f}%")

# CSV ì €ì¥
outfile = 'Evaluation_Result_Weighted.CSV'
results.to_csv(outfile, index=False, encoding='utf-8-sig')
print(f"\nğŸ’¾ ìƒì„¸ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {outfile}")
