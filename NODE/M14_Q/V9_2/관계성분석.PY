#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“Š AMHS ì „ì²´ ì»¬ëŸ¼ vs TOTALCNT ê´€ê³„ì„± ë¶„ì„
- ìƒê´€ê³„ìˆ˜ (Pearson, Spearman)
- ê¸°ë³¸ í†µê³„ëŸ‰
- ê²°ì¸¡ì¹˜/ì´ìƒì¹˜ ë¶„ì„
- ì‹œê°í™”
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
import os
from datetime import datetime

warnings.filterwarnings('ignore')
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

print("="*80)
print("ğŸ“Š AMHS ì „ì²´ ì»¬ëŸ¼ vs TOTALCNT ê´€ê³„ì„± ë¶„ì„")
print("="*80)

# ========================================
# 1. ë°ì´í„° ë¡œë“œ
# ========================================
def load_data(file_path):
    """CSV íŒŒì¼ ë¡œë“œ"""
    print(f"\nğŸ“‚ ë°ì´í„° ë¡œë“œ: {file_path}")
    
    if not os.path.exists(file_path):
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {file_path}")
        return None
    
    df = pd.read_csv(file_path, on_bad_lines='skip')
    print(f"âœ… {len(df):,}í–‰ Ã— {df.shape[1]}ì—´")
    
    return df

# ========================================
# 2. ê¸°ë³¸ ì •ë³´ ë¶„ì„
# ========================================
def basic_info(df):
    """ê¸°ë³¸ ì •ë³´ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ“‹ ê¸°ë³¸ ì •ë³´")
    print("="*80)
    
    print(f"\nì´ ì»¬ëŸ¼ ìˆ˜: {df.shape[1]}")
    print(f"ì´ í–‰ ìˆ˜: {len(df):,}")
    
    # ì»¬ëŸ¼ íƒ€ì…ë³„ ê°œìˆ˜
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    object_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    print(f"\nìˆ˜ì¹˜í˜• ì»¬ëŸ¼: {len(numeric_cols)}ê°œ")
    print(f"ë¬¸ìí˜• ì»¬ëŸ¼: {len(object_cols)}ê°œ")
    
    if 'CURRTIME' in object_cols:
        object_cols.remove('CURRTIME')
    
    return numeric_cols, object_cols

# ========================================
# 3. ê²°ì¸¡ì¹˜ ë¶„ì„
# ========================================
def missing_analysis(df, numeric_cols):
    """ê²°ì¸¡ì¹˜ ë¶„ì„"""
    print("\n" + "="*80)
    print("ğŸ” ê²°ì¸¡ì¹˜ ë¶„ì„")
    print("="*80)
    
    missing_info = []
    
    for col in numeric_cols:
        missing_count = df[col].isna().sum()
        missing_pct = missing_count / len(df) * 100
        zero_count = (df[col] == 0).sum()
        zero_pct = zero_count / len(df) * 100
        
        missing_info.append({
            'ì»¬ëŸ¼': col,
            'ê²°ì¸¡ìˆ˜': missing_count,
            'ê²°ì¸¡ë¥ (%)': round(missing_pct, 2),
            '0ê°’ìˆ˜': zero_count,
            '0ê°’ë¹„ìœ¨(%)': round(zero_pct, 2)
        })
    
    df_missing = pd.DataFrame(missing_info)
    df_missing = df_missing.sort_values('ê²°ì¸¡ë¥ (%)', ascending=False)
    
    # ê²°ì¸¡ì¹˜ ìˆëŠ” ì»¬ëŸ¼ë§Œ ì¶œë ¥
    has_missing = df_missing[df_missing['ê²°ì¸¡ë¥ (%)'] > 0]
    if len(has_missing) > 0:
        print(f"\nâš ï¸ ê²°ì¸¡ì¹˜ ìˆëŠ” ì»¬ëŸ¼: {len(has_missing)}ê°œ")
        print(has_missing.to_string(index=False))
    else:
        print("\nâœ… ê²°ì¸¡ì¹˜ ì—†ìŒ!")
    
    # 0ê°’ ë¹„ìœ¨ ë†’ì€ ì»¬ëŸ¼
    high_zero = df_missing[df_missing['0ê°’ë¹„ìœ¨(%)'] > 50]
    if len(high_zero) > 0:
        print(f"\nâš ï¸ 0ê°’ 50% ì´ìƒ ì»¬ëŸ¼: {len(high_zero)}ê°œ")
        print(high_zero[['ì»¬ëŸ¼', '0ê°’ìˆ˜', '0ê°’ë¹„ìœ¨(%)']].head(20).to_string(index=False))
    
    return df_missing

# ========================================
# 4. ìƒê´€ê´€ê³„ ë¶„ì„ (í•µì‹¬!)
# ========================================
def correlation_analysis(df, numeric_cols, target='TOTALCNT'):
    """TOTALCNTì™€ ì „ì²´ ì»¬ëŸ¼ ìƒê´€ê´€ê³„ ë¶„ì„"""
    print("\n" + "="*80)
    print(f"ğŸ“ˆ {target}ì™€ ì „ì²´ ì»¬ëŸ¼ ìƒê´€ê´€ê³„ ë¶„ì„")
    print("="*80)
    
    if target not in df.columns:
        print(f"âŒ íƒ€ê²Ÿ ì»¬ëŸ¼ ì—†ìŒ: {target}")
        return None
    
    # ë¶„ì„í•  ì»¬ëŸ¼ (íƒ€ê²Ÿ ì œì™¸)
    analysis_cols = [c for c in numeric_cols if c != target]
    
    correlation_results = []
    
    for col in analysis_cols:
        try:
            # NaN ì œê±°
            valid_mask = ~(df[col].isna() | df[target].isna())
            x = df.loc[valid_mask, col]
            y = df.loc[valid_mask, target]
            
            if len(x) < 10:
                continue
            
            # Pearson ìƒê´€ê³„ìˆ˜
            pearson_corr, pearson_p = stats.pearsonr(x, y)
            
            # Spearman ìƒê´€ê³„ìˆ˜ (ë¹„ì„ í˜• ê´€ê³„ í¬ì°©)
            spearman_corr, spearman_p = stats.spearmanr(x, y)
            
            # ê¸°ë³¸ í†µê³„
            col_mean = x.mean()
            col_std = x.std()
            col_min = x.min()
            col_max = x.max()
            
            correlation_results.append({
                'ì»¬ëŸ¼': col,
                'Pearson': round(pearson_corr, 4),
                'Pearson_P': round(pearson_p, 6),
                'Spearman': round(spearman_corr, 4),
                'Spearman_P': round(spearman_p, 6),
                'í‰ê· ': round(col_mean, 2),
                'í‘œì¤€í¸ì°¨': round(col_std, 2),
                'ìµœì†Œ': round(col_min, 2),
                'ìµœëŒ€': round(col_max, 2),
                'ìœ íš¨ë°ì´í„°': len(x)
            })
            
        except Exception as e:
            print(f"  âš ï¸ {col}: {e}")
    
    df_corr = pd.DataFrame(correlation_results)
    
    # ì ˆëŒ€ê°’ ê¸°ì¤€ ì •ë ¬
    df_corr['Pearson_abs'] = df_corr['Pearson'].abs()
    df_corr['Spearman_abs'] = df_corr['Spearman'].abs()
    df_corr = df_corr.sort_values('Pearson_abs', ascending=False)
    
    print(f"\nğŸ“Š ë¶„ì„ ì™„ë£Œ: {len(df_corr)}ê°œ ì»¬ëŸ¼")
    
    return df_corr

# ========================================
# 5. ìƒê´€ê´€ê³„ ë“±ê¸‰ ë¶„ë¥˜
# ========================================
def classify_correlation(df_corr):
    """ìƒê´€ê´€ê³„ ê°•ë„ë³„ ë¶„ë¥˜"""
    print("\n" + "="*80)
    print("ğŸ† ìƒê´€ê´€ê³„ ê°•ë„ë³„ ë¶„ë¥˜")
    print("="*80)
    
    # ë“±ê¸‰ ë¶„ë¥˜
    very_strong = df_corr[df_corr['Pearson_abs'] >= 0.8]
    strong = df_corr[(df_corr['Pearson_abs'] >= 0.6) & (df_corr['Pearson_abs'] < 0.8)]
    moderate = df_corr[(df_corr['Pearson_abs'] >= 0.4) & (df_corr['Pearson_abs'] < 0.6)]
    weak = df_corr[(df_corr['Pearson_abs'] >= 0.2) & (df_corr['Pearson_abs'] < 0.4)]
    very_weak = df_corr[df_corr['Pearson_abs'] < 0.2]
    
    print(f"\nğŸ”´ ë§¤ìš° ê°•í•¨ (|r| â‰¥ 0.8): {len(very_strong)}ê°œ")
    if len(very_strong) > 0:
        print(very_strong[['ì»¬ëŸ¼', 'Pearson', 'Spearman']].to_string(index=False))
    
    print(f"\nğŸŸ  ê°•í•¨ (0.6 â‰¤ |r| < 0.8): {len(strong)}ê°œ")
    if len(strong) > 0:
        print(strong[['ì»¬ëŸ¼', 'Pearson', 'Spearman']].to_string(index=False))
    
    print(f"\nğŸŸ¡ ì¤‘ê°„ (0.4 â‰¤ |r| < 0.6): {len(moderate)}ê°œ")
    if len(moderate) > 0:
        print(moderate[['ì»¬ëŸ¼', 'Pearson', 'Spearman']].to_string(index=False))
    
    print(f"\nğŸŸ¢ ì•½í•¨ (0.2 â‰¤ |r| < 0.4): {len(weak)}ê°œ")
    if len(weak) > 0:
        print(weak[['ì»¬ëŸ¼', 'Pearson', 'Spearman']].head(20).to_string(index=False))
    
    print(f"\nâšª ë§¤ìš° ì•½í•¨ (|r| < 0.2): {len(very_weak)}ê°œ")
    
    return {
        'very_strong': very_strong,
        'strong': strong,
        'moderate': moderate,
        'weak': weak,
        'very_weak': very_weak
    }

# ========================================
# 6. ë°ì´í„° ëˆ„ìˆ˜ ìœ„í—˜ ì»¬ëŸ¼ íƒì§€
# ========================================
def detect_leakage_risk(df_corr, threshold=0.95):
    """ë°ì´í„° ëˆ„ìˆ˜ ìœ„í—˜ ì»¬ëŸ¼ íƒì§€"""
    print("\n" + "="*80)
    print(f"âš ï¸ ë°ì´í„° ëˆ„ìˆ˜ ìœ„í—˜ íƒì§€ (|r| â‰¥ {threshold})")
    print("="*80)
    
    leakage_risk = df_corr[df_corr['Pearson_abs'] >= threshold]
    
    if len(leakage_risk) > 0:
        print(f"\nğŸš¨ ìœ„í—˜ ì»¬ëŸ¼: {len(leakage_risk)}ê°œ")
        print("ì´ ì»¬ëŸ¼ë“¤ì€ TOTALCNTì™€ ê±°ì˜ ë™ì¼í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆì–´ ëˆ„ìˆ˜ ìœ„í—˜!")
        print(leakage_risk[['ì»¬ëŸ¼', 'Pearson', 'Spearman']].to_string(index=False))
    else:
        print("\nâœ… ë°ì´í„° ëˆ„ìˆ˜ ìœ„í—˜ ì»¬ëŸ¼ ì—†ìŒ")
    
    return leakage_risk

# ========================================
# 7. íŒŒìƒë³€ìˆ˜ í›„ë³´ íƒì§€
# ========================================
def detect_derived_candidates(df, numeric_cols, target='TOTALCNT'):
    """íŒŒìƒë³€ìˆ˜ í›„ë³´ íƒì§€ (ì°¨ì´, ë¹„ìœ¨ ë“±)"""
    print("\n" + "="*80)
    print("ğŸ”§ íŒŒìƒë³€ìˆ˜ í›„ë³´ íƒì§€")
    print("="*80)
    
    # CREATED - COMPLETED íŒ¨í„´ íƒì§€
    created_cols = [c for c in numeric_cols if 'CREATED' in c.upper()]
    completed_cols = [c for c in numeric_cols if 'COMPLETED' in c.upper()]
    
    print(f"\nCREATED ì»¬ëŸ¼: {len(created_cols)}ê°œ")
    print(f"COMPLETED ì»¬ëŸ¼: {len(completed_cols)}ê°œ")
    
    derived_results = []
    
    # ì§ ì°¾ê¸°
    for cr in created_cols:
        base_name = cr.replace('CREATED', '').replace('CURRENTQ', '')
        for cp in completed_cols:
            if base_name in cp or cp.replace('COMPLETED', '').replace('CURRENTQ', '') == base_name:
                try:
                    gap = df[cr] - df[cp]
                    valid_mask = ~(gap.isna() | df[target].isna())
                    
                    if valid_mask.sum() > 10:
                        corr, _ = stats.pearsonr(gap[valid_mask], df.loc[valid_mask, target])
                        
                        derived_results.append({
                            'CREATED': cr,
                            'COMPLETED': cp,
                            'GAP_ìƒê´€ê³„ìˆ˜': round(corr, 4),
                            'GAP_í‰ê· ': round(gap.mean(), 2),
                            'GAP_ìµœëŒ€': round(gap.max(), 2)
                        })
                except:
                    pass
    
    if derived_results:
        df_derived = pd.DataFrame(derived_results)
        df_derived = df_derived.sort_values('GAP_ìƒê´€ê³„ìˆ˜', ascending=False)
        print("\nğŸ“Š GAP(CREATED-COMPLETED) ìƒê´€ê´€ê³„:")
        print(df_derived.to_string(index=False))
        return df_derived
    
    return None

# ========================================
# 8. ì‹œê°í™”
# ========================================
def visualize_correlations(df_corr, output_dir='correlation_analysis'):
    """ìƒê´€ê´€ê³„ ì‹œê°í™”"""
    os.makedirs(output_dir, exist_ok=True)
    
    print("\n" + "="*80)
    print("ğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")
    print("="*80)
    
    # 1. TOP 30 ìƒê´€ê³„ìˆ˜ ë°” ì°¨íŠ¸
    fig, ax = plt.subplots(figsize=(14, 10))
    top30 = df_corr.head(30)
    colors = ['red' if x >= 0.8 else 'orange' if x >= 0.6 else 'yellow' if x >= 0.4 else 'green' 
              for x in top30['Pearson_abs']]
    
    bars = ax.barh(range(len(top30)), top30['Pearson'], color=colors, alpha=0.7)
    ax.set_yticks(range(len(top30)))
    ax.set_yticklabels(top30['ì»¬ëŸ¼'], fontsize=8)
    ax.set_xlabel('Pearson Correlation')
    ax.set_title('TOP 30 Correlation with TOTALCNT')
    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)
    ax.axvline(x=0.8, color='red', linestyle='--', linewidth=0.5, label='Very Strong (0.8)')
    ax.axvline(x=0.6, color='orange', linestyle='--', linewidth=0.5, label='Strong (0.6)')
    ax.axvline(x=-0.8, color='red', linestyle='--', linewidth=0.5)
    ax.axvline(x=-0.6, color='orange', linestyle='--', linewidth=0.5)
    ax.legend(loc='lower right')
    ax.invert_yaxis()
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/correlation_top30.png', dpi=150)
    plt.close()
    print(f"  âœ… {output_dir}/correlation_top30.png")
    
    # 2. ìƒê´€ê³„ìˆ˜ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    axes[0].hist(df_corr['Pearson'], bins=50, color='steelblue', alpha=0.7, edgecolor='black')
    axes[0].axvline(x=0.8, color='red', linestyle='--', label='Â±0.8')
    axes[0].axvline(x=-0.8, color='red', linestyle='--')
    axes[0].axvline(x=0.6, color='orange', linestyle='--', label='Â±0.6')
    axes[0].axvline(x=-0.6, color='orange', linestyle='--')
    axes[0].set_xlabel('Pearson Correlation')
    axes[0].set_ylabel('Count')
    axes[0].set_title('Pearson Correlation Distribution')
    axes[0].legend()
    
    axes[1].hist(df_corr['Spearman'], bins=50, color='darkgreen', alpha=0.7, edgecolor='black')
    axes[1].axvline(x=0.8, color='red', linestyle='--', label='Â±0.8')
    axes[1].axvline(x=-0.8, color='red', linestyle='--')
    axes[1].axvline(x=0.6, color='orange', linestyle='--', label='Â±0.6')
    axes[1].axvline(x=-0.6, color='orange', linestyle='--')
    axes[1].set_xlabel('Spearman Correlation')
    axes[1].set_ylabel('Count')
    axes[1].set_title('Spearman Correlation Distribution')
    axes[1].legend()
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/correlation_distribution.png', dpi=150)
    plt.close()
    print(f"  âœ… {output_dir}/correlation_distribution.png")
    
    # 3. Pearson vs Spearman ë¹„êµ
    fig, ax = plt.subplots(figsize=(10, 10))
    ax.scatter(df_corr['Pearson'], df_corr['Spearman'], alpha=0.5, c='steelblue')
    ax.plot([-1, 1], [-1, 1], 'r--', label='y=x')
    ax.set_xlabel('Pearson Correlation')
    ax.set_ylabel('Spearman Correlation')
    ax.set_title('Pearson vs Spearman Correlation')
    ax.legend()
    ax.set_xlim(-1, 1)
    ax.set_ylim(-1, 1)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/pearson_vs_spearman.png', dpi=150)
    plt.close()
    print(f"  âœ… {output_dir}/pearson_vs_spearman.png")

# ========================================
# 9. ìƒìœ„ ì»¬ëŸ¼ ì‚°ì ë„
# ========================================
def plot_scatter_top_columns(df, df_corr, target='TOTALCNT', top_n=12, output_dir='correlation_analysis'):
    """ìƒìœ„ ìƒê´€ê´€ê³„ ì»¬ëŸ¼ ì‚°ì ë„"""
    os.makedirs(output_dir, exist_ok=True)
    
    top_cols = df_corr.head(top_n)['ì»¬ëŸ¼'].tolist()
    
    n_cols = 4
    n_rows = (len(top_cols) + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))
    axes = axes.flatten()
    
    for idx, col in enumerate(top_cols):
        ax = axes[idx]
        valid_mask = ~(df[col].isna() | df[target].isna())
        
        # ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´)
        if valid_mask.sum() > 5000:
            sample_idx = df[valid_mask].sample(5000, random_state=42).index
            x = df.loc[sample_idx, col]
            y = df.loc[sample_idx, target]
        else:
            x = df.loc[valid_mask, col]
            y = df.loc[valid_mask, target]
        
        ax.scatter(x, y, alpha=0.3, s=5, c='steelblue')
        ax.axhline(y=1700, color='red', linestyle='--', alpha=0.7, label='1700')
        ax.axhline(y=1600, color='orange', linestyle='--', alpha=0.5, label='1600')
        
        corr_val = df_corr[df_corr['ì»¬ëŸ¼'] == col]['Pearson'].values[0]
        ax.set_title(f'{col[:30]}\nr={corr_val:.3f}', fontsize=9)
        ax.set_xlabel(col[:20], fontsize=8)
        ax.set_ylabel(target, fontsize=8)
    
    # ë¹ˆ subplot ì œê±°
    for idx in range(len(top_cols), len(axes)):
        fig.delaxes(axes[idx])
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/scatter_top{top_n}.png', dpi=150)
    plt.close()
    print(f"  âœ… {output_dir}/scatter_top{top_n}.png")

# ========================================
# 10. ê²°ê³¼ ì €ì¥
# ========================================
def save_results(df_corr, df_missing, output_dir='correlation_analysis'):
    """ê²°ê³¼ CSV ì €ì¥"""
    os.makedirs(output_dir, exist_ok=True)
    
    # ìƒê´€ê´€ê³„ ê²°ê³¼
    df_corr.to_csv(f'{output_dir}/correlation_all_columns.csv', index=False, encoding='utf-8-sig')
    print(f"  âœ… {output_dir}/correlation_all_columns.csv")
    
    # ê²°ì¸¡ì¹˜ ê²°ê³¼
    df_missing.to_csv(f'{output_dir}/missing_analysis.csv', index=False, encoding='utf-8-sig')
    print(f"  âœ… {output_dir}/missing_analysis.csv")
    
    # ìš”ì•½ ë¦¬í¬íŠ¸
    summary = df_corr[['ì»¬ëŸ¼', 'Pearson', 'Spearman', 'í‰ê· ', 'í‘œì¤€í¸ì°¨', 'ìµœì†Œ', 'ìµœëŒ€']].copy()
    summary.to_csv(f'{output_dir}/correlation_summary.csv', index=False, encoding='utf-8-sig')
    print(f"  âœ… {output_dir}/correlation_summary.csv")

# ========================================
# 11. HTML ë¦¬í¬íŠ¸ ìƒì„±
# ========================================
def generate_html_report(df_corr, classified, output_dir='correlation_analysis'):
    """HTML ë¦¬í¬íŠ¸ ìƒì„±"""
    os.makedirs(output_dir, exist_ok=True)
    
    html = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>AMHS Column Correlation Analysis Report</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1400px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }}
        h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}
        h2 {{ color: #34495e; margin-top: 30px; }}
        .summary {{ display: flex; gap: 20px; flex-wrap: wrap; margin: 20px 0; }}
        .card {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; min-width: 150px; text-align: center; }}
        .card.danger {{ background: linear-gradient(135deg, #e74c3c 0%, #c0392b 100%); }}
        .card.warning {{ background: linear-gradient(135deg, #f39c12 0%, #e67e22 100%); }}
        .card.success {{ background: linear-gradient(135deg, #27ae60 0%, #2ecc71 100%); }}
        .card h3 {{ margin: 0; font-size: 2em; }}
        .card p {{ margin: 5px 0 0 0; opacity: 0.9; }}
        table {{ border-collapse: collapse; width: 100%; margin: 15px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 10px; text-align: left; }}
        th {{ background: #3498db; color: white; }}
        tr:nth-child(even) {{ background: #f9f9f9; }}
        tr:hover {{ background: #e8f4f8; }}
        .high {{ color: #e74c3c; font-weight: bold; }}
        .medium {{ color: #f39c12; font-weight: bold; }}
        .low {{ color: #27ae60; }}
        img {{ max-width: 100%; height: auto; margin: 10px 0; border-radius: 5px; box-shadow: 0 2px 5px rgba(0,0,0,0.2); }}
        .img-container {{ display: flex; gap: 20px; flex-wrap: wrap; justify-content: center; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š AMHS Column Correlation Analysis Report</h1>
        <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        
        <div class="summary">
            <div class="card danger">
                <h3>{len(classified['very_strong'])}</h3>
                <p>Very Strong (â‰¥0.8)</p>
            </div>
            <div class="card warning">
                <h3>{len(classified['strong'])}</h3>
                <p>Strong (0.6-0.8)</p>
            </div>
            <div class="card">
                <h3>{len(classified['moderate'])}</h3>
                <p>Moderate (0.4-0.6)</p>
            </div>
            <div class="card success">
                <h3>{len(classified['weak']) + len(classified['very_weak'])}</h3>
                <p>Weak (<0.4)</p>
            </div>
        </div>
        
        <h2>ğŸ”´ Very Strong Correlation (|r| â‰¥ 0.8)</h2>
        <p>âš ï¸ These columns may cause data leakage!</p>
        <table>
            <tr><th>Column</th><th>Pearson</th><th>Spearman</th><th>Mean</th><th>Std</th></tr>
"""
    
    for _, row in classified['very_strong'].iterrows():
        html += f"<tr><td>{row['ì»¬ëŸ¼']}</td><td class='high'>{row['Pearson']:.4f}</td><td>{row['Spearman']:.4f}</td><td>{row['í‰ê· ']:.2f}</td><td>{row['í‘œì¤€í¸ì°¨']:.2f}</td></tr>\n"
    
    html += """
        </table>
        
        <h2>ğŸŸ  Strong Correlation (0.6 â‰¤ |r| < 0.8)</h2>
        <table>
            <tr><th>Column</th><th>Pearson</th><th>Spearman</th><th>Mean</th><th>Std</th></tr>
"""
    
    for _, row in classified['strong'].iterrows():
        html += f"<tr><td>{row['ì»¬ëŸ¼']}</td><td class='medium'>{row['Pearson']:.4f}</td><td>{row['Spearman']:.4f}</td><td>{row['í‰ê· ']:.2f}</td><td>{row['í‘œì¤€í¸ì°¨']:.2f}</td></tr>\n"
    
    html += """
        </table>
        
        <h2>ğŸŸ¡ Moderate Correlation (0.4 â‰¤ |r| < 0.6)</h2>
        <table>
            <tr><th>Column</th><th>Pearson</th><th>Spearman</th><th>Mean</th><th>Std</th></tr>
"""
    
    for _, row in classified['moderate'].iterrows():
        html += f"<tr><td>{row['ì»¬ëŸ¼']}</td><td>{row['Pearson']:.4f}</td><td>{row['Spearman']:.4f}</td><td>{row['í‰ê· ']:.2f}</td><td>{row['í‘œì¤€í¸ì°¨']:.2f}</td></tr>\n"
    
    html += """
        </table>
        
        <h2>ğŸ“Š TOP 30 Correlation Chart</h2>
        <div class="img-container">
            <img src="correlation_top30.png" alt="Top 30 Correlation">
        </div>
        
        <h2>ğŸ“ˆ Correlation Distribution</h2>
        <div class="img-container">
            <img src="correlation_distribution.png" alt="Correlation Distribution">
        </div>
        
        <h2>ğŸ”— Pearson vs Spearman</h2>
        <div class="img-container">
            <img src="pearson_vs_spearman.png" alt="Pearson vs Spearman">
        </div>
        
        <h2>ğŸ“‰ Top Columns Scatter Plots</h2>
        <div class="img-container">
            <img src="scatter_top12.png" alt="Scatter Plots">
        </div>
        
        <h2>ğŸ“‹ All Columns (Sorted by |Pearson|)</h2>
        <table>
            <tr><th>#</th><th>Column</th><th>Pearson</th><th>Spearman</th><th>Mean</th><th>Std</th><th>Min</th><th>Max</th></tr>
"""
    
    for idx, (_, row) in enumerate(df_corr.iterrows(), 1):
        corr_class = 'high' if row['Pearson_abs'] >= 0.8 else 'medium' if row['Pearson_abs'] >= 0.6 else 'low'
        html += f"<tr><td>{idx}</td><td>{row['ì»¬ëŸ¼']}</td><td class='{corr_class}'>{row['Pearson']:.4f}</td><td>{row['Spearman']:.4f}</td><td>{row['í‰ê· ']:.2f}</td><td>{row['í‘œì¤€í¸ì°¨']:.2f}</td><td>{row['ìµœì†Œ']:.2f}</td><td>{row['ìµœëŒ€']:.2f}</td></tr>\n"
    
    html += """
        </table>
    </div>
</body>
</html>
"""
    
    with open(f'{output_dir}/correlation_report.html', 'w', encoding='utf-8') as f:
        f.write(html)
    
    print(f"  âœ… {output_dir}/correlation_report.html")

# ========================================
# ë©”ì¸ ì‹¤í–‰
# ========================================
def main(csv_file):
    """ë©”ì¸ ë¶„ì„ ì‹¤í–‰"""
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = 'correlation_analysis'
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. ë°ì´í„° ë¡œë“œ
    df = load_data(csv_file)
    if df is None:
        return
    
    # 2. ê¸°ë³¸ ì •ë³´
    numeric_cols, object_cols = basic_info(df)
    
    # 3. ê²°ì¸¡ì¹˜ ë¶„ì„
    df_missing = missing_analysis(df, numeric_cols)
    
    # 4. ìƒê´€ê´€ê³„ ë¶„ì„
    df_corr = correlation_analysis(df, numeric_cols, target='TOTALCNT')
    if df_corr is None:
        return
    
    # 5. ë“±ê¸‰ ë¶„ë¥˜
    classified = classify_correlation(df_corr)
    
    # 6. ë°ì´í„° ëˆ„ìˆ˜ íƒì§€
    leakage = detect_leakage_risk(df_corr)
    
    # 7. íŒŒìƒë³€ìˆ˜ í›„ë³´
    derived = detect_derived_candidates(df, numeric_cols)
    
    # 8. ì‹œê°í™”
    visualize_correlations(df_corr, output_dir)
    
    # 9. ì‚°ì ë„
    plot_scatter_top_columns(df, df_corr, top_n=12, output_dir=output_dir)
    
    # 10. ê²°ê³¼ ì €ì¥
    print("\n" + "="*80)
    print("ğŸ’¾ ê²°ê³¼ ì €ì¥")
    print("="*80)
    save_results(df_corr, df_missing, output_dir)
    
    # 11. HTML ë¦¬í¬íŠ¸
    generate_html_report(df_corr, classified, output_dir)
    
    print("\n" + "="*80)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("="*80)
    print(f"\nğŸ“ ê²°ê³¼ í´ë”: {output_dir}/")
    print(f"   - correlation_report.html (ë©”ì¸ ë¦¬í¬íŠ¸)")
    print(f"   - correlation_all_columns.csv (ì „ì²´ ìƒê´€ê´€ê³„)")
    print(f"   - correlation_summary.csv (ìš”ì•½)")
    print(f"   - missing_analysis.csv (ê²°ì¸¡ì¹˜)")
    print(f"   - *.png (ì°¨íŠ¸ë“¤)")
    
    return df_corr, classified

if __name__ == '__main__':
    import sys
    
    # íŒŒì¼ ê²½ë¡œ ì§€ì • (ìˆ˜ì • í•„ìš”!)
    if len(sys.argv) > 1:
        csv_file = sys.argv[1]
    else:
        # ê¸°ë³¸ íŒŒì¼ ê²½ë¡œë“¤ ì‹œë„
        candidates = [
            'data/M14_Q_20250802_TO_20251015.csv',
            'data/2025_DATA.CSV',
            'M14_Q_20250802_TO_20251015.csv',
            '2025_DATA.CSV'
        ]
        csv_file = None
        for c in candidates:
            if os.path.exists(c):
                csv_file = c
                break
        
        if csv_file is None:
            print("âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print("\nì‚¬ìš©ë²•: python column_correlation_analysis.py [CSVíŒŒì¼ê²½ë¡œ]")
            print("\nì˜ˆì‹œ:")
            print("  python column_correlation_analysis.py data/mydata.csv")
            exit(1)
    
    main(csv_file)