#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ 1ë‹¨ê³„: í•™ìŠµ ì „ìš© (train_v12.py) - ìˆ˜ì •ë²„ì „
ê¸°ëŠ¥: ì»¬ëŸ¼ëª… ì˜¤ë¥˜ í•´ê²° (M14AM14B -> M14B ìë™ ë³€í™˜)
"""

import pandas as pd
import numpy as np
import xgboost as xgb
import pickle
import warnings

warnings.filterwarnings('ignore')

# ============================================
# âš™ï¸ ì„¤ì • (í•™ìŠµ íŒŒì¼ ì§€ì •)
# ============================================
TRAIN_FILE = "UF09.CSV"   # 3ê°œì›”ì¹˜ ë°ì´í„° íŒŒì¼ëª…
PRED_MINUTES = 10         # 10ë¶„ í›„ ì˜ˆì¸¡
THRESHOLD = 1700          # ìœ„í—˜ ê¸°ì¤€

print("="*70)
print(f"ğŸš€ V12 í•™ìŠµ ì‹œì‘: {TRAIN_FILE}")
print("="*70)

# --------------------------------------------
# 1. ì»¬ëŸ¼ëª… í‘œì¤€í™” í•¨ìˆ˜ (KeyError ë°©ì§€)
# --------------------------------------------
def standardize_columns(df):
    """
    CSV íŒŒì¼ì˜ ê¸´ ì»¬ëŸ¼ëª…ì„ ì½”ë“œê°€ ì‚¬ìš©í•˜ëŠ” ì§§ì€ ì´ë¦„ìœ¼ë¡œ í†µì¼í•©ë‹ˆë‹¤.
    """
    # (í‘œì¤€ì´ë¦„ : [CSVì—ì„œ ê°€ëŠ¥í•œ ì´ë¦„ í›„ë³´ë“¤])
    mapping = {
        'TOTALCNT': ['TOTALCNT'],
        'M14B': ['M14AM14B', 'M14B'],
        'M14BSUM': ['M14AM14BSUM', 'M14BSUM'],
        'Q_CREATED': ['M14.QUE.ALL.CURRENTQCREATED', 'Q_CREATED'],
        'Q_COMPLETED': ['M14.QUE.ALL.CURRENTQCOMPLETED', 'Q_COMPLETED']
    }
    
    rename_dict = {}
    for std_name, candidates in mapping.items():
        for col in candidates:
            if col in df.columns:
                rename_dict[col] = std_name
                break
    
    df = df.rename(columns=rename_dict)
    return df

# --------------------------------------------
# 2. Feature ìƒì„± (í‘œì¤€í™”ëœ ì´ë¦„ M14B ì‚¬ìš©)
# --------------------------------------------
def create_features(df):
    df = df.copy()
    if 'CURRTIME' in df.columns:
        df['CURRTIME'] = pd.to_datetime(df['CURRTIME'].astype(str), format='%Y%m%d%H%M', errors='coerce')

    # í‘œì¤€í™”ëœ ì´ë¦„ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ì•ˆì „í•¨
    df['Queue_Gap'] = df['Q_CREATED'] - df['Q_COMPLETED']
    df['Dist_to_Limit'] = THRESHOLD - df['TOTALCNT']
    
    # ì†ë„ ë° íŒ¨í„´
    for gap in [1, 3, 5, 10]:
        df[f'Vel_Total_{gap}m'] = df['TOTALCNT'].diff(gap)
        df[f'Vel_Gap_{gap}m'] = df['Queue_Gap'].diff(gap)
        # ì—¬ê¸°ì„œ M14AM14B ëŒ€ì‹  M14B ì‚¬ìš©
        df[f'Vel_M14B_{gap}m'] = df['M14B'].diff(gap)
    
    df['Acc_Total'] = df['Vel_Total_3m'].diff(1)
    df['Vol_Total_10m'] = df['TOTALCNT'].rolling(10).std()
    
    # íŒ¨í„´ (M14B, M14BSUM ì‚¬ìš©)
    df['Is_Triple_Danger'] = ((df['M14B'] > 500) & (df['M14BSUM'] > 600) & (df['Queue_Gap'] > 200)).astype(int)
    df['Is_Gold_Pattern'] = ((df['M14B'] > 520) & (df['M14BSUM'] > 600)).astype(int)
    
    return df

# --------------------------------------------
# 3. í•™ìŠµ ì‹¤í–‰
# --------------------------------------------
def train():
    print("ğŸ”„ ë°ì´í„° ë¡œë”© ì¤‘...")
    try:
        df = pd.read_csv(TRAIN_FILE, on_bad_lines='skip')
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {TRAIN_FILE}")
        return

    # 1. ì»¬ëŸ¼ ì´ë¦„ë¶€í„° í†µì¼ (ì—¬ê¸°ì„œ ì—ëŸ¬ í•´ê²°!)
    df = standardize_columns(df)
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required = ['TOTALCNT', 'M14B', 'M14BSUM', 'Q_CREATED', 'Q_COMPLETED']
    missing = [c for c in required if c not in df.columns]
    if missing:
        print(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
        print("   CSV íŒŒì¼ì˜ ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # 2. Feature ìƒì„±
    df = create_features(df)
    
    # 3. Target ìƒì„±
    indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=PRED_MINUTES)
    df['Future_Max'] = df['TOTALCNT'].rolling(window=indexer).max().shift(-1)
    df['Target'] = (df['Future_Max'] >= THRESHOLD).astype(int)
    
    # 4. í•™ìŠµí•  Feature ì„ ì •
    features = [
        'TOTALCNT', 'M14B', 'M14BSUM', 'Queue_Gap', 'Dist_to_Limit',
        'Vel_Total_1m', 'Vel_Total_3m', 'Vel_Total_5m', 'Vel_Total_10m',
        'Vel_Gap_3m', 'Acc_Total', 'Vol_Total_10m', 
        'Is_Triple_Danger', 'Is_Gold_Pattern'
    ]
    
    df_train = df.dropna(subset=features + ['Target']).reset_index(drop=True)
    
    print(f"âœ… í•™ìŠµ ë°ì´í„° í™•ë³´: {len(df_train):,}í–‰")
    
    # ê°€ì¤‘ì¹˜ ê³„ì‚°
    neg, pos = np.bincount(df_train['Target'])
    if pos == 0:
        print("âš ï¸ ì£¼ì˜: í•™ìŠµ ë°ì´í„°ì— ìœ„í—˜(1700+) êµ¬ê°„ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ì œëŒ€ë¡œ í•™ìŠµë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        scale_weight = 1
    else:
        scale_weight = neg / pos
        print(f"âš–ï¸ ê°€ì¤‘ì¹˜ ì„¤ì •: {scale_weight:.2f}")
    
    print("ğŸš€ XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘...")
    model = xgb.XGBClassifier(
        n_estimators=500, max_depth=6, learning_rate=0.03,
        scale_pos_weight=scale_weight * 1.5, random_state=42, n_jobs=-1, tree_method='hist'
    )
    model.fit(df_train[features], df_train['Target'])
    
    # ì €ì¥
    with open('model_v12.pkl', 'wb') as f: pickle.dump(model, f)
    with open('features_v12.pkl', 'wb') as f: pickle.dump(features, f)
    
    print("\nâœ… í•™ìŠµ ì™„ë£Œ! (model_v12.pkl ì €ì¥ë¨)")
    print("   ì´ì œ eval_v12.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

if __name__ == "__main__":
    train()
