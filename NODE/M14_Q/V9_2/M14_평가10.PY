#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ V9.1 í‰ê°€ - 100ë¶„/10ë¶„ ì˜ˆì¸¡
íŒ¨í„´ = ê²½ë³´ + Boost / ì˜ˆì¸¡ê°’ = ML!

ìˆ˜ì •:
- íŒ¨í„´ ë§¤ì¹­ â†’ ê²½ë³´ ë ˆë²¨ë§Œ!
- ì˜ˆì¸¡ê°’ â†’ í•­ìƒ ML + íŒ¨í„´ boost!
"""

import numpy as np
import pandas as pd
import pickle
from datetime import timedelta
import os
import gc
import warnings
warnings.filterwarnings('ignore')

print("="*70)
print("ğŸš€ V9.1 í‰ê°€ - 100ë¶„/10ë¶„ ì˜ˆì¸¡")
print("   íŒ¨í„´=ê²½ë³´ / ì˜ˆì¸¡ê°’=ML+Boost!")
print("="*70)

# ============================================
# ì„¤ì •
# ============================================
SEQ_LEN = 100
PRED_MINUTES = 10
DATA_FILE = "YOUR_CSV_FILE.csv"  # â† í‰ê°€ìš© ë°ì´í„°!

# ============================================
# íŒ¨í„´ ì²´í¬ (ê²½ë³´ ë ˆë²¨ë§Œ!)
# ============================================
def check_pattern(m14b, m14bsum, gap, totalcnt):
    """
    íŒ¨í„´ â†’ ê²½ë³´ ë ˆë²¨ + Boostê°’ ë°˜í™˜
    ì˜ˆì¸¡ê°’ì€ MLì´ ë‹´ë‹¹!
    """
    # 1ë‹¨ê³„: í™©ê¸ˆíŒ¨í„´ & gap>400 (100%)
    if m14b > 520 and m14bsum > 600 and gap > 400:
        return ('CRITICAL', 150)  # boost +150
    
    # 2ë‹¨ê³„: gap>500 (99.7%)
    if gap > 500:
        return ('CRITICAL', 130)
    
    # 3ë‹¨ê³„: Triple Check (96.5%)
    if m14b > 520 and m14bsum > 600 and gap > 250:
        return ('CRITICAL', 100)
    
    # 4ë‹¨ê³„: gap>400 (96.2%)
    if gap > 400:
        return ('HIGH', 80)
    
    # 5ë‹¨ê³„: í™©ê¸ˆíŒ¨í„´ (gap ì—†ì´)
    if m14b > 520 and m14bsum > 600:
        return ('HIGH', 60)
    
    # 6ë‹¨ê³„: í˜„ì¬ê°’ ë†’ìŒ
    if totalcnt >= 1680:
        return ('HIGH', 50)
    
    if totalcnt >= 1650:
        return ('WARNING', 30)
    
    if totalcnt >= 1600:
        return ('CAUTION', 15)
    
    return ('NORMAL', 0)

# ============================================
# Feature ìƒì„± (34ê°œ)
# ============================================
def create_features_v9(row_dict):
    """í•„ìˆ˜ 5ê°œ ì»¬ëŸ¼ ê¸°ë°˜ 34ê°œ Feature"""
    features = {}
    
    seq_m14b = np.array(row_dict['M14B'])
    seq_m14bsum = np.array(row_dict['M14BSUM'])
    seq_totalcnt = np.array(row_dict['TOTALCNT'])
    seq_q_created = np.array(row_dict['Q_CREATED'])
    seq_q_completed = np.array(row_dict['Q_COMPLETED'])
    seq_gap = seq_q_created - seq_q_completed
    
    seq_len = len(seq_m14b)
    
    # TOTALCNT (8ê°œ)
    features['total_current'] = seq_totalcnt[-1]
    features['total_mean'] = np.mean(seq_totalcnt)
    features['total_max'] = np.max(seq_totalcnt)
    features['total_min'] = np.min(seq_totalcnt)
    features['total_last10'] = np.mean(seq_totalcnt[-10:])
    features['total_slope'] = np.polyfit(np.arange(seq_len), seq_totalcnt, 1)[0]
    features['total_std'] = np.std(seq_totalcnt)
    features['total_trend10'] = seq_totalcnt[-1] - seq_totalcnt[-10]
    
    # M14AM14B (6ê°œ)
    features['m14b_current'] = seq_m14b[-1]
    features['m14b_mean'] = np.mean(seq_m14b)
    features['m14b_max'] = np.max(seq_m14b)
    features['m14b_last10'] = np.mean(seq_m14b[-10:])
    features['m14b_slope'] = np.polyfit(np.arange(seq_len), seq_m14b, 1)[0]
    features['m14b_trend10'] = seq_m14b[-1] - seq_m14b[-10]
    
    # M14AM14BSUM (6ê°œ)
    features['m14bsum_current'] = seq_m14bsum[-1]
    features['m14bsum_mean'] = np.mean(seq_m14bsum)
    features['m14bsum_max'] = np.max(seq_m14bsum)
    features['m14bsum_last10'] = np.mean(seq_m14bsum[-10:])
    features['m14bsum_slope'] = np.polyfit(np.arange(seq_len), seq_m14bsum, 1)[0]
    features['m14bsum_trend10'] = seq_m14bsum[-1] - seq_m14bsum[-10]
    
    # Queue Gap (8ê°œ)
    features['gap_current'] = seq_gap[-1]
    features['gap_mean'] = np.mean(seq_gap)
    features['gap_max'] = np.max(seq_gap)
    features['gap_min'] = np.min(seq_gap)
    features['gap_last10'] = np.mean(seq_gap[-10:])
    features['gap_slope'] = np.polyfit(np.arange(seq_len), seq_gap, 1)[0]
    features['gap_std'] = np.std(seq_gap)
    features['gap_trend10'] = seq_gap[-1] - seq_gap[-10]
    
    # ì¡°í•© (6ê°œ)
    features['m14b_x_sum'] = seq_m14b[-1] * seq_m14bsum[-1] / 1000
    features['gap_x_m14b'] = seq_gap[-1] * seq_m14b[-1] / 1000
    features['ratio_gap_total'] = seq_gap[-1] / (seq_totalcnt[-1] + 1)
    features['ratio_m14b_total'] = seq_m14b[-1] / (seq_totalcnt[-1] + 1)
    features['m14b_plus_sum'] = seq_m14b[-1] + seq_m14bsum[-1]
    features['gap_per_m14b'] = seq_gap[-1] / (seq_m14b[-1] + 1)
    
    return features

# ============================================
# ì˜ˆì¸¡ ë³´ì •
# ============================================
def adjust_prediction(pred_raw, current_total, boost, level):
    """ML ì˜ˆì¸¡ê°’ ë³´ì •"""
    pred = pred_raw
    
    # 1. íŒ¨í„´ boost ì ìš©
    if boost > 0:
        # 1650 ì´ìƒì¼ ë•Œë§Œ boost ì ìš© (ê³¼ë„í•œ boost ë°©ì§€)
        if pred >= 1600:
            pred = pred + boost
        elif pred >= 1550:
            pred = pred + boost * 0.5
    
    # 2. í•˜í•œì„  (10ë¶„ = -80)
    floor = current_total - 80
    if pred < floor:
        pred = floor
    
    # 3. ìƒí•œì„  (ë¹„í˜„ì‹¤ì  ì˜ˆì¸¡ ë°©ì§€)
    ceiling = current_total + 200
    if pred > ceiling:
        pred = ceiling
    
    return pred

# ============================================
# ëª¨ë¸ ë¡œë“œ
# ============================================
model = None
model_files = ['model_v9_100min_10min.pkl', 'model_v9.pkl']
for mf in model_files:
    if os.path.exists(mf):
        with open(mf, 'rb') as f:
            model = pickle.load(f)
        print(f"âœ… ëª¨ë¸: {mf}")
        break

if not model:
    print("âŒ ëª¨ë¸ ì—†ìŒ!")
    exit(1)

# ============================================
# ë°ì´í„° ë¡œë“œ
# ============================================
df = pd.read_csv(DATA_FILE, on_bad_lines='skip')
print(f"âœ… ë°ì´í„°: {len(df):,}í–‰")

# CURRTIME íŒŒì‹±
if 'CURRTIME' in df.columns:
    df['CURRTIME'] = pd.to_datetime(df['CURRTIME'].astype(str), format='%Y%m%d%H%M', errors='coerce')

# queue_gap ê³„ì‚°
df['queue_gap'] = df['M14.QUE.ALL.CURRENTQCREATED'] - df['M14.QUE.ALL.CURRENTQCOMPLETED']

# ============================================
# í‰ê°€ ì‹¤í–‰
# ============================================
results = []
level_counts = {'CRITICAL': 0, 'HIGH': 0, 'WARNING': 0, 'CAUTION': 0, 'NORMAL': 0}

total = len(df) - SEQ_LEN - PRED_MINUTES
print(f"\nğŸ”„ í‰ê°€ ì¤‘... {total:,}ê°œ")

for i in range(SEQ_LEN, len(df) - PRED_MINUTES):
    row_dict = {
        'TOTALCNT': df['TOTALCNT'].iloc[i-SEQ_LEN:i].values,
        'M14B': df['M14AM14B'].iloc[i-SEQ_LEN:i].values,
        'M14BSUM': df['M14AM14BSUM'].iloc[i-SEQ_LEN:i].values,
        'Q_CREATED': df['M14.QUE.ALL.CURRENTQCREATED'].iloc[i-SEQ_LEN:i].values,
        'Q_COMPLETED': df['M14.QUE.ALL.CURRENTQCOMPLETED'].iloc[i-SEQ_LEN:i].values,
    }
    
    # í˜„ì¬ ìƒíƒœ
    current_total = row_dict['TOTALCNT'][-1]
    current_m14b = row_dict['M14B'][-1]
    current_m14bsum = row_dict['M14BSUM'][-1]
    current_gap = row_dict['Q_CREATED'][-1] - row_dict['Q_COMPLETED'][-1]
    
    # ì‹œê°„ ì •ë³´
    if 'CURRTIME' in df.columns and pd.notna(df['CURRTIME'].iloc[i-1]):
        current_time = df['CURRTIME'].iloc[i-1]
        prediction_time = current_time + timedelta(minutes=PRED_MINUTES)
        time_str = current_time.strftime('%Y-%m-%d %H:%M')
        pred_time_str = prediction_time.strftime('%Y-%m-%d %H:%M')
    else:
        time_str = ''
        pred_time_str = ''
    
    # ì‹¤ì œê°’
    actual = df['TOTALCNT'].iloc[i + PRED_MINUTES - 1]
    
    # ========== íŒ¨í„´ ì²´í¬ (ê²½ë³´ ë ˆë²¨ë§Œ!) ==========
    level, boost = check_pattern(current_m14b, current_m14bsum, current_gap, current_total)
    level_counts[level] += 1
    
    # ========== ML ì˜ˆì¸¡ (í•­ìƒ!) ==========
    features = create_features_v9(row_dict)
    X = pd.DataFrame([features])
    pred_raw = model.predict(X)[0]
    
    # ========== ë³´ì • (ML + boost) ==========
    pred = adjust_prediction(pred_raw, current_total, boost, level)
    
    # ê²°ê³¼ ì €ì¥
    results.append({
        'í˜„ì¬ì‹œê°„': time_str,
        'ì˜ˆì¸¡ì‹œì ': pred_time_str,
        'í˜„ì¬TOTALCNT': round(current_total, 2),
        'MLì›ë³¸': round(pred_raw, 2),
        'Boost': boost,
        'ìµœì¢…ì˜ˆì¸¡': round(pred, 2),
        'ì‹¤ì œê°’': round(actual, 2),
        'ì˜¤ì°¨': round(actual - pred, 2),
        'ì ˆëŒ€ì˜¤ì°¨': round(abs(actual - pred), 2),
        'ê²½ë³´ë ˆë²¨': level,
        'M14B': round(current_m14b, 2),
        'M14BSUM': round(current_m14bsum, 2),
        'queue_gap': round(current_gap, 2),
        'ì‹¤ì œ1700+': 'O' if actual >= 1700 else '',
        'ì˜ˆì¸¡1700+': 'O' if pred >= 1700 else ''
    })
    
    if (i - SEQ_LEN) % 2000 == 0:
        print(f"  {i-SEQ_LEN:,}/{total:,}")
        gc.collect()

print(f"\nâœ… ì™„ë£Œ!")
print(f"\nğŸ“Š ê²½ë³´ ë ˆë²¨ ë¶„í¬:")
for level, count in level_counts.items():
    if count > 0:
        print(f"  {level}: {count:,}ê°œ ({count/total*100:.1f}%)")

# ============================================
# ê²°ê³¼ ì €ì¥
# ============================================
df_result = pd.DataFrame(results)
output_file = 'evaluation_V91_100min_10min.csv'
df_result.to_csv(output_file, index=False, encoding='utf-8-sig')
print(f"\nğŸ’¾ ì €ì¥: {output_file}")

# ============================================
# í†µê³„ ë¶„ì„
# ============================================
print("\n" + "="*70)
print("ğŸ“Š V9.1 í‰ê°€ í†µê³„")
print("="*70)

print(f"\nì´ ì˜ˆì¸¡: {len(df_result):,}ê°œ")
print(f"MAE (ì „ì²´): {df_result['ì ˆëŒ€ì˜¤ì°¨'].mean():.2f}")
print(f"MAE (MLì›ë³¸): {abs(df_result['ì‹¤ì œê°’'] - df_result['MLì›ë³¸']).mean():.2f}")

# 1700+ ê°ì§€ í†µê³„
actual_danger = df_result['ì‹¤ì œ1700+'] == 'O'
pred_danger = df_result['ì˜ˆì¸¡1700+'] == 'O'
actual_count = actual_danger.sum()
pred_count = pred_danger.sum()
detected = (actual_danger & pred_danger).sum()
false_alarm = (pred_danger & ~actual_danger).sum()
missed = (actual_danger & ~pred_danger).sum()

print(f"\nğŸ”¥ 1700+ ê°ì§€:")
print(f"  ì‹¤ì œ 1700+: {actual_count:,}ê°œ")
print(f"  ì˜ˆì¸¡ 1700+: {pred_count:,}ê°œ")
if actual_count > 0:
    print(f"  âœ… ê°ì§€(Recall): {detected:,}/{actual_count:,} ({detected/actual_count*100:.1f}%)")
    print(f"  âŒ ë¯¸ê°ì§€: {missed:,}ê°œ")
if pred_count > 0:
    print(f"  ğŸ¯ ì •ë°€ë„(Precision): {detected:,}/{pred_count:,} ({detected/pred_count*100:.1f}%)")
print(f"  âš ï¸ ì˜¤íƒ(False Alarm): {false_alarm:,}ê°œ")

# ê²½ë³´ ë ˆë²¨ë³„ ì •í™•ë„
print(f"\nğŸ“Š ê²½ë³´ ë ˆë²¨ë³„ 1700+ ì‹¤ì œ ë°œìƒë¥ :")
for level in ['CRITICAL', 'HIGH', 'WARNING', 'CAUTION', 'NORMAL']:
    subset = df_result[df_result['ê²½ë³´ë ˆë²¨'] == level]
    if len(subset) > 0:
        actual_1700 = (subset['ì‹¤ì œ1700+'] == 'O').sum()
        rate = actual_1700 / len(subset) * 100
        print(f"  {level}: {actual_1700:,}/{len(subset):,} ({rate:.1f}%)")

# Boost íš¨ê³¼
print(f"\nğŸ“Š Boost íš¨ê³¼:")
boosted = df_result[df_result['Boost'] > 0]
if len(boosted) > 0:
    mae_raw = abs(boosted['ì‹¤ì œê°’'] - boosted['MLì›ë³¸']).mean()
    mae_final = boosted['ì ˆëŒ€ì˜¤ì°¨'].mean()
    print(f"  Boost ì ìš©: {len(boosted):,}ê°œ")
    print(f"  MLì›ë³¸ MAE: {mae_raw:.2f}")
    print(f"  Boostí›„ MAE: {mae_final:.2f}")
    print(f"  ê°œì„ : {mae_raw - mae_final:+.2f}")

# ë¯¸ê°ì§€ ë¶„ì„
if missed > 0:
    print(f"\nğŸ“Š ë¯¸ê°ì§€ {missed}ê°œ ë¶„ì„:")
    missed_df = df_result[actual_danger & ~pred_danger]
    print(f"  í˜„ì¬ê°’ í‰ê· : {missed_df['í˜„ì¬TOTALCNT'].mean():.0f}")
    print(f"  MLì›ë³¸ í‰ê· : {missed_df['MLì›ë³¸'].mean():.0f}")
    print(f"  ìµœì¢…ì˜ˆì¸¡ í‰ê· : {missed_df['ìµœì¢…ì˜ˆì¸¡'].mean():.0f}")
    print(f"  ì‹¤ì œê°’ í‰ê· : {missed_df['ì‹¤ì œê°’'].mean():.0f}")
    
    # í˜„ì¬ê°’ ë¶„í¬
    print(f"\n  í˜„ì¬ê°’ ë¶„í¬ (ë¯¸ê°ì§€):")
    for thresh in [1600, 1650, 1680]:
        cnt = (missed_df['í˜„ì¬TOTALCNT'] >= thresh).sum()
        print(f"    >= {thresh}: {cnt}ê°œ ({cnt/missed*100:.1f}%)")

print(f"\n" + "="*70)
print(f"âœ… V9.1 í‰ê°€ ì™„ë£Œ!")
print("="*70)