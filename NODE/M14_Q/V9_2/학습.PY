#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ V8.3.1 í•™ìŠµ - 10ë¶„ ì˜ˆì¸¡
í•µì‹¬ ë°œê²¬ ë°˜ì˜: í˜„ì¬ TOTALCNT >= 1580 â†’ 10ë¶„ í›„ 1700+ (100%)

ì „ëµ ë³€ê²½:
1. íƒ€ê²Ÿ = ë³€í™”ëŸ‰ (10ë¶„ í›„ - í˜„ì¬)  â† í•µì‹¬!
2. Feature = í˜„ì¬ê°’ + ë‹¨ê¸° ì¶”ì„¸ (30ê°œ ì´í•˜)
3. ì‹œê³„ì—´ = 60ë¶„ (280ë¶„ â†’ 60ë¶„)
4. ì¦ê°• = ì œê±° ë˜ëŠ” ìµœì†Œí™”
5. ì˜ˆì¸¡ê°’ = í˜„ì¬ê°’ + ì˜ˆì¸¡_ë³€í™”ëŸ‰
"""

import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle
import warnings
warnings.filterwarnings('ignore')

print("="*70)
print("ğŸš€ V8.3.1 í•™ìŠµ - 10ë¶„ ì˜ˆì¸¡")
print("   ì „ëµ: í˜„ì¬ê°’ + ë³€í™”ëŸ‰ ì˜ˆì¸¡")
print("="*70)

# ========================================
# ì„¤ì •
# ========================================
SEQ_LEN = 60       # 60ë¶„ ì‹œê³„ì—´ (ê¸°ì¡´ 280ë¶„ â†’ 60ë¶„)
PRED_MINUTES = 10  # 10ë¶„ í›„ ì˜ˆì¸¡

# ========================================
# Feature ìƒì„± í•¨ìˆ˜ (ê°„ì†Œí™” ~30ê°œ)
# ========================================
def create_features_v831(row_dict):
    """
    í•µì‹¬ Featureë§Œ (ì•½ 30ê°œ)
    - í˜„ì¬ê°’ ì¤‘ì‹¬
    - ë‹¨ê¸° ì¶”ì„¸ ê°•ì¡°
    - ë¶ˆí•„ìš”í•œ í†µê³„ëŸ‰ ì œê±°
    """
    features = {}
    
    seq_totalcnt = np.array(row_dict['TOTALCNT'])
    seq_m14b = np.array(row_dict['M14AM14B'])
    seq_m14bsum = np.array(row_dict['M14AM14BSUM'])
    seq_m10arev = np.array(row_dict['M10AM14A'])
    seq_m16m14a = np.array(row_dict['M16M14A'])
    seq_transport = np.array(row_dict['TRANSPORT'])
    seq_oht = np.array(row_dict['OHT'])
    seq_gap = np.array(row_dict['Q_CREATED']) - np.array(row_dict['Q_COMPLETED'])
    
    seq_len = len(seq_totalcnt)
    
    # ========================================
    # 1. TOTALCNT (ê°€ì¥ ì¤‘ìš”!) - 7ê°œ
    # ========================================
    features['total_current'] = seq_totalcnt[-1]
    features['total_last5'] = np.mean(seq_totalcnt[-5:])
    features['total_last10'] = np.mean(seq_totalcnt[-10:])
    features['total_trend5'] = seq_totalcnt[-1] - seq_totalcnt[-5]
    features['total_trend10'] = seq_totalcnt[-1] - seq_totalcnt[-10]
    features['total_slope'] = np.polyfit(np.arange(min(30, seq_len)), seq_totalcnt[-30:], 1)[0]
    features['total_std10'] = np.std(seq_totalcnt[-10:])
    
    # ========================================
    # 2. M14AM14B - 4ê°œ
    # ========================================
    features['m14b_current'] = seq_m14b[-1]
    features['m14b_last10'] = np.mean(seq_m14b[-10:])
    features['m14b_trend10'] = seq_m14b[-1] - seq_m14b[-10]
    features['m14b_slope'] = np.polyfit(np.arange(min(30, seq_len)), seq_m14b[-30:], 1)[0]
    
    # ========================================
    # 3. M14AM14BSUM - 4ê°œ
    # ========================================
    features['m14bsum_current'] = seq_m14bsum[-1]
    features['m14bsum_last10'] = np.mean(seq_m14bsum[-10:])
    features['m14bsum_trend10'] = seq_m14bsum[-1] - seq_m14bsum[-10]
    features['m14bsum_slope'] = np.polyfit(np.arange(min(30, seq_len)), seq_m14bsum[-30:], 1)[0]
    
    # ========================================
    # 4. M16M14A (ìƒˆë¡œ ì¶”ê°€!) - 3ê°œ
    # ========================================
    features['m16_current'] = seq_m16m14a[-1]
    features['m16_last10'] = np.mean(seq_m16m14a[-10:])
    features['m16_trend10'] = seq_m16m14a[-1] - seq_m16m14a[-10]
    
    # ========================================
    # 5. M10AM14A - 2ê°œ
    # ========================================
    features['m10arev_current'] = seq_m10arev[-1]
    features['m10arev_trend10'] = seq_m10arev[-1] - seq_m10arev[-10]
    
    # ========================================
    # 6. TRANSPORT - 2ê°œ
    # ========================================
    features['trans_current'] = seq_transport[-1]
    features['trans_trend10'] = seq_transport[-1] - seq_transport[-10]
    
    # ========================================
    # 7. OHT - 2ê°œ
    # ========================================
    features['oht_current'] = seq_oht[-1]
    features['oht_last10'] = np.mean(seq_oht[-10:])
    
    # ========================================
    # 8. Queue Gap - 3ê°œ
    # ========================================
    features['gap_current'] = seq_gap[-1]
    features['gap_last10'] = np.mean(seq_gap[-10:])
    features['gap_trend10'] = seq_gap[-1] - seq_gap[-10]
    
    # ========================================
    # 9. í•µì‹¬ ì„ê³„ê°’ (ìƒˆë¡œìš´ ë°œê²¬ ë°˜ì˜) - 4ê°œ
    # ========================================
    features['is_over_1550'] = 1 if seq_totalcnt[-1] >= 1550 else 0
    features['is_over_1580'] = 1 if seq_totalcnt[-1] >= 1580 else 0
    features['is_over_1600'] = 1 if seq_totalcnt[-1] >= 1600 else 0
    features['is_over_1650'] = 1 if seq_totalcnt[-1] >= 1650 else 0
    
    # ========================================
    # 10. ë³µí•© ì§€í‘œ - 2ê°œ
    # ========================================
    features['m14b_plus_sum'] = seq_m14b[-1] + seq_m14bsum[-1]
    features['total_momentum'] = features['total_trend5'] + features['total_trend10']
    
    return features

# ========================================
# ë°ì´í„° ì¤€ë¹„ (ë³€í™”ëŸ‰ íƒ€ê²Ÿ!)
# ========================================
def prepare_data(csv_path, seq_len=SEQ_LEN, pred_minutes=PRED_MINUTES):
    print(f"\nğŸ“‚ ë°ì´í„° ë¡œë”©: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"âœ… {len(df):,}í–‰ Ã— {df.shape[1]}ì—´")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required = ['M14AM14B', 'M14AM14BSUM', 'M10AM14A', 'TOTALCNT', 'M16M14A',
                'M14.QUE.ALL.TRANSPORT4MINOVERCNT', 'M14.QUE.OHT.OHTUTIL',
                'M14.QUE.ALL.CURRENTQCREATED', 'M14.QUE.ALL.CURRENTQCOMPLETED']
    
    missing = [c for c in required if c not in df.columns]
    if missing:
        print(f"âŒ ëˆ„ë½ ì»¬ëŸ¼: {missing}")
        return None, None, None
    
    print(f"âœ… 9ê°œ ì»¬ëŸ¼ í™•ì¸ (M16M14A ì¶”ê°€!)")
    
    # NaN ì œê±°
    before = len(df)
    df = df.dropna(subset=required)
    after = len(df)
    if before != after:
        print(f"âš ï¸ NaN ì œê±°: {before:,} â†’ {after:,}")
    
    # í†µê³„
    print(f"\nğŸ“Š TOTALCNT ë¶„í¬:")
    print(f"  ë²”ìœ„: {df['TOTALCNT'].min():.0f} ~ {df['TOTALCNT'].max():.0f}")
    print(f"  í‰ê· : {df['TOTALCNT'].mean():.0f}")
    print(f"  1700+: {(df['TOTALCNT']>=1700).sum()}ê°œ ({(df['TOTALCNT']>=1700).sum()/len(df)*100:.2f}%)")
    
    print(f"\nğŸ”„ Feature ìƒì„± ì¤‘... (ì‹œê³„ì—´: {seq_len}ë¶„, ì˜ˆì¸¡: {pred_minutes}ë¶„)")
    
    X_list = []
    y_change_list = []  # ë³€í™”ëŸ‰!
    y_actual_list = []  # ì‹¤ì œê°’ (í‰ê°€ìš©)
    current_list = []   # í˜„ì¬ê°’ (í‰ê°€ìš©)
    
    pred_offset = pred_minutes
    total = len(df) - seq_len - pred_offset
    
    for i in range(seq_len, len(df) - pred_offset):
        row_dict = {
            'M14AM14B': df['M14AM14B'].iloc[i-seq_len:i].values,
            'M14AM14BSUM': df['M14AM14BSUM'].iloc[i-seq_len:i].values,
            'M10AM14A': df['M10AM14A'].iloc[i-seq_len:i].values,
            'TOTALCNT': df['TOTALCNT'].iloc[i-seq_len:i].values,
            'M16M14A': df['M16M14A'].iloc[i-seq_len:i].values,
            'TRANSPORT': df['M14.QUE.ALL.TRANSPORT4MINOVERCNT'].iloc[i-seq_len:i].values,
            'OHT': df['M14.QUE.OHT.OHTUTIL'].iloc[i-seq_len:i].values,
            'Q_CREATED': df['M14.QUE.ALL.CURRENTQCREATED'].iloc[i-seq_len:i].values,
            'Q_COMPLETED': df['M14.QUE.ALL.CURRENTQCOMPLETED'].iloc[i-seq_len:i].values,
        }
        
        current_total = df['TOTALCNT'].iloc[i-1]
        future_total = df['TOTALCNT'].iloc[i + pred_offset - 1]
        
        if pd.isna(future_total) or pd.isna(current_total):
            continue
        
        # ğŸ”¥ íƒ€ê²Ÿ = ë³€í™”ëŸ‰!
        change = future_total - current_total
        
        X_list.append(create_features_v831(row_dict))
        y_change_list.append(change)
        y_actual_list.append(future_total)
        current_list.append(current_total)
        
        if (i - seq_len) % 5000 == 0:
            print(f"  {i-seq_len:,}/{total:,} ({(i-seq_len)/total*100:.1f}%)")
    
    print(f"âœ… ì™„ë£Œ!")
    
    X = pd.DataFrame(X_list)
    y_change = pd.Series(y_change_list, name='change')
    y_actual = pd.Series(y_actual_list, name='actual')
    current = pd.Series(current_list, name='current')
    
    # NaN ì œê±°
    mask = ~(X.isna().any(axis=1) | y_change.isna())
    X = X[mask].reset_index(drop=True)
    y_change = y_change[mask].reset_index(drop=True)
    y_actual = y_actual[mask].reset_index(drop=True)
    current = current[mask].reset_index(drop=True)
    
    print(f"\nğŸ“Š ê²°ê³¼:")
    print(f"  Feature: {X.shape[1]}ê°œ")
    print(f"  ìƒ˜í”Œ: {len(X):,}ê°œ")
    print(f"  ë³€í™”ëŸ‰ ë²”ìœ„: {y_change.min():.0f} ~ {y_change.max():.0f}")
    print(f"  ë³€í™”ëŸ‰ í‰ê· : {y_change.mean():.1f}")
    print(f"  10ë¶„ í›„ 1700+: {(y_actual>=1700).sum()}ê°œ")
    
    return X, y_change, pd.DataFrame({'current': current, 'actual': y_actual})

# ========================================
# í•™ìŠµ (ì¦ê°• ì œê±°!)
# ========================================
def train_model(X, y):
    print(f"\nğŸš€ XGBoost í•™ìŠµ (ë³€í™”ëŸ‰ ì˜ˆì¸¡)")
    print(f"  ìƒ˜í”Œ: {len(X):,}ê°œ")
    print(f"  Feature: {X.shape[1]}ê°œ")
    
    model = xgb.XGBRegressor(
        objective='reg:squarederror',
        max_depth=6,           # 8 â†’ 6 (ê³¼ì í•© ë°©ì§€)
        learning_rate=0.05,
        n_estimators=300,      # 500 â†’ 300
        subsample=0.8,
        colsample_bytree=0.8,
        min_child_weight=5,    # 3 â†’ 5
        gamma=0.1,
        reg_alpha=0.1,
        reg_lambda=1.0,
        random_state=42,
        n_jobs=-1,
        tree_method='hist'
    )
    
    model.fit(X, y, verbose=50)
    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ!")
    return model

# ========================================
# í‰ê°€
# ========================================
def evaluate(model, X, y_change, meta):
    print(f"\n" + "="*70)
    print(f"ğŸ“Š ì„±ëŠ¥ í‰ê°€")
    print("="*70)
    
    # ë³€í™”ëŸ‰ ì˜ˆì¸¡
    pred_change = model.predict(X)
    
    # ì‹¤ì œ ì˜ˆì¸¡ê°’ = í˜„ì¬ê°’ + ì˜ˆì¸¡_ë³€í™”ëŸ‰
    pred_actual = meta['current'] + pred_change
    actual = meta['actual']
    
    # ì „ì²´ MAE
    mae_change = mean_absolute_error(y_change, pred_change)
    mae_actual = mean_absolute_error(actual, pred_actual)
    rmse = np.sqrt(mean_squared_error(actual, pred_actual))
    r2 = r2_score(actual, pred_actual)
    
    print(f"\në³€í™”ëŸ‰ ì˜ˆì¸¡ MAE: {mae_change:.2f}")
    print(f"ì‹¤ì œê°’ ì˜ˆì¸¡ MAE: {mae_actual:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"RÂ²: {r2:.4f}")
    
    # 1700+ ê°ì§€ìœ¨
    actual_danger = actual >= 1700
    pred_danger = pred_actual >= 1700
    
    if actual_danger.sum() > 0:
        tp = (actual_danger & pred_danger).sum()
        recall = tp / actual_danger.sum() * 100
        precision = tp / pred_danger.sum() * 100 if pred_danger.sum() > 0 else 0
        
        print(f"\nğŸ”¥ 1700+ ê°ì§€:")
        print(f"  ì‹¤ì œ: {actual_danger.sum()}ê°œ")
        print(f"  ê°ì§€: {tp}ê°œ")
        print(f"  ê°ì§€ìœ¨(Recall): {recall:.1f}%")
        print(f"  ì •ë°€ë„(Precision): {precision:.1f}%")
    
    # í˜„ì¬ê°’ ê¸°ì¤€ê³¼ ë¹„êµ
    print(f"\nğŸ“Œ ë‹¨ìˆœ ì„ê³„ê°’ vs ML ë¹„êµ:")
    simple_pred = meta['current'] >= 1580
    simple_tp = (actual_danger & simple_pred).sum()
    simple_recall = simple_tp / actual_danger.sum() * 100 if actual_danger.sum() > 0 else 0
    print(f"  ë‹¨ìˆœ (>=1580): ê°ì§€ìœ¨ {simple_recall:.1f}%")
    print(f"  ML ëª¨ë¸: ê°ì§€ìœ¨ {recall:.1f}%")
    
    return mae_actual, rmse, r2

# ========================================
# Feature ì¤‘ìš”ë„
# ========================================
def show_importance(model, X):
    print(f"\nğŸ† Feature ì¤‘ìš”ë„ TOP 15")
    imp = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    print(imp.head(15).to_string(index=False))
    return imp

# ========================================
# ë©”ì¸
# ========================================
if __name__ == '__main__':
    # ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ìˆ˜ì • í•„ìš”!)
    CSV_FILE = "big_data.csv"  # 11/8 ~ 12/10 ë°ì´í„°
    
    # ë°ì´í„° ì¤€ë¹„
    X, y_change, meta = prepare_data(CSV_FILE, seq_len=SEQ_LEN, pred_minutes=PRED_MINUTES)
    
    if X is None:
        print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
        exit(1)
    
    # í•™ìŠµ (ì¦ê°• ì—†ìŒ!)
    model = train_model(X, y_change)
    
    # í‰ê°€
    mae, rmse, r2 = evaluate(model, X, y_change, meta)
    
    # Feature ì¤‘ìš”ë„
    show_importance(model, X)
    
    # ì €ì¥
    with open('model_V8.3.1_10min.pkl', 'wb') as f:
        pickle.dump(model, f)
    with open('features_V8.3.1_10min.pkl', 'wb') as f:
        pickle.dump(list(X.columns), f)
    
    print(f"\n" + "="*70)
    print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ!")
    print(f"  ëª¨ë¸: model_V8.3.1_10min.pkl")
    print(f"  Feature: features_V8.3.1_10min.pkl ({X.shape[1]}ê°œ)")
    print("="*70)
    
    print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸš€ V8.3.1 í•µì‹¬ ë³€ê²½ì‚¬í•­                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. íƒ€ê²Ÿ: ì‹¤ì œê°’ â†’ ë³€í™”ëŸ‰ (10ë¶„ í›„ - í˜„ì¬)                        â”‚
â”‚  2. Feature: 82ê°œ â†’ {X.shape[1]}ê°œ                                    â”‚
â”‚  3. ì‹œê³„ì—´: 280ë¶„ â†’ 60ë¶„                                         â”‚
â”‚  4. ì¦ê°•: 50ë°° â†’ ì—†ìŒ                                            â”‚
â”‚  5. ì˜ˆì¸¡: í˜„ì¬ê°’ + ì˜ˆì¸¡_ë³€í™”ëŸ‰                                    â”‚
â”‚  6. ìƒˆ Feature: M16M14A, ì„ê³„ê°’(1550/1580/1600/1650)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")