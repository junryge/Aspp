#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ V13 í•™ìŠµ: ê°’ ì˜ˆì¸¡(Regression) ì „ìš©
ëª©í‘œ: 10ë¶„ ë’¤ 'ìµœëŒ€ê°’(MAX)'ì´ ì •í™•íˆ ëª‡ì´ ë ì§€ ìˆ«ìë¡œ ì˜ˆì¸¡
"""

import pandas as pd
import numpy as np
import xgboost as xgb
import pickle
import warnings

warnings.filterwarnings('ignore')

# ============================================
# âš™ï¸ ì„¤ì • (í•™ìŠµ íŒŒì¼)
# ============================================
TRAIN_FILE = "UF09.CSV"   # 3ê°œì›”ì¹˜ ë°ì´í„°
PRED_MINUTES = 10         # 10ë¶„ ì˜ˆì§€

# íŒŒì¼ì— ìˆëŠ” ì •í™•í•œ ì»¬ëŸ¼ëª… ì§€ì •
COL_TOTAL = 'TOTALCNT'
COL_M14B  = 'M14AM14B'
COL_SUM   = 'M14AM14BSUM'
COL_Q_CR  = 'M14.QUE.ALL.CURRENTQCREATED'
COL_Q_CP  = 'M14.QUE.ALL.CURRENTQCOMPLETED'

print("="*70)
print(f"ğŸš€ V13 ìˆ«ì ì˜ˆì¸¡ í•™ìŠµ ì‹œì‘: {TRAIN_FILE}")
print("="*70)

def create_features(df):
    df = df.copy()
    
    # í ê°­
    df['Queue_Gap'] = df[COL_Q_CR] - df[COL_Q_CP]
    
    # ì†ë„(Velocity) ë³€ìˆ˜ (ë§¤ìš° ì¤‘ìš”)
    for gap in [1, 3, 5, 10]:
        df[f'Vel_Total_{gap}m'] = df[COL_TOTAL].diff(gap)
        df[f'Vel_Gap_{gap}m'] = df['Queue_Gap'].diff(gap)
        df[f'Vel_M14B_{gap}m'] = df[COL_M14B].diff(gap)
    
    # ê°€ì†ë„ ë° ë³€ë™ì„±
    df['Acc_Total'] = df['Vel_Total_3m'].diff(1)
    df['Vol_Total_10m'] = df[COL_TOTAL].rolling(10).std()
    
    # íŒ¨í„´ ì ìˆ˜í™”
    df['Triple_Score'] = (df[COL_M14B]/500) + (df[COL_SUM]/600) + (df['Queue_Gap']/200)
    
    return df

def train():
    print("ğŸ”„ ë°ì´í„° ë¡œë”© ì¤‘...")
    try:
        df = pd.read_csv(TRAIN_FILE, on_bad_lines='skip')
    except FileNotFoundError:
        print("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1. Feature ìƒì„±
    print("ğŸ”„ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    df = create_features(df)
    
    # 2. Target ìƒì„± (í•µì‹¬!)
    # ëª©í‘œ: 10ë¶„ ë’¤ MAXê°’ - í˜„ì¬ê°’ = "ìƒìŠ¹í­(Delta)"ì„ ì˜ˆì¸¡
    indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=PRED_MINUTES)
    df['Future_Max'] = df[COL_TOTAL].rolling(window=indexer).max().shift(-1)
    
    # Target = ë¯¸ë˜ìµœëŒ€ê°’ - í˜„ì¬ê°’ (ì–¼ë§ˆë‚˜ ì˜¤ë¥¼ ê²ƒì¸ê°€?)
    df['Target_Delta'] = df['Future_Max'] - df[COL_TOTAL]
    
    # í•™ìŠµ ë³€ìˆ˜
    features = [
        COL_TOTAL, COL_M14B, COL_SUM, 'Queue_Gap',
        'Vel_Total_1m', 'Vel_Total_3m', 'Vel_Total_5m', 'Vel_Total_10m',
        'Vel_Gap_3m', 'Acc_Total', 'Vol_Total_10m', 'Triple_Score'
    ]
    
    # ê²°ì¸¡ì¹˜ ì œê±°
    df_train = df.dropna(subset=features + ['Target_Delta']).reset_index(drop=True)
    print(f"âœ… í•™ìŠµ ë°ì´í„°: {len(df_train):,}ê°œ")
    
    # XGBoost íšŒê·€(Regressor) ëª¨ë¸
    print("ğŸš€ ìˆ«ì ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    model = xgb.XGBRegressor(
        n_estimators=1000,       # ì •ë°€í•œ ê°’ ì˜ˆì¸¡ì„ ìœ„í•´ íŠ¸ë¦¬ ë§ì´
        max_depth=7,
        learning_rate=0.02,      # ì²œì²œíˆ ê¼¼ê¼¼í•˜ê²Œ í•™ìŠµ
        objective='reg:absoluteerror', # ì˜¤ì°¨ ì¤„ì´ê¸° (MAE)
        n_jobs=-1,
        random_state=42,
        tree_method='hist'
    )
    
    model.fit(df_train[features], df_train['Target_Delta'])
    
    # ì €ì¥
    with open('model_v13_reg.pkl', 'wb') as f: pickle.dump(model, f)
    with open('features_v13_reg.pkl', 'wb') as f: pickle.dump(features, f)
    
    print("\nâœ… í•™ìŠµ ì™„ë£Œ! (model_v13_reg.pkl)")

if __name__ == "__main__":
    train()
