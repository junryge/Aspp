#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ V11.5 í•™ìŠµ - ë³€í™”ëŸ‰(Delta) ì§‘ì¤‘ ê³µëµ
íŠ¹ì§•: ê³ ë¶€í•˜(1700) ë° 'ê¸‰ìƒìŠ¹(Delta í­ë°œ)' êµ¬ê°„ì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬
      ëª¨ë¸ì´ í˜„ì¬ê°’ì„ ë”°ë¼ê°€ëŠ” ê²Œ ì•„ë‹ˆë¼ 'ë³€í™”'ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ê°•ì œí•¨.
"""
import numpy as np
import pandas as pd
import xgboost as xgb
import pickle
import glob
import warnings
warnings.filterwarnings('ignore')

print("="*70)
print("ğŸš€ V11.5 í•™ìŠµ - ë³€í™”ëŸ‰(Delta) ì§‘ì¤‘ í•™ìŠµ")
print("="*70)

PRED_OFFSET = 10

def load_data(path_pattern):
    print(f"\nğŸ“‚ ë°ì´í„° ë¡œë”©: {path_pattern}")
    files = glob.glob(path_pattern)
    if not files: 
        print("âš  ì§€ì •ëœ íŒŒì¼ì´ ì—†ì–´ ê¸°ë³¸ íŒ¨í„´(M14_Q_*.CSV)ì„ ì°¾ìŠµë‹ˆë‹¤.")
        files = glob.glob('M14_Q_*.CSV')
    
    dfs = []
    for f in sorted(files):
        try: dfs.append(pd.read_csv(f, on_bad_lines='skip', encoding='utf-8'))
        except: dfs.append(pd.read_csv(f, on_bad_lines='skip', encoding='cp949'))
    
    if not dfs: raise ValueError("âŒ í•™ìŠµí•  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
    return pd.concat(dfs, ignore_index=True)

def create_vectorized_features(df):
    df = df.copy()
    cols = ['TOTALCNT', 'M14AM14B', 'M14AM14BSUM', 'M10AM14A', 
            'M14.QUE.ALL.TRANSPORT4MINOVERCNT', 'M14.QUE.OHT.OHTUTIL',
            'M14.QUE.ALL.CURRENTQCREATED', 'M14.QUE.ALL.CURRENTQCOMPLETED']
    for c in cols: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
    
    df['Gap'] = df['M14.QUE.ALL.CURRENTQCREATED'] - df['M14.QUE.ALL.CURRENTQCOMPLETED']
    
    # Lag & Rolling
    lags = [1, 3, 5, 10, 20]
    for lag in lags:
        df[f'Total_Lag_{lag}'] = df['TOTALCNT'].shift(lag)
        df[f'M14B_Lag_{lag}'] = df['M14AM14B'].shift(lag)
    
    windows = [10, 30, 60]
    for w in windows:
        df[f'Total_Mean_{w}'] = df['TOTALCNT'].rolling(w).mean()
        df[f'Total_Std_{w}'] = df['TOTALCNT'].rolling(w).std()

    # ğŸ”¥ [ì¤‘ìš”] ë³€í™”ëŸ‰ Feature ê°•í™” (ë”°ë¼ê°€ê¸° ë°©ì§€ìš©)
    # ê¸°ìš¸ê¸°(Slope)
    df['Slope_1'] = df['TOTALCNT'] - df['TOTALCNT'].shift(1)  # 1ë¶„ê°„ ë³€í™”ëŸ‰
    df['Slope_3'] = df['TOTALCNT'] - df['TOTALCNT'].shift(3)  # 3ë¶„ê°„ ë³€í™”ëŸ‰
    df['Slope_5'] = df['TOTALCNT'] - df['TOTALCNT'].shift(5)  # 5ë¶„ê°„ ë³€í™”ëŸ‰
    
    # ê°€ì†ë„(Accel): ë³€í™”ëŸ‰ì´ ë” ì»¤ì§€ê³  ìˆëŠ”ì§€?
    df['Accel_1'] = df['Slope_1'] - df['Slope_1'].shift(1)

    # íƒ€ê²Ÿ ìƒì„±
    df['Target_Total_Future'] = df['TOTALCNT'].shift(-PRED_OFFSET)
    df['Target_Delta'] = df['Target_Total_Future'] - df['TOTALCNT'] # ë³€í™”ëŸ‰ ì˜ˆì¸¡
    
    return df.dropna().reset_index(drop=True)

# 1. ì‹¤í–‰
df = load_data('M14_Q_*.CSV')
print("\nğŸ”„ í”¼ì²˜ ìƒì„± ì¤‘...")
df_features = create_vectorized_features(df)

# 2. í•™ìŠµ ì¤€ë¹„
exclude = ['CURRTIME', 'Target_Total_Future', 'Target_Delta']
cols = [c for c in df_features.columns if c not in exclude]
X = df_features[cols]
y_delta = df_features['Target_Delta']
y_total = df_features['Target_Total_Future'] # ê°€ì¤‘ì¹˜ìš©

# -------------------------------------------------------------
# ğŸ”¥ [í•µì‹¬ ìˆ˜ì •] ê°€ì¤‘ì¹˜ ì „ëµ ë³€ê²½
# -------------------------------------------------------------
weights = np.ones(len(y_total))

# 1. ê³ ë¶€í•˜ êµ¬ê°„ ì¤‘ìš” (ê¸°ì¡´ ìœ ì§€)
weights[y_total >= 1500] = 5
weights[y_total >= 1700] = 20

# 2. ê¸‰ìƒìŠ¹ êµ¬ê°„ ì¤‘ìš” (ì‹ ê·œ ì¶”ê°€)
# ë¯¸ë˜ì— +50 ì´ìƒ ê¸‰ë“±í•˜ëŠ” êµ¬ê°„ì€ ë†“ì¹˜ë©´ ì•ˆ ë¨!
weights[y_delta >= 50] = 10 

print(f"\nâš–ï¸ ê°€ì¤‘ì¹˜ ì ìš©: 1700+ êµ¬ê°„(20ë°°) & ê¸‰ìƒìŠ¹ êµ¬ê°„(10ë°°)")

print(f"\nğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ë³€í™”ëŸ‰ ì§‘ì¤‘)...")
model = xgb.XGBRegressor(
    n_estimators=2000,
    learning_rate=0.015,  # ì •ë°€ í•™ìŠµ
    max_depth=10,
    subsample=0.8,
    colsample_bytree=0.8,
    min_child_weight=1,
    n_jobs=4,
    device='cuda',        # GPU ì—†ìœ¼ë©´ 'cpu'ë¡œ ë³€ê²½
    tree_method='hist',
    random_state=42
)

# ë³€í™”ëŸ‰(Delta)ì„ í•™ìŠµ ëª©í‘œë¡œ ì„¤ì •
model.fit(X, y_delta, sample_weight=weights, verbose=False)

# ì €ì¥
with open('model_v11_delta_focused.pkl', 'wb') as f: pickle.dump(model, f)
with open('features_v11_delta_focused.pkl', 'wb') as f: pickle.dump(cols, f)
print("âœ… í•™ìŠµ ì™„ë£Œ! (model_v11_delta_focused.pkl)")
