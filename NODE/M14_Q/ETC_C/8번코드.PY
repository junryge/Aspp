#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
ğŸš€ 8ë‹¨ê³„: Feature Engineering ìˆ˜í–‰
================================================================================
7ë‹¨ê³„ ê³„íšì„œ ê¸°ë°˜ ~297ê°œ Feature ìƒì„±
- 12ê°œ í•µì‹¬ ì»¬ëŸ¼ Ã— ë“±ê¸‰ë³„ Feature
- ìƒí˜¸ì‘ìš© Feature 25ê°œ
- TOTALCNT ìì²´ Feature 15ê°œ
================================================================================
"""

import numpy as np
import pandas as pd
import glob
import os
import warnings
from datetime import datetime
import gc

warnings.filterwarnings('ignore')

print("="*80)
print("ğŸš€ 8ë‹¨ê³„: Feature Engineering ìˆ˜í–‰")
print("   7ë‹¨ê³„ ê³„íšì„œ ê¸°ë°˜ ~297ê°œ Feature ìƒì„±")
print("="*80)


# ==============================================================================
# 1. ì„¤ì •
# ==============================================================================

# ì‹œí€€ìŠ¤ ì„¤ì •
SEQ_LEN = 280  # 280ë¶„ ì‹œí€€ìŠ¤
PRED_OFFSETS = [10, 15, 25]  # ì˜ˆì¸¡ ì˜¤í”„ì…‹ (ë¶„)

# í•µì‹¬ ì»¬ëŸ¼ ì •ì˜ (12ê°œ)
CORE_COLUMNS = {
    # ê¸°ì¡´ 6ê°œ
    'M14AM14B': {'grade': 'S', 'thresholds': [450, 500, 520, 540, 560]},
    'M14AM14BSUM': {'grade': 'S', 'thresholds': [550, 600, 620, 650, 700]},
    'M10AM14A': {'grade': 'A', 'thresholds': [45, 50, 55, 60]},
    'M14.QUE.OHT.OHTUTIL': {'grade': 'A', 'thresholds': [80, 85, 90, 95]},
    'M14.QUE.ALL.TRANSPORT4MINOVERCNT': {'grade': 'B', 'thresholds': [100, 120, 151, 180]},
    # queue_gapì€ íŒŒìƒ (ì•„ë˜ì—ì„œ ìƒì„±)
    
    # ì‹ ê·œ 6ê°œ
    'M14.QUE.SENDFAB.VERTICALQUEUECOUNT': {'grade': 'S', 'thresholds': [150, 200, 230, 250, 280]},
    'M14AM16SUM': {'grade': 'A', 'thresholds': [150, 180, 200, 220]},
    'M16M14A': {'grade': 'A', 'thresholds': [80, 100, 110, 120]},
    'M14.QUE.CNV.SOUTHCURRENTQCNT': {'grade': 'A', 'thresholds': [40, 50, 55]},
    'M14.QUE.CNV.NORTHCURRENTQCNT': {'grade': 'A', 'thresholds': [45, 50, 55]},
    'M14.QUE.OHT.CURRENTOHTQCNT': {'grade': 'A', 'thresholds': [800, 900, 950]},
}

# queue_gap ì„¤ì • (íŒŒìƒë³€ìˆ˜)
QUEUE_GAP_CONFIG = {
    'grade': 'B',
    'thresholds': [150, 200, 250, 300, 350]
}


# ==============================================================================
# 2. ë°ì´í„° ë¡œë”©
# ==============================================================================

def load_data(path_pattern='*.CSV'):
    """CSV íŒŒì¼ ë¡œë“œ"""
    print(f"\nğŸ“‚ ë°ì´í„° ë¡œë”©: {path_pattern}")
    
    files = glob.glob(path_pattern)
    if not files:
        files = glob.glob('data/*.CSV') + glob.glob('M14_Q_*.CSV')
    
    if not files:
        print("âš ï¸ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    dfs = []
    for f in sorted(files):
        try:
            df = pd.read_csv(f, on_bad_lines='skip', encoding='utf-8')
            print(f"  âœ… {os.path.basename(f)}: {len(df):,}í–‰")
            dfs.append(df)
        except UnicodeDecodeError:
            try:
                df = pd.read_csv(f, on_bad_lines='skip', encoding='cp949')
                print(f"  âœ… {os.path.basename(f)} (cp949): {len(df):,}í–‰")
                dfs.append(df)
            except Exception as e:
                print(f"  âŒ {f}: {e}")
    
    if not dfs:
        return None
    
    df_all = pd.concat(dfs, ignore_index=True)
    print(f"\nğŸ“Š ì´ ë°ì´í„°: {len(df_all):,}í–‰")
    return df_all


def preprocess_data(df):
    """ë°ì´í„° ì „ì²˜ë¦¬"""
    print("\nğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬...")
    
    df = df.copy()
    
    # CURRTIME íŒŒì‹±
    if 'CURRTIME' in df.columns:
        df['CURRTIME'] = df['CURRTIME'].astype(str).str.strip()
        df = df[df['CURRTIME'].str.len() == 12].copy()
        df['CURRTIME'] = pd.to_datetime(df['CURRTIME'], format='%Y%m%d%H%M', errors='coerce')
        df = df.dropna(subset=['CURRTIME']).copy()
        df = df.sort_values('CURRTIME').reset_index(drop=True)
    
    # ìˆ«ìí˜• ë³€í™˜
    exclude_cols = ['CURRTIME']
    for col in df.columns:
        if col not in exclude_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)
    
    # íŒŒìƒë³€ìˆ˜ ìƒì„±
    if 'M14.QUE.ALL.CURRENTQCREATED' in df.columns and 'M14.QUE.ALL.CURRENTQCOMPLETED' in df.columns:
        df['queue_gap'] = df['M14.QUE.ALL.CURRENTQCREATED'] - df['M14.QUE.ALL.CURRENTQCOMPLETED']
    else:
        df['queue_gap'] = 0
    
    if 'M14B.QUE.ALL.CURRENTQCREATED' in df.columns and 'M14B.QUE.ALL.CURRENTQCOMPLETED' in df.columns:
        df['queue_gap_B'] = df['M14B.QUE.ALL.CURRENTQCREATED'] - df['M14B.QUE.ALL.CURRENTQCOMPLETED']
    else:
        df['queue_gap_B'] = 0
    
    print(f"  âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df):,}í–‰")
    return df


# ==============================================================================
# 3. Feature ìƒì„± í•¨ìˆ˜ë“¤
# ==============================================================================

def create_stat_features(seq, prefix, grade):
    """í†µê³„ Feature ìƒì„±"""
    features = {}
    
    features[f'{prefix}_mean'] = np.mean(seq)
    features[f'{prefix}_max'] = np.max(seq)
    features[f'{prefix}_min'] = np.min(seq)
    features[f'{prefix}_std'] = np.std(seq)
    
    if grade == 'S':
        features[f'{prefix}_median'] = np.median(seq)
        features[f'{prefix}_skew'] = pd.Series(seq).skew() if len(seq) > 2 else 0
    
    return features


def create_lag_features(seq, prefix, grade):
    """ì‹œì°¨(Lag) Feature ìƒì„±"""
    features = {}
    
    features[f'{prefix}_current'] = seq[-1]
    features[f'{prefix}_last5'] = np.mean(seq[-5:])
    features[f'{prefix}_last10'] = np.mean(seq[-10:])
    features[f'{prefix}_last20'] = np.mean(seq[-20:])
    
    if grade in ['S', 'A']:
        features[f'{prefix}_last30'] = np.mean(seq[-30:])
    
    if grade == 'S':
        features[f'{prefix}_last60'] = np.mean(seq[-60:])
    
    return features


def create_trend_features(seq, prefix, grade):
    """ì¶”ì„¸ Feature ìƒì„±"""
    features = {}
    seq_len = len(seq)
    
    # slope (ì „ì²´ ê¸°ìš¸ê¸°)
    try:
        features[f'{prefix}_slope'] = np.polyfit(np.arange(seq_len), seq, 1)[0]
    except:
        features[f'{prefix}_slope'] = 0
    
    # trend (ìµœê·¼ ë³€í™”ëŸ‰)
    features[f'{prefix}_trend10'] = seq[-1] - seq[-10] if len(seq) >= 10 else 0
    
    if grade in ['S', 'A']:
        features[f'{prefix}_trend20'] = seq[-1] - seq[-20] if len(seq) >= 20 else 0
    
    if grade == 'S':
        features[f'{prefix}_trend5'] = seq[-1] - seq[-5] if len(seq) >= 5 else 0
        # ê°€ì†ë„ (2ì°¨ ë¯¸ë¶„)
        if len(seq) >= 3:
            diff1 = seq[-1] - seq[-2]
            diff2 = seq[-2] - seq[-3]
            features[f'{prefix}_accel'] = diff1 - diff2
        else:
            features[f'{prefix}_accel'] = 0
    
    return features


def create_threshold_features(seq, prefix, thresholds):
    """ì„ê³„ê°’ Feature ìƒì„±"""
    features = {}
    
    for th in thresholds:
        features[f'{prefix}_over_{th}'] = np.sum(seq > th)
    
    return features


def create_rolling_features(seq, prefix, grade):
    """ë¡¤ë§ í†µê³„ Feature ìƒì„±"""
    features = {}
    
    windows = [10, 20, 30]
    if grade == 'S':
        windows = [5, 10, 20, 30, 60]
    
    for w in windows:
        if len(seq) >= w:
            rolling_mean = np.mean(seq[-w:])
            rolling_std = np.std(seq[-w:])
            features[f'{prefix}_roll{w}_mean'] = rolling_mean
            features[f'{prefix}_roll{w}_std'] = rolling_std
    
    return features


def create_special_features(seq, prefix, grade):
    """íŠ¹ìˆ˜ Feature ìƒì„±"""
    features = {}
    
    if grade in ['S', 'B']:  # Së“±ê¸‰ ë˜ëŠ” queue_gap(B)
        # ê¸‰ë“± ê°ì§€ (ìµœê·¼ 10ë¶„ ëŒ€ë¹„ í˜„ì¬ê°’ ê¸‰ë“±)
        recent_mean = np.mean(seq[-10:])
        if recent_mean > 0:
            surge_ratio = seq[-1] / recent_mean
            features[f'{prefix}_surge'] = 1 if surge_ratio > 1.3 else 0
        else:
            features[f'{prefix}_surge'] = 0
    
    if grade == 'S':
        # í”¼í¬ ì¹´ìš´íŠ¸ (ìƒìœ„ 10% ì´ˆê³¼ íšŸìˆ˜)
        threshold_90 = np.percentile(seq, 90)
        features[f'{prefix}_peak_count'] = np.sum(seq > threshold_90)
        
        # ë³€ë™ì„± (í‘œì¤€í¸ì°¨ / í‰ê· )
        mean_val = np.mean(seq)
        if mean_val > 0:
            features[f'{prefix}_volatility'] = np.std(seq) / mean_val
        else:
            features[f'{prefix}_volatility'] = 0
    
    if prefix == 'queue_gap':
        # ëˆ„ì  ì¦ê°€ëŸ‰
        features[f'{prefix}_cumsum'] = np.sum(np.diff(seq)[np.diff(seq) > 0])
        
        # ì—°ì† ì¦ê°€ íšŸìˆ˜
        diff = np.diff(seq)
        consecutive = 0
        max_consecutive = 0
        for d in diff:
            if d > 0:
                consecutive += 1
                max_consecutive = max(max_consecutive, consecutive)
            else:
                consecutive = 0
        features[f'{prefix}_consec_increase'] = max_consecutive
    
    return features


# ==============================================================================
# 4. ì»¬ëŸ¼ë³„ Feature ìƒì„±
# ==============================================================================

def create_column_features(seq, col_name, config):
    """ë‹¨ì¼ ì»¬ëŸ¼ì˜ ëª¨ë“  Feature ìƒì„±"""
    features = {}
    grade = config['grade']
    thresholds = config['thresholds']
    
    # ì§§ì€ prefix ìƒì„±
    prefix = col_name.replace('M14.QUE.', '').replace('M14B.QUE.', 'B_')
    prefix = prefix.replace('.', '_').replace('CURRENTQCNT', 'QCNT')
    prefix = prefix[:30]  # ìµœëŒ€ 30ì
    
    # ê° ì¢…ë¥˜ë³„ Feature ìƒì„±
    features.update(create_stat_features(seq, prefix, grade))
    features.update(create_lag_features(seq, prefix, grade))
    features.update(create_trend_features(seq, prefix, grade))
    features.update(create_threshold_features(seq, prefix, thresholds))
    features.update(create_rolling_features(seq, prefix, grade))
    features.update(create_special_features(seq, prefix, grade))
    
    return features


# ==============================================================================
# 5. ìƒí˜¸ì‘ìš© Feature ìƒì„±
# ==============================================================================

def create_interaction_features(row_dict):
    """ìƒí˜¸ì‘ìš© Feature ìƒì„± (25ê°œ)"""
    features = {}
    
    # í˜„ì¬ê°’ ì¶”ì¶œ
    m14b = row_dict.get('M14AM14B', np.zeros(1))[-1]
    m14bsum = row_dict.get('M14AM14BSUM', np.zeros(1))[-1]
    m10a = row_dict.get('M10AM14A', np.zeros(1))[-1]
    m16m14a = row_dict.get('M16M14A', np.zeros(1))[-1]
    m14am16sum = row_dict.get('M14AM16SUM', np.zeros(1))[-1]
    vertical = row_dict.get('M14.QUE.SENDFAB.VERTICALQUEUECOUNT', np.zeros(1))[-1]
    south = row_dict.get('M14.QUE.CNV.SOUTHCURRENTQCNT', np.zeros(1))[-1]
    north = row_dict.get('M14.QUE.CNV.NORTHCURRENTQCNT', np.zeros(1))[-1]
    ohtutil = row_dict.get('M14.QUE.OHT.OHTUTIL', np.zeros(1))[-1]
    ohtqcnt = row_dict.get('M14.QUE.OHT.CURRENTOHTQCNT', np.zeros(1))[-1]
    transport = row_dict.get('M14.QUE.ALL.TRANSPORT4MINOVERCNT', np.zeros(1))[-1]
    gap = row_dict.get('queue_gap', np.zeros(1))[-1]
    
    # gap trend (ìµœê·¼ 10ë¶„ ë³€í™”)
    gap_seq = row_dict.get('queue_gap', np.zeros(10))
    gap_trend10 = gap_seq[-1] - gap_seq[-10] if len(gap_seq) >= 10 else 0
    
    # =========================================================================
    # íŒ¨í„´ Feature (ê¸°ì¡´ 4ê°œ + ì‹ ê·œ 7ê°œ)
    # =========================================================================
    
    # ê¸°ì¡´ íŒ¨í„´
    features['gold_strict'] = 1 if (m14b > 540 and m14bsum > 620) else 0
    features['gold_normal'] = 1 if (m14b > 520 and m14bsum > 600) else 0
    features['triple_check'] = 1 if (m14b > 520 and m14bsum > 600 and gap > 250) else 0
    features['quad_check'] = 1 if (m14b > 520 and m14bsum > 600 and gap > 250 and transport > 145) else 0
    
    # ì‹ ê·œ íŒ¨í„´
    features['vertical_gold'] = 1 if (vertical > 230 and m14b > 500) else 0
    features['cnv_imbalance'] = 1 if abs(south - north) > 20 else 0
    features['cnv_total_high'] = 1 if (south + north) > 100 else 0
    features['oht_overload'] = 1 if (ohtutil > 90 and ohtqcnt > 900) else 0
    features['m16_surge'] = 1 if (m16m14a > 110 and m14am16sum > 200) else 0
    features['inflow_surge'] = 1 if (m10a > 55 and m16m14a > 100) else 0
    features['queue_accel_danger'] = 1 if (gap > 200 and gap_trend10 > 30) else 0
    
    # =========================================================================
    # ê³±ì…ˆ/ë¹„ìœ¨ Feature (14ê°œ)
    # =========================================================================
    
    features['m14b_x_sum'] = m14b * m14bsum / 1000
    features['m14b_x_vertical'] = m14b * vertical / 1000
    features['gap_x_m14b'] = gap * m14b / 1000
    features['gap_x_oht'] = gap * ohtqcnt / 10000
    features['cnv_ratio'] = south / (north + 1)
    features['cnv_total'] = south + north
    features['inflow_total'] = m10a + m16m14a
    features['inflow_ratio'] = m16m14a / (m10a + 1)
    features['oht_efficiency'] = ohtqcnt / (ohtutil + 1)
    features['m14_m16_ratio'] = m14bsum / (m14am16sum + 1)
    features['m14b_x_sum_mean'] = np.mean(row_dict.get('M14AM14B', [0]) * row_dict.get('M14AM14BSUM', [0])) / 1000
    features['ratio_m14b_total'] = m14b / (row_dict.get('TOTALCNT', [1])[-1] + 1)
    features['ratio_sum_total'] = m14bsum / (row_dict.get('TOTALCNT', [1])[-1] + 1)
    features['gap_x_trans'] = gap * transport / 100
    
    return features


# ==============================================================================
# 6. TOTALCNT ìì²´ Feature ìƒì„±
# ==============================================================================

def create_totalcnt_features(seq):
    """TOTALCNT ìì²´ Feature ìƒì„± (15ê°œ)"""
    features = {}
    
    features['total_mean'] = np.mean(seq)
    features['total_max'] = np.max(seq)
    features['total_min'] = np.min(seq)
    features['total_std'] = np.std(seq)
    features['total_median'] = np.median(seq)
    
    features['total_current'] = seq[-1]
    features['total_last5'] = np.mean(seq[-5:])
    features['total_last10'] = np.mean(seq[-10:])
    features['total_last30'] = np.mean(seq[-30:])
    
    try:
        features['total_slope'] = np.polyfit(np.arange(len(seq)), seq, 1)[0]
    except:
        features['total_slope'] = 0
    
    features['total_trend10'] = seq[-1] - seq[-10]
    features['total_trend20'] = seq[-1] - seq[-20]
    
    features['total_over_1600'] = np.sum(seq >= 1600)
    features['total_over_1650'] = np.sum(seq >= 1650)
    features['total_over_1700'] = np.sum(seq >= 1700)
    
    return features


# ==============================================================================
# 7. ì „ì²´ Feature ìƒì„± (ì‹œí€€ìŠ¤ â†’ Feature ë²¡í„°)
# ==============================================================================

def create_all_features(row_dict):
    """ëª¨ë“  Feature ìƒì„± (í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ â†’ í•˜ë‚˜ì˜ Feature ë²¡í„°)"""
    features = {}
    
    # 1. ê° í•µì‹¬ ì»¬ëŸ¼ë³„ Feature
    for col_name, config in CORE_COLUMNS.items():
        if col_name in row_dict:
            seq = np.array(row_dict[col_name])
            col_features = create_column_features(seq, col_name, config)
            features.update(col_features)
    
    # 2. queue_gap Feature (íŒŒìƒë³€ìˆ˜)
    if 'queue_gap' in row_dict:
        seq = np.array(row_dict['queue_gap'])
        gap_features = create_column_features(seq, 'queue_gap', QUEUE_GAP_CONFIG)
        features.update(gap_features)
    
    # 3. ìƒí˜¸ì‘ìš© Feature
    interaction_features = create_interaction_features(row_dict)
    features.update(interaction_features)
    
    # 4. TOTALCNT ìì²´ Feature
    if 'TOTALCNT' in row_dict:
        totalcnt_features = create_totalcnt_features(np.array(row_dict['TOTALCNT']))
        features.update(totalcnt_features)
    
    return features


# ==============================================================================
# 8. ì „ì²´ ë°ì´í„°ì…‹ Feature ìƒì„±
# ==============================================================================

def generate_feature_dataset(df, pred_offset=10):
    """ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ Feature ìƒì„±"""
    print(f"\nğŸ”„ Feature ìƒì„± ì‹œì‘ (ì˜ˆì¸¡ ì˜¤í”„ì…‹: {pred_offset}ë¶„)")
    print(f"   ì‹œí€€ìŠ¤ ê¸¸ì´: {SEQ_LEN}ë¶„")
    
    results = []
    total = len(df) - SEQ_LEN - pred_offset
    
    # í•„ìš”í•œ ì»¬ëŸ¼ ëª©ë¡
    required_cols = list(CORE_COLUMNS.keys()) + ['TOTALCNT', 'queue_gap', 
                                                  'M14.QUE.ALL.CURRENTQCREATED', 
                                                  'M14.QUE.ALL.CURRENTQCOMPLETED']
    
    # ì—†ëŠ” ì»¬ëŸ¼ í™•ì¸
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        print(f"  âš ï¸ ëˆ„ë½ ì»¬ëŸ¼: {missing}")
    
    for i in range(SEQ_LEN, len(df) - pred_offset):
        # ì‹œí€€ìŠ¤ ë°ì´í„° ì¶”ì¶œ
        row_dict = {}
        
        for col in df.columns:
            if col not in ['CURRTIME']:
                row_dict[col] = df[col].iloc[i-SEQ_LEN:i].values
        
        # Feature ìƒì„±
        features = create_all_features(row_dict)
        
        # ë©”íƒ€ ì •ë³´ ì¶”ê°€
        if 'CURRTIME' in df.columns:
            features['CURRTIME'] = df['CURRTIME'].iloc[i-1]
        
        features['current_TOTALCNT'] = df['TOTALCNT'].iloc[i-1]
        features['target_TOTALCNT'] = df['TOTALCNT'].iloc[i + pred_offset - 1]
        features['target_delta'] = features['target_TOTALCNT'] - features['current_TOTALCNT']
        features['is_danger'] = 1 if features['target_TOTALCNT'] >= 1700 else 0
        
        results.append(features)
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥
        if (i - SEQ_LEN) % 5000 == 0:
            print(f"  ì§„í–‰: {i-SEQ_LEN:,}/{total:,} ({(i-SEQ_LEN)/total*100:.1f}%)")
            gc.collect()
    
    df_features = pd.DataFrame(results)
    print(f"\nâœ… Feature ìƒì„± ì™„ë£Œ!")
    print(f"   ì´ ìƒ˜í”Œ: {len(df_features):,}ê°œ")
    print(f"   ì´ Feature: {len(df_features.columns)}ê°œ")
    
    return df_features


# ==============================================================================
# 9. ë©”ì¸ ì‹¤í–‰
# ==============================================================================

if __name__ == '__main__':
    # 1. ë°ì´í„° ë¡œë“œ
    df = load_data('*.CSV')
    
    if df is None:
        print("\nâš ï¸ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ì‚¬ìš©ë²•: ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— CSV íŒŒì¼ì„ ë‘ì„¸ìš”.")
        exit(1)
    
    # 2. ì „ì²˜ë¦¬
    df = preprocess_data(df)
    
    # 3. Feature ìƒì„± (10ë¶„ ì˜ˆì¸¡)
    df_features = generate_feature_dataset(df, pred_offset=10)
    
    # 4. ì €ì¥
    output_file = 'step8_features_10min.csv'
    df_features.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}")
    
    # 5. Feature ëª©ë¡ ì €ì¥
    feature_cols = [c for c in df_features.columns if c not in ['CURRTIME', 'current_TOTALCNT', 
                                                                  'target_TOTALCNT', 'target_delta', 'is_danger']]
    with open('step8_feature_list.txt', 'w', encoding='utf-8') as f:
        f.write(f"ì´ Feature ìˆ˜: {len(feature_cols)}\n\n")
        for i, col in enumerate(feature_cols, 1):
            f.write(f"{i:3d}. {col}\n")
    
    print(f"ğŸ“‹ Feature ëª©ë¡ ì €ì¥: step8_feature_list.txt")
    
    # 6. ìš”ì•½ í†µê³„
    print("\n" + "="*80)
    print("ğŸ“Š ìƒì„± ê²°ê³¼ ìš”ì•½")
    print("="*80)
    print(f"  ì´ ìƒ˜í”Œ ìˆ˜: {len(df_features):,}ê°œ")
    print(f"  ì´ Feature ìˆ˜: {len(feature_cols)}ê°œ")
    print(f"  1700+ ìƒ˜í”Œ ìˆ˜: {df_features['is_danger'].sum():,}ê°œ ({df_features['is_danger'].mean()*100:.2f}%)")
    print(f"  íƒ€ê²Ÿ í‰ê· : {df_features['target_TOTALCNT'].mean():.2f}")
    print(f"  íƒ€ê²Ÿ í‘œì¤€í¸ì°¨: {df_features['target_TOTALCNT'].std():.2f}")
    
    print("\nâœ… 8ë‹¨ê³„ ì™„ë£Œ!")
    print("   â†’ 9ë‹¨ê³„: ìƒì„±ëœ Featureë¡œ 2ì°¨ Selection ì§„í–‰")