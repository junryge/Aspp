#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
ğŸš€ 9ë‹¨ê³„: Feature Selection 2ì°¨
================================================================================
346ê°œ Feature â†’ 80~120ê°œ ì¶•ì†Œ
- íƒ€ê²Ÿ ìƒê´€ê´€ê³„ ë¶„ì„
- Feature ê°„ ë‹¤ì¤‘ê³µì„ ì„± ì œê±°
- Tree Importance (XGBoost)
- LASSO
- ìµœì¢… ì„ íƒ
================================================================================
"""

import numpy as np
import pandas as pd
import warnings
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor
from sklearn.linear_model import LassoCV
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import mutual_info_regression
import gc

warnings.filterwarnings('ignore')

print("="*80)
print("ğŸš€ 9ë‹¨ê³„: Feature Selection 2ì°¨")
print("   346ê°œ Feature â†’ 80~120ê°œ ì¶•ì†Œ")
print("="*80)

# ==============================================================================
# 1. ë°ì´í„° ë¡œë“œ
# ==============================================================================

print("\nğŸ“‚ ë°ì´í„° ë¡œë”©...")
INPUT_FILE = 'step8_features_10min.csv'

# ë©”íƒ€ ì»¬ëŸ¼ (ì œì™¸í•  ê²ƒë“¤)
META_COLS = ['CURRTIME', 'current_TOTALCNT', 'target_TOTALCNT', 'target_delta', 'is_danger']

# ìƒ˜í”Œë§í•´ì„œ ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½)
df = pd.read_csv(INPUT_FILE)
print(f"  âœ… ì „ì²´ ë°ì´í„°: {len(df):,}í–‰")

# Feature ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
feature_cols = [c for c in df.columns if c not in META_COLS]
print(f"  âœ… Feature ìˆ˜: {len(feature_cols)}ê°œ")

# X, y ë¶„ë¦¬
X = df[feature_cols].copy()
y = df['target_TOTALCNT'].copy()

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
X = X.fillna(0)
X = X.replace([np.inf, -np.inf], 0)

del df
gc.collect()

# ==============================================================================
# 2. íƒ€ê²Ÿ ìƒê´€ê´€ê³„ ë¶„ì„
# ==============================================================================

print("\nğŸ“Š 1ë‹¨ê³„: íƒ€ê²Ÿ ìƒê´€ê´€ê³„ ë¶„ì„...")

correlations = {}
for col in feature_cols:
    try:
        corr = X[col].corr(y)
        if pd.notna(corr):
            correlations[col] = abs(corr)
    except:
        correlations[col] = 0

# ì •ë ¬
corr_sorted = sorted(correlations.items(), key=lambda x: x[1], reverse=True)

print(f"\n  ğŸ“ˆ ìƒê´€ê´€ê³„ TOP 30:")
for i, (col, corr) in enumerate(corr_sorted[:30], 1):
    print(f"    {i:2d}. {col[:50]:50s} {corr:.4f}")

# ìƒê´€ê´€ê³„ 0.1 ì´ìƒë§Œ ì„ íƒ
high_corr_features = [col for col, corr in corr_sorted if corr >= 0.1]
print(f"\n  âœ… ìƒê´€ê³„ìˆ˜ >= 0.1: {len(high_corr_features)}ê°œ")

# ==============================================================================
# 3. ë‹¤ì¤‘ê³µì„ ì„± ì œê±°
# ==============================================================================

print("\nğŸ“Š 2ë‹¨ê³„: ë‹¤ì¤‘ê³µì„ ì„± ì œê±°...")

def remove_multicollinearity(X_subset, threshold=0.95):
    """ìƒê´€ê³„ìˆ˜ ë†’ì€ Feature ìŒ ì¤‘ í•˜ë‚˜ ì œê±°"""
    corr_matrix = X_subset.corr().abs()
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    
    to_drop = set()
    for col in upper.columns:
        high_corr = upper[col][upper[col] > threshold].index.tolist()
        for hc in high_corr:
            # íƒ€ê²Ÿ ìƒê´€ì´ ë‚®ì€ ìª½ ì œê±°
            if correlations.get(col, 0) >= correlations.get(hc, 0):
                to_drop.add(hc)
            else:
                to_drop.add(col)
    
    return list(to_drop)

# ìƒê´€ê´€ê³„ ë†’ì€ Featureë“¤ë§Œ ëŒ€ìƒ
X_high = X[high_corr_features]
to_drop = remove_multicollinearity(X_high, threshold=0.95)
print(f"  âš ï¸ ë‹¤ì¤‘ê³µì„ ì„± ì œê±°: {len(to_drop)}ê°œ")

after_multicollinearity = [c for c in high_corr_features if c not in to_drop]
print(f"  âœ… ë‚¨ì€ Feature: {len(after_multicollinearity)}ê°œ")

# ==============================================================================
# 4. Tree Importance (XGBoost)
# ==============================================================================

print("\nğŸ“Š 3ë‹¨ê³„: Tree Importance (XGBoost)...")

try:
    import xgboost as xgb
    
    # ìƒ˜í”Œë§ (ì†ë„)
    sample_size = min(50000, len(X))
    idx = np.random.choice(len(X), sample_size, replace=False)
    X_sample = X.iloc[idx]
    y_sample = y.iloc[idx]
    
    model = xgb.XGBRegressor(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        n_jobs=-1,
        random_state=42
    )
    model.fit(X_sample, y_sample, verbose=False)
    
    importances = dict(zip(feature_cols, model.feature_importances_))
    imp_sorted = sorted(importances.items(), key=lambda x: x[1], reverse=True)
    
    print(f"\n  ğŸ“ˆ XGBoost Importance TOP 30:")
    for i, (col, imp) in enumerate(imp_sorted[:30], 1):
        print(f"    {i:2d}. {col[:50]:50s} {imp:.4f}")
    
    # Importance > 0.001
    xgb_features = [col for col, imp in imp_sorted if imp >= 0.001]
    print(f"\n  âœ… Importance >= 0.001: {len(xgb_features)}ê°œ")
    
except Exception as e:
    print(f"  âš ï¸ XGBoost ì˜¤ë¥˜: {e}")
    xgb_features = after_multicollinearity

gc.collect()

# ==============================================================================
# 5. ExtraTrees Importance
# ==============================================================================

print("\nğŸ“Š 4ë‹¨ê³„: ExtraTrees Importance...")

try:
    model_et = ExtraTreesRegressor(
        n_estimators=100,
        max_depth=10,
        n_jobs=-1,
        random_state=42
    )
    model_et.fit(X_sample, y_sample)
    
    et_importances = dict(zip(feature_cols, model_et.feature_importances_))
    et_sorted = sorted(et_importances.items(), key=lambda x: x[1], reverse=True)
    
    print(f"\n  ğŸ“ˆ ExtraTrees Importance TOP 30:")
    for i, (col, imp) in enumerate(et_sorted[:30], 1):
        print(f"    {i:2d}. {col[:50]:50s} {imp:.4f}")
    
    et_features = [col for col, imp in et_sorted if imp >= 0.001]
    print(f"\n  âœ… Importance >= 0.001: {len(et_features)}ê°œ")
    
except Exception as e:
    print(f"  âš ï¸ ExtraTrees ì˜¤ë¥˜: {e}")
    et_features = xgb_features

gc.collect()

# ==============================================================================
# 6. LASSO
# ==============================================================================

print("\nğŸ“Š 5ë‹¨ê³„: LASSO Selection...")

try:
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_sample)
    
    lasso = LassoCV(cv=5, random_state=42, n_jobs=-1, max_iter=1000)
    lasso.fit(X_scaled, y_sample)
    
    lasso_coef = dict(zip(feature_cols, np.abs(lasso.coef_)))
    lasso_sorted = sorted(lasso_coef.items(), key=lambda x: x[1], reverse=True)
    
    print(f"\n  ğŸ“ˆ LASSO Coefficient TOP 30:")
    for i, (col, coef) in enumerate(lasso_sorted[:30], 1):
        print(f"    {i:2d}. {col[:50]:50s} {coef:.4f}")
    
    lasso_features = [col for col, coef in lasso_sorted if coef > 0]
    print(f"\n  âœ… Non-zero coefficient: {len(lasso_features)}ê°œ")
    
except Exception as e:
    print(f"  âš ï¸ LASSO ì˜¤ë¥˜: {e}")
    lasso_features = []

gc.collect()

# ==============================================================================
# 7. ì•™ìƒë¸” ì„ íƒ (2ê°œ ì´ìƒ ë°©ë²•ì—ì„œ ì„ íƒ)
# ==============================================================================

print("\nğŸ“Š 6ë‹¨ê³„: ì•™ìƒë¸” ì„ íƒ...")

# ê° ë°©ë²•ì—ì„œ TOP 100 ì„ íƒ
top_corr = [c for c, _ in corr_sorted[:100]]
top_xgb = [c for c, _ in imp_sorted[:100]] if 'imp_sorted' in dir() else []
top_et = [c for c, _ in et_sorted[:100]] if 'et_sorted' in dir() else []
top_lasso = [c for c, _ in lasso_sorted[:100]] if 'lasso_sorted' in dir() else []

# ì¹´ìš´íŠ¸
from collections import Counter
all_features = top_corr + top_xgb + top_et + top_lasso
feature_counts = Counter(all_features)

# 2ê°œ ì´ìƒì—ì„œ ì„ íƒëœ Feature
ensemble_features = [f for f, count in feature_counts.items() if count >= 2]
print(f"  âœ… 2ê°œ+ ë°©ë²•ì—ì„œ ì„ íƒ: {len(ensemble_features)}ê°œ")

# 3ê°œ ì´ìƒì—ì„œ ì„ íƒëœ Feature
strong_features = [f for f, count in feature_counts.items() if count >= 3]
print(f"  âœ… 3ê°œ+ ë°©ë²•ì—ì„œ ì„ íƒ: {len(strong_features)}ê°œ")

# ==============================================================================
# 8. ìµœì¢… ì„ íƒ
# ==============================================================================

print("\n" + "="*80)
print("ğŸ“‹ ìµœì¢… Feature ì„ íƒ")
print("="*80)

# ìµœì¢… ì„ íƒ ê¸°ì¤€:
# 1. 3ê°œ+ ë°©ë²•ì—ì„œ ì„ íƒëœ Feature (strong)
# 2. ë‹¤ì¤‘ê³µì„ ì„± ì œê±° í›„ ë‚¨ì€ ê²ƒ
# 3. ìƒí˜¸ì‘ìš© íŒ¨í„´ FeatureëŠ” ë³´ì¡´

# ìƒí˜¸ì‘ìš© íŒ¨í„´ Feature (ë¬´ì¡°ê±´ í¬í•¨)
interaction_features = [
    'gold_strict', 'gold_normal', 'triple_check', 'quad_check',
    'vertical_gold', 'cnv_imbalance', 'cnv_total_high', 'oht_overload',
    'm16_surge', 'inflow_surge', 'queue_accel_danger'
]

# ìµœì¢… ì„ íƒ
final_features = set(strong_features)

# ìƒí˜¸ì‘ìš© íŒ¨í„´ ì¶”ê°€
for f in interaction_features:
    if f in feature_cols:
        final_features.add(f)

# ë‹¤ì¤‘ê³µì„ ì„± ì œê±°
final_features = [f for f in final_features if f not in to_drop]

# ìƒê´€ê´€ê³„ìˆœ ì •ë ¬
final_features = sorted(final_features, key=lambda x: correlations.get(x, 0), reverse=True)

print(f"\nğŸ¯ ìµœì¢… ì„ íƒ: {len(final_features)}ê°œ")
print("\n" + "-"*80)

for i, col in enumerate(final_features, 1):
    corr = correlations.get(col, 0)
    xgb_imp = importances.get(col, 0) if 'importances' in dir() else 0
    count = feature_counts.get(col, 0)
    print(f"  {i:3d}. {col[:55]:55s} ìƒê´€:{corr:.3f} XGB:{xgb_imp:.3f} ì„ íƒ:{count}íšŒ")

# ==============================================================================
# 9. ê²°ê³¼ ì €ì¥
# ==============================================================================

print("\nğŸ’¾ ê²°ê³¼ ì €ì¥...")

# Feature ëª©ë¡ ì €ì¥
with open('step9_selected_features.txt', 'w', encoding='utf-8') as f:
    f.write(f"9ë‹¨ê³„ Feature Selection ê²°ê³¼\n")
    f.write(f"="*60 + "\n")
    f.write(f"ì´ ì„ íƒ: {len(final_features)}ê°œ\n\n")
    
    for i, col in enumerate(final_features, 1):
        corr = correlations.get(col, 0)
        f.write(f"{i:3d}. {col} (ìƒê´€:{corr:.4f})\n")

print(f"  âœ… step9_selected_features.txt ì €ì¥")

# ìƒì„¸ ê²°ê³¼ ì €ì¥
results_df = pd.DataFrame({
    'feature': feature_cols,
    'correlation': [correlations.get(c, 0) for c in feature_cols],
    'xgb_importance': [importances.get(c, 0) for c in feature_cols] if 'importances' in dir() else [0]*len(feature_cols),
    'et_importance': [et_importances.get(c, 0) for c in feature_cols] if 'et_importances' in dir() else [0]*len(feature_cols),
    'lasso_coef': [lasso_coef.get(c, 0) for c in feature_cols] if 'lasso_coef' in dir() else [0]*len(feature_cols),
    'selection_count': [feature_counts.get(c, 0) for c in feature_cols],
    'is_selected': [c in final_features for c in feature_cols]
})
results_df = results_df.sort_values('correlation', ascending=False)
results_df.to_csv('step9_feature_analysis.csv', index=False, encoding='utf-8-sig')
print(f"  âœ… step9_feature_analysis.csv ì €ì¥")

# ì„ íƒëœ Featureë§Œ ìˆëŠ” ë°ì´í„°ì…‹ ì €ì¥
print("\nğŸ“‚ ì„ íƒëœ Feature ë°ì´í„°ì…‹ ìƒì„±...")
df_full = pd.read_csv(INPUT_FILE)
selected_cols = final_features + META_COLS
selected_cols = [c for c in selected_cols if c in df_full.columns]
df_selected = df_full[selected_cols]
df_selected.to_csv('step9_selected_data.csv', index=False, encoding='utf-8-sig')
print(f"  âœ… step9_selected_data.csv ì €ì¥ ({len(df_selected):,}í–‰ Ã— {len(selected_cols)}ì»¬ëŸ¼)")

# ==============================================================================
# 10. ìš”ì•½
# ==============================================================================

print("\n" + "="*80)
print("ğŸ“Š 9ë‹¨ê³„ ìš”ì•½")
print("="*80)
print(f"  ì›ë³¸ Feature: 346ê°œ")
print(f"  ìƒê´€ê´€ê³„ >= 0.1: {len(high_corr_features)}ê°œ")
print(f"  ë‹¤ì¤‘ê³µì„ ì„± ì œê±°: -{len(to_drop)}ê°œ")
print(f"  XGBoost ì„ íƒ: {len(xgb_features)}ê°œ")
print(f"  ExtraTrees ì„ íƒ: {len(et_features)}ê°œ")
print(f"  LASSO ì„ íƒ: {len(lasso_features)}ê°œ")
print(f"  ì•™ìƒë¸” (2ê°œ+): {len(ensemble_features)}ê°œ")
print(f"  ì•™ìƒë¸” (3ê°œ+): {len(strong_features)}ê°œ")
print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
print(f"  ğŸ¯ ìµœì¢… ì„ íƒ: {len(final_features)}ê°œ")

print("\nâœ… 9ë‹¨ê³„ ì™„ë£Œ!")
print("   â†’ 10ë‹¨ê³„: ì„ íƒëœ Featureë¡œ ëª¨ë¸ í•™ìŠµ")