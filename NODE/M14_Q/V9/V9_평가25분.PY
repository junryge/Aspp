#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ V9 í‰ê°€ - í˜„ì¬ê°’ í•˜í•œì„  ì ìš©! (25ë¶„ ì˜ˆì¸¡)

í•µì‹¬ ìˆ˜ì •:
1. ì˜ˆì¸¡ê°’ >= í˜„ì¬ê°’ - 130 (ë¬¼ë¦¬ì  í•˜í•œì„ !)
2. ìƒí•œì„  ì œê±° - ìˆëŠ” ê·¸ëŒ€ë¡œ!
3. Feature ê°„ì†Œí™” (í•™ìŠµê³¼ ë™ì¼)
"""

import numpy as np
import pandas as pd
import pickle
from datetime import timedelta
import os
import gc
import warnings
warnings.filterwarnings('ignore')

print("="*70)
print("ğŸš€ V9 í‰ê°€ - 25ë¶„ ì˜ˆì¸¡ (í˜„ì¬ê°’ í•˜í•œì„  + ìƒí•œì„  ì œê±°)")
print("="*70)

# ========================================
# Feature ìƒì„± í•¨ìˆ˜ (í•™ìŠµê³¼ 100% ë™ì¼!)
# ========================================
def create_features_v9(row_dict):
    """í•µì‹¬ ì»¬ëŸ¼ ê¸°ë°˜ 60ê°œ Feature"""
    features = {}
    
    seq_m14b = np.array(row_dict['M14AM14B'])
    seq_m14bsum = np.array(row_dict['M14AM14BSUM'])
    seq_m10arev = np.array(row_dict['M10AM14A'])
    seq_totalcnt = np.array(row_dict['TOTALCNT'])
    seq_transport = np.array(row_dict['TRANSPORT'])
    seq_oht = np.array(row_dict['OHT'])
    
    seq_len = len(seq_m14b)
    
    # 1. M14AM14B (8ê°œ)
    features['m14b_mean'] = np.mean(seq_m14b)
    features['m14b_max'] = np.max(seq_m14b)
    features['m14b_current'] = seq_m14b[-1]
    features['m14b_last10'] = np.mean(seq_m14b[-10:])
    features['m14b_last30'] = np.mean(seq_m14b[-30:])
    features['m14b_slope'] = np.polyfit(np.arange(seq_len), seq_m14b, 1)[0]
    features['m14b_std'] = np.std(seq_m14b)
    features['m14b_trend10'] = seq_m14b[-1] - seq_m14b[-10]
    
    # 2. M14AM14BSUM (8ê°œ)
    features['m14bsum_mean'] = np.mean(seq_m14bsum)
    features['m14bsum_max'] = np.max(seq_m14bsum)
    features['m14bsum_current'] = seq_m14bsum[-1]
    features['m14bsum_last10'] = np.mean(seq_m14bsum[-10:])
    features['m14bsum_last30'] = np.mean(seq_m14bsum[-30:])
    features['m14bsum_slope'] = np.polyfit(np.arange(seq_len), seq_m14bsum, 1)[0]
    features['m14bsum_std'] = np.std(seq_m14bsum)
    features['m14bsum_trend10'] = seq_m14bsum[-1] - seq_m14bsum[-10]
    
    # 3. TOTALCNT (10ê°œ)
    features['total_mean'] = np.mean(seq_totalcnt)
    features['total_max'] = np.max(seq_totalcnt)
    features['total_min'] = np.min(seq_totalcnt)
    features['total_current'] = seq_totalcnt[-1]
    features['total_last5'] = np.mean(seq_totalcnt[-5:])
    features['total_last10'] = np.mean(seq_totalcnt[-10:])
    features['total_last30'] = np.mean(seq_totalcnt[-30:])
    features['total_slope'] = np.polyfit(np.arange(seq_len), seq_totalcnt, 1)[0]
    features['total_std'] = np.std(seq_totalcnt)
    features['total_trend10'] = seq_totalcnt[-1] - seq_totalcnt[-10]
    
    # 4. M10AM14A (5ê°œ)
    features['m10arev_mean'] = np.mean(seq_m10arev)
    features['m10arev_max'] = np.max(seq_m10arev)
    features['m10arev_current'] = seq_m10arev[-1]
    features['m10arev_last10'] = np.mean(seq_m10arev[-10:])
    features['m10arev_slope'] = np.polyfit(np.arange(seq_len), seq_m10arev, 1)[0]
    
    # 5. TRANSPORT (5ê°œ)
    features['trans_mean'] = np.mean(seq_transport)
    features['trans_max'] = np.max(seq_transport)
    features['trans_current'] = seq_transport[-1]
    features['trans_last10'] = np.mean(seq_transport[-10:])
    features['trans_slope'] = np.polyfit(np.arange(seq_len), seq_transport, 1)[0]
    
    # 6. OHT (4ê°œ)
    features['oht_mean'] = np.mean(seq_oht)
    features['oht_max'] = np.max(seq_oht)
    features['oht_current'] = seq_oht[-1]
    features['oht_last10'] = np.mean(seq_oht[-10:])
    
    # Interaction (8ê°œ)
    features['m14b_x_sum'] = seq_m14b[-1] * seq_m14bsum[-1] / 1000
    features['m14b_x_sum_mean'] = np.mean(seq_m14b * seq_m14bsum) / 1000
    features['sum_per_m14b'] = seq_m14bsum[-1] / (seq_m14b[-1] + 1)
    features['m14b_plus_sum'] = seq_m14b[-1] + seq_m14bsum[-1]
    features['m10arev_x_m14b'] = seq_m10arev[-1] * seq_m14b[-1] / 100
    features['trans_x_m14b'] = seq_transport[-1] * seq_m14b[-1] / 100
    features['ratio_m14b_total'] = seq_m14b[-1] / (seq_totalcnt[-1] + 1)
    features['ratio_sum_total'] = seq_m14bsum[-1] / (seq_totalcnt[-1] + 1)
    
    # ì„ê³„ê°’ (8ê°œ)
    features['m14b_over_520'] = np.sum(seq_m14b > 520)
    features['m14b_over_540'] = np.sum(seq_m14b > 540)
    features['m14bsum_over_600'] = np.sum(seq_m14bsum > 600)
    features['m14bsum_over_620'] = np.sum(seq_m14bsum > 620)
    features['m10arev_over_55'] = np.sum(seq_m10arev > 55)
    features['total_over_1600'] = np.sum(seq_totalcnt >= 1600)
    features['total_over_1650'] = np.sum(seq_totalcnt >= 1650)
    features['total_over_1700'] = np.sum(seq_totalcnt >= 1700)
    
    # í™©ê¸ˆ íŒ¨í„´ (4ê°œ)
    features['gold_strict'] = 1 if (seq_m14b[-1] > 540 and seq_m14bsum[-1] > 620) else 0
    features['gold_normal'] = 1 if (seq_m14b[-1] > 520 and seq_m14bsum[-1] > 600) else 0
    features['in_danger'] = 1 if seq_totalcnt[-1] >= 1700 else 0
    features['near_danger'] = 1 if seq_totalcnt[-1] >= 1600 else 0
    
    return features

# ========================================
# ë³´ì • í•¨ìˆ˜ - í˜„ì¬ê°’ í•˜í•œì„ !
# ========================================
def adjust_prediction(pred, current_total, m14b, m14bsum):
    """
    ğŸ”¥ í•µì‹¬ ë³´ì •:
    1. í˜„ì¬ê°’ í•˜í•œì„ : ì˜ˆì¸¡ >= í˜„ì¬ - 130 (25ë¶„ì— 130 ì´ìƒ í•˜ë½ ë¶ˆê°€ëŠ¥!)
    2. í™©ê¸ˆíŒ¨í„´ ì‹œ ìƒí–¥ boost
    3. ìƒí•œì„  ì—†ìŒ!
    """
    
    # ğŸ”¥ 1. í˜„ì¬ê°’ í•˜í•œì„  (ê°€ì¥ ì¤‘ìš”!)
    floor = current_total - 130
    if pred < floor:
        pred = floor
    
    # 2. í™©ê¸ˆíŒ¨í„´ boost (1650~1699 êµ¬ê°„ë§Œ)
    if 1650 <= pred < 1700:
        boost = 0
        
        if m14b > 540 and m14bsum > 620:
            boost += 50
        elif m14b > 520 and m14bsum > 600:
            boost += 40
        
        if m14b > 560:
            boost += 20
        if m14bsum > 650:
            boost += 20
            
        pred = pred + boost
    
    # 3. ì´ë¯¸ ìœ„í—˜ êµ¬ê°„ì¼ ë•Œ
    if current_total >= 1700:
        if pred < 1680:
            pred = max(pred, current_total - 100)
    
    return pred

# ========================================
# ë©”ì¸
# ========================================
model = None
for mf in ['model_v9_25min.pkl', 'model_v9.pkl']:
    if os.path.exists(mf):
        with open(mf, 'rb') as f:
            model = pickle.load(f)
        print(f"âœ… ëª¨ë¸: {mf}")
        break

if not model:
    print("âŒ ëª¨ë¸ ì—†ìŒ! model_v9_25min.pkl í•„ìš”")
    exit(1)

DATA_FILE = 'data/M14_Q_20251014_TO_20251015.CSV'
df = pd.read_csv(DATA_FILE, on_bad_lines='skip')
print(f"âœ… ë°ì´í„°: {len(df):,}í–‰")
df['CURRTIME'] = pd.to_datetime(df['CURRTIME'].astype(str), format='%Y%m%d%H%M')

results = []
seq_len = 280
total = len(df) - seq_len - 25
print(f"\nğŸ”„ í‰ê°€ ì¤‘... {total:,}ê°œ")

for i in range(seq_len, len(df) - 25):
    row_dict = {
        'M14AM14B': df['M14AM14B'].iloc[i-seq_len:i].values,
        'M14AM14BSUM': df['M14AM14BSUM'].iloc[i-seq_len:i].values,
        'M10AM14A': df['M10AM14A'].iloc[i-seq_len:i].values,
        'TOTALCNT': df['TOTALCNT'].iloc[i-seq_len:i].values,
        'TRANSPORT': df['M14.QUE.ALL.TRANSPORT4MINOVERCNT'].iloc[i-seq_len:i].values,
        'OHT': df['M14.QUE.OHT.OHTUTIL'].iloc[i-seq_len:i].values,
    }
    
    seq_totalcnt = row_dict['TOTALCNT']
    seq_m14b = row_dict['M14AM14B']
    seq_m14bsum = row_dict['M14AM14BSUM']
    
    current_time = df['CURRTIME'].iloc[i-1]
    current_total = seq_totalcnt[-1]
    actual = df['TOTALCNT'].iloc[i+24]
    
    seq_start_time = df['CURRTIME'].iloc[i-seq_len]
    prediction_time = current_time + timedelta(minutes=25)
    actual_time = df['CURRTIME'].iloc[i+24]
    
    features = create_features_v9(row_dict)
    X = pd.DataFrame([features])
    
    pred_raw = model.predict(X)[0]
    pred = adjust_prediction(pred_raw, current_total, seq_m14b[-1], seq_m14bsum[-1])
    
    gold_strict = (seq_m14b[-1] > 540 and seq_m14bsum[-1] > 620)
    gold_normal = (seq_m14b[-1] > 520 and seq_m14bsum[-1] > 600)
    
    results.append({
        'ì‹œí€€ìŠ¤ì‹œì‘': seq_start_time.strftime('%Y-%m-%d %H:%M'),
        'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
        'í˜„ì¬TOTALCNT': round(current_total, 2),
        'ì˜ˆì¸¡ì‹œì ': prediction_time.strftime('%Y-%m-%d %H:%M'),
        'ì‹¤ì œì‹œì ': actual_time.strftime('%Y-%m-%d %H:%M'),
        'ì‹¤ì œê°’': round(actual, 2),
        'ì›ë³¸ì˜ˆì¸¡': round(pred_raw, 2),
        'ë³´ì •ì˜ˆì¸¡': round(pred, 2),
        'ì˜¤ì°¨': round(actual - pred, 2),
        'ì ˆëŒ€ì˜¤ì°¨': round(abs(actual - pred), 2),
        'ì˜¤ì°¨ìœ¨(%)': round(abs(actual - pred) / max(actual, 1) * 100, 2),
        'M14AM14B': round(seq_m14b[-1], 2),
        'M14AM14BSUM': round(seq_m14bsum[-1], 2),
        'M10AM14A': round(row_dict['M10AM14A'][-1], 2),
        'TRANSPORT': round(row_dict['TRANSPORT'][-1], 2),
        'OHT_UTIL': round(row_dict['OHT'][-1], 2),
        'í™©ê¸ˆíŒ¨í„´(ì—„ê²©)': 'O' if gold_strict else '',
        'í™©ê¸ˆíŒ¨í„´(ë³´í†µ)': 'O' if gold_normal else '',
        'ì‹¤ì œìœ„í—˜(1700+)': 'O' if actual >= 1700 else '',
        'ì˜ˆì¸¡ìœ„í—˜(1700+)': 'O' if pred >= 1700 else ''
    })
    
    if (i - seq_len) % 1000 == 0:
        print(f"  {i-seq_len:,}/{total:,}")
        gc.collect()

print(f"âœ… ì™„ë£Œ!")

df_result = pd.DataFrame(results)
output = 'evaluation_V9_25min.csv'
df_result.to_csv(output, index=False, encoding='utf-8-sig')
print(f"âœ… ì €ì¥: {output}")

del df
gc.collect()

# ===== í†µê³„ =====
print("\n" + "="*70)
print("ğŸ“Š V9 25ë¶„ í‰ê°€ í†µê³„")
print("="*70)
print(f"ì´ ì˜ˆì¸¡: {len(df_result):,}ê°œ")
print(f"MAE: {df_result['ì ˆëŒ€ì˜¤ì°¨'].mean():.2f}")
print(f"ì˜¤ì°¨ìœ¨: {df_result['ì˜¤ì°¨ìœ¨(%)'].mean():.2f}%")

actual_danger = df_result['ì‹¤ì œìœ„í—˜(1700+)'] == 'O'
pred_danger = df_result['ì˜ˆì¸¡ìœ„í—˜(1700+)'] == 'O'

actual_count = actual_danger.sum()
detected = (actual_danger & pred_danger).sum()

print(f"\nğŸ”¥ 1700+ ê°ì§€:")
print(f"  ì‹¤ì œ: {actual_count}ê°œ")
if actual_count > 0:
    print(f"  ê°ì§€: {detected}ê°œ")
    print(f"  ê°ì§€ìœ¨: {detected/actual_count*100:.1f}%")
    
    missed = df_result[actual_danger & ~pred_danger]
    if len(missed) > 0:
        print(f"\nâŒ ë¯¸ê°ì§€ {len(missed)}ê°œ:")
        cols = ['í˜„ì¬ì‹œê°„', 'í˜„ì¬TOTALCNT', 'ì‹¤ì œê°’', 'ì›ë³¸ì˜ˆì¸¡', 'ë³´ì •ì˜ˆì¸¡', 'M14AM14B', 'M14AM14BSUM']
        print(missed[cols].head(10).to_string(index=False))

if actual_count > 0:
    danger_rows = df_result[actual_danger]
    raw_detected = (danger_rows['ì›ë³¸ì˜ˆì¸¡'] >= 1700).sum()
    adj_detected = (danger_rows['ë³´ì •ì˜ˆì¸¡'] >= 1700).sum()
    
    print(f"\nğŸ“ˆ ë³´ì • íš¨ê³¼:")
    print(f"  ì›ë³¸ ê°ì§€ìœ¨: {raw_detected/actual_count*100:.1f}%")
    print(f"  ë³´ì • ê°ì§€ìœ¨: {adj_detected/actual_count*100:.1f}%")
    print(f"  ê°œì„ : +{(adj_detected-raw_detected)/actual_count*100:.1f}%p")

print("\n" + "="*70)
print(f"âœ… V9 25ë¶„ í‰ê°€ ì™„ë£Œ! â†’ {output}")
print("="*70)