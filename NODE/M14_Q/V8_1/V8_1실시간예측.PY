import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta
import os

def create_single_prediction_features(seq_m14b, seq_m10a, seq_m16, seq_totalcnt):
    """
    í•˜ë‚˜ì˜ 280ë¶„ ì‹œí€€ìŠ¤ë¡œë¶€í„° Feature ìƒì„± (ì¡°ê¸° ê²½ë³´ í¬í•¨ 85ê°œ)
    """
    features = {}
    
    # ========== M14AM14B ê¸°ë³¸ 8ê°œ ==========
    features['m14b_mean'] = np.mean(seq_m14b)
    features['m14b_std'] = np.std(seq_m14b)
    features['m14b_last_5_mean'] = np.mean(seq_m14b[-5:])
    features['m14b_max'] = np.max(seq_m14b)
    features['m14b_min'] = np.min(seq_m14b)
    features['m14b_slope'] = np.polyfit(np.arange(280), seq_m14b, 1)[0]
    features['m14b_last_10_mean'] = np.mean(seq_m14b[-10:])
    features['m14b_first_10_mean'] = np.mean(seq_m14b[:10])
    
    # ========== M14AM10A ê¸°ë³¸ 8ê°œ ==========
    features['m10a_mean'] = np.mean(seq_m10a)
    features['m10a_std'] = np.std(seq_m10a)
    features['m10a_last_5_mean'] = np.mean(seq_m10a[-5:])
    features['m10a_max'] = np.max(seq_m10a)
    features['m10a_min'] = np.min(seq_m10a)
    features['m10a_slope'] = np.polyfit(np.arange(280), seq_m10a, 1)[0]
    features['m10a_last_10_mean'] = np.mean(seq_m10a[-10:])
    features['m10a_first_10_mean'] = np.mean(seq_m10a[:10])
    
    # ========== M14AM16 ê¸°ë³¸ 8ê°œ ==========
    features['m16_mean'] = np.mean(seq_m16)
    features['m16_std'] = np.std(seq_m16)
    features['m16_last_5_mean'] = np.mean(seq_m16[-5:])
    features['m16_max'] = np.max(seq_m16)
    features['m16_min'] = np.min(seq_m16)
    features['m16_slope'] = np.polyfit(np.arange(280), seq_m16, 1)[0]
    features['m16_last_10_mean'] = np.mean(seq_m16[-10:])
    features['m16_first_10_mean'] = np.mean(seq_m16[:10])
    
    # ========== TOTALCNT ê¸°ë³¸ 8ê°œ ==========
    features['totalcnt_mean'] = np.mean(seq_totalcnt)
    features['totalcnt_std'] = np.std(seq_totalcnt)
    features['totalcnt_last_5_mean'] = np.mean(seq_totalcnt[-5:])
    features['totalcnt_max'] = np.max(seq_totalcnt)
    features['totalcnt_min'] = np.min(seq_totalcnt)
    features['totalcnt_slope'] = np.polyfit(np.arange(280), seq_totalcnt, 1)[0]
    features['totalcnt_last_10_mean'] = np.mean(seq_totalcnt[-10:])
    features['totalcnt_first_10_mean'] = np.mean(seq_totalcnt[:10])
    
    # ========== ë¹„ìœ¨ Feature (8ê°œ) ==========
    features['ratio_m14b_m10a'] = seq_m14b[-1] / (seq_m10a[-1] + 1)
    features['ratio_m14b_m16'] = seq_m14b[-1] / (seq_m16[-1] + 1)
    features['ratio_m10a_m16'] = seq_m10a[-1] / (seq_m16[-1] + 1)
    features['ratio_m14b_m10a_mean'] = np.mean(seq_m14b) / (np.mean(seq_m10a) + 1)
    features['ratio_m14b_m16_mean'] = np.mean(seq_m14b) / (np.mean(seq_m16) + 1)
    features['ratio_m14b_m10a_max'] = np.max(seq_m14b) / (np.max(seq_m10a) + 1)
    features['volatility_m14b'] = np.std(seq_m14b) / (np.mean(seq_m14b) + 1)
    features['volatility_totalcnt'] = np.std(seq_totalcnt) / (np.mean(seq_totalcnt) + 1)
    
    # ========== M14AM14B ì„ê³„ê°’ ì¹´ìš´íŠ¸ (8ê°œ) ==========
    features['m14b_over_250'] = np.sum(seq_m14b > 250)
    features['m14b_over_300'] = np.sum(seq_m14b > 300)
    features['m14b_over_350'] = np.sum(seq_m14b > 350)
    features['m14b_over_400'] = np.sum(seq_m14b > 400)
    features['m14b_over_450'] = np.sum(seq_m14b > 450)
    features['m14b_over_300_last30'] = np.sum(seq_m14b[-30:] > 300)
    features['m14b_over_350_last30'] = np.sum(seq_m14b[-30:] > 350)
    features['m14b_over_400_last30'] = np.sum(seq_m14b[-30:] > 400)
    
    # ========== M14AM10A ì„ê³„ê°’ ì¹´ìš´íŠ¸ (4ê°œ) ==========
    features['m10a_over_70'] = np.sum(seq_m10a > 70)
    features['m10a_over_80'] = np.sum(seq_m10a > 80)
    features['m10a_under_80'] = np.sum(seq_m10a < 80)
    features['m10a_under_70'] = np.sum(seq_m10a < 70)
    
    # ========== TOTALCNT ì„ê³„ê°’ ì¹´ìš´íŠ¸ (8ê°œ) ==========
    features['totalcnt_over_1400'] = np.sum(seq_totalcnt >= 1400)
    features['totalcnt_over_1500'] = np.sum(seq_totalcnt >= 1500)
    features['totalcnt_over_1600'] = np.sum(seq_totalcnt >= 1600)
    features['totalcnt_over_1700'] = np.sum(seq_totalcnt >= 1700)
    features['totalcnt_over_1400_last30'] = np.sum(seq_totalcnt[-30:] >= 1400)
    features['totalcnt_over_1500_last30'] = np.sum(seq_totalcnt[-30:] >= 1500)
    features['totalcnt_over_1600_last30'] = np.sum(seq_totalcnt[-30:] >= 1600)
    features['totalcnt_over_1700_last30'] = np.sum(seq_totalcnt[-30:] >= 1700)
    
    # ========== í™©ê¸ˆ íŒ¨í„´ (4ê°œ) ==========
    features['golden_pattern_300_80'] = 1 if (seq_m14b[-1] > 300 and seq_m10a[-1] < 80) else 0
    features['golden_pattern_350_80'] = 1 if (seq_m14b[-1] > 350 and seq_m10a[-1] < 80) else 0
    features['golden_pattern_400_70'] = 1 if (seq_m14b[-1] > 400 and seq_m10a[-1] < 70) else 0
    features['danger_zone'] = 1 if seq_totalcnt[-1] >= 1700 else 0
    
    # ========== ë³€í™”ìœ¨/ê°€ì†ë„ (8ê°œ) ==========
    features['m14b_change_rate'] = (seq_m14b[-1] - seq_m14b[-30]) / 30 if len(seq_m14b) >= 30 else 0
    features['totalcnt_change_rate'] = (seq_totalcnt[-1] - seq_totalcnt[-30]) / 30 if len(seq_totalcnt) >= 30 else 0
    
    recent_30_m14b = np.mean(seq_m14b[-30:])
    previous_30_m14b = np.mean(seq_m14b[-60:-30]) if len(seq_m14b) >= 60 else np.mean(seq_m14b[-30:])
    features['m14b_acceleration'] = recent_30_m14b - previous_30_m14b
    
    recent_30_totalcnt = np.mean(seq_totalcnt[-30:])
    previous_30_totalcnt = np.mean(seq_totalcnt[-60:-30]) if len(seq_totalcnt) >= 60 else np.mean(seq_totalcnt[-30:])
    features['totalcnt_acceleration'] = recent_30_totalcnt - previous_30_totalcnt
    
    features['m14b_range'] = np.max(seq_m14b) - np.min(seq_m14b)
    features['totalcnt_range'] = np.max(seq_totalcnt) - np.min(seq_totalcnt)
    features['m14b_recent_vs_mean'] = np.mean(seq_m14b[-30:]) / (np.mean(seq_m14b) + 1)
    features['totalcnt_recent_vs_mean'] = np.mean(seq_totalcnt[-30:]) / (np.mean(seq_totalcnt) + 1)
    
    # ========== ì‹œê°„ëŒ€ë³„ í†µê³„ (8ê°œ) ==========
    q1 = seq_totalcnt[:70]
    q2 = seq_totalcnt[70:140]
    q3 = seq_totalcnt[140:210]
    q4 = seq_totalcnt[210:280]
    
    features['totalcnt_q1_mean'] = np.mean(q1)
    features['totalcnt_q2_mean'] = np.mean(q2)
    features['totalcnt_q3_mean'] = np.mean(q3)
    features['totalcnt_q4_mean'] = np.mean(q4)
    features['totalcnt_trend_q1_q2'] = np.mean(q2) - np.mean(q1)
    features['totalcnt_trend_q2_q3'] = np.mean(q3) - np.mean(q2)
    features['totalcnt_trend_q3_q4'] = np.mean(q4) - np.mean(q3)
    features['totalcnt_trend_overall'] = np.mean(q4) - np.mean(q1)
    
    # ========== ğŸ”¥ ì¡°ê¸° ê²½ë³´ Feature (5ê°œ) ==========
    # ë§ˆì§€ë§‰ 10ë¶„ ë¶„ì„
    last_10min = seq_totalcnt[-10:]
    
    features['last_10min_max'] = np.max(last_10min)
    features['last_10min_min'] = np.min(last_10min)
    features['last_10min_mean'] = np.mean(last_10min)
    features['last_10min_rise'] = last_10min[-1] - last_10min[0]  # 10ë¶„ê°„ ìƒìŠ¹í­
    
    # ì¡°ê¸° ê²½ë³´: 1650 ì´ìƒ + 20 ì´ìƒ ìƒìŠ¹
    early_warning = (np.max(last_10min) >= 1650) and ((last_10min[-1] - last_10min[0]) > 20)
    features['early_warning_1650_rising'] = 1 if early_warning else 0
    
    return features

def get_status_info(value):
    """
    ë¬¼ë¥˜ëŸ‰ì— ë”°ë¥¸ ìƒíƒœ ì •ë³´ ë°˜í™˜
    900-1599: ì •ìƒ
    1600-1699: ì£¼ì˜
    1700+: ì‹¬ê°
    """
    if value < 900:
        return 'ğŸ”µì €ì¡°', 'blue'
    elif value < 1600:
        return 'ğŸŸ¢ì •ìƒ', 'green'
    elif value < 1700:
        return 'ğŸŸ¡ì£¼ì˜', 'yellow'
    else:
        return 'ğŸ”´ì‹¬ê°', 'red'

def realtime_prediction():
    """ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ (ì¡°ê¸° ê²½ë³´ í¬í•¨)"""
    
    print("="*80)
    print("280ë¶„ â†’ 10ë¶„ í›„ ë¬¼ë¥˜ëŸ‰ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ (ì¡°ê¸° ê²½ë³´ í¬í•¨)")
    print("="*80)
    print("Feature: 85ê°œ (ì¡°ê¸° ê²½ë³´ 5ê°œ í¬í•¨)")
    print("="*80)
    
    # ëª¨ë¸ ë¡œë“œ (ì—¬ëŸ¬ íŒŒì¼ëª… ì‹œë„)
    model_files = [
        'xgboost_280to10_1year_augmented.pkl',
        'xgboost_280to10_enhanced_earlywarning.pkl',
        '280to10_enhanced.pkl'
    ]
    
    model = None
    model_file = None
    
    for mf in model_files:
        if os.path.exists(mf):
            try:
                with open(mf, 'rb') as f:
                    model = pickle.load(f)
                model_file = mf
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_file}")
                break
            except Exception as e:
                print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({mf}): {e}")
    
    if model is None:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ!")
        print(f"ì‹œë„í•œ íŒŒì¼:")
        for mf in model_files:
            print(f"  - {mf}")
        return None
    
    # ë°ì´í„° ë¡œë“œ
    csv_files = [
        'data/222.csv',
        'data/20250807_DATA.csv',
        '222.csv'
    ]
    
    csv_file = None
    for cf in csv_files:
        if os.path.exists(cf):
            csv_file = cf
            break
    
    if csv_file is None:
        print(f"âŒ CSV íŒŒì¼ ì—†ìŒ!")
        print(f"ì‹œë„í•œ íŒŒì¼:")
        for cf in csv_files:
            print(f"  - {cf}")
        return None
    
    df = pd.read_csv(csv_file, on_bad_lines='skip')
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ í–‰")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_cols = ['M14AM14B', 'M14AM10A', 'M14AM16', 'TOTALCNT']
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        print(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
        print(f"í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")
        return None
    
    print(f"âœ… í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ì™„ë£Œ")
    
    # CURRTIME ì²˜ë¦¬
    if 'CURRTIME' in df.columns:
        try:
            df['CURRTIME'] = pd.to_datetime(df['CURRTIME'].astype(str), format='%Y%m%d%H%M')
            print("âœ… CURRTIME íŒŒì‹± ì™„ë£Œ (YYYYMMDDHHMM í˜•ì‹)")
        except:
            try:
                df['CURRTIME'] = pd.to_datetime(df['CURRTIME'])
                print("âœ… CURRTIME ìë™ íŒŒì‹± ì™„ë£Œ")
            except:
                print("âš ï¸ CURRTIME ë³€í™˜ ì‹¤íŒ¨, ê°€ìƒ ì‹œê°„ ìƒì„±")
                base_time = datetime(2024, 1, 1, 0, 0)
                df['CURRTIME'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
    else:
        print("âš ï¸ CURRTIME ì—†ìŒ, ê°€ìƒ ì‹œê°„ ìƒì„±")
        base_time = datetime(2024, 1, 1, 0, 0)
        df['CURRTIME'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
    
    # ë°ì´í„° ê¸¸ì´ í™•ì¸
    if len(df) < 280:
        print(f"âŒ ë°ì´í„° ë¶€ì¡±: ìµœì†Œ 280ê°œ í•„ìš”, í˜„ì¬ {len(df)}ê°œ")
        return None
    
    results = []
    
    print(f"\nğŸ”® ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œì‘...")
    print(f"ì´ ì˜ˆì¸¡ ê°€ëŠ¥: {len(df) - 280 + 1:,}ê°œ")
    print(f"ì˜ˆì¸¡ ë°©ì‹: 280ë¶„ ì‹œí€€ìŠ¤ â†’ 10ë¶„ í›„ ì˜ˆì¸¡")
    print(f"ì¡°ê¸° ê²½ë³´: 1650+ & 20+ ìƒìŠ¹ ê°ì§€ ì‹œ ì˜ˆì¸¡ê°’ 2% ì¦ê°€")
    print("-"*80)
    
    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì˜ˆì¸¡
    for i in range(280, len(df) + 1):
        # 280ë¶„ ì‹œí€€ìŠ¤ ì¶”ì¶œ
        seq_m14b = df['M14AM14B'].iloc[i-280:i].values
        seq_m10a = df['M14AM10A'].iloc[i-280:i].values
        seq_m16 = df['M14AM16'].iloc[i-280:i].values
        seq_totalcnt = df['TOTALCNT'].iloc[i-280:i].values
        
        # ì‹œê°„ ì •ë³´
        current_time = df['CURRTIME'].iloc[i-1]
        prediction_time = current_time + timedelta(minutes=10)
        
        # í˜„ì¬ ìƒíƒœ
        current_totalcnt = seq_totalcnt[-1]
        current_m14b = seq_m14b[-1]
        current_m10a = seq_m10a[-1]
        
        # Feature ìƒì„± (85ê°œ)
        features = create_single_prediction_features(seq_m14b, seq_m10a, seq_m16, seq_totalcnt)
        X_pred = pd.DataFrame([features])
        
        # ì˜ˆì¸¡
        prediction = model.predict(X_pred)[0]
        
        # ğŸ”¥ ì¡°ê¸° ê²½ë³´ ê°ì§€
        last_10min = seq_totalcnt[-10:]
        early_warning_detected = (np.max(last_10min) >= 1650) and ((last_10min[-1] - last_10min[0]) > 20)
        
        # ğŸ”¥ğŸ”¥ ì¡°ê¸°ê²½ë³´ ë°œìƒ ì‹œ ì˜ˆì¸¡ê°’ * 1.02 (2% ì¦ê°€)
        if early_warning_detected:
            prediction = prediction * 1.02
        
        # í™©ê¸ˆ íŒ¨í„´ ê°ì§€
        golden_pattern = (current_m14b > 300 and current_m10a < 80)
        
        # ìƒíƒœ íŒì •
        current_status, current_color = get_status_info(current_totalcnt)
        pred_status, pred_color = get_status_info(prediction)
        
        # ìƒíƒœ ë³€í™” ê°ì§€
        status_change = ''
        if current_color != pred_color:
            if pred_color == 'red' and current_color != 'red':
                status_change = 'âš ï¸ìƒìŠ¹ê²½ë³´'
            elif pred_color == 'yellow' and current_color == 'green':
                status_change = 'âš ï¸ì£¼ì˜ì „í™˜'
            elif pred_color == 'green' and current_color in ['yellow', 'red']:
                status_change = 'âœ…ì•ˆì •í™”'
        
        # ê²°ê³¼ ì €ì¥
        results.append({
            'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
            'ì˜ˆì¸¡ì‹œì (10ë¶„í›„)': prediction_time.strftime('%Y-%m-%d %H:%M'),
            'í˜„ì¬ë¬¼ë¥˜ëŸ‰': int(current_totalcnt),
            'í˜„ì¬ìƒíƒœ': current_status,
            'ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰': int(prediction),
            'ì˜ˆì¸¡ìƒíƒœ': pred_status,
            'ë³€í™”ëŸ‰': int(prediction - current_totalcnt),
            'ìƒíƒœë³€í™”': status_change,
            'M14AM14B': int(current_m14b),
            'M14AM10A': int(current_m10a),
            'í™©ê¸ˆíŒ¨í„´': 'â­' if golden_pattern else '',
            'ğŸ”¥ì¡°ê¸°ê²½ë³´': 'ğŸ”¥' if early_warning_detected else '',
            'ì¡°ê¸°ê²½ë³´2%ì ìš©': 'O' if early_warning_detected else '',
            'ë§ˆì§€ë§‰10ë¶„_MAX': int(np.max(last_10min)),
            'ë§ˆì§€ë§‰10ë¶„_ìƒìŠ¹í­': int(last_10min[-1] - last_10min[0]),
            'ì‹œí€€ìŠ¤ìµœëŒ€': int(np.max(seq_totalcnt)),
            'ì‹œí€€ìŠ¤ìµœì†Œ': int(np.min(seq_totalcnt)),
            'ì‹œí€€ìŠ¤í‰ê· ': int(np.mean(seq_totalcnt))
        })
        
        # ì§„í–‰ìƒí™© (100ê°œë§ˆë‹¤)
        if (i - 280) % 100 == 0:
            progress = (i - 280) / (len(df) - 280 + 1) * 100
            print(f"  ì§„í–‰ì¤‘... {i-280}/{len(df)-280+1} ({progress:.1f}%)")
    
    # DataFrame ë³€í™˜
    results_df = pd.DataFrame(results)
    
    # ===== í†µê³„ ë¶„ì„ =====
    print("\n" + "="*80)
    print("ğŸ“Š ì˜ˆì¸¡ í†µê³„")
    print("="*80)
    print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(results_df):,}ê°œ")
    print(f"\ní˜„ì¬ ìƒíƒœ ë¶„í¬:")
    print(results_df['í˜„ì¬ìƒíƒœ'].value_counts())
    print(f"\nì˜ˆì¸¡ ìƒíƒœ ë¶„í¬:")
    print(results_df['ì˜ˆì¸¡ìƒíƒœ'].value_counts())
    
    # ì¡°ê¸° ê²½ë³´ ë¶„ì„
    early_warning_cases = results_df[results_df['ğŸ”¥ì¡°ê¸°ê²½ë³´'] == 'ğŸ”¥']
    if len(early_warning_cases) > 0:
        print(f"\nğŸ”¥ ì¡°ê¸° ê²½ë³´ ë°œìƒ: {len(early_warning_cases):,}ê±´")
        print(f"   í‰ê·  ì˜ˆì¸¡ê°’: {early_warning_cases['ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰'].mean():.0f}")
        print(f"   í‰ê·  ë§ˆì§€ë§‰10ë¶„_MAX: {early_warning_cases['ë§ˆì§€ë§‰10ë¶„_MAX'].mean():.0f}")
        print(f"   í‰ê·  ìƒìŠ¹í­: {early_warning_cases['ë§ˆì§€ë§‰10ë¶„_ìƒìŠ¹í­'].mean():.0f}")
    
    # ìƒíƒœ ë³€í™” ë¶„ì„
    status_changes = results_df[results_df['ìƒíƒœë³€í™”'] != '']
    if len(status_changes) > 0:
        print(f"\nâš ï¸ ìƒíƒœ ë³€í™” ë°œìƒ: {len(status_changes):,}ê±´")
        print(status_changes['ìƒíƒœë³€í™”'].value_counts())
    
    # ì‹¬ê° ìƒíƒœ ë¶„ì„
    critical_cases = results_df[results_df['ì˜ˆì¸¡ìƒíƒœ'] == 'ğŸ”´ì‹¬ê°']
    if len(critical_cases) > 0:
        print(f"\nğŸ”´ ì‹¬ê°(1700+) ì˜ˆì¸¡: {len(critical_cases):,}ê±´")
        print(f"   í‰ê·  ì˜ˆì¸¡ê°’: {critical_cases['ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰'].mean():.0f}")
        print(f"   ìµœëŒ€ ì˜ˆì¸¡ê°’: {critical_cases['ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰'].max():.0f}")
        
        # ì¡°ê¸° ê²½ë³´ & ì‹¬ê° ë™ì‹œ ë°œìƒ
        early_and_critical = critical_cases[critical_cases['ğŸ”¥ì¡°ê¸°ê²½ë³´'] == 'ğŸ”¥']
        if len(early_and_critical) > 0:
            print(f"   ğŸ”¥ ì¡°ê¸°ê²½ë³´+ì‹¬ê°: {len(early_and_critical):,}ê±´ ({len(early_and_critical)/len(critical_cases)*100:.1f}%)")
    
    # ì£¼ì˜ ìƒíƒœ ë¶„ì„
    warning_cases = results_df[results_df['ì˜ˆì¸¡ìƒíƒœ'] == 'ğŸŸ¡ì£¼ì˜']
    if len(warning_cases) > 0:
        print(f"\nğŸŸ¡ ì£¼ì˜(1600-1699) ì˜ˆì¸¡: {len(warning_cases):,}ê±´")
        print(f"   í‰ê·  ì˜ˆì¸¡ê°’: {warning_cases['ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰'].mean():.0f}")
    
    # í™©ê¸ˆ íŒ¨í„´ ë¶„ì„
    golden_cases = results_df[results_df['í™©ê¸ˆíŒ¨í„´'] == 'â­']
    if len(golden_cases) > 0:
        print(f"\nâ­ í™©ê¸ˆ íŒ¨í„´ ë°œìƒ: {len(golden_cases):,}ê±´")
        print(f"   í‰ê·  ì˜ˆì¸¡ê°’: {golden_cases['ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰'].mean():.0f}")
    
    # ìµœê·¼ 10ê°œ ì˜ˆì¸¡ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ“‹ ìµœê·¼ 10ê°œ ì˜ˆì¸¡ ê²°ê³¼")
    print("="*80)
    print(results_df[['í˜„ì¬ì‹œê°„', 'í˜„ì¬ë¬¼ë¥˜ëŸ‰', 'í˜„ì¬ìƒíƒœ', 'ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰', 'ì˜ˆì¸¡ìƒíƒœ', 'ë³€í™”ëŸ‰', 'ğŸ”¥ì¡°ê¸°ê²½ë³´', 'ìƒíƒœë³€í™”']].tail(10).to_string(index=False))
    
    # ì¡°ê¸° ê²½ë³´ ë°œìƒ êµ¬ê°„ (ìƒìœ„ 20ê°œ)
    if len(early_warning_cases) > 0:
        print("\n" + "="*80)
        print("ğŸ”¥ ì¡°ê¸° ê²½ë³´ ë°œìƒ êµ¬ê°„ (ìƒìœ„ 20ê°œ)")
        print("="*80)
        print(early_warning_cases[['í˜„ì¬ì‹œê°„', 'ë§ˆì§€ë§‰10ë¶„_MAX', 'ë§ˆì§€ë§‰10ë¶„_ìƒìŠ¹í­', 'í˜„ì¬ë¬¼ë¥˜ëŸ‰', 'ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰', 'ì˜ˆì¸¡ìƒíƒœ']].head(20).to_string(index=False))
    
    # ì‹¬ê° ì˜ˆì¸¡ ìƒìœ„ 10ê°œ
    if len(critical_cases) > 0:
        print("\n" + "="*80)
        print("ğŸ”´ ì‹¬ê° ì˜ˆì¸¡ ìƒìœ„ 10ê°œ")
        print("="*80)
        top_critical = critical_cases.nlargest(10, 'ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰')
        print(top_critical[['í˜„ì¬ì‹œê°„', 'í˜„ì¬ë¬¼ë¥˜ëŸ‰', 'ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰', 'ë³€í™”ëŸ‰', 'M14AM14B', 'M14AM10A', 'ğŸ”¥ì¡°ê¸°ê²½ë³´']].to_string(index=False))
    
    # ìƒìŠ¹ ê²½ë³´ ë°œìƒ
    alerts = results_df[results_df['ìƒíƒœë³€í™”'].str.contains('ìƒìŠ¹ê²½ë³´', na=False)]
    if len(alerts) > 0:
        print("\n" + "="*80)
        print("âš ï¸ ìƒìŠ¹ ê²½ë³´ ë°œìƒ êµ¬ê°„")
        print("="*80)
        print(alerts[['í˜„ì¬ì‹œê°„', 'í˜„ì¬ìƒíƒœ', 'ì˜ˆì¸¡ìƒíƒœ', 'í˜„ì¬ë¬¼ë¥˜ëŸ‰', 'ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰', 'ë³€í™”ëŸ‰', 'ğŸ”¥ì¡°ê¸°ê²½ë³´']].to_string(index=False))
    
    return results_df

def predict_latest_only():
    """
    ê°€ì¥ ìµœê·¼ 280ë¶„ ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡ (ì¡°ê¸° ê²½ë³´ í¬í•¨)
    """
    
    print("="*80)
    print("ìµœì‹  ë°ì´í„° ì˜ˆì¸¡ (ì¡°ê¸° ê²½ë³´ í¬í•¨)")
    print("="*80)
    
    # ëª¨ë¸ ë¡œë“œ
    model_files = [
        'xgboost_280to10_1year_augmented.pkl',
        'xgboost_280to10_enhanced_earlywarning.pkl',
        '280to10_enhanced.pkl'
    ]
    
    model = None
    for mf in model_files:
        if os.path.exists(mf):
            try:
                with open(mf, 'rb') as f:
                    model = pickle.load(f)
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {mf}")
                break
            except:
                pass
    
    if model is None:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ!")
        return None
    
    # ë°ì´í„° ë¡œë“œ
    csv_files = [
        'data/20250807_DATA.csv',
        'data/222.csv',
        '222.csv'
    ]
    
    csv_file = None
    for cf in csv_files:
        if os.path.exists(cf):
            csv_file = cf
            break
    
    if csv_file is None:
        print(f"âŒ CSV íŒŒì¼ ì—†ìŒ!")
        return None
    
    df = pd.read_csv(csv_file, on_bad_lines='skip')
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ í–‰")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_cols = ['M14AM14B', 'M14AM10A', 'M14AM16', 'TOTALCNT']
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        print(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
        return None
    
    # ë°ì´í„° ê¸¸ì´ í™•ì¸
    if len(df) < 280:
        print(f"âŒ ë°ì´í„° ë¶€ì¡±: ìµœì†Œ 280ê°œ í•„ìš”, í˜„ì¬ {len(df)}ê°œ")
        return None
    
    # CURRTIME ì²˜ë¦¬
    if 'CURRTIME' in df.columns:
        try:
            df['CURRTIME'] = pd.to_datetime(df['CURRTIME'].astype(str), format='%Y%m%d%H%M')
        except:
            try:
                df['CURRTIME'] = pd.to_datetime(df['CURRTIME'])
            except:
                base_time = datetime(2024, 1, 1, 0, 0)
                df['CURRTIME'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
    else:
        base_time = datetime(2024, 1, 1, 0, 0)
        df['CURRTIME'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
    
    # ìµœê·¼ 280ë¶„ ë°ì´í„° ì¶”ì¶œ
    seq_m14b = df['M14AM14B'].iloc[-280:].values
    seq_m10a = df['M14AM10A'].iloc[-280:].values
    seq_m16 = df['M14AM16'].iloc[-280:].values
    seq_totalcnt = df['TOTALCNT'].iloc[-280:].values
    
    # í˜„ì¬ ì‹œê°„ ì •ë³´
    current_time = df['CURRTIME'].iloc[-1]
    prediction_time = current_time + timedelta(minutes=10)
    
    # í˜„ì¬ ìƒíƒœ
    current_totalcnt = seq_totalcnt[-1]
    current_m14b = seq_m14b[-1]
    current_m10a = seq_m10a[-1]
    
    # Feature ìƒì„± (85ê°œ)
    features = create_single_prediction_features(seq_m14b, seq_m10a, seq_m16, seq_totalcnt)
    X_pred = pd.DataFrame([features])
    
    # ì˜ˆì¸¡
    prediction = model.predict(X_pred)[0]
    
    # ğŸ”¥ ì¡°ê¸° ê²½ë³´ ê°ì§€
    last_10min = seq_totalcnt[-10:]
    early_warning_detected = (np.max(last_10min) >= 1650) and ((last_10min[-1] - last_10min[0]) > 20)
    
    # ğŸ”¥ğŸ”¥ ì¡°ê¸°ê²½ë³´ ë°œìƒ ì‹œ ì˜ˆì¸¡ê°’ * 1.02 (2% ì¦ê°€)
    if early_warning_detected:
        prediction = prediction * 1.02
    
    # í™©ê¸ˆ íŒ¨í„´ ê°ì§€
    golden_pattern = (current_m14b > 300 and current_m10a < 80)
    
    # ìƒíƒœ íŒì •
    current_status, current_color = get_status_info(current_totalcnt)
    pred_status, pred_color = get_status_info(prediction)
    
    # ê°„ë‹¨í•œ ê²°ê³¼ë§Œ ì¶œë ¥
    if early_warning_detected:
        print("ğŸ”¥ ì¡°ê¸° ê²½ë³´: ë°œìƒ!")
    
    simple_dict = {
        'ì˜ˆì¸¡ë¬¼ë¥˜ëŸ‰': int(prediction),
        'ì˜ˆì¸¡ìƒíƒœ': pred_status
    }
    
    print(simple_dict)
    
    return simple_dict

if __name__ == '__main__':
    # ì „ì²´ ë°ì´í„° ì‹¤ì‹œê°„ ì˜ˆì¸¡
    print("\nğŸš€ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹œì‘ (ì¡°ê¸° ê²½ë³´ í¬í•¨)...\n")
    results = realtime_prediction()
    
    if results is not None:
        print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ! ì´ {len(results):,}ê°œ ì˜ˆì¸¡ ìƒì„±")