# -*- coding: utf-8 -*-
"""
280ë¶„ ì‹œí€€ìŠ¤ â†’ 10ë¶„ í›„ ì˜ˆì¸¡ í‰ê°€ (1ë…„ì¹˜ ë°ì´í„°)
ì¡°ê¸° ê²½ë³´ + 1550â†’1700 íŒ¨í„´ Feature í¬í•¨ (96ê°œ)
"""

import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta
import os
import gc

def create_single_prediction_features(seq_m14b, seq_m10a, seq_m16, seq_totalcnt, df=None, idx=None):
    """í•˜ë‚˜ì˜ 280ë¶„ ì‹œí€€ìŠ¤ë¡œë¶€í„° Feature ìƒì„± (96ê°œ: ì¡°ê¸° ê²½ë³´ + 1550â†’1700 íŒ¨í„´)"""
    features = {}
    
    # ========== M14AM14B ê¸°ë³¸ 8ê°œ ==========
    features['m14b_mean'] = np.mean(seq_m14b)
    features['m14b_std'] = np.std(seq_m14b)
    features['m14b_last_5_mean'] = np.mean(seq_m14b[-5:])
    features['m14b_max'] = np.max(seq_m14b)
    features['m14b_min'] = np.min(seq_m14b)
    features['m14b_slope'] = np.polyfit(np.arange(280), seq_m14b, 1)[0]
    features['m14b_last_10_mean'] = np.mean(seq_m14b[-10:])
    features['m14b_first_10_mean'] = np.mean(seq_m14b[:10])
    
    # ========== M14AM10A ê¸°ë³¸ 8ê°œ ==========
    features['m10a_mean'] = np.mean(seq_m10a)
    features['m10a_std'] = np.std(seq_m10a)
    features['m10a_last_5_mean'] = np.mean(seq_m10a[-5:])
    features['m10a_max'] = np.max(seq_m10a)
    features['m10a_min'] = np.min(seq_m10a)
    features['m10a_slope'] = np.polyfit(np.arange(280), seq_m10a, 1)[0]
    features['m10a_last_10_mean'] = np.mean(seq_m10a[-10:])
    features['m10a_first_10_mean'] = np.mean(seq_m10a[:10])
    
    # ========== M14AM16 ê¸°ë³¸ 8ê°œ ==========
    features['m16_mean'] = np.mean(seq_m16)
    features['m16_std'] = np.std(seq_m16)
    features['m16_last_5_mean'] = np.mean(seq_m16[-5:])
    features['m16_max'] = np.max(seq_m16)
    features['m16_min'] = np.min(seq_m16)
    features['m16_slope'] = np.polyfit(np.arange(280), seq_m16, 1)[0]
    features['m16_last_10_mean'] = np.mean(seq_m16[-10:])
    features['m16_first_10_mean'] = np.mean(seq_m16[:10])
    
    # ========== TOTALCNT ê¸°ë³¸ 8ê°œ ==========
    features['totalcnt_mean'] = np.mean(seq_totalcnt)
    features['totalcnt_std'] = np.std(seq_totalcnt)
    features['totalcnt_last_5_mean'] = np.mean(seq_totalcnt[-5:])
    features['totalcnt_max'] = np.max(seq_totalcnt)
    features['totalcnt_min'] = np.min(seq_totalcnt)
    features['totalcnt_slope'] = np.polyfit(np.arange(280), seq_totalcnt, 1)[0]
    features['totalcnt_last_10_mean'] = np.mean(seq_totalcnt[-10:])
    features['totalcnt_first_10_mean'] = np.mean(seq_totalcnt[:10])
    
    # ========== ë¹„ìœ¨ Feature (8ê°œ) ==========
    features['ratio_m14b_m10a'] = seq_m14b[-1] / (seq_m10a[-1] + 1)
    features['ratio_m14b_m16'] = seq_m14b[-1] / (seq_m16[-1] + 1)
    features['ratio_m10a_m16'] = seq_m10a[-1] / (seq_m16[-1] + 1)
    features['ratio_m14b_m10a_mean'] = np.mean(seq_m14b) / (np.mean(seq_m10a) + 1)
    features['ratio_m14b_m16_mean'] = np.mean(seq_m14b) / (np.mean(seq_m16) + 1)
    features['ratio_m14b_m10a_max'] = np.max(seq_m14b) / (np.max(seq_m10a) + 1)
    features['volatility_m14b'] = np.std(seq_m14b) / (np.mean(seq_m14b) + 1)
    features['volatility_totalcnt'] = np.std(seq_totalcnt) / (np.mean(seq_totalcnt) + 1)
    
    # ========== M14AM14B ì„ê³„ê°’ ì¹´ìš´íŠ¸ (8ê°œ) ==========
    features['m14b_over_250'] = np.sum(seq_m14b > 250)
    features['m14b_over_300'] = np.sum(seq_m14b > 300)
    features['m14b_over_350'] = np.sum(seq_m14b > 350)
    features['m14b_over_400'] = np.sum(seq_m14b > 400)
    features['m14b_over_450'] = np.sum(seq_m14b > 450)
    features['m14b_over_300_last30'] = np.sum(seq_m14b[-30:] > 300)
    features['m14b_over_350_last30'] = np.sum(seq_m14b[-30:] > 350)
    features['m14b_over_400_last30'] = np.sum(seq_m14b[-30:] > 400)
    
    # ========== M14AM10A ì„ê³„ê°’ ì¹´ìš´íŠ¸ (4ê°œ) ==========
    features['m10a_over_70'] = np.sum(seq_m10a > 70)
    features['m10a_over_80'] = np.sum(seq_m10a > 80)
    features['m10a_under_80'] = np.sum(seq_m10a < 80)
    features['m10a_under_70'] = np.sum(seq_m10a < 70)
    
    # ========== TOTALCNT ì„ê³„ê°’ ì¹´ìš´íŠ¸ (8ê°œ) ==========
    features['totalcnt_over_1400'] = np.sum(seq_totalcnt >= 1400)
    features['totalcnt_over_1500'] = np.sum(seq_totalcnt >= 1500)
    features['totalcnt_over_1600'] = np.sum(seq_totalcnt >= 1600)
    features['totalcnt_over_1700'] = np.sum(seq_totalcnt >= 1700)
    features['totalcnt_over_1400_last30'] = np.sum(seq_totalcnt[-30:] >= 1400)
    features['totalcnt_over_1500_last30'] = np.sum(seq_totalcnt[-30:] >= 1500)
    features['totalcnt_over_1600_last30'] = np.sum(seq_totalcnt[-30:] >= 1600)
    features['totalcnt_over_1700_last30'] = np.sum(seq_totalcnt[-30:] >= 1700)
    
    # ========== í™©ê¸ˆ íŒ¨í„´ (4ê°œ) ==========
    features['golden_pattern_300_80'] = 1 if (seq_m14b[-1] > 300 and seq_m10a[-1] < 80) else 0
    features['golden_pattern_350_80'] = 1 if (seq_m14b[-1] > 350 and seq_m10a[-1] < 80) else 0
    features['golden_pattern_400_70'] = 1 if (seq_m14b[-1] > 400 and seq_m10a[-1] < 70) else 0
    features['danger_zone'] = 1 if seq_totalcnt[-1] >= 1700 else 0
    
    # ========== ë³€í™”ìœ¨/ê°€ì†ë„ (8ê°œ) ==========
    features['m14b_change_rate'] = (seq_m14b[-1] - seq_m14b[-30]) / 30 if len(seq_m14b) >= 30 else 0
    features['totalcnt_change_rate'] = (seq_totalcnt[-1] - seq_totalcnt[-30]) / 30 if len(seq_totalcnt) >= 30 else 0
    
    recent_30_m14b = np.mean(seq_m14b[-30:])
    previous_30_m14b = np.mean(seq_m14b[-60:-30]) if len(seq_m14b) >= 60 else np.mean(seq_m14b[-30:])
    features['m14b_acceleration'] = recent_30_m14b - previous_30_m14b
    
    recent_30_totalcnt = np.mean(seq_totalcnt[-30:])
    previous_30_totalcnt = np.mean(seq_totalcnt[-60:-30]) if len(seq_totalcnt) >= 60 else np.mean(seq_totalcnt[-30:])
    features['totalcnt_acceleration'] = recent_30_totalcnt - previous_30_totalcnt
    
    features['m14b_range'] = np.max(seq_m14b) - np.min(seq_m14b)
    features['totalcnt_range'] = np.max(seq_totalcnt) - np.min(seq_totalcnt)
    features['m14b_recent_vs_mean'] = np.mean(seq_m14b[-30:]) / (np.mean(seq_m14b) + 1)
    features['totalcnt_recent_vs_mean'] = np.mean(seq_totalcnt[-30:]) / (np.mean(seq_totalcnt) + 1)
    
    # ========== ì‹œê°„ëŒ€ë³„ í†µê³„ (8ê°œ) ==========
    q1 = seq_totalcnt[:70]
    q2 = seq_totalcnt[70:140]
    q3 = seq_totalcnt[140:210]
    q4 = seq_totalcnt[210:280]
    
    features['totalcnt_q1_mean'] = np.mean(q1)
    features['totalcnt_q2_mean'] = np.mean(q2)
    features['totalcnt_q3_mean'] = np.mean(q3)
    features['totalcnt_q4_mean'] = np.mean(q4)
    features['totalcnt_trend_q1_q2'] = np.mean(q2) - np.mean(q1)
    features['totalcnt_trend_q2_q3'] = np.mean(q3) - np.mean(q2)
    features['totalcnt_trend_q3_q4'] = np.mean(q4) - np.mean(q3)
    features['totalcnt_trend_overall'] = np.mean(q4) - np.mean(q1)
    
    # ========== ğŸ”¥ ì¡°ê¸° ê²½ë³´ Feature (5ê°œ) ==========
    # ë§ˆì§€ë§‰ 10ë¶„ ë¶„ì„
    last_10min = seq_totalcnt[-10:]
    
    features['last_10min_max'] = np.max(last_10min)
    features['last_10min_min'] = np.min(last_10min)
    features['last_10min_mean'] = np.mean(last_10min)
    features['last_10min_rise'] = last_10min[-1] - last_10min[0]  # 10ë¶„ê°„ ìƒìŠ¹í­
    
    # ì¡°ê¸° ê²½ë³´: 1650 ì´ìƒ + 20 ì´ìƒ ìƒìŠ¹
    early_warning = (np.max(last_10min) >= 1650) and ((last_10min[-1] - last_10min[0]) > 20)
    features['early_warning_1650_rising'] = 1 if early_warning else 0
    
    # ========== ğŸ¯ 1550â†’1700 íŒ¨í„´ Feature (11ê°œ) ==========
    # ë§ˆì§€ë§‰ 5ë¶„ì—ì„œ TOTALCNT ì²´í¬
    last_5min_totalcnt = seq_totalcnt[-5:]
    current_totalcnt_max = np.max(last_5min_totalcnt)  # ë§ˆì§€ë§‰ 5ë¶„ ìµœëŒ€ê°’
    current_totalcnt_mean = np.mean(last_5min_totalcnt)  # ë§ˆì§€ë§‰ 5ë¶„ í‰ê· 
    
    # ìƒìŠ¹ ì¶”ì„¸ ì²´í¬ (ë§ˆì§€ë§‰ 5ë¶„ í‰ê·  vs ì´ì „ 5ë¶„ í‰ê· )
    prev_5min_totalcnt = seq_totalcnt[-10:-5]
    prev_5min_mean = np.mean(prev_5min_totalcnt)
    is_rising = current_totalcnt_mean > prev_5min_mean
    rise_amount = current_totalcnt_mean - prev_5min_mean
    
    features['current_totalcnt'] = current_totalcnt_max  # ë§ˆì§€ë§‰ 5ë¶„ ìµœëŒ€ê°’
    features['totalcnt_rise_5min'] = rise_amount  # 5ë¶„ ìƒìŠ¹í­
    
    # ğŸ”¥ 1550+ ì¡°ê±´: TOTALCNT 1550+ AND ìƒìŠ¹ ì¶”ì„¸ AND M14AM16 ì¡°ê±´
    is_1550_plus_with_conditions = (
        (current_totalcnt_max >= 1550) and 
        is_rising and 
        (seq_m16[-1] >= 217)  # M14AM16ì´ 217 ì´ìƒ
    )
    features['is_1550_plus'] = 1 if is_1550_plus_with_conditions else 0
    
    # ğŸ”¥ 1600+ ì¡°ê±´: TOTALCNT 1600+ AND ìƒìŠ¹ ì¶”ì„¸ AND ê°•í•œ M14AM16 ì¡°ê±´
    is_1600_plus_with_conditions = (
        (current_totalcnt_max >= 1600) and 
        is_rising and 
        (seq_m16[-1] >= 272)  # M14AM16ì´ 272 ì´ìƒ (75% ë¶„ìœ„ìˆ˜)
    )
    features['is_1600_plus'] = 1 if is_1600_plus_with_conditions else 0
    
    # M14AM16 í•µì‹¬ ë³€ìˆ˜ (46.2% ì°¨ì´)
    features['m16_last'] = seq_m16[-1]
    features['m16_last_vs_mean'] = seq_m16[-1] / (np.mean(seq_m16) + 1)
    
    # M14AM16SUM ê³„ì‚° (28.7% ì°¨ì´)
    if df is not None and 'M14AM16SUM' in df.columns and idx is not None:
        m16sum_current = df['M14AM16SUM'].iloc[idx-1]
    else:
        # M14AM16SUMì´ ì—†ìœ¼ë©´ ê³„ì‚°
        m16sum_current = np.sum(seq_m16[-10:])  # ìµœê·¼ 10ë¶„ í•©
    features['m16sum_current'] = m16sum_current
    
    # 1700+ ì˜ˆì¸¡ ê·œì¹™ (LEVEL 2 ê¸°ì¤€)
    rule_level2 = (seq_m16[-1] >= 272) and (m16sum_current >= 494) and (seq_m14b[-1] <= 194)
    features['pattern_1700_level2'] = 1 if rule_level2 else 0
    
    # 1700+ ì˜ˆì¸¡ ê·œì¹™ (LEVEL 3 ê¸´ê¸‰)
    rule_level3 = (seq_m16[-1] >= 641) and (m16sum_current >= 853)
    features['pattern_1700_level3'] = 1 if rule_level3 else 0
    
    # M14BM14A ë¹„ìœ¨ (15.3% ì°¨ì´)
    if df is not None and 'M14BM14A' in df.columns and idx is not None:
        m14bm14a_current = df['M14BM14A'].iloc[idx-1]
    else:
        m14bm14a_current = 0
    features['m14bm14a_current'] = m14bm14a_current
    
    # ë³µí•© íŒ¨í„´: 1550+ êµ¬ê°„ì—ì„œ ìœ„í—˜ ì‹ í˜¸ (ë§ˆì§€ë§‰ 5ë¶„ ê¸°ì¤€)
    high_base_danger = (
        (current_totalcnt_max >= 1550) and 
        (seq_m16[-1] >= 217) and 
        (m16sum_current >= 430)
    )
    features['pattern_1550_danger'] = 1 if high_base_danger else 0
    
    return features

def evaluate_all_predictions():
    """ì „ì²´ ë°ì´í„°ë¥¼ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ í‰ê°€ - 10ë¶„ í›„ (1ë…„ì¹˜ ë°ì´í„°)"""
    
    print("="*80)
    print("ğŸš€ 280ë¶„ ì‹œí€€ìŠ¤ â†’ 10ë¶„ í›„ ì˜ˆì¸¡ í‰ê°€ (1ë…„ì¹˜ ë°ì´í„°)")
    print("="*80)
    print("Feature: 96ê°œ (ì¡°ê¸° ê²½ë³´ 5 + 1550â†’1700 íŒ¨í„´ 11)")
    print("="*80)
    
    # ëª¨ë¸ ë¡œë“œ (ì—¬ëŸ¬ íŒŒì¼ëª… ì‹œë„)
    model_files = [
        'xgboost_280to10_1year_augmented.pkl',
        'xgboost_280to10_enhanced_earlywarning.pkl',
        '/mnt/user-data/outputs/xgboost_280to10_1year_augmented.pkl'
    ]
    
    model = None
    model_file = None
    
    for mf in model_files:
        if os.path.exists(mf):
            try:
                with open(mf, 'rb') as f:
                    model = pickle.load(f)
                model_file = mf
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_file}")
                break
            except Exception as e:
                print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({mf}): {e}")
    
    if model is None:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ!")
        print(f"ì‹œë„í•œ íŒŒì¼:")
        for mf in model_files:
            print(f"  - {mf}")
        print("\në¨¼ì € FINAL_xgb_280_COMPLETE.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
        return None
    
    # ë°ì´í„° ë¡œë“œ (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
    csv_files = [
        '/mnt/project/V6_6ê²°ê³¼.CSV',
        'V6_6ê²°ê³¼.CSV',
        '/mnt/project/uu.csv',
        'uu.csv'
    ]
    
    df = None
    csv_file = None
    
    for cf in csv_files:
        if os.path.exists(cf):
            try:
                print(f"ë°ì´í„° ë¡œë”© ì¤‘: {cf}...")
                df = pd.read_csv(cf, on_bad_lines='skip')
                csv_file = cf
                print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ í–‰")
                break
            except Exception as e:
                print(f"âš ï¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ({cf}): {e}")
    
    if df is None:
        print(f"âŒ CSV íŒŒì¼ ì—†ìŒ!")
        print(f"ì‹œë„í•œ íŒŒì¼:")
        for cf in csv_files:
            print(f"  - {cf}")
        return None
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    memory_mb = df.memory_usage(deep=True).sum() / 1024 / 1024
    print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_mb:.1f} MB")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_cols = ['M14AM14B', 'M14AM10A', 'M14AM16', 'TOTALCNT']
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        print(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
        print(f"í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")
        return None
    
    print(f"âœ… í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ì™„ë£Œ")
    
    # CURRTIME ì²˜ë¦¬
    if 'CURRTIME' in df.columns:
        try:
            df['CURRTIME'] = pd.to_datetime(df['CURRTIME'].astype(str), format='%Y%m%d%H%M')
            print("âœ… CURRTIME íŒŒì‹± ì™„ë£Œ")
        except:
            print("âš ï¸ CURRTIME ë³€í™˜ ì‹¤íŒ¨, ê°€ìƒ ì‹œê°„ ìƒì„±")
            base_time = datetime(2024, 1, 1, 0, 0)
            df['CURRTIME'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
    else:
        print("âš ï¸ CURRTIME ì—†ìŒ, ê°€ìƒ ì‹œê°„ ìƒì„±")
        base_time = datetime(2024, 1, 1, 0, 0)
        df['CURRTIME'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
    
    results = []
    
    total_predictions = len(df) - 280 - 10
    print(f"\nğŸ”„ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° í‰ê°€ ì‹œì‘...")
    print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {total_predictions:,}ê°œ")
    print(f"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {total_predictions / 10000:.1f}ë¶„")
    
    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
    for i in range(280, len(df) - 10):
        # 280ë¶„ ì‹œí€€ìŠ¤
        seq_m14b = df['M14AM14B'].iloc[i-280:i].values
        seq_m10a = df['M14AM10A'].iloc[i-280:i].values
        seq_m16 = df['M14AM16'].iloc[i-280:i].values
        seq_totalcnt = df['TOTALCNT'].iloc[i-280:i].values
        
        # ì‹œê°„ ì •ë³´
        current_time = df['CURRTIME'].iloc[i-1]  # ì‹œí€€ìŠ¤ ë§ˆì§€ë§‰ (í˜„ì¬)
        seq_start_time = df['CURRTIME'].iloc[i-280]
        prediction_time = current_time + timedelta(minutes=10)
        actual_time = df['CURRTIME'].iloc[i+9]  # âœ… 10ë¶„ í›„ (i+9)
        
        # âœ… ì‹¤ì œê°’ (10ë¶„ í›„)
        actual_value = df['TOTALCNT'].iloc[i+9]  # iëŠ” 1ë¶„ í›„, i+9ëŠ” 10ë¶„ í›„
        
        # Feature ìƒì„± (96ê°œ: ì¡°ê¸° ê²½ë³´ + 1550â†’1700 íŒ¨í„´)
        features = create_single_prediction_features(seq_m14b, seq_m10a, seq_m16, seq_totalcnt, df, i)
        X_pred = pd.DataFrame([features])
        
        # ì˜ˆì¸¡
        prediction = model.predict(X_pred)[0]
        
        # í™©ê¸ˆ íŒ¨í„´ ê°ì§€
        golden_pattern = (seq_m14b[-1] > 300 and seq_m10a[-1] < 80)
        
        # ìœ„í—˜ êµ¬ê°„ ê°ì§€
        danger_in_seq = np.sum(seq_totalcnt >= 1700) > 0
        
        # ğŸ”¥ ì¡°ê¸° ê²½ë³´ ê°ì§€
        last_10min = seq_totalcnt[-10:]
        early_warning_detected = (np.max(last_10min) >= 1650) and ((last_10min[-1] - last_10min[0]) > 20)
        
        # ğŸ¯ 1550â†’1700 íŒ¨í„´ ê°ì§€
        pattern_1550_detected = features['is_1550_plus'] == 1
        pattern_1700_level2 = features['pattern_1700_level2'] == 1
        pattern_1700_level3 = features['pattern_1700_level3'] == 1
        
        # ğŸ”¥ğŸ”¥ ì¡°ê¸°ê²½ë³´ ë°œìƒ ì‹œ ì˜ˆì¸¡ê°’ * 1.02 (2% ì¦ê°€)
        if early_warning_detected:
            prediction = prediction * 1.02
        
        # ê²°ê³¼ ì €ì¥
        results.append({
            'ì‹œí€€ìŠ¤ì‹œì‘': seq_start_time.strftime('%Y-%m-%d %H:%M'),
            'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
            'í˜„ì¬TOTALCNT': round(seq_totalcnt[-1], 2),  # âœ… í˜„ì¬ ì‹œì ì˜ ì‹¤ì œ TOTALCNT
            'ì˜ˆì¸¡ì‹œì ': prediction_time.strftime('%Y-%m-%d %H:%M'),
            'ì‹¤ì œì‹œì ': actual_time.strftime('%Y-%m-%d %H:%M'),
            'ì‹¤ì œê°’': round(actual_value, 2),
            'ì˜ˆì¸¡ê°’': round(prediction, 2),
            'ì˜¤ì°¨': round(actual_value - prediction, 2),
            'ì ˆëŒ€ì˜¤ì°¨': round(abs(actual_value - prediction), 2),
            'ì˜¤ì°¨ìœ¨(%)': round(abs(actual_value - prediction) / max(actual_value, 1) * 100, 2),
            'M14AM14B': round(seq_m14b[-1], 2),
            'M14AM10A': round(seq_m10a[-1], 2),
            'M14AM16': round(seq_m16[-1], 2),
            'ì‹œí€€ìŠ¤TOTALCNT_MAX': round(np.max(seq_totalcnt), 2),
            'ì‹œí€€ìŠ¤TOTALCNT_MIN': round(np.min(seq_totalcnt), 2),
            'ì‹œí€€ìŠ¤TOTALCNT_í‰ê· ': round(np.mean(seq_totalcnt), 2),
            'ë§ˆì§€ë§‰10ë¶„_MAX': round(np.max(last_10min), 2),
            'ë§ˆì§€ë§‰10ë¶„_ìƒìŠ¹í­': round(last_10min[-1] - last_10min[0], 2),
            'ë§ˆì§€ë§‰5ë¶„_MAX': round(features['current_totalcnt'], 2),
            '5ë¶„ìƒìŠ¹í­': round(features['totalcnt_rise_5min'], 2),
            'í™©ê¸ˆíŒ¨í„´': 'O' if golden_pattern else '',
            'ì‹œí€€ìŠ¤ìœ„í—˜': 'O' if danger_in_seq else '',
            'ì¡°ê¸°ê²½ë³´': 'O' if early_warning_detected else '',
            'ì¡°ê¸°ê²½ë³´2%ì ìš©': 'O' if early_warning_detected else '',
            '1550+íŒ¨í„´': 'O' if pattern_1550_detected else '',
            '1700_LEVEL2': 'O' if pattern_1700_level2 else '',
            '1700_LEVEL3': 'O' if pattern_1700_level3 else '',
            'ì‹¤ì œìœ„í—˜(1700+)': 'O' if actual_value >= 1700 else '',
            'ì˜ˆì¸¡ìœ„í—˜(1650+)': 'O' if prediction >= 1650 else ''
        })
        
        # ì§„í–‰ìƒí™© ì¶œë ¥ (1ë…„ì¹˜ ë°ì´í„°ìš© - 50000ê°œë§ˆë‹¤)
        if (i - 280) % 50000 == 0 and i > 280:
            progress = (i - 280) / total_predictions * 100
            elapsed = (i - 280) / 10000  # ëŒ€ëµì ì¸ ê²½ê³¼ ì‹œê°„
            print(f"  ì§„í–‰ì¤‘... {i-280:,}/{total_predictions:,} ({progress:.1f}%) - ì•½ {elapsed:.1f}ë¶„ ê²½ê³¼")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
    
    print(f"âœ… í‰ê°€ ì™„ë£Œ!")
    
    # DataFrame ë³€í™˜
    results_df = pd.DataFrame(results)
    
    # CSV ì €ì¥
    output_file = 'evaluation_280to10_1year_with_1550pattern.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    del df
    gc.collect()
    
    # ===== í†µê³„ ë¶„ì„ =====
    print("\n" + "="*80)
    print("ğŸ“Š í‰ê°€ í†µê³„ (280ë¶„ â†’ 10ë¶„ í›„)")
    print("="*80)
    print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(results_df):,}ê°œ")
    print(f"í‰ê·  ì ˆëŒ€ ì˜¤ì°¨(MAE): {results_df['ì ˆëŒ€ì˜¤ì°¨'].mean():.2f}")
    print(f"í‰ê·  ì˜¤ì°¨ìœ¨: {results_df['ì˜¤ì°¨ìœ¨(%)'].mean():.2f}%")
    print(f"ìµœëŒ€ ì ˆëŒ€ ì˜¤ì°¨: {results_df['ì ˆëŒ€ì˜¤ì°¨'].max():.2f}")
    print(f"ìµœì†Œ ì ˆëŒ€ ì˜¤ì°¨: {results_df['ì ˆëŒ€ì˜¤ì°¨'].min():.2f}")
    
    print(f"\ní™©ê¸ˆ íŒ¨í„´ ë°œìƒ: {results_df['í™©ê¸ˆíŒ¨í„´'].value_counts().get('O', 0):,}ê°œ")
    print(f"ì‹œí€€ìŠ¤ ìœ„í—˜ êµ¬ê°„: {results_df['ì‹œí€€ìŠ¤ìœ„í—˜'].value_counts().get('O', 0):,}ê°œ")
    print(f"ğŸ”¥ ì¡°ê¸° ê²½ë³´ ë°œìƒ: {results_df['ì¡°ê¸°ê²½ë³´'].value_counts().get('O', 0):,}ê°œ")
    print(f"ğŸ¯ 1550+ íŒ¨í„´ ë°œìƒ: {results_df['1550+íŒ¨í„´'].value_counts().get('O', 0):,}ê°œ")
    print(f"ğŸ¯ 1700 LEVEL2 ë°œìƒ: {results_df['1700_LEVEL2'].value_counts().get('O', 0):,}ê°œ")
    print(f"ğŸ¯ 1700 LEVEL3 ë°œìƒ: {results_df['1700_LEVEL3'].value_counts().get('O', 0):,}ê°œ")
    
    # ìœ„í—˜ êµ¬ê°„ ë¶„ì„
    actual_danger = results_df['ì‹¤ì œìœ„í—˜(1700+)'] == 'O'
    pred_danger = results_df['ì˜ˆì¸¡ìœ„í—˜(1650+)'] == 'O'
    early_warning = results_df['ì¡°ê¸°ê²½ë³´'] == 'O'
    pattern_1550 = results_df['1550+íŒ¨í„´'] == 'O'
    pattern_level2 = results_df['1700_LEVEL2'] == 'O'
    pattern_level3 = results_df['1700_LEVEL3'] == 'O'
    
    actual_danger_count = actual_danger.sum()
    pred_danger_count = pred_danger.sum()
    danger_detected = (actual_danger & pred_danger).sum()
    early_warning_count = early_warning.sum()
    pattern_1550_count = pattern_1550.sum()
    pattern_level2_count = pattern_level2.sum()
    pattern_level3_count = pattern_level3.sum()
    
    # ì¡°ê¸° ê²½ë³´ì˜ 1700+ ì˜ˆì¸¡ë ¥
    early_to_danger = (early_warning & actual_danger).sum()
    
    # 1550+ íŒ¨í„´ì˜ 1700+ ì˜ˆì¸¡ë ¥
    pattern_1550_to_danger = (pattern_1550 & actual_danger).sum()
    
    # LEVEL2ì˜ 1700+ ì˜ˆì¸¡ë ¥
    level2_to_danger = (pattern_level2 & actual_danger).sum()
    
    # LEVEL3ì˜ 1700+ ì˜ˆì¸¡ë ¥
    level3_to_danger = (pattern_level3 & actual_danger).sum()
    
    print(f"\nì‹¤ì œ ìœ„í—˜(1700+): {actual_danger_count:,}ê°œ")
    print(f"ì˜ˆì¸¡ ìœ„í—˜(1650+): {pred_danger_count:,}ê°œ")
    print(f"ìœ„í—˜ ê°ì§€ ì„±ê³µ: {danger_detected:,}ê°œ")
    if actual_danger_count > 0:
        print(f"ìœ„í—˜ ê°ì§€ìœ¨: {danger_detected/actual_danger_count*100:.1f}%")
    
    if early_warning_count > 0:
        print(f"\nğŸ”¥ ì¡°ê¸° ê²½ë³´ â†’ ì‹¤ì œ 1700+ ë°œìƒ: {early_to_danger:,}ê°œ ({early_to_danger/early_warning_count*100:.1f}%)")
    
    if pattern_1550_count > 0:
        print(f"ğŸ¯ 1550+ íŒ¨í„´ â†’ ì‹¤ì œ 1700+ ë°œìƒ: {pattern_1550_to_danger:,}ê°œ ({pattern_1550_to_danger/pattern_1550_count*100:.1f}%)")
    
    if pattern_level2_count > 0:
        print(f"ğŸ¯ LEVEL2 íŒ¨í„´ â†’ ì‹¤ì œ 1700+ ë°œìƒ: {level2_to_danger:,}ê°œ ({level2_to_danger/pattern_level2_count*100:.1f}%)")
    
    if pattern_level3_count > 0:
        print(f"ğŸ¯ LEVEL3 íŒ¨í„´ â†’ ì‹¤ì œ 1700+ ë°œìƒ: {level3_to_danger:,}ê°œ ({level3_to_danger/pattern_level3_count*100:.1f}%)")
    
    # M14AM14B 450+ êµ¬ê°„ ë¶„ì„
    high_m14b_mask = results_df['M14AM14B'] >= 450
    high_m14b_count = high_m14b_mask.sum()
    if high_m14b_count > 0:
        print(f"\nğŸ”¥ M14AM14B 450+ êµ¬ê°„: {high_m14b_count:,}ê°œ")
        high_m14b_mae = results_df[high_m14b_mask]['ì ˆëŒ€ì˜¤ì°¨'].mean()
        print(f"   í‰ê·  MAE: {high_m14b_mae:.2f}")
        high_m14b_danger = (high_m14b_mask & actual_danger).sum()
        print(f"   1700+ ë°œìƒ: {high_m14b_danger:,}ê°œ ({high_m14b_danger/high_m14b_count*100:.1f}%)")
    
    # ì˜¤ì°¨ ìƒìœ„ 10ê°œ
    print("\n" + "="*80)
    print("ì˜¤ì°¨ ìƒìœ„ 10ê°œ êµ¬ê°„")
    print("="*80)
    top_errors = results_df.nlargest(10, 'ì ˆëŒ€ì˜¤ì°¨')
    print(top_errors[['í˜„ì¬ì‹œê°„', 'í˜„ì¬TOTALCNT', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’', 'ì ˆëŒ€ì˜¤ì°¨', 'M14AM14B', '1550+íŒ¨í„´', 'ì¡°ê¸°ê²½ë³´']].to_string(index=False))
    
    # âœ… 10ì¹¸ ë‚´ë ¤ì„œ ë¹„êµ ê²€ì¦ (ìƒ˜í”Œ 10ê°œ)
    print("\n" + "="*80)
    print("ğŸ” 10ì¹¸ ë‚´ë ¤ì„œ ì˜ˆì¸¡ ê²€ì¦ (ìƒ˜í”Œ 10ê°œ)")
    print("="*80)
    print("Line 1ì˜ ì˜ˆì¸¡ê°’ vs Line 11ì˜ í˜„ì¬TOTALCNT ë¹„êµ")
    print("-"*80)
    
    for idx in [0, 100, 200, 300, 400, 500, 600, 700, 800, 900]:
        if idx + 10 < len(results_df):
            line1_time = results_df.iloc[idx]['í˜„ì¬ì‹œê°„']
            line1_pred = results_df.iloc[idx]['ì˜ˆì¸¡ê°’']
            line11_time = results_df.iloc[idx+10]['í˜„ì¬ì‹œê°„']
            line11_current = results_df.iloc[idx+10]['í˜„ì¬TOTALCNT']
            diff = abs(line11_current - line1_pred)
            
            print(f"Line {idx+1:4d} (ì˜ˆì¸¡): {line1_time} â†’ ì˜ˆì¸¡ê°’: {line1_pred:7.2f}")
            print(f"Line {idx+11:4d} (ì‹¤ì œ): {line11_time} â†’ í˜„ì¬ê°’: {line11_current:7.2f}")
            print(f"           ì°¨ì´: {diff:.2f}")
            print("-"*40)
    
    # 1550+ íŒ¨í„´ ë°œìƒ êµ¬ê°„ ë¶„ì„
    if pattern_1550_count > 0:
        print("\n" + "="*80)
        print("ğŸ¯ 1550+ íŒ¨í„´ ë°œìƒ êµ¬ê°„ (ìƒ˜í”Œ 20ê°œ)")
        print("="*80)
        pattern_cases = results_df[results_df['1550+íŒ¨í„´'] == 'O']
        print(f"ì´ {len(pattern_cases):,}ê°œ")
        print(pattern_cases[['í˜„ì¬ì‹œê°„', 'ë§ˆì§€ë§‰5ë¶„_MAX', '5ë¶„ìƒìŠ¹í­', 'M14AM16', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’', 'ì‹¤ì œìœ„í—˜(1700+)']].head(20).to_string(index=False))
    
    # ì¡°ê¸° ê²½ë³´ ë°œìƒ êµ¬ê°„ ë¶„ì„
    if early_warning_count > 0:
        print("\n" + "="*80)
        print("ğŸ”¥ ì¡°ê¸° ê²½ë³´ ë°œìƒ êµ¬ê°„ (ìƒ˜í”Œ 20ê°œ)")
        print("="*80)
        early_cases = results_df[results_df['ì¡°ê¸°ê²½ë³´'] == 'O']
        print(f"ì´ {len(early_cases):,}ê°œ")
        print(early_cases[['í˜„ì¬ì‹œê°„', 'ë§ˆì§€ë§‰10ë¶„_MAX', 'ë§ˆì§€ë§‰10ë¶„_ìƒìŠ¹í­', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’', 'ì‹¤ì œìœ„í—˜(1700+)']].head(20).to_string(index=False))
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "="*80)
    print("âœ… ìµœì¢… í‰ê°€ ìš”ì•½")
    print("="*80)
    print(f"1. ì „ì²´ ì„±ëŠ¥:")
    print(f"   - MAE: {results_df['ì ˆëŒ€ì˜¤ì°¨'].mean():.2f}")
    print(f"   - ìœ„í—˜ ê°ì§€ìœ¨: {danger_detected/actual_danger_count*100:.1f}% ({danger_detected:,}/{actual_danger_count:,})")
    
    if high_m14b_count > 0:
        print(f"\n2. M14AM14B 450+ êµ¬ê°„:")
        print(f"   - ë°œìƒ íšŸìˆ˜: {high_m14b_count:,}ê°œ")
        print(f"   - MAE: {high_m14b_mae:.2f}")
        print(f"   - 1700+ ë¹„ìœ¨: {high_m14b_danger/high_m14b_count*100:.1f}%")
    
    if early_warning_count > 0:
        print(f"\n3. ì¡°ê¸° ê²½ë³´:")
        print(f"   - ë°œìƒ íšŸìˆ˜: {early_warning_count:,}ê°œ")
        print(f"   - ì •í™•ë„: {early_to_danger/early_warning_count*100:.1f}% (1700+ ì˜ˆì¸¡)")
    
    if pattern_1550_count > 0:
        print(f"\n4. 1550â†’1700 íŒ¨í„´:")
        print(f"   - ë°œìƒ íšŸìˆ˜: {pattern_1550_count:,}ê°œ")
        print(f"   - ì •í™•ë„: {pattern_1550_to_danger/pattern_1550_count*100:.1f}% (1700+ ì˜ˆì¸¡)")
        
        if pattern_level2_count > 0:
            print(f"   - LEVEL2: {pattern_level2_count:,}ê°œ ({level2_to_danger/pattern_level2_count*100:.1f}% ì •í™•ë„)")
        
        if pattern_level3_count > 0:
            print(f"   - LEVEL3: {pattern_level3_count:,}ê°œ ({level3_to_danger/pattern_level3_count*100:.1f}% ì •í™•ë„)")
    
    print(f"\n5. ì €ì¥ íŒŒì¼:")
    print(f"   - {output_file}")
    print("="*80)
    
    return results_df

if __name__ == '__main__':
    print("\nğŸš€ 280ë¶„ ì‹œí€€ìŠ¤ â†’ 10ë¶„ í›„ ì˜ˆì¸¡ í‰ê°€ ì‹œì‘ (1ë…„ì¹˜ ë°ì´í„°)...\n")
    results = evaluate_all_predictions()
    
    if results is not None:
        print(f"\nâœ… í‰ê°€ ì™„ë£Œ! ì´ {len(results):,}ê°œ ì˜ˆì¸¡ ìƒì„±")
        print(f"âœ… ê²°ê³¼ íŒŒì¼: evaluation_280to10_1year_with_1550pattern.csv")