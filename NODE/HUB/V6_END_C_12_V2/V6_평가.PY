import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta

def evaluate_change_prediction():
    """
    ğŸ¯ ë³€í™”ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ í‰ê°€
    - ë‹¨ì¼ ëª¨ë¸ë¡œ ê¸‰ì¦/ê¸‰ê° ë™ì‹œ ê°ì§€
    """
    print("="*80)
    print("ğŸ¯ ë³€í™”ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ í‰ê°€")
    print("="*80)
   
    FEATURE_COLS = {
        'storage': ['M16A_3F_STORAGE_UTIL'],
        'fs_storage': ['CD_M163FSTORAGEUSE', 'CD_M163FSTORAGETOTAL', 'CD_M163FSTORAGEUTIL'],
        'hub': ['HUBROOMTOTAL'],
        'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],
        'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],
        'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],
        'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA']
    }
   
    # ëª¨ë¸ ë¡œë“œ
    try:
        with open('xgboost_ë³€í™”ëŸ‰ì˜ˆì¸¡.pkl', 'rb') as f:
            model = pickle.load(f)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: xgboost_ë³€í™”ëŸ‰ì˜ˆì¸¡.pkl")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {e}")
        print("   ë¨¼ì € 'V7_ë³€í™”ëŸ‰_í•™ìŠµì½”ë“œ.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return None
   
    # ë°ì´í„° ë¡œë“œ
    try:
        df = pd.read_csv('HUB0905101512.csv', on_bad_lines='skip', encoding='utf-8', low_memory=False)
    except:
        try:
            df = pd.read_csv('HUB0905101512.csv', on_bad_lines='skip', encoding='cp949', low_memory=False)
        except:
            df = pd.read_csv('HUB0905101512.csv', on_bad_lines='skip', encoding='euc-kr', low_memory=False)
   
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
   
    # íƒ€ì… ë³€í™˜
    df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')
    df = df.dropna(subset=[TARGET_COL])
   
    print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(df)}ê°œ í–‰")
   
    # STAT_DT ì²˜ë¦¬
    if 'STAT_DT' in df.columns:
        try:
            df['STAT_DT'] = pd.to_datetime(df['STAT_DT'].astype(str), format='%Y%m%d%H%M')
        except:
            base_time = datetime(2024, 1, 1, 0, 0)
            df['STAT_DT'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
   
    results = []
   
    print("\nìŠ¬ë¼ì´ë”© ìœˆë„ìš° í‰ê°€ ì‹œì‘...")
    for i in range(30, len(df) - 10):
        if (i - 30) % 1000 == 0:
            print(f"ì§„í–‰: {i-30}/{len(df)-40} ({(i-30)/(len(df)-40)*100:.1f}%)")
       
        seq_data = df.iloc[i-30:i].copy()
        seq_target = seq_data[TARGET_COL].values
       
        current_time = seq_data['STAT_DT'].iloc[-1]
        current_value = seq_target[-1]
        prediction_time = current_time + timedelta(minutes=10)
       
        # 10ë¶„ í›„ ì‹¤ì œ ê°’
        actual_value = df.iloc[i+10][TARGET_COL]
        actual_time = df.iloc[i+10]['STAT_DT']
        actual_change = actual_value - current_value
       
        # Feature ìƒì„± (í•™ìŠµ ì½”ë“œì™€ ë™ì¼)
        features = {
            'target_mean': np.mean(seq_target),
            'target_std': np.std(seq_target),
            'target_max': np.max(seq_target),
            'target_min': np.min(seq_target),
            'target_last_value': seq_target[-1],
            'target_last_5_mean': np.mean(seq_target[-5:]),
            'target_slope': np.polyfit(np.arange(30), seq_target, 1)[0],
        }
       
        # ë³€í™”ëŸ‰ ì˜ˆì¸¡ìš© ì¶”ê°€ Feature
        features['target_from_max'] = np.max(seq_target) - seq_target[-1]
        features['target_decreasing'] = 1 if features['target_slope'] < -1 else 0
        features['target_increasing'] = 1 if features['target_slope'] > 1 else 0
        features['target_volatility'] = np.std(np.diff(seq_target))
        features['target_momentum'] = np.mean(seq_target[-5:]) - np.mean(seq_target[:5])
       
        # ê° ì»¬ëŸ¼ Feature
        for group_name, cols in FEATURE_COLS.items():
            for col in cols:
                if col not in df.columns:
                    continue
               
                col_seq = seq_data[col].values
               
                if group_name == 'maxcapa':
                    features[f'{col}_last_value'] = col_seq[-1]
               
                elif group_name in ['cmd', 'storage', 'fs_storage', 'hub']:
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_std'] = np.std(col_seq)
                    features[f'{col}_max'] = np.max(col_seq)
                    features[f'{col}_min'] = np.min(col_seq)
                    features[f'{col}_last_value'] = col_seq[-1]
                    features[f'{col}_last_5_mean'] = np.mean(col_seq[-5:])
                    features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
               
                else:
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_last_value'] = col_seq[-1]
                    features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
       
        # FS Storage Feature
        if 'CD_M163FSTORAGEUSE' in df.columns and 'CD_M163FSTORAGETOTAL' in df.columns and 'CD_M163FSTORAGEUTIL' in df.columns:
            use_seq = seq_data['CD_M163FSTORAGEUSE'].values
            total_seq = seq_data['CD_M163FSTORAGETOTAL'].values
            util_seq = seq_data['CD_M163FSTORAGEUTIL'].values
           
            features['storage_use_rate'] = (use_seq[-1] - use_seq[0]) / 30
            features['storage_remaining'] = total_seq[-1] - use_seq[-1]
            features['storage_util_last'] = util_seq[-1]
            features['storage_util_high'] = 1 if util_seq[-1] >= 7 else 0
            features['storage_util_critical'] = 1 if util_seq[-1] >= 10 else 0
       
        # HUBROOMTOTAL Feature
        if 'HUBROOMTOTAL' in df.columns:
            hub_seq = seq_data['HUBROOMTOTAL'].values
            hub_last = hub_seq[-1]
           
            features['hub_critical'] = 1 if hub_last < 590 else 0
            features['hub_high'] = 1 if hub_last < 610 else 0
            features['hub_warning'] = 1 if hub_last < 620 else 0
            features['hub_decrease_rate'] = (hub_seq[0] - hub_last) / 30
           
            if 'CD_M163FSTORAGEUTIL' in df.columns:
                storage_util_last = df['CD_M163FSTORAGEUTIL'].iloc[i-1]
                features['hub_storage_risk'] = 1 if (hub_last < 610 and storage_util_last >= 7) else 0
       
        # CMD Feature
        inflow_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['inflow'] if col in df.columns)
        outflow_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['outflow'] if col in df.columns)
        features['net_flow'] = inflow_sum - outflow_sum
       
        cmd_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['cmd'] if col in df.columns)
        features['total_cmd'] = cmd_sum
        features['total_cmd_low'] = 1 if cmd_sum < 220 else 0
        features['total_cmd_very_low'] = 1 if cmd_sum < 200 else 0
       
        if 'HUBROOMTOTAL' in df.columns:
            hub_last = df['HUBROOMTOTAL'].iloc[i-1]
            features['hub_cmd_bottleneck'] = 1 if (hub_last < 610 and cmd_sum < 220) else 0
       
        # Storage Util
        if 'M16A_3F_STORAGE_UTIL' in df.columns:
            storage_util = df['M16A_3F_STORAGE_UTIL'].iloc[i-1]
            features['storage_util_critical'] = 1 if storage_util >= 205 else 0
            features['storage_util_high_risk'] = 1 if storage_util >= 207 else 0
       
        # DataFrameìœ¼ë¡œ ë³€í™˜
        X_pred = pd.DataFrame([features])
       
        # ë³€í™”ëŸ‰ ì˜ˆì¸¡
        predicted_change = model.predict(X_pred)[0]
        predicted_value = current_value + predicted_change
       
        # ê¸‰ì¦/ê¸‰ê° íŒì •
        is_surge = (current_value < 300 and actual_value >= 300)
        is_drop = (current_value >= 300 and actual_value < 300)
        is_extreme = (actual_value >= 300)
       
        surge_detected = (is_surge and predicted_value >= 290)
        drop_detected = (is_drop and predicted_value < 310)
        extreme_detected = (is_extreme and predicted_value >= 290)
       
        # ìœ„í—˜ë„ íŒì •
        risk_level = "LOW"
        if abs(predicted_change) >= 40:
            risk_level = "HIGH"
        elif abs(predicted_change) >= 25:
            risk_level = "MEDIUM"
       
        results.append({
            'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
            'ì˜ˆì¸¡ì‹œì ': prediction_time.strftime('%Y-%m-%d %H:%M'),
            'í˜„ì¬ê°’': round(current_value, 2),
            'ì‹¤ì œ_10ë¶„í›„': round(actual_value, 2),
            'ì˜ˆì¸¡_10ë¶„í›„': round(predicted_value, 2),
            'ì‹¤ì œ_ë³€í™”ëŸ‰': round(actual_change, 2),
            'ì˜ˆì¸¡_ë³€í™”ëŸ‰': round(predicted_change, 2),
            'ë³€í™”ëŸ‰_ì˜¤ì°¨': round(abs(actual_change - predicted_change), 2),
            'ì˜ˆì¸¡ê°’_ì˜¤ì°¨': round(abs(actual_value - predicted_value), 2),
            'ê¸‰ì¦': 'âœ…' if is_surge else '',
            'ê¸‰ì¦ê°ì§€': 'âœ…' if surge_detected else '',
            'ê¸‰ê°': 'âœ…' if is_drop else '',
            'ê¸‰ê°ê°ì§€': 'âœ…' if drop_detected else '',
            'ê·¹ë‹¨ê°’': 'âœ…' if is_extreme else '',
            'ê·¹ë‹¨ê°’ê°ì§€': 'âœ…' if extreme_detected else '',
            'ìœ„í—˜ë„': risk_level,
            'HUBROOMTOTAL': round(features.get('HUBROOMTOTAL_last_value', 0), 0),
            'FS_UTIL': round(features.get('CD_M163FSTORAGEUTIL_last_value', 0), 0),
            'CMD': round(features.get('total_cmd', 0), 0),
            'STORAGE_UTIL': round(features.get('M16A_3F_STORAGE_UTIL_last_value', 0), 0),
        })
   
    results_df = pd.DataFrame(results)
   
    output_file = 'ë³€í™”ëŸ‰ì˜ˆì¸¡_í‰ê°€ê²°ê³¼.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")
   
    # í†µê³„
    print("\n" + "="*80)
    print("ğŸ“Š í‰ê°€ í†µê³„")
    print("="*80)
   
    print(f"ì´ ì˜ˆì¸¡: {len(results_df)}ê°œ")
    print(f"\në³€í™”ëŸ‰ ì˜ˆì¸¡ ì •í™•ë„:")
    print(f"  í‰ê·  ë³€í™”ëŸ‰ ì˜¤ì°¨: {results_df['ë³€í™”ëŸ‰_ì˜¤ì°¨'].mean():.2f}")
    print(f"  í‰ê·  ì˜ˆì¸¡ê°’ ì˜¤ì°¨: {results_df['ì˜ˆì¸¡ê°’_ì˜¤ì°¨'].mean():.2f}")
   
    # ê¸‰ì¦ ì„±ëŠ¥
    surge_cases = results_df[results_df['ê¸‰ì¦'] == 'âœ…']
    if len(surge_cases) > 0:
        surge_detected = (surge_cases['ê¸‰ì¦ê°ì§€'] == 'âœ…').sum()
       
        print(f"\nğŸ”º ê¸‰ì¦ ì˜ˆì¸¡ ì„±ëŠ¥:")
        print(f"  ë°œìƒ: {len(surge_cases)}ê°œ ({len(surge_cases)/len(results_df)*100:.2f}%)")
        print(f"  ê°ì§€: {surge_detected}/{len(surge_cases)}ê°œ ({surge_detected/len(surge_cases)*100:.1f}%)")
       
        if surge_detected/len(surge_cases) >= 0.78:
            print(f"  âœ… ëª©í‘œ 78% ì´ìƒ ë‹¬ì„±!")
        else:
            print(f"  âš ï¸ ëª©í‘œ 78% ë¯¸ë‹¬")
   
    # ê¸‰ê° ì„±ëŠ¥
    drop_cases = results_df[results_df['ê¸‰ê°'] == 'âœ…']
    if len(drop_cases) > 0:
        drop_detected = (drop_cases['ê¸‰ê°ê°ì§€'] == 'âœ…').sum()
       
        print(f"\nğŸ”» ê¸‰ê° ì˜ˆì¸¡ ì„±ëŠ¥:")
        print(f"  ë°œìƒ: {len(drop_cases)}ê°œ ({len(drop_cases)/len(results_df)*100:.2f}%)")
        print(f"  ê°ì§€: {drop_detected}/{len(drop_cases)}ê°œ ({drop_detected/len(drop_cases)*100:.1f}%)")
   
    # ê·¹ë‹¨ê°’ ì„±ëŠ¥
    extreme_cases = results_df[results_df['ê·¹ë‹¨ê°’'] == 'âœ…']
    if len(extreme_cases) > 0:
        extreme_detected = (extreme_cases['ê·¹ë‹¨ê°’ê°ì§€'] == 'âœ…').sum()
       
        print(f"\nê·¹ë‹¨ê°’ (300+) ê°ì§€:")
        print(f"  ë°œìƒ: {len(extreme_cases)}ê°œ ({len(extreme_cases)/len(results_df)*100:.1f}%)")
        print(f"  ê°ì§€: {extreme_detected}/{len(extreme_cases)}ê°œ ({extreme_detected/len(extreme_cases)*100:.1f}%)")
   
    # ìœ„í—˜ë„ë³„ í†µê³„
    print(f"\nìœ„í—˜ë„ë³„ ë¶„ì„:")
    for risk in ['HIGH', 'MEDIUM', 'LOW']:
        risk_df = results_df[results_df['ìœ„í—˜ë„'] == risk]
        if len(risk_df) > 0:
            surge_in_risk = (risk_df['ê¸‰ì¦'] == 'âœ…').sum()
            drop_in_risk = (risk_df['ê¸‰ê°'] == 'âœ…').sum()
            print(f"  {risk}: {len(risk_df)}ê°œ - ê¸‰ì¦ {surge_in_risk}ê°œ, ê¸‰ê° {drop_in_risk}ê°œ")
   
    # ì˜¤ì°¨ ìƒìœ„ ì¼€ì´ìŠ¤
    print(f"\nâŒ ë³€í™”ëŸ‰ ì˜¤ì°¨ ìƒìœ„ 10ê°œ:")
    top_errors = results_df.nlargest(10, 'ë³€í™”ëŸ‰_ì˜¤ì°¨')
    print(top_errors[['í˜„ì¬ì‹œê°„', 'í˜„ì¬ê°’', 'ì‹¤ì œ_ë³€í™”ëŸ‰', 'ì˜ˆì¸¡_ë³€í™”ëŸ‰', 'ë³€í™”ëŸ‰_ì˜¤ì°¨', 'ê¸‰ì¦', 'ê¸‰ê°']].to_string(index=False))
   
    # ê¸‰ì¦ ì˜ˆì¸¡ ì‹¤íŒ¨ ì¼€ì´ìŠ¤
    if len(surge_cases) > 0:
        surge_failed = surge_cases[surge_cases['ê¸‰ì¦ê°ì§€'] != 'âœ…']
        if len(surge_failed) > 0:
            print(f"\nâŒ ê¸‰ì¦ ì˜ˆì¸¡ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ (ìƒìœ„ 5ê°œ):")
            failed_top = surge_failed.nlargest(5, 'ì‹¤ì œ_ë³€í™”ëŸ‰')
            print(failed_top[['í˜„ì¬ì‹œê°„', 'í˜„ì¬ê°’', 'ì‹¤ì œ_10ë¶„í›„', 'ì˜ˆì¸¡_10ë¶„í›„', 'ì‹¤ì œ_ë³€í™”ëŸ‰', 'ì˜ˆì¸¡_ë³€í™”ëŸ‰']].to_string(index=False))
   
    # ê¸‰ê° ì˜ˆì¸¡ ì‹¤íŒ¨ ì¼€ì´ìŠ¤
    if len(drop_cases) > 0:
        drop_failed = drop_cases[drop_cases['ê¸‰ê°ê°ì§€'] != 'âœ…']
        if len(drop_failed) > 0:
            print(f"\nâŒ ê¸‰ê° ì˜ˆì¸¡ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ (ìƒìœ„ 5ê°œ):")
            failed_top = drop_failed.nsmallest(5, 'ì‹¤ì œ_ë³€í™”ëŸ‰')
            print(failed_top[['í˜„ì¬ì‹œê°„', 'í˜„ì¬ê°’', 'ì‹¤ì œ_10ë¶„í›„', 'ì˜ˆì¸¡_10ë¶„í›„', 'ì‹¤ì œ_ë³€í™”ëŸ‰', 'ì˜ˆì¸¡_ë³€í™”ëŸ‰']].to_string(index=False))
   
    # ë³€í™”ëŸ‰ ë¶„í¬
    print(f"\nğŸ“Š ë³€í™”ëŸ‰ ë¶„í¬:")
    print(f"  ì‹¤ì œ ë³€í™”ëŸ‰:")
    print(f"    í‰ê· : {results_df['ì‹¤ì œ_ë³€í™”ëŸ‰'].mean():.2f}")
    print(f"    í‘œì¤€í¸ì°¨: {results_df['ì‹¤ì œ_ë³€í™”ëŸ‰'].std():.2f}")
    print(f"    ìµœì†Œ: {results_df['ì‹¤ì œ_ë³€í™”ëŸ‰'].min():.2f}")
    print(f"    ìµœëŒ€: {results_df['ì‹¤ì œ_ë³€í™”ëŸ‰'].max():.2f}")
   
    print(f"\n  ì˜ˆì¸¡ ë³€í™”ëŸ‰:")
    print(f"    í‰ê· : {results_df['ì˜ˆì¸¡_ë³€í™”ëŸ‰'].mean():.2f}")
    print(f"    í‘œì¤€í¸ì°¨: {results_df['ì˜ˆì¸¡_ë³€í™”ëŸ‰'].std():.2f}")
    print(f"    ìµœì†Œ: {results_df['ì˜ˆì¸¡_ë³€í™”ëŸ‰'].min():.2f}")
    print(f"    ìµœëŒ€: {results_df['ì˜ˆì¸¡_ë³€í™”ëŸ‰'].max():.2f}")
   
    return results_df

if __name__ == '__main__':
    print("ğŸš€ ë³€í™”ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ í‰ê°€ ì‹œì‘...\n")
    results = evaluate_change_prediction()
   
    if results is not None:
        print(f"\nâœ… í‰ê°€ ì™„ë£Œ! ì´ {len(results)}ê°œ ì˜ˆì¸¡")
        print(f"ğŸ“ ê²°ê³¼: ë³€í™”ëŸ‰ì˜ˆì¸¡_í‰ê°€ê²°ê³¼.csv")
        
        # ìµœì¢… ìš”ì•½
        surge_total = (results['ê¸‰ì¦'] == 'âœ…').sum()
        surge_detected = ((results['ê¸‰ì¦'] == 'âœ…') & (results['ê¸‰ì¦ê°ì§€'] == 'âœ…')).sum()
        drop_total = (results['ê¸‰ê°'] == 'âœ…').sum()
        drop_detected = ((results['ê¸‰ê°'] == 'âœ…') & (results['ê¸‰ê°ê°ì§€'] == 'âœ…')).sum()
        extreme_total = (results['ê·¹ë‹¨ê°’'] == 'âœ…').sum()
        extreme_detected = ((results['ê·¹ë‹¨ê°’'] == 'âœ…') & (results['ê·¹ë‹¨ê°’ê°ì§€'] == 'âœ…')).sum()
        
        print("\n" + "="*80)
        print("ğŸ¯ ìµœì¢… ì„±ëŠ¥ ìš”ì•½")
        print("="*80)
        print(f"\nğŸ”º ê¸‰ì¦: {surge_detected}/{surge_total} ({surge_detected/surge_total*100 if surge_total > 0 else 0:.1f}%)")
        print(f"ğŸ”» ê¸‰ê°: {drop_detected}/{drop_total} ({drop_detected/drop_total*100 if drop_total > 0 else 0:.1f}%)")
        print(f"âš¡ ê·¹ë‹¨ê°’ (300+): {extreme_detected}/{extreme_total} ({extreme_detected/extreme_total*100 if extreme_total > 0 else 0:.1f}%)")
        
        if surge_total > 0 and surge_detected/surge_total >= 0.78:
            print("\nâœ… ê¸‰ì¦ ê°ì§€ìœ¨ 78% ì´ìƒ ë‹¬ì„±!")
        elif surge_total > 0:
            print(f"\nâš ï¸ ê¸‰ì¦ ê°ì§€ìœ¨ {surge_detected/surge_total*100:.1f}% - 78% ëª©í‘œ ë¯¸ë‹¬")