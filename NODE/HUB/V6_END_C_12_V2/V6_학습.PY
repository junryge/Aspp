import numpy as np
import pandas as pd
import xgboost as xgb
import pickle
import warnings
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

warnings.filterwarnings('ignore')
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

def train_change_prediction():
    """
    ğŸ¯ ë³€í™”ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ (ë‹¨ì¼ ëª¨ë¸ë¡œ ê¸‰ì¦/ê¸‰ê° í•´ê²°)
    
    í•µì‹¬ ì•„ì´ë””ì–´:
    - íƒ€ê²Ÿ: 10ë¶„ í›„ ë³€í™”ëŸ‰ (delta = future - current)
    - ê¸‰ì¦: ë³€í™”ëŸ‰ +30 ì´ìƒ (ì–‘ìˆ˜)
    - ê¸‰ê°: ë³€í™”ëŸ‰ -30 ì´í•˜ (ìŒìˆ˜)
    - ì •ìƒ: -30 ~ +30 ë²”ìœ„
    
    ì¥ì :
    - ë‹¨ì¼ ëª¨ë¸ë¡œ ê¸‰ì¦/ê¸‰ê° ìë™ êµ¬ë¶„
    - ê¸°ì¡´ Feature 100% í™œìš©
    - ë¶€í˜¸ë¡œ ëª…í™•íˆ êµ¬ë¶„ë¨
    """
    print("="*80)
    print("ğŸ¯ ë³€í™”ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ (ê¸‰ì¦/ê¸‰ê° í†µí•©)")
    print("="*80)
   
    FEATURE_COLS = {
        'storage': ['M16A_3F_STORAGE_UTIL'],
        'fs_storage': ['CD_M163FSTORAGEUSE', 'CD_M163FSTORAGETOTAL', 'CD_M163FSTORAGEUTIL'],
        'hub': ['HUBROOMTOTAL'],
        'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],
        'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],
        'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],
        'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA']
    }
   
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
   
    def create_features_for_change(df, start_idx=30):
        """ë³€í™”ëŸ‰ ì˜ˆì¸¡ì„ ìœ„í•œ Feature ìƒì„±"""
        features_list = []
        labels = []  # ë³€í™”ëŸ‰
        current_values = []
        future_values = []
        indices = []
        seq_target_list = []
       
        for i in range(start_idx, len(df) - 10):
            seq_target = df[TARGET_COL].iloc[i-30:i].values
            current_value = seq_target[-1]  # í˜„ì¬ê°’
            future_value = df[TARGET_COL].iloc[i+10]  # 10ë¶„ í›„
            change = future_value - current_value  # ë³€í™”ëŸ‰ (íƒ€ê²Ÿ!)
           
            # ê¸°ë³¸ íƒ€ê²Ÿ Feature
            features = {
                'target_mean': np.mean(seq_target),
                'target_std': np.std(seq_target),
                'target_max': np.max(seq_target),
                'target_min': np.min(seq_target),
                'target_last_value': seq_target[-1],
                'target_last_5_mean': np.mean(seq_target[-5:]),
                'target_slope': np.polyfit(np.arange(30), seq_target, 1)[0],
            }
           
            # ë³€í™”ëŸ‰ ì˜ˆì¸¡ì— ìœ ìš©í•œ ì¶”ê°€ Feature
            features['target_from_max'] = np.max(seq_target) - seq_target[-1]
            features['target_decreasing'] = 1 if features['target_slope'] < -1 else 0
            features['target_increasing'] = 1 if features['target_slope'] > 1 else 0
            features['target_volatility'] = np.std(np.diff(seq_target))
            features['target_momentum'] = np.mean(seq_target[-5:]) - np.mean(seq_target[:5])
           
            # ê° ì»¬ëŸ¼ ê·¸ë£¹ Feature
            for group_name, cols in FEATURE_COLS.items():
                for col in cols:
                    if col not in df.columns:
                        continue
                   
                    col_seq = df[col].iloc[i-30:i].values
                   
                    if group_name == 'maxcapa':
                        features[f'{col}_last_value'] = col_seq[-1]
                   
                    elif group_name in ['cmd', 'storage', 'fs_storage', 'hub']:
                        features[f'{col}_mean'] = np.mean(col_seq)
                        features[f'{col}_std'] = np.std(col_seq)
                        features[f'{col}_max'] = np.max(col_seq)
                        features[f'{col}_min'] = np.min(col_seq)
                        features[f'{col}_last_value'] = col_seq[-1]
                        features[f'{col}_last_5_mean'] = np.mean(col_seq[-5:])
                        features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
                   
                    else:
                        features[f'{col}_mean'] = np.mean(col_seq)
                        features[f'{col}_last_value'] = col_seq[-1]
                        features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
           
            # FS Storage Feature
            if 'CD_M163FSTORAGEUSE' in df.columns and 'CD_M163FSTORAGETOTAL' in df.columns:
                storage_use = df['CD_M163FSTORAGEUSE'].iloc[i-30:i].values
                storage_total = df['CD_M163FSTORAGETOTAL'].iloc[i-30:i].values
                storage_util = df['CD_M163FSTORAGEUTIL'].iloc[i-30:i].values
               
                features['storage_use_rate'] = (storage_use[-1] - storage_use[0]) / 30
                features['storage_remaining'] = storage_total[-1] - storage_use[-1]
                features['storage_util_last'] = storage_util[-1]
                features['storage_util_high'] = 1 if storage_util[-1] >= 7 else 0
                features['storage_util_critical'] = 1 if storage_util[-1] >= 10 else 0
           
            # HUBROOMTOTAL Feature
            if 'HUBROOMTOTAL' in df.columns:
                hub_seq = df['HUBROOMTOTAL'].iloc[i-30:i].values
                hub_last = hub_seq[-1]
               
                features['hub_critical'] = 1 if hub_last < 590 else 0
                features['hub_high'] = 1 if hub_last < 610 else 0
                features['hub_warning'] = 1 if hub_last < 620 else 0
                features['hub_decrease_rate'] = (hub_seq[0] - hub_last) / 30
               
                if 'CD_M163FSTORAGEUTIL' in df.columns:
                    storage_util_last = df['CD_M163FSTORAGEUTIL'].iloc[i-1]
                    features['hub_storage_risk'] = 1 if (hub_last < 610 and storage_util_last >= 7) else 0
           
            # CMD Feature
            inflow_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['inflow'] if col in df.columns)
            outflow_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['outflow'] if col in df.columns)
            features['net_flow'] = inflow_sum - outflow_sum
           
            cmd_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['cmd'] if col in df.columns)
            features['total_cmd'] = cmd_sum
            features['total_cmd_low'] = 1 if cmd_sum < 220 else 0
            features['total_cmd_very_low'] = 1 if cmd_sum < 200 else 0
           
            if 'HUBROOMTOTAL' in df.columns:
                hub_last = df['HUBROOMTOTAL'].iloc[i-1]
                features['hub_cmd_bottleneck'] = 1 if (hub_last < 610 and cmd_sum < 220) else 0
           
            # Storage Util
            if 'M16A_3F_STORAGE_UTIL' in df.columns:
                storage_util = df['M16A_3F_STORAGE_UTIL'].iloc[i-1]
                features['storage_util_critical'] = 1 if storage_util >= 205 else 0
                features['storage_util_high_risk'] = 1 if storage_util >= 207 else 0
           
            features_list.append(features)
            labels.append(change)  # ğŸ”¥ íƒ€ê²Ÿ: ë³€í™”ëŸ‰!
            current_values.append(current_value)
            future_values.append(future_value)
            indices.append(i)
            seq_target_list.append(seq_target)
       
        return (pd.DataFrame(features_list), np.array(labels), 
                current_values, future_values, indices, seq_target_list)
   
    # ===== 1. í•™ìŠµ =====
    print("\n[STEP 1] ë°ì´í„° ë¡œë“œ ë° Feature ìƒì„±")
    print("-"*40)
   
    try:
        df_train = pd.read_csv('20250904_TO_20251020.csv', on_bad_lines='skip', encoding='utf-8', low_memory=False)
    except:
        try:
            df_train = pd.read_csv('20250904_TO_20251020.csv', on_bad_lines='skip', encoding='cp949', low_memory=False)
        except:
            df_train = pd.read_csv('20250904_TO_20251020.csv', on_bad_lines='skip', encoding='euc-kr', low_memory=False)
   
    df_train[TARGET_COL] = pd.to_numeric(df_train[TARGET_COL], errors='coerce')
    df_train = df_train.dropna(subset=[TARGET_COL])
   
    print(f"í•™ìŠµ ë°ì´í„°: {len(df_train)}ê°œ í–‰")
   
    X_train, y_train, current_vals, future_vals, _, seq_list = create_features_for_change(df_train)
   
    print(f"\nâœ… Feature ìƒì„± ì™„ë£Œ:")
    print(f"  - ì´ Feature: {len(X_train.columns)}ê°œ")
    print(f"  - í•™ìŠµ ìƒ˜í”Œ: {len(X_train)}ê°œ")
   
    # ë³€í™”ëŸ‰ ë¶„í¬ í™•ì¸
    print(f"\në³€í™”ëŸ‰ ë¶„í¬:")
    print(f"  í‰ê· : {np.mean(y_train):.2f}")
    print(f"  í‘œì¤€í¸ì°¨: {np.std(y_train):.2f}")
    print(f"  ìµœì†Œ: {np.min(y_train):.2f}")
    print(f"  ìµœëŒ€: {np.max(y_train):.2f}")
   
    # ê¸‰ì¦/ê¸‰ê° ì¼€ì´ìŠ¤ í™•ì¸
    surge_cases = sum(1 for i in range(len(y_train))
                      if current_vals[i] < 300 and future_vals[i] >= 300)
    drop_cases = sum(1 for i in range(len(y_train))
                     if current_vals[i] >= 300 and future_vals[i] < 300)
   
    print(f"\nì¼€ì´ìŠ¤ ë¶„í¬:")
    print(f"  ğŸ”º ê¸‰ì¦ (current<300, futureâ‰¥300): {surge_cases}ê°œ ({surge_cases/len(y_train)*100:.2f}%)")
    print(f"  ğŸ”» ê¸‰ê° (currentâ‰¥300, future<300): {drop_cases}ê°œ ({drop_cases/len(y_train)*100:.2f}%)")
    print(f"  âšª ì •ìƒ: {len(y_train)-surge_cases-drop_cases}ê°œ")
   
    # í•™ìŠµ/ê²€ì¦ ë¶„í• 
    X_tr, X_val, y_tr, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42
    )
   
    # GPU/CPU ê°ì§€
    print("\nğŸ” í•™ìŠµ í™˜ê²½ ê°ì§€...")
    use_gpu = False
   
    try:
        test_model = xgb.XGBRegressor(
            n_estimators=5, max_depth=3, random_state=42,
            tree_method='gpu_hist', gpu_id=0
        )
        test_model.fit(X_tr[:100], y_tr[:100], verbose=False)
        use_gpu = True
        print("  âœ… GPU ëª¨ë“œ\n")
    except:
        print("  âš ï¸ CPU ëª¨ë“œ\n")
        use_gpu = False
   
    # ëª¨ë¸ ìƒì„±
    if use_gpu:
        model = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=7,
            learning_rate=0.04,
            subsample=0.85,
            colsample_bytree=0.85,
            min_child_weight=2,
            gamma=0.05,
            reg_alpha=0.05,
            reg_lambda=0.8,
            random_state=42,
            tree_method='gpu_hist',
            gpu_id=0,
            predictor='gpu_predictor'
        )
    else:
        model = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=7,
            learning_rate=0.04,
            subsample=0.85,
            colsample_bytree=0.85,
            min_child_weight=2,
            gamma=0.05,
            reg_alpha=0.05,
            reg_lambda=0.8,
            random_state=42,
            tree_method='hist',
            n_jobs=-1
        )
   
    print("ëª¨ë¸ í•™ìŠµ ì¤‘ (ë³€í™”ëŸ‰ ì˜ˆì¸¡)...")
    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)
   
    # í‰ê°€
    y_val_pred = model.predict(X_val)
    train_mae = mean_absolute_error(y_val, y_val_pred)
    train_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))
    train_r2 = r2_score(y_val, y_val_pred)
   
    print(f"\ní•™ìŠµ ì„±ëŠ¥:")
    print(f"  MAE (ë³€í™”ëŸ‰):  {train_mae:.4f}")
    print(f"  RMSE: {train_rmse:.4f}")
    print(f"  RÂ²:   {train_r2:.4f}")
   
    # ëª¨ë¸ ì €ì¥
    with open('xgboost_ë³€í™”ëŸ‰ì˜ˆì¸¡.pkl', 'wb') as f:
        pickle.dump(model, f)
    print("âœ… ëª¨ë¸ ì €ì¥: xgboost_ë³€í™”ëŸ‰ì˜ˆì¸¡.pkl")
   
    # Feature ì¤‘ìš”ë„
    print("\nğŸ”¥ Feature ì¤‘ìš”ë„ Top 20:")
    feature_importance = pd.DataFrame({
        'feature': X_train.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False).head(20)
   
    for idx, row in feature_importance.iterrows():
        print(f"  {row['feature']}: {row['importance']:.4f}")
   
    # ===== 2. í‰ê°€ =====
    print("\n[STEP 2] í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€")
    print("-"*40)
   
    split_idx = int(len(df_train) * 0.8)
    df_test = df_train.iloc[split_idx:].copy()
   
    X_test, y_test_change, current_test, future_test, indices, seq_test = create_features_for_change(df_test, start_idx=30)
   
    y_pred_change = model.predict(X_test)
   
    # ë³€í™”ëŸ‰ ì˜ˆì¸¡ ì„±ëŠ¥
    test_mae = mean_absolute_error(y_test_change, y_pred_change)
    test_rmse = np.sqrt(mean_squared_error(y_test_change, y_pred_change))
    test_r2 = r2_score(y_test_change, y_pred_change)
   
    print(f"\në³€í™”ëŸ‰ ì˜ˆì¸¡ ì„±ëŠ¥:")
    print(f"  MAE:  {test_mae:.4f}")
    print(f"  RMSE: {test_rmse:.4f}")
    print(f"  RÂ²:   {test_r2:.4f}")
   
    # ê¸‰ì¦/ê¸‰ê° ê°ì§€ ì„±ëŠ¥
    print(f"\n[STEP 3] ê¸‰ì¦/ê¸‰ê° ê°ì§€ ì„±ëŠ¥")
    print("-"*40)
   
    surge_count = 0
    surge_detected = 0
    drop_count = 0
    drop_detected = 0
   
    for i in range(len(X_test)):
        current = current_test[i]
        future_actual = future_test[i]
        predicted_change = y_pred_change[i]
        predicted_future = current + predicted_change
       
        # ê¸‰ì¦
        if current < 300 and future_actual >= 300:
            surge_count += 1
            if predicted_future >= 290:  # ì—¬ìœ ìˆê²Œ 290
                surge_detected += 1
       
        # ê¸‰ê°
        elif current >= 300 and future_actual < 300:
            drop_count += 1
            if predicted_future < 310:  # ì—¬ìœ ìˆê²Œ 310
                drop_detected += 1
   
    print(f"ğŸ”º ê¸‰ì¦ ê°ì§€:")
    print(f"  ë°œìƒ: {surge_count}ê°œ")
    print(f"  ê°ì§€: {surge_detected}/{surge_count}ê°œ ({surge_detected/surge_count*100 if surge_count > 0 else 0:.1f}%)")
   
    print(f"\nğŸ”» ê¸‰ê° ê°ì§€:")
    print(f"  ë°œìƒ: {drop_count}ê°œ")
    print(f"  ê°ì§€: {drop_detected}/{drop_count}ê°œ ({drop_detected/drop_count*100 if drop_count > 0 else 0:.1f}%)")
   
    # ê·¹ë‹¨ê°’ ì„±ëŠ¥
    extreme_count = sum(1 for i in range(len(future_test)) if future_test[i] >= 300)
    extreme_detected = sum(1 for i in range(len(future_test)) 
                          if future_test[i] >= 300 and (current_test[i] + y_pred_change[i]) >= 290)
   
    print(f"\nê·¹ë‹¨ê°’ (300+) ê°ì§€:")
    print(f"  ë°œìƒ: {extreme_count}ê°œ")
    print(f"  ê°ì§€: {extreme_detected}/{extreme_count}ê°œ ({extreme_detected/extreme_count*100 if extreme_count > 0 else 0:.1f}%)")
   
    # ê²°ê³¼ ì €ì¥
    results = []
    for i in range(len(X_test)):
        current = current_test[i]
        future_actual = future_test[i]
        change_actual = y_test_change[i]
        change_pred = y_pred_change[i]
        predicted_future = current + change_pred
       
        is_surge = (current < 300 and future_actual >= 300)
        is_drop = (current >= 300 and future_actual < 300)
        is_extreme = (future_actual >= 300)
       
        results.append({
            'í˜„ì¬ê°’': round(current, 2),
            'ì‹¤ì œ_10ë¶„í›„': round(future_actual, 2),
            'ì˜ˆì¸¡_10ë¶„í›„': round(predicted_future, 2),
            'ì‹¤ì œ_ë³€í™”ëŸ‰': round(change_actual, 2),
            'ì˜ˆì¸¡_ë³€í™”ëŸ‰': round(change_pred, 2),
            'ë³€í™”ëŸ‰_ì˜¤ì°¨': round(abs(change_actual - change_pred), 2),
            'ê¸‰ì¦': 'O' if is_surge else '-',
            'ê¸‰ì¦ê°ì§€': 'O' if (is_surge and predicted_future >= 290) else '-',
            'ê¸‰ê°': 'O' if is_drop else '-',
            'ê¸‰ê°ê°ì§€': 'O' if (is_drop and predicted_future < 310) else '-',
            'ê·¹ë‹¨ê°’': 'O' if is_extreme else '-',
            'ê·¹ë‹¨ê°’ê°ì§€': 'O' if (is_extreme and predicted_future >= 290) else '-'
        })
   
    df_results = pd.DataFrame(results)
    df_results.to_csv('ë³€í™”ëŸ‰ì˜ˆì¸¡_ê²°ê³¼.csv', index=False, encoding='utf-8-sig')
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: ë³€í™”ëŸ‰ì˜ˆì¸¡_ê²°ê³¼.csv")
   
    # ìµœì¢… ìš”ì•½
    print("\n" + "="*80)
    print("ğŸ“Š ìµœì¢… ìš”ì•½ (ë³€í™”ëŸ‰ ì˜ˆì¸¡ ë°©ì‹)")
    print("="*80)
   
    print(f"\n1. ì ‘ê·¼ ë°©ì‹:")
    print(f"   - íƒ€ê²Ÿ: 10ë¶„ í›„ ë³€í™”ëŸ‰")
    print(f"   - ê¸‰ì¦/ê¸‰ê° ìë™ êµ¬ë¶„ (ë¶€í˜¸)")
    print(f"   - ë‹¨ì¼ ëª¨ë¸")
   
    print(f"\n2. ë³€í™”ëŸ‰ ì˜ˆì¸¡ ì„±ëŠ¥:")
    print(f"   - MAE: {test_mae:.2f}")
    print(f"   - RÂ²: {test_r2:.3f}")
   
    print(f"\n3. ê¸‰ì¦ ê°ì§€:")
    print(f"   - ì„±ê³µë¥ : {surge_detected/surge_count*100 if surge_count > 0 else 0:.1f}%")
   
    print(f"\n4. ê¸‰ê° ê°ì§€:")
    print(f"   - ì„±ê³µë¥ : {drop_detected/drop_count*100 if drop_count > 0 else 0:.1f}%")
   
    print(f"\n5. ê·¹ë‹¨ê°’ (300+) ê°ì§€:")
    print(f"   - ë°œìƒ: {extreme_count}ê°œ")
    print(f"   - ê°ì§€ìœ¨: {extreme_detected/extreme_count*100 if extreme_count > 0 else 0:.1f}%")
   
    if surge_detected/surge_count >= 0.78 if surge_count > 0 else False:
        print(f"\nâœ… ê¸‰ì¦ ê°ì§€ìœ¨ 78% ì´ìƒ ë‹¬ì„±!")
    else:
        print(f"\nâš ï¸ ê¸‰ì¦ ê°ì§€ìœ¨ ê°œì„  í•„ìš”")
   
    return model, df_results, feature_importance

if __name__ == '__main__':
    model, results, importance = train_change_prediction()