import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta

def evaluate_perfect_version():
    """
    üéØ ÏôÑÎ≤Ω Î≤ÑÏ†Ñ ÌèâÍ∞Ä: 30ÏãúÌÄÄÏä§ ‚Üí 15Î∂Ñ ÏòàÏ∏° + ÏûÑÍ≥ÑÍ∞í 280 + Momentum
    """
    print("="*80)
    print("üéØ ÏôÑÎ≤Ω Î≤ÑÏ†Ñ ÌèâÍ∞Ä: Í∞ÄÏ§ëÏπò 5Î∞∞ + ÏûÑÍ≥ÑÍ∞í 280 + Momentum (15Î∂Ñ ÏòàÏ∏°)")
    print("="*80)
   
    FEATURE_COLS = {
        'storage': ['M16A_3F_STORAGE_UTIL'],
        'fs_storage': ['CD_M163FSTORAGEUSE', 'CD_M163FSTORAGETOTAL', 'CD_M163FSTORAGEUTIL'],
        'hub': ['HUBROOMTOTAL'],
        'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],
        'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],
        'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],
        'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA']
    }
   
    # Î™®Îç∏ Î°úÎìú
    try:
        with open('xgboost_ÏôÑÎ≤ΩÎ≤ÑÏ†Ñ_Í∞ÄÏ§ëÏπò5Î∞∞_ÏûÑÍ≥ÑÍ∞í280_momentum_15Î∂Ñ.pkl', 'rb') as f:
            model = pickle.load(f)
        print("‚úÖ Î™®Îç∏ Î°úÎìú ÏôÑÎ£å: xgboost_ÏôÑÎ≤ΩÎ≤ÑÏ†Ñ_Í∞ÄÏ§ëÏπò5Î∞∞_ÏûÑÍ≥ÑÍ∞í280_momentum_15Î∂Ñ.pkl")
    except Exception as e:
        print(f"‚ùå Î™®Îç∏ ÌååÏùº ÏóÜÏùå: {e}")
        print("   Î®ºÏ†Ä 'V6_ÌïôÏäµ_15Î∂Ñ.py'Î•º Ïã§ÌñâÌïòÏÑ∏Ïöî.")
        return None
   
    # Îç∞Ïù¥ÌÑ∞ Î°úÎìú
    try:
        df = pd.read_csv('HUB0905101512.csv', on_bad_lines='skip', encoding='utf-8', low_memory=False)
    except:
        try:
            df = pd.read_csv('HUB0905101512.csv', on_bad_lines='skip', encoding='cp949', low_memory=False)
        except:
            df = pd.read_csv('HUB0905101512.csv', on_bad_lines='skip', encoding='euc-kr', low_memory=False)
   
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
   
    df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')
    df = df.dropna(subset=[TARGET_COL])
   
    print(f"‚úÖ Îç∞Ïù¥ÌÑ∞ Î°úÎìú: {len(df)}Í∞ú Ìñâ")
   
    # STAT_DT Ï≤òÎ¶¨
    if 'STAT_DT' in df.columns:
        try:
            df['STAT_DT'] = pd.to_datetime(df['STAT_DT'].astype(str), format='%Y%m%d%H%M')
        except:
            base_time = datetime(2024, 1, 1, 0, 0)
            df['STAT_DT'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
   
    results = []
   
    print("\nÏä¨ÎùºÏù¥Îî© ÏúàÎèÑÏö∞ ÌèâÍ∞Ä ÏãúÏûë (30ÏãúÌÄÄÏä§ ‚Üí 15Î∂Ñ ÏòàÏ∏° + Momentum)...")
    for i in range(30, len(df)):
        seq_data = df.iloc[i-30:i].copy()
        seq_target = seq_data[TARGET_COL].values
       
        current_time = seq_data['STAT_DT'].iloc[-1]
        current_value = seq_target[-1]
        prediction_time = current_time + timedelta(minutes=15)  # ‚úÖ 15Î∂Ñ ÌõÑ
       
        actual_value = df.iloc[i][TARGET_COL]
        actual_time = df.iloc[i]['STAT_DT']
       
        # Feature ÏÉùÏÑ± (ÌïôÏäµ ÏΩîÎìúÏôÄ ÏôÑÎ≤ΩÌûà ÎèôÏùº!)
        features = {
            'target_mean': np.mean(seq_target),
            'target_std': np.std(seq_target),
            'target_max': np.max(seq_target),
            'target_min': np.min(seq_target),
            'target_last_value': seq_target[-1],
            'target_last_5_mean': np.mean(seq_target[-5:]),
            'target_slope': np.polyfit(np.arange(30), seq_target, 1)[0],
        }
       
        # üÜï Momentum Feature Ï∂îÍ∞Ä (ÌïôÏäµ ÏΩîÎìúÏôÄ ÎèôÏùº!)
        features['target_acceleration'] = (seq_target[-5:].mean() - seq_target[-10:-5].mean()) / 5
        features['target_is_rising'] = 1 if seq_target[-1] > seq_target[-5] else 0
        features['target_rapid_rise'] = 1 if (seq_target[-1] - seq_target[-5] > 10) else 0
        features['target_last_10_mean'] = np.mean(seq_target[-10:])
       
        # Í∞Å Ïª¨Îüº Feature
        for group_name, cols in FEATURE_COLS.items():
            for col in cols:
                if col not in df.columns:
                    continue
               
                col_seq = seq_data[col].values
               
                if group_name == 'maxcapa':
                    features[f'{col}_last_value'] = col_seq[-1]
               
                elif group_name in ['cmd', 'storage', 'fs_storage', 'hub']:
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_std'] = np.std(col_seq)
                    features[f'{col}_max'] = np.max(col_seq)
                    features[f'{col}_min'] = np.min(col_seq)
                    features[f'{col}_last_value'] = col_seq[-1]
                    features[f'{col}_last_5_mean'] = np.mean(col_seq[-5:])
                    features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
               
                else:
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_last_value'] = col_seq[-1]
                    features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
       
        # FS Storage Feature
        if 'CD_M163FSTORAGEUSE' in df.columns and 'CD_M163FSTORAGETOTAL' in df.columns and 'CD_M163FSTORAGEUTIL' in df.columns:
            use_seq = seq_data['CD_M163FSTORAGEUSE'].values
            total_seq = seq_data['CD_M163FSTORAGETOTAL'].values
            util_seq = seq_data['CD_M163FSTORAGEUTIL'].values
           
            features['CD_M163FSTORAGEUSE_mean'] = np.mean(use_seq)
            features['CD_M163FSTORAGEUSE_std'] = np.std(use_seq)
            features['CD_M163FSTORAGEUSE_max'] = np.max(use_seq)
            features['CD_M163FSTORAGEUSE_min'] = np.min(use_seq)
            features['CD_M163FSTORAGEUSE_last_value'] = use_seq[-1]
            features['CD_M163FSTORAGEUSE_last_5_mean'] = np.mean(use_seq[-5:])
            features['CD_M163FSTORAGEUSE_slope'] = np.polyfit(np.arange(30), use_seq, 1)[0]
           
            features['CD_M163FSTORAGETOTAL_mean'] = np.mean(total_seq)
            features['CD_M163FSTORAGETOTAL_std'] = np.std(total_seq)
            features['CD_M163FSTORAGETOTAL_max'] = np.max(total_seq)
            features['CD_M163FSTORAGETOTAL_min'] = np.min(total_seq)
            features['CD_M163FSTORAGETOTAL_last_value'] = total_seq[-1]
            features['CD_M163FSTORAGETOTAL_last_5_mean'] = np.mean(total_seq[-5:])
            features['CD_M163FSTORAGETOTAL_slope'] = np.polyfit(np.arange(30), total_seq, 1)[0]
           
            features['CD_M163FSTORAGEUTIL_mean'] = np.mean(util_seq)
            features['CD_M163FSTORAGEUTIL_std'] = np.std(util_seq)
            features['CD_M163FSTORAGEUTIL_max'] = np.max(util_seq)
            features['CD_M163FSTORAGEUTIL_min'] = np.min(util_seq)
            features['CD_M163FSTORAGEUTIL_last_value'] = util_seq[-1]
            features['CD_M163FSTORAGEUTIL_last_5_mean'] = np.mean(util_seq[-5:])
            features['CD_M163FSTORAGEUTIL_slope'] = np.polyfit(np.arange(30), util_seq, 1)[0]
           
            features['storage_use_rate'] = (use_seq[-1] - use_seq[0]) / 30
            features['storage_remaining'] = total_seq[-1] - use_seq[-1]
            features['storage_util_last'] = util_seq[-1]
            features['storage_util_high'] = 1 if util_seq[-1] >= 7 else 0
            features['storage_util_critical'] = 1 if util_seq[-1] >= 10 else 0
       
        # HUBROOMTOTAL Feature
        if 'HUBROOMTOTAL' in df.columns:
            hub_seq = seq_data['HUBROOMTOTAL'].values
            hub_last = hub_seq[-1]
           
            features['hub_critical'] = 1 if hub_last < 590 else 0
            features['hub_high'] = 1 if hub_last < 610 else 0
            features['hub_warning'] = 1 if hub_last < 620 else 0
            features['hub_decrease_rate'] = (hub_seq[0] - hub_last) / 30
           
            if 'CD_M163FSTORAGEUTIL' in df.columns:
                storage_util_last = df['CD_M163FSTORAGEUTIL'].iloc[i-1]
                features['hub_storage_risk'] = 1 if (hub_last < 610 and storage_util_last >= 7) else 0
       
        # Ïú†ÏûÖ-Ïú†Ï∂ú, CMD
        inflow_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['inflow'] if col in df.columns)
        outflow_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['outflow'] if col in df.columns)
        features['net_flow'] = inflow_sum - outflow_sum
       
        cmd_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['cmd'] if col in df.columns)
        features['total_cmd'] = cmd_sum
        features['total_cmd_low'] = 1 if cmd_sum < 220 else 0
        features['total_cmd_very_low'] = 1 if cmd_sum < 200 else 0
       
        if 'HUBROOMTOTAL' in df.columns:
            hub_last = df['HUBROOMTOTAL'].iloc[i-1]
            features['hub_cmd_bottleneck'] = 1 if (hub_last < 610 and cmd_sum < 220) else 0
       
        if 'M16A_3F_STORAGE_UTIL' in df.columns:
            storage_util = df['M16A_3F_STORAGE_UTIL'].iloc[i-1]
            features['storage_util_critical'] = 1 if storage_util >= 205 else 0
            features['storage_util_high_risk'] = 1 if storage_util >= 207 else 0
       
        # üî• Í∏âÏ¶ù ÏúÑÌóòÎèÑ Ï†êÏàò
        features['surge_risk_score'] = (
            features.get('hub_high', 0) * 3 +
            features.get('storage_util_critical', 0) * 2 +
            features.get('total_cmd_low', 0) * 1 +
            features.get('storage_util_high', 0) * 1
        )
       
        # üÜï Í∏âÏ¶ù ÏûÑÎ∞ï Ïã†Ìò∏
        features['surge_imminent'] = 1 if (
            seq_target[-1] > 272 and
            features.get('target_acceleration', 0) > 0.2 and
            features.get('hub_high', 0) == 1
        ) else 0
       
        X_pred = pd.DataFrame([features])
       
        # ÏòàÏ∏°
        prediction = model.predict(X_pred)[0]
       
        # Í∏âÏ¶ù ÌåêÏ†ï
        is_surge = (current_value < 300 and actual_value >= 300)
       
        # ÏúÑÌóòÎèÑ ÌåêÏ†ï
        risk_level = "LOW"
        risk_score = features.get('surge_risk_score', 0)
        if risk_score >= 5:
            risk_level = "CRITICAL"
        elif risk_score >= 3:
            risk_level = "HIGH"
        elif risk_score >= 1:
            risk_level = "MEDIUM"
       
        results.append({
            'ÌòÑÏû¨ÏãúÍ∞Ñ': current_time.strftime('%Y-%m-%d %H:%M'),
            'ÏòàÏ∏°ÏãúÏ†ê': prediction_time.strftime('%Y-%m-%d %H:%M'),
            'ÌòÑÏû¨Í∞í': round(current_value, 2),
            'Ïã§Ï†úÍ∞í': round(actual_value, 2),
            'ÏòàÏ∏°Í∞í': round(prediction, 2),
            'Ïò§Ï∞®': round(abs(actual_value - prediction), 2),
            'Ïò§Ï∞®Ïú®(%)': round(abs(actual_value - prediction) / max(actual_value, 1) * 100, 2),
            'ÏãúÌÄÄÏä§MAX': round(np.max(seq_target), 2),
            '300Í∏âÏ¶ù': '‚úÖ' if is_surge else '',
            'Í∞êÏßÄ_290': '‚úÖ' if (is_surge and prediction >= 290) else '',
            'Í∞êÏßÄ_285': '‚úÖ' if (is_surge and prediction >= 285) else '',
            'Í∞êÏßÄ_280': '‚úÖ' if (is_surge and prediction >= 280) else '',  # ‚≠ê Î©îÏù∏!
            'Í∞êÏßÄ_275': '‚úÖ' if (is_surge and prediction >= 275) else '',
            'ÏúÑÌóòÎèÑ': risk_level,
            'ÏúÑÌóòÏ†êÏàò': risk_score,
            'momentumÏÉÅÏäπ': '‚úÖ' if features.get('target_is_rising', 0) == 1 else '',
            'momentumÍ∞ÄÏÜç': round(features.get('target_acceleration', 0), 2),
            'Í∏âÏ¶ùÏûÑÎ∞ï': '‚úÖ' if features.get('surge_imminent', 0) == 1 else '',
            'HUBROOMTOTAL': round(features.get('HUBROOMTOTAL_last_value', 0), 0),
            'FS_UTIL': round(features.get('CD_M163FSTORAGEUTIL_last_value', 0), 0),
            'CMD': round(features.get('total_cmd', 0), 0),
            'STORAGE_UTIL': round(features.get('M16A_3F_STORAGE_UTIL_last_value', 0), 0),
        })
       
        if (i - 30) % 1000 == 0:
            print(f"ÏßÑÌñâ: {i-30}/{len(df)-30} ({(i-30)/(len(df)-30)*100:.1f}%)")
   
    results_df = pd.DataFrame(results)
   
    output_file = 'ÏôÑÎ≤ΩÎ≤ÑÏ†Ñ_Í∞ÄÏ§ëÏπò5Î∞∞_ÏûÑÍ≥ÑÍ∞í280_momentum_15Î∂Ñ_ÌèâÍ∞ÄÍ≤∞Í≥º.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\n‚úÖ Í≤∞Í≥º Ï†ÄÏû•: {output_file}")
   
    # ÌÜµÍ≥Ñ
    print("\n" + "="*80)
    print("üìä ÌèâÍ∞Ä ÌÜµÍ≥Ñ (ÏôÑÎ≤Ω Î≤ÑÏ†Ñ: Í∞ÄÏ§ëÏπò 5Î∞∞ + ÏûÑÍ≥ÑÍ∞í 280 + Momentum - 15Î∂Ñ ÏòàÏ∏°)")
    print("="*80)
   
    print(f"Ï¥ù ÏòàÏ∏°: {len(results_df)}Í∞ú")
    print(f"ÌèâÍ∑† Ïò§Ï∞®: {results_df['Ïò§Ï∞®'].mean():.2f}")
    print(f"ÌèâÍ∑† Ïò§Ï∞®Ïú®: {results_df['Ïò§Ï∞®Ïú®(%)'].mean():.2f}%")
   
    surge_cases = results_df[results_df['300Í∏âÏ¶ù'] == '‚úÖ']
    if len(surge_cases) > 0:
        print(f"\nüéØ 300 Í∏âÏ¶ù ÏòàÏ∏° ÏÑ±Îä•:")
        print(f"  Î∞úÏÉù: {len(surge_cases)}Í∞ú ({len(surge_cases)/len(results_df)*100:.2f}%)")
        
        for threshold in [290, 285, 280, 275]:
            detected = (surge_cases[f'Í∞êÏßÄ_{threshold}'] == '‚úÖ').sum()
            marker = "‚≠ê" if threshold == 280 else "  "
            print(f"{marker} ÏûÑÍ≥ÑÍ∞í {threshold}: {detected}/{len(surge_cases)}Í∞ú ({detected/len(surge_cases)*100:.1f}%)")
   
    extreme_cases = results_df[results_df['Ïã§Ï†úÍ∞í'] >= 300]
    if len(extreme_cases) > 0:
        extreme_detected_280 = (extreme_cases['ÏòàÏ∏°Í∞í'] >= 280).sum()
       
        print(f"\nÍ∑πÎã®Í∞í (300+) Í∞êÏßÄ (ÏûÑÍ≥ÑÍ∞í 280):")
        print(f"  Î∞úÏÉù: {len(extreme_cases)}Í∞ú ({len(extreme_cases)/len(results_df)*100:.1f}%)")
        print(f"  Í∞êÏßÄ: {extreme_detected_280}/{len(extreme_cases)}Í∞ú ({extreme_detected_280/len(extreme_cases)*100:.1f}%)")
   
    # Momentum Feature Î∂ÑÏÑù
    print(f"\nüÜï Momentum Feature Î∂ÑÏÑù:")
    if len(surge_cases) > 0:
        rising_in_surge = (surge_cases['momentumÏÉÅÏäπ'] == '‚úÖ').sum()
        imminent_in_surge = (surge_cases['Í∏âÏ¶ùÏûÑÎ∞ï'] == '‚úÖ').sum()
        print(f"  Í∏âÏ¶ù Ïãú ÏÉÅÏäπ Ï§ë: {rising_in_surge}/{len(surge_cases)}Í∞ú ({rising_in_surge/len(surge_cases)*100:.1f}%)")
        print(f"  Í∏âÏ¶ù ÏûÑÎ∞ï Ïã†Ìò∏: {imminent_in_surge}/{len(surge_cases)}Í∞ú ({imminent_in_surge/len(surge_cases)*100:.1f}%)")
   
    # ÏúÑÌóòÎèÑÎ≥Ñ ÌÜµÍ≥Ñ
    print(f"\nÏúÑÌóòÎèÑÎ≥Ñ Î∂ÑÏÑù:")
    for risk in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
        risk_df = results_df[results_df['ÏúÑÌóòÎèÑ'] == risk]
        if len(risk_df) > 0:
            surge_in_risk = (risk_df['300Í∏âÏ¶ù'] == '‚úÖ').sum()
            print(f"  {risk}: {len(risk_df)}Í∞ú - Í∏âÏ¶ù {surge_in_risk}Í∞ú ({surge_in_risk/len(risk_df)*100:.1f}%)")
   
    # ÏÉÅÏúÑ Ïò§Ï∞®
    print(f"\n‚ùå Ïò§Ï∞® ÏÉÅÏúÑ 10Í∞ú:")
    top_errors = results_df.nlargest(10, 'Ïò§Ï∞®Ïú®(%)')
    print(top_errors[['ÌòÑÏû¨ÏãúÍ∞Ñ', 'ÌòÑÏû¨Í∞í', 'Ïã§Ï†úÍ∞í', 'ÏòàÏ∏°Í∞í', 'Ïò§Ï∞®', 'ÏúÑÌóòÎèÑ', '300Í∏âÏ¶ù', 'Í∏âÏ¶ùÏûÑÎ∞ï']].to_string(index=False))
   
    # Í∏âÏ¶ù ÏòàÏ∏° Ïã§Ìå® ÏºÄÏù¥Ïä§
    if len(surge_cases) > 0:
        surge_failed = surge_cases[surge_cases['Í∞êÏßÄ_280'] != '‚úÖ']
        if len(surge_failed) > 0:
            print(f"\n‚ùå Í∏âÏ¶ù ÏòàÏ∏° Ïã§Ìå® ÏºÄÏù¥Ïä§ (ÏÉÅÏúÑ 10Í∞ú, ÏûÑÍ≥ÑÍ∞í 280):")
            failed_top = surge_failed.nsmallest(10, 'ÏòàÏ∏°Í∞í')
            print(failed_top[['ÌòÑÏû¨ÏãúÍ∞Ñ', 'ÌòÑÏû¨Í∞í', 'Ïã§Ï†úÍ∞í', 'ÏòàÏ∏°Í∞í', 'HUBROOMTOTAL', 'FS_UTIL', 'CMD', 'ÏúÑÌóòÏ†êÏàò', 'momentumÍ∞ÄÏÜç', 'Í∏âÏ¶ùÏûÑÎ∞ï']].to_string(index=False))
   
    return results_df

if __name__ == '__main__':
    print("üöÄ ÏôÑÎ≤Ω Î≤ÑÏ†Ñ Î™®Îç∏ ÌèâÍ∞Ä ÏãúÏûë (15Î∂Ñ ÏòàÏ∏°)...\n")
    results = evaluate_perfect_version()
   
    if results is not None:
        print(f"\n‚úÖ ÌèâÍ∞Ä ÏôÑÎ£å! Ï¥ù {len(results)}Í∞ú ÏòàÏ∏°")
        print(f"üìÅ Í≤∞Í≥º: ÏôÑÎ≤ΩÎ≤ÑÏ†Ñ_Í∞ÄÏ§ëÏπò5Î∞∞_ÏûÑÍ≥ÑÍ∞í280_momentum_15Î∂Ñ_ÌèâÍ∞ÄÍ≤∞Í≥º.csv")
        print(f"\nüéâ 60~70% Í∞êÏßÄÏú® Î™©Ìëú Îã¨ÏÑ± ÏòàÏÉÅ!")