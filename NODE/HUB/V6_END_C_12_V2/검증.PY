import pandas as pd
import numpy as np

def analyze_all_correlations():
    """
    ğŸ” ì „ì²´ ì»¬ëŸ¼ ìƒê´€ê³„ìˆ˜ ë¶„ì„ - TOP 30 ì°¾ê¸°
    """
    print("="*80)
    print("ğŸ” ì „ì²´ ì»¬ëŸ¼ ìƒê´€ê³„ìˆ˜ ë¶„ì„")
    print("="*80)
    
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
    
    # ë°ì´í„° ë¡œë“œ
    print("\n[1] ë°ì´í„° ë¡œë“œ...")
    
    # âœ… íŒŒì¼ëª…ì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”!
    data_file = '20250904_TO_20251020.csv'
    
    print(f"ğŸ“‚ íŒŒì¼: {data_file}")
    
    try:
        df = pd.read_csv(data_file, on_bad_lines='skip', encoding='utf-8', low_memory=False)
    except:
        try:
            df = pd.read_csv(data_file, on_bad_lines='skip', encoding='cp949', low_memory=False)
        except:
            df = pd.read_csv(data_file, on_bad_lines='skip', encoding='euc-kr', low_memory=False)
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰, {len(df.columns)}ê°œ ì»¬ëŸ¼")
    
    # íƒ€ê²Ÿ ì»¬ëŸ¼ í™•ì¸
    if TARGET_COL not in df.columns:
        print(f"\nâŒ íƒ€ê²Ÿ ì»¬ëŸ¼ ì—†ìŒ: {TARGET_COL}")
        return
    
    # ğŸ†• NULL ê°’ ì²˜ë¦¬ - ë°”ë¡œ ìœ„ ê°’ìœ¼ë¡œ ì±„ìš°ê¸° (forward fill)
    print(f"\nğŸ”§ NULL ê°’ ì²˜ë¦¬ ì¤‘...")
    null_before = df.isnull().sum().sum()
    print(f"  ì²˜ë¦¬ ì „ NULL: {null_before}ê°œ")
    
    # ëª¨ë“  ì»¬ëŸ¼ì— ëŒ€í•´ forward fill ì ìš©
    df = df.ffill()
    
    # ë§Œì•½ ì²« í–‰ì— NULLì´ ìˆìœ¼ë©´ backward fillë¡œ ë³´ì™„
    df = df.bfill()
    
    null_after = df.isnull().sum().sum()
    print(f"  ì²˜ë¦¬ í›„ NULL: {null_after}ê°œ")
    print(f"  âœ… {null_before - null_after}ê°œ NULL ê°’ ì²˜ë¦¬ ì™„ë£Œ!")
    
    # íƒ€ê²Ÿ ì»¬ëŸ¼ ìˆ«ì ë³€í™˜
    df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')
    
    # ì—¬ì „íˆ NULLì´ ë‚¨ì•„ìˆë‹¤ë©´ ì œê±°
    before_drop = len(df)
    df = df.dropna(subset=[TARGET_COL])
    dropped = before_drop - len(df)
    if dropped > 0:
        print(f"  íƒ€ê²Ÿ ì»¬ëŸ¼ NULL ì œê±°: {dropped}ê°œ í–‰")
    
    print(f"âœ… ìµœì¢… ë°ì´í„°: {len(df)}ê°œ í–‰")
    
    # [2] ì „ì²´ ì»¬ëŸ¼ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
    print("\n[2] ì „ì²´ ì»¬ëŸ¼ ìƒê´€ê³„ìˆ˜ ê³„ì‚° ì¤‘...")
    print("-"*80)
    
    results = []
    
    for col in df.columns:
        if col == TARGET_COL:
            continue  # íƒ€ê²Ÿ ì»¬ëŸ¼ ìì²´ëŠ” ì œì™¸
        
        if col == 'STAT_DT':
            continue  # ì‹œê°„ ì»¬ëŸ¼ ì œì™¸
        
        # ìˆ«ì ë³€í™˜
        col_data = pd.to_numeric(df[col], errors='coerce')
        
        # NULL ì²˜ë¦¬
        col_data = col_data.ffill().bfill()
        
        # ë³€ë™ì„± í™•ì¸ (ëª¨ë‘ ê°™ì€ ê°’ì´ë©´ ì œì™¸)
        if col_data.nunique() <= 1:
            continue
        
        # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        valid_mask = col_data.notna() & df[TARGET_COL].notna()
        
        if valid_mask.sum() < 10:  # ìœ íš¨ ë°ì´í„° 10ê°œ ë¯¸ë§Œì´ë©´ ì œì™¸
            continue
        
        try:
            corr = col_data[valid_mask].corr(df[TARGET_COL][valid_mask])
            
            if pd.notna(corr):
                results.append({
                    'ì»¬ëŸ¼ëª…': col,
                    'ìƒê´€ê³„ìˆ˜': round(corr, 4),
                    'ì ˆëŒ€ê°’': round(abs(corr), 4),
                    'ê²°ì¸¡ë¥ (%)': round((col_data.isna().sum() / len(col_data)) * 100, 2),
                    'ê³ ìœ ê°’ê°œìˆ˜': col_data.nunique(),
                    'í‰ê· ': round(col_data.mean(), 2),
                    'í‘œì¤€í¸ì°¨': round(col_data.std(), 2)
                })
        except:
            continue
    
    # DataFrame ë³€í™˜
    results_df = pd.DataFrame(results)
    
    if len(results_df) == 0:
        print("\nâŒ ê³„ì‚° ê°€ëŠ¥í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ì ˆëŒ€ê°’ ê¸°ì¤€ ì •ë ¬
    results_df = results_df.sort_values('ì ˆëŒ€ê°’', ascending=False)
    
    # ê²°ê³¼ ì €ì¥
    output_file = 'ì „ì²´ì»¬ëŸ¼_ìƒê´€ê³„ìˆ˜_ë¶„ì„ê²°ê³¼.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"âœ… ì „ì²´ ê²°ê³¼ ì €ì¥: {output_file}")
    
    # [3] TOP 30 ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ”¥ ìƒê´€ê³„ìˆ˜ TOP 30 (ì ˆëŒ€ê°’ ê¸°ì¤€)")
    print("="*80)
    
    top30 = results_df.head(30)
    
    for idx, row in top30.iterrows():
        # ìƒê´€ê³„ìˆ˜ ì–‘ìˆ˜/ìŒìˆ˜ í‘œì‹œ
        if row['ìƒê´€ê³„ìˆ˜'] > 0:
            sign = "+"
            marker = "ğŸ“ˆ" if row['ì ˆëŒ€ê°’'] >= 0.3 else "  "
        else:
            sign = ""
            marker = "ğŸ“‰" if row['ì ˆëŒ€ê°’'] >= 0.3 else "  "
        
        print(f"{marker} {row['ì»¬ëŸ¼ëª…'][:55]:<55} : {sign}{row['ìƒê´€ê³„ìˆ˜']:>7.4f}")
    
    # [4] í†µê³„ ìš”ì•½
    print("\n" + "="*80)
    print("ğŸ“Š ë¶„ì„ ìš”ì•½")
    print("="*80)
    
    print(f"\nì´ ë¶„ì„ ì»¬ëŸ¼: {len(results_df)}ê°œ")
    
    high_corr = results_df[results_df['ì ˆëŒ€ê°’'] >= 0.3]
    medium_corr = results_df[(results_df['ì ˆëŒ€ê°’'] >= 0.2) & (results_df['ì ˆëŒ€ê°’'] < 0.3)]
    low_corr = results_df[results_df['ì ˆëŒ€ê°’'] < 0.2]
    
    print(f"\nìƒê´€ê³„ìˆ˜ ë¶„í¬:")
    print(f"  - ë†’ìŒ (â‰¥0.30): {len(high_corr)}ê°œ")
    print(f"  - ì¤‘ê°„ (0.20~0.29): {len(medium_corr)}ê°œ")
    print(f"  - ë‚®ìŒ (<0.20): {len(low_corr)}ê°œ")
    
    # ìƒê´€ê³„ìˆ˜ ë†’ì€ ì»¬ëŸ¼ ê·¸ë£¹í™”
    print(f"\nğŸ¯ ìƒê´€ê³„ìˆ˜ â‰¥0.30 ì»¬ëŸ¼ ({len(high_corr)}ê°œ):")
    for idx, row in high_corr.iterrows():
        print(f"  â€¢ {row['ì»¬ëŸ¼ëª…'][:50]:<50} : {row['ìƒê´€ê³„ìˆ˜']:>7.4f}")
    
    # TOP 10 ìƒì„¸ ì •ë³´
    print(f"\nğŸ“Œ TOP 10 ìƒì„¸ ì •ë³´:")
    print("-"*80)
    top10 = results_df.head(10)
    print(top10[['ì»¬ëŸ¼ëª…', 'ìƒê´€ê³„ìˆ˜', 'ê³ ìœ ê°’ê°œìˆ˜', 'í‰ê· ', 'í‘œì¤€í¸ì°¨']].to_string(index=False))
    
    return results_df

if __name__ == '__main__':
    print("ğŸš€ ì „ì²´ ì»¬ëŸ¼ ìƒê´€ê³„ìˆ˜ ë¶„ì„ ì‹œì‘...\n")
    results = analyze_all_correlations()
    
    if results is not None:
        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼: ì „ì²´ì»¬ëŸ¼_ìƒê´€ê³„ìˆ˜_ë¶„ì„ê²°ê³¼.csv")
        print(f"\nğŸ’¡ ì´ì œ ì´ ê²°ê³¼ë¥¼ ë³´ê³  V7 featureë¥¼ ì„ íƒí•˜ì„¸ìš”!")