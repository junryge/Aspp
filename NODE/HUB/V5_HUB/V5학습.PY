# -*- coding: utf-8 -*-
"""
================================================================================
ğŸ”¥ HUBROOM V4 ULTIMATE ì™„ì „ í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ - 30ë¶„â†’10ë¶„ ì˜ˆì¸¡
================================================================================
âœ¨ í•µì‹¬ ê¸°ëŠ¥:
   1. 30ë¶„ ì‹œí€€ìŠ¤ ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡
   2. Base Models: PatchTST (ì•ˆì •í˜•) + PatchTST+PINN (ê·¹ë‹¨í˜•)
   3. Fine-tuning Network: ë¯¸ì„¸ì¡°ì • ë¡œì§ì„ í•™ìŠµìœ¼ë¡œ ë³€í™˜
   4. Jump Detection Network: 277â†’300 ì í”„ íŠ¹í™” í•™ìŠµ
   5. Decision Fusion Network: ìµœì¢… í†µí•© ì˜ˆì¸¡
   6. ì™„ë²½í•œ ì¤‘ë‹¨/ì¬ê°œ ì‹œìŠ¤í…œ
   
ğŸ¯ í•™ìŠµ êµ¬ì¡°:
   - Stage 1: Base ëª¨ë¸ë“¤ í•™ìŠµ (ê¸°ì¡´ ë°©ì‹)
   - Stage 2: Fine-tuning Network í•™ìŠµ (ruleì„ networkë¡œ)
   - Stage 3: Decision Fusion í•™ìŠµ (ëª¨ë¸ ì„ íƒ ë¡œì§)
   - Stage 4: End-to-End í†µí•© í•™ìŠµ
================================================================================
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback
from sklearn.preprocessing import RobustScaler, StandardScaler
from sklearn.model_selection import train_test_split
import os
import pickle
import warnings
from datetime import datetime
import signal
import sys
import joblib
import h5py
from tqdm import tqdm
from typing import Dict, List, Tuple, Optional, Any

warnings.filterwarnings('ignore')
np.random.seed(42)
tf.random.set_seed(42)

print("="*80)
print("ğŸ”¥ HUBROOM V4 ULTIMATE ì™„ì „ í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ")
print("ğŸ“Š 30ë¶„ ì‹œí€€ìŠ¤ â†’ 10ë¶„ í›„ ì˜ˆì¸¡")
print("ğŸ¯ Base Models + Fine-tuning + Jump Detection + Decision Fusion")
print("="*80)
print(f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"ğŸ”§ TensorFlow Version: {tf.__version__}")
print("="*80)

# ==============================================================================
#