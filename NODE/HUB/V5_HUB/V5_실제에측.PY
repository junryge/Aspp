#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
ðŸŽ¯ HUBROOM V4 Ultimate - ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ (ê°„ë‹¨ ë²„ì „)
================================================================================
ê¸°ë°˜: ì œê³µëœ ì í”„ ê°ì§€ 80% ì‹œìŠ¤í…œ í•™ìŠµ ì½”ë“œ
ëª©í‘œ: ê³¼ê±° 20ë¶„ ë°ì´í„°ë¡œ 10ë¶„ í›„ CURRENT_M16A_3F_JOB_2 ì˜ˆì¸¡
- ë°ì´í„° ë¶€ì¡± ì‹œ ì•Œë¦¼
- ë°”ë¡œ ì˜ˆì¸¡ ì‹¤í–‰
- ê°„ë‹¨í•œ ìš”ì•½ ì œê³µ: ì˜ˆì¸¡ê°’, {ì•ˆì •/ì£¼ì˜/ìœ„í—˜, í¼ì„¼íŠ¸}
================================================================================
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, ExtraTreesRegressor
from xgboost import XGBClassifier
import joblib
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("ðŸŽ¯ HUBROOM V4 Ultimate ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
print("ðŸ“Š ê°„ë‹¨ ìš”ì•½: ì˜ˆì¸¡ê°’ + ìœ„í—˜ë„ + í¼ì„¼íŠ¸")
print("="*80)

# ==============================================================================
# ðŸ§  ì˜ˆì¸¡ìš© ë°ì´í„° ì²˜ë¦¬ê¸°
# ==============================================================================

class HubRoomPredictionProcessor:
    """ì˜ˆì¸¡ìš© ë°ì´í„° ì²˜ë¦¬ - í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•œ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§"""
    
    def __init__(self):
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        
        # 21ê°œ í•„ìˆ˜ ì»¬ëŸ¼
        self.inflow_cols = [
            'M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2',
            'M14A_3F_TO_HUB_JOB2', 'M14B_7F_TO_HUB_JOB2', 'M16B_10F_TO_HUB_JOB'
        ]
        
        self.outflow_cols = [
            'M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB',
            'M16A_3F_TO_M14A_3F_JOB', 'M16A_3F_TO_M14B_7F_JOB', 'M16A_3F_TO_3F_MLUD_JOB'
        ]
        
        self.cmd_cols = [
            'M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD', 'M16A_2F_TO_HUB_CMD',
            'M14A_3F_TO_HUB_CMD', 'M14B_7F_TO_HUB_CMD'
        ]
        
        self.capa_cols = ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA']
        self.other_cols = ['M16A_3F_STORAGE_UTIL', 'M14_TO_M16_OFS_CUR', 'M16_TO_M14_OFS_CUR']
        
        # í™•ë¥  ë§µ
        self.probability_map = {
            0: 0.003, 1: 0.15, 2: 0.25, 3: 0.31, 4: 0.43, 5: 0.43,
            6: 0.35, 7: 0.42, 8: 0.53, 9: 0.49, 10: 0.42,
            11: 0.47, 12: 0.52, 13: 0.60, 14: 0.54, 15: 0.66,
            16: 0.62, 17: 0.71, 18: 0.79, 19: 0.83, 20: 0.987,
            21: 0.99, 22: 0.99, 23: 0.99, 24: 0.99, 25: 0.99,
            26: 0.99, 27: 0.99, 28: 0.99, 29: 0.99, 30: 0.99
        }
    
    def load_and_process_data(self, file_path='data/HUBROOM_PIVOT_DATA.csv'):
        """ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì²˜ë¦¬"""
        print(f"ðŸ“‚ ë°ì´í„° ë¡œë“œ: {file_path}")
        
        try:
            df = pd.read_csv(file_path)
            print(f"âœ… ë°ì´í„° ë¡œë“œ: {df.shape}")
            
            # ì‹œê°„ ì»¬ëŸ¼ ì²˜ë¦¬
            time_col = df.columns[0]
            try:
                df['datetime'] = pd.to_datetime(df[time_col], format='%Y%m%d%H%M')
            except:
                df['datetime'] = pd.to_datetime(df[time_col])
            
            # BRIDGE_TIME ì²˜ë¦¬
            if 'BRIDGE_TIME' not in df.columns:
                df['BRIDGE_TIME'] = 3.5
            else:
                df['BRIDGE_TIME'] = df['BRIDGE_TIME'].fillna(3.5)
            
            # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
            all_required_cols = [self.target_col] + self.inflow_cols + self.outflow_cols + self.cmd_cols + self.capa_cols + self.other_cols
            missing_cols = [col for col in all_required_cols if col not in df.columns]
            
            if missing_cols:
                print(f"âš ï¸ ëˆ„ë½ ì»¬ëŸ¼: {missing_cols[:5]}..." if len(missing_cols) > 5 else f"âš ï¸ ëˆ„ë½ ì»¬ëŸ¼: {missing_cols}")
                for col in missing_cols:
                    df[col] = 0
            
            return df
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def create_prediction_features(self, df):
        """íŠ¹ì§• ìƒì„±"""
        print("ðŸ”§ íŠ¹ì§• ìƒì„± ì¤‘...")
        
        # ê¸°ë³¸ íŠ¹ì§•ë“¤
        df['flow_balance'] = df[self.inflow_cols].sum(axis=1) - df[self.outflow_cols].sum(axis=1)
        df['flow_ratio'] = df[self.inflow_cols].sum(axis=1) / (df[self.outflow_cols].sum(axis=1) + 1)
        df['trend_20min'] = df[self.target_col].diff(20)
        df['trend_10min'] = df[self.target_col].diff(10)
        df['acceleration'] = df['trend_10min'] - df['trend_10min'].shift(10)
        df['consecutive_250+'] = (df[self.target_col] > 250).rolling(10).sum()
        df['consecutive_270+'] = (df[self.target_col] > 270).rolling(10).sum()
        df['cmd_sync_count'] = (df[self.cmd_cols] > 235).sum(axis=1)
        df['cmd_max'] = df[self.cmd_cols].max(axis=1)
        df['bridge_diff'] = df['BRIDGE_TIME'].diff(5)
        df['bridge_high'] = (df['BRIDGE_TIME'] > 4.0).astype(int)
        df['storage_x_bridge'] = df['M16A_3F_STORAGE_UTIL'] * df['BRIDGE_TIME']
        
        # ì—°ì† 300+ í™•ë¥  (ê°„ì†Œí™”)
        df['consecutive_300_count'] = 0
        df['consecutive_300_prob'] = 0.003
        for i in range(30, len(df)):
            window = df[self.target_col].iloc[i-30:i].values
            count = sum(1 for v in window if v >= 300)
            prob = self.probability_map.get(count, 0.5)
            df.loc[df.index[i], 'consecutive_300_count'] = count
            df.loc[df.index[i], 'consecutive_300_prob'] = prob
        
        # ê¸°íƒ€ íŠ¹ì§•ë“¤
        conditions = [df[self.target_col] < 150, (df[self.target_col] >= 150) & (df[self.target_col] < 300), df[self.target_col] >= 300]
        df['range_class'] = np.select(conditions, [0, 1, 2], default=1)
        
        df['past_30min_max'] = df[self.target_col].rolling(30).max()
        df['is_jump'] = ((df['past_30min_max'].shift(10) < 280) & (df[self.target_col] >= 300)).astype(int)
        
        df['change_20min'] = df[self.target_col] - df[self.target_col].shift(20)
        trend_conditions = [df['change_20min'] < -20, (df['change_20min'] >= -20) & (df['change_20min'] < 20), (df['change_20min'] >= 20) & (df['change_20min'] < 50), df['change_20min'] >= 50]
        df['trend_pattern'] = np.select(trend_conditions, [0, 1, 2, 3], default=1)
        
        df['change_rate_10min'] = ((df[self.target_col] - df[self.target_col].shift(10)) / (df[self.target_col].shift(10) + 1)) * 100
        df['change_rate_20min'] = ((df[self.target_col] - df[self.target_col].shift(20)) / (df[self.target_col].shift(20) + 1)) * 100
        df['change_rate_30min'] = ((df[self.target_col] - df[self.target_col].shift(30)) / (df[self.target_col].shift(30) + 1)) * 100
        
        df['volatility_10min'] = df[self.target_col].rolling(10).std()
        df['volatility_20min'] = df[self.target_col].rolling(20).std()
        df['volatility_30min'] = df[self.target_col].rolling(30).std()
        
        df['distance_to_300'] = 300 - df[self.target_col]
        df['near_extreme'] = (df[self.target_col] > 280).astype(int)
        df['recent_5min_mean'] = df[self.target_col].rolling(5).mean()
        df['recent_5min_max'] = df[self.target_col].rolling(5).max()
        df['recent_10min_mean'] = df[self.target_col].rolling(10).mean()
        df['in_jump_zone'] = ((df[self.target_col] >= 275) & (df[self.target_col] <= 279)).astype(int)
        
        # NaN ì²˜ë¦¬
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        df[numeric_columns] = df[numeric_columns].fillna(method='ffill').fillna(0)
        
        print(f"âœ… íŠ¹ì§• ì™„ë£Œ: {len(df.columns)}ê°œ")
        return df

# ==============================================================================
# ðŸ¤– ì˜ˆì¸¡ ì‹œìŠ¤í…œ
# ==============================================================================

class HUBROOMPredictionSystem:
    """HUBROOM ì˜ˆì¸¡ ì‹œìŠ¤í…œ"""
    
    def __init__(self, model_dir='./checkpoints_jump80'):
        self.model_dir = model_dir
        self.models = {}
        self.target_col = 'CURRENT_M16A_3F_JOB_2'  # ëˆ„ë½ëœ ì†ì„± ì¶”ê°€
        self.load_models()
    
    def load_models(self):
        """ëª¨ë¸ ë¡œë“œ"""
        print(f"ðŸ”„ ëª¨ë¸ ë¡œë“œ: {self.model_dir}")
        
        model_files = {'model_value': 'model_value.pkl'}
        models_dir = os.path.join(self.model_dir, 'models')
        
        if not os.path.exists(models_dir):
            print(f"âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì—†ìŒ: {models_dir}")
            return
        
        for model_name, filename in model_files.items():
            filepath = os.path.join(models_dir, filename)
            if os.path.exists(filepath):
                self.models[model_name] = joblib.load(filepath)
                print(f"  âœ… {model_name} ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"  âŒ {model_name} íŒŒì¼ ì—†ìŒ")
    
    def prepare_features_for_prediction(self, X_seq):
        """ì‹œí€€ìŠ¤ë¥¼ íŠ¹ì§•ìœ¼ë¡œ ë³€í™˜"""
        last_features = X_seq[:, -1, :]
        mean_features = np.mean(X_seq, axis=1)
        std_features = np.std(X_seq, axis=1)
        max_features = np.max(X_seq, axis=1)
        min_features = np.min(X_seq, axis=1)
        trend_features = X_seq[:, -1, :] - X_seq[:, 0, :]
        
        features = np.hstack([last_features, mean_features, std_features, max_features, min_features, trend_features])
        return features
    
    def get_risk_classification(self, value):
        """ìœ„í—˜ë„ ë¶„ë¥˜"""
        if value < 220:
            return {'level': 'SAFE', 'korean': 'ì•ˆì •', 'percentage': max(10, min(30, (220 - value) / 220 * 100))}
        elif value < 300:
            return {'level': 'WARNING', 'korean': 'ì£¼ì˜', 'percentage': max(30, min(70, (value - 220) / 80 * 100))}
        else:
            return {'level': 'DANGER', 'korean': 'ìœ„í—˜', 'percentage': max(70, min(99, 70 + (value - 300) / 100 * 29))}
    
    def predict_sequence(self, df, start_idx):
        """ë‹¨ì¼ ì‹œí€€ìŠ¤ ì˜ˆì¸¡"""
        seq_len = 20
        
        if start_idx < seq_len:
            return None
            
        # íŠ¹ì§• ì»¬ëŸ¼ ì„ íƒ
        feature_cols = [col for col in df.columns if col not in ['datetime', 'range_class', 'is_jump', 'trend_pattern']]
        
        # ì‹œí€€ìŠ¤ ìƒì„±
        sequence = df[feature_cols].iloc[start_idx-seq_len:start_idx].values
        sequence = sequence.reshape(1, seq_len, -1)
        
        # íŠ¹ì§• ì¤€ë¹„
        features = self.prepare_features_for_prediction(sequence)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = {}
        
        if 'model_value' in self.models:
            value_pred = self.models['model_value'].predict(features)[0]
            risk_info = self.get_risk_classification(value_pred)
            
            predictions['value'] = {
                'prediction': value_pred,
                'risk_korean': risk_info['korean'],
                'risk_percentage': risk_info['percentage']
            }
        
        # í˜„ìž¬ ì •ë³´
        current_value = df[self.target_col].iloc[start_idx-1]
        predictions['current'] = {
            'value': current_value,
            'datetime': df['datetime'].iloc[start_idx-1]
        }
        
        return predictions

# ==============================================================================
# ðŸŽ¯ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹¤í–‰ê¸°
# ==============================================================================

class RealTimePredictionRunner:
    """ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹¤í–‰"""
    
    def __init__(self):
        self.processor = HubRoomPredictionProcessor()
        self.predictor = HUBROOMPredictionSystem()
    
    def run_prediction(self, file_path='data/HUBROOM_PIVOT_DATA.csv', num_predictions=5):
        """ì˜ˆì¸¡ ì‹¤í–‰"""
        try:
            # ë°ì´í„° ë¡œë“œ
            df = self.processor.load_and_process_data(file_path)
            
            # ë°ì´í„° ë¶€ì¡± ì²´í¬
            if len(df) < 30:
                print(f"ë°ì´í„° ë¶€ì¡±: {len(df)}ê°œ (ìµœì†Œ 30ê°œ í•„ìš”)")
                return []
            
            df = self.processor.create_prediction_features(df)
            
            # ëª¨ë¸ ì²´í¬
            if not self.predictor.models:
                print("ëª¨ë¸ ì—†ìŒ")
                return []
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            results = []
            start_idx = len(df) - num_predictions
            
            for i in range(num_predictions):
                idx = start_idx + i
                if idx >= 20 and idx < len(df):
                    try:
                        result = self.predictor.predict_sequence(df, idx)
                        if result:
                            results.append(result)
                    except:
                        continue
            
            # ê²°ê³¼ í‘œì‹œ
            self.display_simple_results(results)
            return results
            
        except Exception as e:
            print(f"ì˜¤ë¥˜: {e}")
            return []
    
    def display_simple_results(self, results):
        """ì´ˆê°„ë‹¨ ê²°ê³¼ í‘œì‹œ"""
        if not results:
            print("ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ")
            return
        
        # ìµœì‹  ì˜ˆì¸¡ë§Œ ê°„ë‹¨í•˜ê²Œ
        latest = results[-1]
        if 'value' in latest:
            pred_value = latest['value']['prediction']
            risk_korean = latest['value']['risk_korean']
            risk_percentage = latest['value']['risk_percentage']
            
            print(f"{{{pred_value:.1f},{risk_korean}({risk_percentage:.0f}%)}}")
        else:
            print("ì˜ˆì¸¡ ì‹¤íŒ¨")

# ==============================================================================
# ðŸš€ ë©”ì¸ ì‹¤í–‰
# ==============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    try:
        runner = RealTimePredictionRunner()
        results = runner.run_prediction('data/HUBROOM_PIVOT_DATA.csv', 5)
        
        if results:
            print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
        
    except FileNotFoundError:
        print("âŒ íŒŒì¼ ì—†ìŒ: data/HUBROOM_PIVOT_DATA.csv")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()