#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
ğŸ¯ HUBROOM V4 Ultimate - ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
================================================================================
ê¸°ë°˜: ì œê³µëœ ì í”„ ê°ì§€ 80% ì‹œìŠ¤í…œ í•™ìŠµ ì½”ë“œ
ëª©í‘œ: ê³¼ê±° 20ë¶„ ë°ì´í„°ë¡œ 10ë¶„ í›„ CURRENT_M16A_3F_JOB_2 ì˜ˆì¸¡
- Model 1: PatchTST (ì•ˆì •í˜•, 200-300 êµ¬ê°„ ì „ë¬¸)  
- Model 2: PatchTST+PINN (ê·¹ë‹¨í˜•, 300+ ì „ë¬¸)
- ì˜ˆì¸¡ êµ¬ê°„: 90-220 ì•ˆì •, 220-299 ì£¼ì˜, 300+ ìœ„í—˜
- íŒŒì¼: data/HUBROOM_PIVOT_DATA.csv
================================================================================
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import RobustScaler
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, ExtraTreesRegressor
from xgboost import XGBClassifier
import joblib
import os
import pickle
from datetime import datetime, timedelta
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("ğŸ¯ HUBROOM V4 Ultimate ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
print("ğŸ“Š 3êµ¬ê°„ ë¶„ë¥˜ + ì í”„ ê°ì§€ + ìƒìŠ¹/í•˜ë½ íŒ¨í„´")
print("â° ê³¼ê±° 20ë¶„ â†’ 10ë¶„ í›„ ì˜ˆì¸¡")
print("="*80)

# ==============================================================================
# ğŸ§  ì˜ˆì¸¡ìš© ë°ì´í„° ì²˜ë¦¬ê¸° (í•™ìŠµ ì½”ë“œ ê¸°ë°˜)
# ==============================================================================

class HubRoomPredictionProcessor:
    """ì˜ˆì¸¡ìš© ë°ì´í„° ì²˜ë¦¬ - í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•œ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§"""
    
    def __init__(self):
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        
        # 21ê°œ í•„ìˆ˜ ì»¬ëŸ¼ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼)
        self.inflow_cols = [
            'M16A_6F_TO_HUB_JOB',
            'M16A_2F_TO_HUB_JOB2',
            'M14A_3F_TO_HUB_JOB2',
            'M14B_7F_TO_HUB_JOB2',
            'M16B_10F_TO_HUB_JOB'
        ]
        
        self.outflow_cols = [
            'M16A_3F_TO_M16A_6F_JOB',
            'M16A_3F_TO_M16A_2F_JOB',
            'M16A_3F_TO_M14A_3F_JOB',
            'M16A_3F_TO_M14B_7F_JOB',
            'M16A_3F_TO_3F_MLUD_JOB'
        ]
        
        self.cmd_cols = [
            'M16A_3F_CMD',
            'M16A_6F_TO_HUB_CMD',
            'M16A_2F_TO_HUB_CMD',
            'M14A_3F_TO_HUB_CMD',
            'M14B_7F_TO_HUB_CMD'
        ]
        
        self.capa_cols = [
            'M16A_6F_LFT_MAXCAPA',
            'M16A_2F_LFT_MAXCAPA'
        ]
        
        self.other_cols = [
            'M16A_3F_STORAGE_UTIL',
            'M14_TO_M16_OFS_CUR',
            'M16_TO_M14_OFS_CUR'
        ]
        
        # í™•ë¥  ë§µ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼)
        self.probability_map = {
            0: 0.003, 1: 0.15, 2: 0.25, 3: 0.31, 4: 0.43, 5: 0.43,
            6: 0.35, 7: 0.42, 8: 0.53, 9: 0.49, 10: 0.42,
            11: 0.47, 12: 0.52, 13: 0.60, 14: 0.54, 15: 0.66,
            16: 0.62, 17: 0.71, 18: 0.79, 19: 0.83, 20: 0.987,
            21: 0.99, 22: 0.99, 23: 0.99, 24: 0.99, 25: 0.99,
            26: 0.99, 27: 0.99, 28: 0.99, 29: 0.99, 30: 0.99
        }
    
    def load_and_process_data(self, file_path='data/HUBROOM_PIVOT_DATA.csv'):
        """ë°ì´í„° ë¡œë“œ ë° BRIDGE_TIME ì²˜ë¦¬"""
        print(f"\nğŸ“‚ ë°ì´í„° ë¡œë“œ: {file_path}")
        
        # ë©”ì¸ ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(file_path)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}")
        
        # ì‹œê°„ ì»¬ëŸ¼ ì²˜ë¦¬
        time_col = df.columns[0]
        df['datetime'] = pd.to_datetime(df[time_col], format='%Y%m%d%H%M')
        
        # BRIDGE_TIME ì²˜ë¦¬ (ìˆë‹¤ë©´)
        if 'BRIDGE_TIME' not in df.columns:
            # BRIDGE_TIMEì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            df['BRIDGE_TIME'] = 3.5
            print("âš ï¸ BRIDGE_TIME ì»¬ëŸ¼ì´ ì—†ì–´ ê¸°ë³¸ê°’(3.5)ìœ¼ë¡œ ì„¤ì •")
        else:
            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            df['BRIDGE_TIME'] = df['BRIDGE_TIME'].fillna(3.5)
            print(f"âœ… BRIDGE_TIME ì²˜ë¦¬ ì™„ë£Œ")
        
        return df
    
    def create_prediction_features(self, df):
        """ì˜ˆì¸¡ìš© íŠ¹ì§• ìƒì„± (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•œ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§)"""
        print("\nğŸ”§ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§ ì¤‘...")
        
        # 1. ìœ ì…/ìœ ì¶œ ë°¸ëŸ°ìŠ¤
        df['flow_balance'] = df[self.inflow_cols].sum(axis=1) - df[self.outflow_cols].sum(axis=1)
        df['flow_ratio'] = df[self.inflow_cols].sum(axis=1) / (df[self.outflow_cols].sum(axis=1) + 1)
        
        # 2. ì¶”ì„¸ íŠ¹ì§•
        df['trend_20min'] = df[self.target_col].diff(20)
        df['trend_10min'] = df[self.target_col].diff(10)
        df['acceleration'] = df['trend_10min'] - df['trend_10min'].shift(10)
        
        # 3. ì—°ì† íŒ¨í„´
        df['consecutive_250+'] = (df[self.target_col] > 250).rolling(10).sum()
        df['consecutive_270+'] = (df[self.target_col] > 270).rolling(10).sum()
        
        # 4. CMD ë™ê¸°í™”
        df['cmd_sync_count'] = (df[self.cmd_cols] > 235).sum(axis=1)
        df['cmd_max'] = df[self.cmd_cols].max(axis=1)
        
        # 5. ë¸Œë¦¿ì§€íƒ€ì„ ë³€í™”
        df['bridge_diff'] = df['BRIDGE_TIME'].diff(5)
        df['bridge_high'] = (df['BRIDGE_TIME'] > 4.0).astype(int)
        
        # 6. storage x bridge ìƒí˜¸ì‘ìš©
        df['storage_x_bridge'] = df['M16A_3F_STORAGE_UTIL'] * df['BRIDGE_TIME']
        
        # 7. ì—°ì† 300+ ì¹´ìš´íŠ¸ì™€ í™•ë¥ 
        consecutive_300_counts = []
        consecutive_300_probs = []
        
        for i in range(len(df)):
            if i < 30:
                count = 0
                prob = 0.003
            else:
                window = df[self.target_col].iloc[i-30:i].values
                count = sum(1 for v in window if v >= 300)
                prob = self.probability_map.get(count, 0.5)
            
            consecutive_300_counts.append(count)
            consecutive_300_probs.append(prob)
        
        df['consecutive_300_count'] = consecutive_300_counts
        df['consecutive_300_prob'] = consecutive_300_probs
        
        # 8. 3êµ¬ê°„ ë¶„ë¥˜
        conditions = [
            df[self.target_col] < 150,
            (df[self.target_col] >= 150) & (df[self.target_col] < 300),
            df[self.target_col] >= 300
        ]
        choices = [0, 1, 2]  # 0: ì €ìœ„í—˜, 1: ì¤‘ìœ„í—˜, 2: ê³ ìœ„í—˜
        df['range_class'] = np.select(conditions, choices, default=1)
        
        # 9. ì í”„ ì—¬ë¶€
        df['past_30min_max'] = df[self.target_col].rolling(30).max()
        df['is_jump'] = ((df['past_30min_max'].shift(10) < 280) & 
                        (df[self.target_col] >= 300)).astype(int)
        
        # 10. ìƒìŠ¹/í•˜ë½ íŒ¨í„´
        df['change_20min'] = df[self.target_col] - df[self.target_col].shift(20)
        
        trend_conditions = [
            df['change_20min'] < -20,
            (df['change_20min'] >= -20) & (df['change_20min'] < 20),
            (df['change_20min'] >= 20) & (df['change_20min'] < 50),
            df['change_20min'] >= 50
        ]
        trend_choices = [0, 1, 2, 3]  # 0:down, 1:stable, 2:gradual_up, 3:rapid_up
        df['trend_pattern'] = np.select(trend_conditions, trend_choices, default=1)
        
        # 11. ë³€í™”ìœ¨ (%)
        df['change_rate_10min'] = ((df[self.target_col] - df[self.target_col].shift(10)) / 
                                   (df[self.target_col].shift(10) + 1)) * 100
        df['change_rate_20min'] = ((df[self.target_col] - df[self.target_col].shift(20)) / 
                                   (df[self.target_col].shift(20) + 1)) * 100
        df['change_rate_30min'] = ((df[self.target_col] - df[self.target_col].shift(30)) / 
                                   (df[self.target_col].shift(30) + 1)) * 100
        
        # 12. ë³€ë™ì„±
        df['volatility_10min'] = df[self.target_col].rolling(10).std()
        df['volatility_20min'] = df[self.target_col].rolling(20).std()
        df['volatility_30min'] = df[self.target_col].rolling(30).std()
        
        # 13. ê·¹ë‹¨ê°’ ê·¼ì ‘ë„
        df['distance_to_300'] = 300 - df[self.target_col]
        df['near_extreme'] = (df[self.target_col] > 280).astype(int)
        
        # 14. ìµœê·¼ í†µê³„
        df['recent_5min_mean'] = df[self.target_col].rolling(5).mean()
        df['recent_5min_max'] = df[self.target_col].rolling(5).max()
        df['recent_10min_mean'] = df[self.target_col].rolling(10).mean()
        
        # 15. 277 êµ¬ê°„ íŠ¹ë³„ ì§€í‘œ
        df['in_jump_zone'] = ((df[self.target_col] >= 275) & (df[self.target_col] <= 279)).astype(int)
        
        # NaN ì²˜ë¦¬
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        df[numeric_columns] = df[numeric_columns].fillna(method='ffill').fillna(0)
        
        print(f"âœ… íŠ¹ì§• ìƒì„± ì™„ë£Œ: {len(df.columns)}ê°œ ì»¬ëŸ¼")
        return df

# ==============================================================================
# ğŸ¤– ì˜ˆì¸¡ ì‹œìŠ¤í…œ (í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ)
# ==============================================================================

class HUBROOMPredictionSystem:
    """HUBROOM ì˜ˆì¸¡ ì‹œìŠ¤í…œ - í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©"""
    
    def __init__(self, model_dir='./checkpoints_jump80'):
        self.model_dir = model_dir
        self.models = {}
        self.feature_indices = {}
        
        # ëª¨ë¸ ë¡œë“œ
        self.load_models()
    
    def load_models(self):
        """í•™ìŠµëœ ëª¨ë¸ë“¤ ë¡œë“œ"""
        print("\nğŸ”„ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        
        model_files = {
            'model_jump': 'model_jump.pkl',
            'model_range': 'model_range.pkl', 
            'model_trend': 'model_trend.pkl',
            'model_value': 'model_value.pkl'
        }
        
        models_dir = os.path.join(self.model_dir, 'models')
        
        for model_name, filename in model_files.items():
            filepath = os.path.join(models_dir, filename)
            if os.path.exists(filepath):
                self.models[model_name] = joblib.load(filepath)
                print(f"  âœ… {model_name} ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"  âŒ {model_name} íŒŒì¼ ì—†ìŒ: {filepath}")
    
    def prepare_features_for_prediction(self, X_seq):
        """ì‹œí€€ìŠ¤ë¥¼ ì˜ˆì¸¡ìš© íŠ¹ì§•ìœ¼ë¡œ ë³€í™˜ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼)"""
        # ë§ˆì§€ë§‰ ì‹œì  íŠ¹ì§•
        last_features = X_seq[:, -1, :]
        
        # í†µê³„ íŠ¹ì§•
        mean_features = np.mean(X_seq, axis=1)
        std_features = np.std(X_seq, axis=1)
        max_features = np.max(X_seq, axis=1)
        min_features = np.min(X_seq, axis=1)
        
        # ì¶”ì„¸ íŠ¹ì§•
        trend_features = X_seq[:, -1, :] - X_seq[:, 0, :]
        
        # ëª¨ë“  íŠ¹ì§• ê²°í•©
        features = np.hstack([
            last_features,
            mean_features, 
            std_features,
            max_features,
            min_features,
            trend_features
        ])
        
        return features
    
    def get_risk_classification(self, value):
        """ìœ„í—˜ë„ ë¶„ë¥˜"""
        if value < 220:
            return {
                'level': 'SAFE',
                'korean': 'ì•ˆì •', 
                'color': 'GREEN',
                'probability': max(0.1, min(0.3, (220 - value) / 220))
            }
        elif value < 300:
            return {
                'level': 'WARNING',
                'korean': 'ì£¼ì˜',
                'color': 'YELLOW', 
                'probability': max(0.3, min(0.7, (value - 220) / 80))
            }
        else:
            return {
                'level': 'DANGER',
                'korean': 'ìœ„í—˜',
                'color': 'RED',
                'probability': max(0.7, min(0.99, 0.7 + (value - 300) / 100))
            }
    
    def predict_sequence(self, df, start_idx):
        """ë‹¨ì¼ ì‹œí€€ìŠ¤ ì˜ˆì¸¡"""
        seq_len = 20
        
        if start_idx < seq_len:
            return None
            
        # íŠ¹ì§• ì»¬ëŸ¼ ì„ íƒ (í•™ìŠµ ì‹œì™€ ë™ì¼)
        feature_cols = [col for col in df.columns 
                       if col not in ['datetime', 'range_class', 'is_jump', 'trend_pattern']]
        
        # ì‹œí€€ìŠ¤ ìƒì„± (ê³¼ê±° 20ë¶„)
        sequence = df[feature_cols].iloc[start_idx-seq_len:start_idx].values
        sequence = sequence.reshape(1, seq_len, -1)
        
        # íŠ¹ì§• ì¤€ë¹„
        features = self.prepare_features_for_prediction(sequence)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = {}
        
        # 1. ì í”„ ê°ì§€
        if 'model_jump' in self.models:
            jump_prob = self.models['model_jump'].predict_proba(features)[0, 1]
            jump_pred = self.models['model_jump'].predict(features)[0]
            predictions['jump'] = {
                'probability': jump_prob,
                'prediction': bool(jump_pred),
                'confidence': 'HIGH' if jump_prob > 0.7 else 'MEDIUM' if jump_prob > 0.3 else 'LOW'
            }
        
        # 2. 3êµ¬ê°„ ë¶„ë¥˜  
        if 'model_range' in self.models:
            range_prob = self.models['model_range'].predict_proba(features)[0]
            range_pred = self.models['model_range'].predict(features)[0]
            predictions['range'] = {
                'prediction': int(range_pred),
                'probabilities': {
                    'low_risk': range_prob[0],
                    'medium_risk': range_prob[1], 
                    'high_risk': range_prob[2]
                },
                'class_names': ['ì €ìœ„í—˜(<150)', 'ì¤‘ìœ„í—˜(150-299)', 'ê³ ìœ„í—˜(300+)']
            }
        
        # 3. ìƒìŠ¹/í•˜ë½ íŒ¨í„´
        if 'model_trend' in self.models:
            trend_prob = self.models['model_trend'].predict_proba(features)[0]
            trend_pred = self.models['model_trend'].predict(features)[0]
            predictions['trend'] = {
                'prediction': int(trend_pred),
                'probabilities': {
                    'down': trend_prob[0],
                    'stable': trend_prob[1],
                    'gradual_up': trend_prob[2] if len(trend_prob) > 2 else 0,
                    'rapid_up': trend_prob[3] if len(trend_prob) > 3 else 0
                },
                'class_names': ['í•˜ë½', 'ì•ˆì •', 'ì ì§„ìƒìŠ¹', 'ê¸‰ìƒìŠ¹']
            }
        
        # 4. ê°’ ì˜ˆì¸¡
        if 'model_value' in self.models:
            value_pred = self.models['model_value'].predict(features)[0]
            
            # ìœ„í—˜ë„ ë¶„ë¥˜
            risk_info = self.get_risk_classification(value_pred)
            
            predictions['value'] = {
                'prediction': value_pred,
                'risk_level': risk_info['level'],
                'risk_korean': risk_info['korean'],
                'risk_color': risk_info['color'],
                'risk_probability': risk_info['probability']
            }
        
        # í˜„ì¬ ìƒíƒœ ì •ë³´
        current_value = df[df.columns[1]].iloc[start_idx-1]  # CURRENT_M16A_3F_JOB_2
        predictions['current'] = {
            'value': current_value,
            'datetime': df['datetime'].iloc[start_idx-1],
            'risk_info': self.get_risk_classification(current_value)
        }
        
        return predictions

# ==============================================================================
# ğŸ¯ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹¤í–‰ê¸°
# ==============================================================================

class RealTimePredictionRunner:
    """ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹¤í–‰ ë° ê²°ê³¼ í‘œì‹œ"""
    
    def __init__(self):
        self.processor = HubRoomPredictionProcessor()
        self.predictor = HUBROOMPredictionSystem()
    
    def run_prediction(self, file_path='data/HUBROOM_PIVOT_DATA.csv', num_predictions=10):
        """ì˜ˆì¸¡ ì‹¤í–‰"""
        print(f"\nğŸš€ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œì‘ (ìµœê·¼ {num_predictions}ê°œ ì‹œì )")
        print("="*80)
        
        # 1. ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬
        df = self.processor.load_and_process_data(file_path)
        df = self.processor.create_prediction_features(df)
        
        # 2. ìµœê·¼ ë°ì´í„° ì˜ˆì¸¡
        results = []
        start_idx = len(df) - num_predictions
        
        print(f"\nğŸ“Š ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
        for i in range(num_predictions):
            idx = start_idx + i
            if idx >= 20:  # ìµœì†Œ 20ê°œ ì‹œì  í•„ìš”
                result = self.predictor.predict_sequence(df, idx)
                if result:
                    result['index'] = idx
                    result['sequence_end'] = df['datetime'].iloc[idx-1]
                    results.append(result)
        
        # 3. ê²°ê³¼ ì¶œë ¥
        self.display_results(results)
        
        return results
    
    def display_results(self, results):
        """ê²°ê³¼ í‘œì‹œ"""
        print("\n" + "="*100)
        print("ğŸ“ˆ HUBROOM V4 Ultimate ì˜ˆì¸¡ ê²°ê³¼")
        print("="*100)
        
        for i, result in enumerate(results, 1):
            print(f"\n[ì˜ˆì¸¡ {i}] ì‹œê°„: {result['sequence_end']}")
            print("-" * 60)
            
            # í˜„ì¬ ìƒíƒœ
            current = result['current']
            print(f"ğŸ”¸ í˜„ì¬ê°’: {current['value']:.1f} ({current['risk_info']['korean']})")
            
            # ê°’ ì˜ˆì¸¡  
            if 'value' in result:
                value_pred = result['value']
                print(f"ğŸ”¹ ì˜ˆì¸¡ê°’: {value_pred['prediction']:.1f}")
                print(f"ğŸ”¹ ìœ„í—˜ë„: {value_pred['risk_korean']} ({value_pred['risk_level']})")
                print(f"ğŸ”¹ ìœ„í—˜í™•ë¥ : {value_pred['risk_probability']:.1%}")
                
                # êµ¬ê°„ë³„ ë¶„ë¥˜
                if value_pred['prediction'] < 220:
                    status = "âœ… ì•ˆì • êµ¬ê°„"
                elif value_pred['prediction'] < 300:
                    status = "âš ï¸ ì£¼ì˜ êµ¬ê°„" 
                else:
                    status = "ğŸš¨ ìœ„í—˜ êµ¬ê°„"
                print(f"ğŸ”¹ ìƒíƒœ: {status}")
            
            # ì í”„ ìœ„í—˜
            if 'jump' in result:
                jump = result['jump']
                jump_risk = "ğŸš¨ ì í”„ ìœ„í—˜" if jump['prediction'] else "âœ… ì í”„ ì•ˆì „"
                print(f"ğŸ”¹ ì í”„ ì˜ˆì¸¡: {jump_risk} (í™•ë¥ : {jump['probability']:.1%})")
            
            # 3êµ¬ê°„ ë¶„ë¥˜
            if 'range' in result:
                range_pred = result['range']
                class_name = range_pred['class_names'][range_pred['prediction']]
                probabilities = range_pred['probabilities']
                print(f"ğŸ”¹ ìœ„í—˜ ë¶„ë¥˜: {class_name}")
                print(f"   - ì €ìœ„í—˜: {probabilities['low_risk']:.1%}")
                print(f"   - ì¤‘ìœ„í—˜: {probabilities['medium_risk']:.1%}")
                print(f"   - ê³ ìœ„í—˜: {probabilities['high_risk']:.1%}")
            
            # ì¶”ì„¸ ë¶„ì„
            if 'trend' in result:
                trend = result['trend']
                trend_name = trend['class_names'][trend['prediction']]
                print(f"ğŸ”¹ ì¶”ì„¸ íŒ¨í„´: {trend_name}")
        
        # ì „ì²´ ìš”ì•½
        print("\n" + "="*100)
        print("ğŸ“‹ ì „ì²´ ìš”ì•½")
        print("="*100)
        
        # ìœ„í—˜ êµ¬ê°„ í†µê³„
        danger_count = sum(1 for r in results if r.get('value', {}).get('prediction', 0) >= 300)
        warning_count = sum(1 for r in results if 220 <= r.get('value', {}).get('prediction', 0) < 300)
        safe_count = sum(1 for r in results if r.get('value', {}).get('prediction', 0) < 220)
        
        print(f"ğŸ”¸ ì•ˆì • êµ¬ê°„ (< 220): {safe_count}ê°œ ({safe_count/len(results):.1%})")
        print(f"ğŸ”¸ ì£¼ì˜ êµ¬ê°„ (220-299): {warning_count}ê°œ ({warning_count/len(results):.1%})")  
        print(f"ğŸ”¸ ìœ„í—˜ êµ¬ê°„ (â‰¥ 300): {danger_count}ê°œ ({danger_count/len(results):.1%})")
        
        # ì í”„ ìœ„í—˜ í†µê³„
        jump_risk_count = sum(1 for r in results if r.get('jump', {}).get('prediction', False))
        print(f"ğŸ”¸ ì í”„ ìœ„í—˜: {jump_risk_count}ê°œ ({jump_risk_count/len(results):.1%})")
        
        # ê¶Œì¥ ì¡°ì¹˜
        if danger_count > 0:
            print(f"\nğŸš¨ ê¶Œì¥ ì¡°ì¹˜: M16 6F AI MAXCAPA 50% DOWN ì¦‰ì‹œ ì‹¤í–‰")
        elif warning_count > len(results) * 0.5:
            print(f"\nâš ï¸ ê¶Œì¥ ì¡°ì¹˜: ëª¨ë‹ˆí„°ë§ ê°•í™” ë° ì˜ˆë°© ì¡°ì¹˜ ì¤€ë¹„")
        else:
            print(f"\nâœ… ìƒíƒœ: ì •ìƒ ë²”ìœ„ ë‚´ ìš´ì˜ ì¤‘")

# ==============================================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ì˜ˆì¸¡ ì‹¤í–‰ê¸° ì´ˆê¸°í™”
        runner = RealTimePredictionRunner()
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        results = runner.run_prediction(
            file_path='data/HUBROOM_PIVOT_DATA.csv',
            num_predictions=10
        )
        
        print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ! ì´ {len(results)}ê°œ ê²°ê³¼ ìƒì„±")
        
        # ê°œë³„ ì˜ˆì¸¡ ìƒì„¸ ì •ë³´ (ì˜µì…˜)
        detail_view = input("\nìƒì„¸ ì˜ˆì¸¡ ì •ë³´ë¥¼ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if detail_view.lower() == 'y':
            for i, result in enumerate(results, 1):
                print(f"\n[ìƒì„¸ {i}] ===================")
                print(f"ì˜ˆì¸¡ê°’: {result.get('value', {}).get('prediction', 'N/A'):.1f}")
                print(f"ì í”„í™•ë¥ : {result.get('jump', {}).get('probability', 0):.1%}")
                print(f"ìœ„í—˜í™•ë¥ : {result.get('value', {}).get('risk_probability', 0):.1%}")
        
    except FileNotFoundError:
        print("âŒ ì˜¤ë¥˜: data/HUBROOM_PIVOT_DATA.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()