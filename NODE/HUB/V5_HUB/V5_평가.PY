# -*- coding: utf-8 -*-
"""
================================================================================
ğŸ“Š V4 ULTIMATE í‰ê°€ ì‹œìŠ¤í…œ - 2025ë…„ 8ì›” ë°ì´í„° í‰ê°€
================================================================================
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import joblib
import h5py
import os
from datetime import datetime, timedelta
from tqdm import tqdm

print("="*80)
print("ğŸ“Š V4 ULTIMATE í‰ê°€ ì‹œìŠ¤í…œ")
print("ğŸ¯ 2025ë…„ 8ì›” ë°ì´í„° (í•™ìŠµë˜ì§€ ì•Šì€ ë°ì´í„°) í‰ê°€")
print("="*80)

# ë°ì´í„° í”„ë¡œì„¸ì„œ ë¡œë“œ (ê¸°ì¡´ ì½”ë“œì—ì„œ ê°€ì ¸ì˜´)
from your_training_script import IntegratedDataProcessor, IntegratedV4Model

class V4Evaluator:
    """V4 ëª¨ë¸ í‰ê°€ ë° ê²°ê³¼ ìƒì„±"""
    
    def __init__(self):
        self.processor = IntegratedDataProcessor()
        self.model = None
        self.evaluation_results = []
        
    def load_august_data(self):
        """8ì›” ë°ì´í„°ë§Œ ë¡œë“œ"""
        print("\nğŸ“Š 8ì›” í‰ê°€ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ì „ì²´ ë°ì´í„° ë¡œë“œ
        df_raw = pd.read_csv('data/HUB_0509_TO_0807_DATA.CSV')
        
        # ì‹œê°„ ì²˜ë¦¬
        time_col = df_raw.columns[0]
        df_raw['timestamp'] = pd.to_datetime(df_raw[time_col], format='%Y%m%d%H%M', errors='coerce')
        
        # 8ì›” ë°ì´í„°ë§Œ í•„í„°ë§
        df_august = df_raw[(df_raw['timestamp'] >= '2025-08-01') & 
                          (df_raw['timestamp'] < '2025-09-01')].copy()
        
        print(f"âœ… 8ì›” ë°ì´í„°: {len(df_august)} í–‰")
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ì²˜ë¦¬ (processor ì‚¬ìš©)
        available_cols = ['timestamp']
        for col in self.processor.v4_essential_cols:
            if col in df_august.columns:
                available_cols.append(col)
            else:
                df_august[col] = 0
        
        # BRIDGE_TIME ì²˜ë¦¬
        df_august['BRIDGE_TIME'] = 3.5  # ê°„ë‹¨íˆ ê¸°ë³¸ê°’ ì‚¬ìš©
        
        # ê³ ê¸‰ íŠ¹ì§• ìƒì„±
        df_august = self.processor.create_advanced_features(df_august)
        
        return df_august
    
    def load_trained_model(self):
        """í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ"""
        print("\nğŸ¤– í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self.processor.scaler_X = joblib.load('./checkpoints_integrated_30min/scalers/scaler_X.pkl')
        self.processor.scaler_y = joblib.load('./checkpoints_integrated_30min/scalers/scaler_y.pkl')
        self.processor.scaler_physics = joblib.load('./checkpoints_integrated_30min/scalers/scaler_physics.pkl')
        self.processor.scaler_features = joblib.load('./checkpoints_integrated_30min/scalers/scaler_features.pkl')
        
        # ëª¨ë¸ ì„¤ì •
        with h5py.File('./checkpoints_integrated_30min/scaled_integrated_data.h5', 'r') as f:
            n_features = f.attrs['n_features']
        
        config = {
            'seq_len': 30,
            'n_features': n_features,
            'patch_len': 6
        }
        
        # í†µí•© ëª¨ë¸ ë¡œë“œ
        self.model = IntegratedV4Model(config)
        
        # ê°€ì¤‘ì¹˜ ë¡œë“œ
        dummy_input = [
            np.zeros((1, 30, n_features)),
            np.zeros((1, 11)),
            np.zeros((1, 15))
        ]
        _ = self.model(dummy_input, training=False)
        
        self.model.load_weights('./checkpoints_integrated_30min/models/integrated_model.weights.h5')
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
    def evaluate_sequences(self, df):
        """ì‹œí€€ìŠ¤ë³„ í‰ê°€ ìˆ˜í–‰"""
        print("\nğŸ” ì‹œí€€ìŠ¤ë³„ í‰ê°€ ì‹œì‘...")
        
        results = []
        
        # ì‚¬ìš©í•  ì»¬ëŸ¼ë“¤
        all_cols = self.processor.v4_essential_cols + ['BRIDGE_TIME'] + [
            'consecutive_300_count', 'consecutive_300_prob', 'long_trend',
            'mid_trend', 'acceleration', 'volatility_change', 'jump_risk', 'extreme_risk'
        ]
        available_cols = [col for col in all_cols if col in df.columns]
        
        # timestamp ì €ì¥
        timestamps = df['timestamp'].values
        
        # timestamp ì œê±°í•˜ê³  ì²˜ë¦¬
        df_process = df.drop('timestamp', axis=1)
        
        total_sequences = len(df_process) - 30 - 10
        
        for i in tqdm(range(total_sequences)):
            # 30ë¶„ ì‹œí€€ìŠ¤
            X = df_process[available_cols].iloc[i:i+30].values
            
            # 10ë¶„ í›„ ì‹¤ì œê°’
            y_true = df_process[self.processor.target_col].iloc[i+30+9]
            
            # ì‹œí€€ìŠ¤ ì •ë³´
            seq_start_time = timestamps[i]
            seq_end_time = timestamps[i+29]
            target_time = timestamps[i+30+9]
            
            # ì‹œí€€ìŠ¤ í†µê³„
            seq_values = df_process[self.processor.target_col].iloc[i:i+30].values
            seq_max = np.max(seq_values)
            seq_min = np.min(seq_values)
            seq_mean = np.mean(seq_values)
            seq_std = np.std(seq_values)
            
            # ìµœê·¼ 5ë¶„ í†µê³„
            recent_5 = seq_values[-5:]
            recent_5_max = np.max(recent_5)
            recent_5_mean = np.mean(recent_5)
            
            # 30ë¶„ êµ¬ê°„ë³„ ë¶„ì„
            first_10 = seq_values[:10]
            middle_10 = seq_values[10:20]
            last_10 = seq_values[20:30]
            
            first_10_mean = np.mean(first_10)
            middle_10_mean = np.mean(middle_10)
            last_10_mean = np.mean(last_10)
            
            # íŠ¹ì§• ì¶”ì„¸
            long_trend = last_10_mean - first_10_mean
            acceleration = (last_10_mean - middle_10_mean) - (middle_10_mean - first_10_mean)
            
            # ì í”„/ê·¹ë‹¨ê°’ íŒë‹¨
            is_jump_case = (seq_max < 280) and (y_true >= 300)
            is_extreme = y_true >= 300
            is_277_zone = 275 <= recent_5_max <= 279
            
            # ì˜ˆì¸¡ ë‚œì´ë„ ì ìˆ˜
            difficulty_score = 0
            if is_jump_case:
                difficulty_score += 50
            if is_277_zone:
                difficulty_score += 30
            if seq_std > 50:
                difficulty_score += 20
            
            # ëª¨ë¸ ì˜ˆì¸¡
            X_scaled = self.processor.scaler_X.transform(X.reshape(-1, X.shape[1]))
            X_scaled = X_scaled.reshape(1, 30, X.shape[1])
            
            # ë¬¼ë¦¬ íŠ¹ì§•
            physics = self.processor.create_physics_features(df_process, i+29)
            physics_scaled = self.processor.scaler_physics.transform(physics.reshape(1, -1))
            
            # ë¯¸ì„¸ì¡°ì • íŠ¹ì§•
            features = self.processor.create_fine_tuning_features(df_process, i+29)
            features_scaled = self.processor.scaler_features.transform(features.reshape(1, -1))
            
            # ì˜ˆì¸¡
            y_pred_scaled = self.model.predict([X_scaled, physics_scaled, features_scaled], verbose=0)
            y_pred = self.processor.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()[0]
            
            # ì˜¤ì°¨
            mae = abs(y_true - y_pred)
            
            # Base ëª¨ë¸ë³„ ì˜ˆì¸¡ (ì°¸ê³ ìš©)
            pred1_scaled = self.model.model1.predict(X_scaled, verbose=0)
            pred1 = self.processor.scaler_y.inverse_transform(pred1_scaled.reshape(-1, 1)).flatten()[0]
            
            pred2_scaled = self.model.model2.predict([X_scaled, physics_scaled], verbose=0)
            pred2 = self.processor.scaler_y.inverse_transform(pred2_scaled.reshape(-1, 1)).flatten()[0]
            
            # ì–´ëŠ ëª¨ë¸ì´ ì„ íƒë˜ì—ˆë‚˜ íŒë‹¨
            model_selected = "Model1" if abs(y_pred - pred1) < abs(y_pred - pred2) else "Model2"
            
            # ì—°ì† 300+ ì¹´ìš´íŠ¸
            consecutive_300 = sum(1 for v in seq_values if v >= 300)
            
            # ê²°ê³¼ ì €ì¥
            result = {
                'ë‚ ì§œì‹œê°„': target_time.strftime('%Y-%m-%d %H:%M'),
                'íƒ€ê²Ÿë‚ ì§œ': target_time.strftime('%Y-%m-%d'),
                'ì‹œí€€ìŠ¤ì‹œì‘ì‹œê°„': seq_start_time.strftime('%H:%M'),
                'ì‹œí€€ìŠ¤ì¢…ë£Œì‹œê°„': seq_end_time.strftime('%H:%M'),
                'JUMP_277êµ¬ê°„': is_277_zone,
                'ì‹œí€€ìŠ¤MAX': seq_max,
                'ì‹œí€€ìŠ¤MIN': seq_min,
                'ì‹œí€€ìŠ¤í‰ê· ': seq_mean,
                'ì‹œí€€ìŠ¤í‘œì¤€í¸ì°¨': seq_std,
                'ìµœê·¼5ë¶„MAX': recent_5_max,
                'ìµœê·¼5ë¶„í‰ê· ': recent_5_mean,
                'ì²«10ë¶„í‰ê· ': first_10_mean,
                'ì¤‘ê°„10ë¶„í‰ê· ': middle_10_mean,
                'ë§ˆì§€ë§‰10ë¶„í‰ê· ': last_10_mean,
                'ì¥ê¸°ì¶”ì„¸': long_trend,
                'ê°€ì†ë„': acceleration,
                'ì—°ì†300ì¹´ìš´íŠ¸': consecutive_300,
                'ì‹¤ì œê°’': y_true,
                'ì˜ˆì¸¡ê°’': y_pred,
                'Model1ì˜ˆì¸¡': pred1,
                'Model2ì˜ˆì¸¡': pred2,
                'ì„ íƒëª¨ë¸': model_selected,
                'MAE': mae,
                '300ì´ìƒì—¬ë¶€': is_extreme,
                'ì í”„ì¼€ì´ìŠ¤': is_jump_case,
                'ì˜ˆì¸¡ë‚œì´ë„': difficulty_score,
                'ì˜ˆì¸¡ì„±ê³µ': (is_extreme and y_pred >= 300) or (not is_extreme and y_pred < 300)
            }
            
            results.append(result)
        
        return pd.DataFrame(results)
    
    def analyze_results(self, df_results):
        """ê²°ê³¼ ë¶„ì„ ë° ìš”ì•½"""
        print("\nğŸ“Š í‰ê°€ ê²°ê³¼ ë¶„ì„")
        print("="*60)
        
        # ì „ì²´ ì„±ëŠ¥
        mae = df_results['MAE'].mean()
        print(f"ì „ì²´ MAE: {mae:.2f}")
        
        # ê·¹ë‹¨ê°’ ì„±ëŠ¥
        extreme_mask = df_results['300ì´ìƒì—¬ë¶€']
        if extreme_mask.sum() > 0:
            extreme_recall = (df_results[extreme_mask]['ì˜ˆì¸¡ê°’'] >= 300).sum() / extreme_mask.sum() * 100
            print(f"300+ ê°ì§€ìœ¨: {extreme_recall:.1f}%")
        
        # ì í”„ ì¼€ì´ìŠ¤ ì„±ëŠ¥
        jump_mask = df_results['ì í”„ì¼€ì´ìŠ¤']
        if jump_mask.sum() > 0:
            jump_detection = (df_results[jump_mask]['ì˜ˆì¸¡ê°’'] >= 290).sum() / jump_mask.sum() * 100
            print(f"ì í”„ ê°ì§€ìœ¨: {jump_detection:.1f}% ({jump_mask.sum()}ê°œ ì¼€ì´ìŠ¤)")
        
        # 277 êµ¬ê°„ ì„±ëŠ¥
        zone_277_mask = df_results['JUMP_277êµ¬ê°„']
        if zone_277_mask.sum() > 0:
            zone_277_mae = df_results[zone_277_mask]['MAE'].mean()
            print(f"277êµ¬ê°„ MAE: {zone_277_mae:.2f} ({zone_277_mask.sum()}ê°œ ì¼€ì´ìŠ¤)")
        
        # False Positive
        stable_mask = ~df_results['300ì´ìƒì—¬ë¶€']
        if stable_mask.sum() > 0:
            fp_rate = (df_results[stable_mask]['ì˜ˆì¸¡ê°’'] >= 300).sum() / stable_mask.sum() * 100
            print(f"False Positiveìœ¨: {fp_rate:.1f}%")
        
        # ë‚œì´ë„ë³„ ì„±ëŠ¥
        print("\në‚œì´ë„ë³„ MAE:")
        for difficulty in [0, 20, 50, 80, 100]:
            mask = df_results['ì˜ˆì¸¡ë‚œì´ë„'] >= difficulty
            if mask.sum() > 0:
                print(f"  ë‚œì´ë„ {difficulty}+: {df_results[mask]['MAE'].mean():.2f} ({mask.sum()}ê°œ)")
        
        # ëª¨ë¸ ì„ íƒ ë¶„í¬
        model_dist = df_results['ì„ íƒëª¨ë¸'].value_counts()
        print(f"\nëª¨ë¸ ì„ íƒ ë¶„í¬:")
        for model, count in model_dist.items():
            print(f"  {model}: {count} ({count/len(df_results)*100:.1f}%)")
    
    def save_evaluation(self, df_results):
        """í‰ê°€ ê²°ê³¼ ì €ì¥"""
        output_path = 'evaluation_august_2025.csv'
        df_results.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ í‰ê°€ ê²°ê³¼ ì €ì¥: {output_path}")
        print(f"   ì´ {len(df_results)}ê°œ ì‹œí€€ìŠ¤ í‰ê°€ ì™„ë£Œ")
        
        # ì¶”ê°€ ë¶„ì„ íŒŒì¼ ìƒì„±
        summary_path = 'evaluation_august_summary.txt'
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("V4 ULTIMATE ëª¨ë¸ í‰ê°€ ìš”ì•½\n")
            f.write("="*60 + "\n")
            f.write(f"í‰ê°€ ê¸°ê°„: 2025ë…„ 8ì›”\n")
            f.write(f"ì´ ì‹œí€€ìŠ¤: {len(df_results)}ê°œ\n")
            f.write(f"í‰ê·  MAE: {df_results['MAE'].mean():.2f}\n")
            f.write(f"ìµœëŒ€ ì˜¤ì°¨: {df_results['MAE'].max():.2f}\n")
            f.write(f"ìµœì†Œ ì˜¤ì°¨: {df_results['MAE'].min():.2f}\n")
            
        print(f"   ìš”ì•½ íŒŒì¼: {summary_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    evaluator = V4Evaluator()
    
    # 1. ë°ì´í„° ë¡œë“œ
    df_august = evaluator.load_august_data()
    
    # 2. ëª¨ë¸ ë¡œë“œ
    evaluator.load_trained_model()
    
    # 3. í‰ê°€ ìˆ˜í–‰
    df_results = evaluator.evaluate_sequences(df_august)
    
    # 4. ê²°ê³¼ ë¶„ì„
    evaluator.analyze_results(df_results)
    
    # 5. ê²°ê³¼ ì €ì¥
    evaluator.save_evaluation(df_results)
    
    print("\nâœ… í‰ê°€ ì™„ë£Œ!")

if __name__ == "__main__":
    main()