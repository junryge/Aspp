# -*- coding: utf-8 -*-
"""
HUBROOM ë°˜ì†¡ëŸ‰ ì˜ˆì¸¡ í‰ê°€ ì‹œìŠ¤í…œ - PatchTST ë‹¨ì¼ ëª¨ë¸
Created on Mon Sep 1 15:13:16 2025
@author: X0163954
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.layers import Dense, Dropout, LayerNormalization, MultiHeadAttention, Flatten, Embedding
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle
import os
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ===========================
# ğŸ”§ ëª¨ë¸ ì¬êµ¬ì„± (PatchTSTë§Œ)
# ===========================

class TransformerEncoderLayer(layers.Layer):
    """ì»¤ìŠ¤í…€ Transformer Encoder Layer"""
    
    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1, **kwargs):
        super(TransformerEncoderLayer, self).__init__(**kwargs)
        
        self.mha = MultiHeadAttention(
            num_heads=num_heads, 
            key_dim=d_model // num_heads,
            dropout=dropout_rate
        )
        
        self.ffn = keras.Sequential([
            Dense(dff, activation='relu'),
            Dense(d_model)
        ])
        
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        
        self.dropout1 = Dropout(dropout_rate)
        self.dropout2 = Dropout(dropout_rate)
    
    def call(self, inputs, training=False):
        attn_output = self.mha(inputs, inputs, training=training)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        out2 = self.layernorm2(out1 + ffn_output)
        
        return out2

def build_patchtst_model(seq_len=20, n_features=39, patch_len=5, d_model=128, 
                        n_heads=8, d_ff=256, n_layers=3, dropout=0.1):
    """PatchTST ëª¨ë¸ ì¬êµ¬ì„±"""
    
    inputs = Input(shape=(seq_len, n_features))
    
    # Patching
    n_patches = seq_len // patch_len
    patches = tf.reshape(inputs, (-1, n_patches, patch_len * n_features))
    
    # Linear projection (dense)
    x = Dense(d_model, name='dense')(patches)
    
    # Positional encoding
    positions = tf.range(start=0, limit=n_patches, delta=1)
    pos_embedding = Embedding(input_dim=n_patches, output_dim=d_model, name='pos_embedding')(positions)
    x = x + pos_embedding
    
    # Transformer layers (3ê°œ)
    x = TransformerEncoderLayer(d_model, n_heads, d_ff, dropout, name='transformer_encoder_layer')(x)
    x = TransformerEncoderLayer(d_model, n_heads, d_ff, dropout, name='transformer_encoder_layer_1')(x)
    x = TransformerEncoderLayer(d_model, n_heads, d_ff, dropout, name='transformer_encoder_layer_2')(x)
    
    # Flatten
    x = Flatten(name='flatten')(x)
    
    # Dense layers
    x = Dense(128, activation='relu', name='dense_7')(x)
    x = Dropout(dropout, name='dropout_6')(x)
    x = Dense(64, activation='relu', name='dense_8')(x)
    outputs = Dense(1, name='dense_9')(x)
    
    model = Model(inputs=inputs, outputs=outputs, name='patch_tst')
    return model

# ===========================
# ğŸ“Š í‰ê°€ í´ë˜ìŠ¤
# ===========================

class HUBROOMEvaluator:
    """HUBROOM ì˜ˆì¸¡ ëª¨ë¸ í‰ê°€ í´ë˜ìŠ¤ - PatchTST ì „ìš©"""
    
    def __init__(self, data_path='20250801_to_20250831.csv'):
        self.data_path = data_path
        self.seq_len = 20
        self.pred_len = 10
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        self.critical_threshold = 300
        
        # ëª¨ë¸ ê²½ë¡œ (PatchTSTë§Œ)
        self.patchtst_weights = './checkpoints/PatchTST_best.h5'
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self.scaler_X = self.load_scaler('scaler_X.pkl')
        self.scaler_y = self.load_scaler('scaler_y.pkl')
        
        self.n_features = None  # ë°ì´í„° ë¡œë“œ í›„ ì„¤ì •
    
    def load_scaler(self, filename):
        """ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ"""
        filepath = f'./checkpoints/{filename}'
        if os.path.exists(filepath):
            with open(filepath, 'rb') as f:
                print(f"âœ… {filename} ë¡œë“œ ì™„ë£Œ")
                return pickle.load(f)
        else:
            print(f"âš ï¸ {filename}ì´ ì—†ìŠµë‹ˆë‹¤. save_scalers.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!")
            return None
    
    def prepare_data(self):
        """2025ë…„ 9ì›” ë°ì´í„° ì¤€ë¹„"""
        print("\nğŸ“‚ 2025ë…„ 9ì›” ë°ì´í„° ë¡œë“œ ì¤‘...")
        df = pd.read_csv(self.data_path)
        
        # ì‹œê°„ ì»¬ëŸ¼ ì²˜ë¦¬
        time_col = df.columns[0]
        df['timestamp'] = pd.to_datetime(df[time_col], format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('timestamp').reset_index(drop=True)
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = df.fillna(method='ffill').fillna(0)
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        self.n_features = len(numeric_cols)
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰")
        print(f"ğŸ“… ê¸°ê°„: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        print(f"ğŸ“Š íŠ¹ì„± ìˆ˜: {self.n_features}ê°œ")
        
        return df, numeric_cols
    
    def create_evaluation_sequences(self, df, numeric_cols):
        """í‰ê°€ìš© ì‹œí€€ìŠ¤ ìƒì„±"""
        X_list = []
        y_actual_list = []
        
        # ì‹œê°„ ê´€ë ¨ ì •ë³´ ì €ì¥
        input_start_times = []
        input_end_times = []
        predicted_target_times = []
        
        # ì…ë ¥ ë°ì´í„° í†µê³„ ì •ë³´
        input_max_values = []
        input_min_values = []
        
        data = df[numeric_cols].values
        target_idx = numeric_cols.index(self.target_col)
        
        print(f"\nğŸ“Š ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        total_sequences = len(data) - self.seq_len - self.pred_len + 1
        
        # ì‹œí€€ìŠ¤ ìƒì„±
        for i in range(total_sequences):
            # ì…ë ¥ ì‹œí€€ìŠ¤ (ê³¼ê±° 20ë¶„)
            X_seq = data[i:i+self.seq_len]
            
            # ì‹¤ì œ ê°’ (ë¯¸ë˜ 10ë¶„)
            y_actual = data[i+self.seq_len:i+self.seq_len+self.pred_len, target_idx]
            
            # ì‹œê°„ ì •ë³´
            input_start = df['timestamp'].iloc[i]
            input_end = df['timestamp'].iloc[i+self.seq_len-1]
            target_time = df['timestamp'].iloc[i+self.seq_len+self.pred_len-1]  # 10ë¶„ í›„ ì‹œì 
            
            # ì…ë ¥ ì‹œí€€ìŠ¤ì˜ íƒ€ê²Ÿ ì»¬ëŸ¼ ìµœëŒ€/ìµœì†Œê°’
            input_target_values = X_seq[:, target_idx]
            input_max = np.max(input_target_values)
            input_min = np.min(input_target_values)
            
            # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            X_list.append(X_seq)
            y_actual_list.append(y_actual)
            
            input_start_times.append(input_start)
            input_end_times.append(input_end)
            predicted_target_times.append(target_time)
            input_max_values.append(input_max)
            input_min_values.append(input_min)
        
        print(f"âœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ: {len(X_list)}ê°œ")
        
        # ì‹œê°„ ì •ë³´ì™€ í†µê³„ ì •ë³´ë„ í•¨ê»˜ ë°˜í™˜
        time_info = {
            'input_start': input_start_times,
            'input_end': input_end_times,
            'predicted_target_time': predicted_target_times,
            'input_max': input_max_values,
            'input_min': input_min_values
        }
        
        return np.array(X_list), np.array(y_actual_list), time_info
    
    def load_model(self):
        """PatchTST ëª¨ë¸ ì¬êµ¬ì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ"""
        print("\nğŸ¤– PatchTST ëª¨ë¸ ì¬êµ¬ì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘...")
        
        if not os.path.exists(self.patchtst_weights):
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.patchtst_weights}")
            return None
        
        try:
            model = build_patchtst_model(
                seq_len=self.seq_len,
                n_features=self.n_features,
                patch_len=5,
                d_model=128,
                n_heads=8,
                d_ff=256,
                n_layers=3,
                dropout=0.1
            )
            
            # ë”ë¯¸ ë°ì´í„°ë¡œ ëª¨ë¸ ë¹Œë“œ
            dummy_input = np.zeros((1, self.seq_len, self.n_features))
            _ = model(dummy_input)
            
            # ê°€ì¤‘ì¹˜ ë¡œë“œ
            model.load_weights(self.patchtst_weights, by_name=True, skip_mismatch=True)
            print("âœ… PatchTST ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            return model
            
        except Exception as e:
            print(f"âŒ PatchTST ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def predict_and_evaluate(self, model, X, y_actual, time_info):
        """PatchTST ì˜ˆì¸¡ ë° í‰ê°€"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š PatchTST ëª¨ë¸ í‰ê°€")
        print(f"{'='*60}")
        
        # ë°ì´í„° ì •ê·œí™”
        n_samples, seq_len, n_features = X.shape
        
        # ìŠ¤ì¼€ì¼ëŸ¬ í™•ì¸
        if self.scaler_X is None or self.scaler_y is None:
            print("âŒ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return None
        
        X_scaled = self.scaler_X.transform(X.reshape(-1, n_features)).reshape(n_samples, seq_len, n_features)
        
        try:
            # ì˜ˆì¸¡
            print("ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
            y_pred_scaled = model.predict(X_scaled, verbose=1, batch_size=32)
            
            # ëª¨ë¸ ì¶œë ¥ í˜•íƒœ í™•ì¸
            print(f"ì˜ˆì¸¡ ì¶œë ¥ í˜•íƒœ: {y_pred_scaled.shape}")
            
            # ì—­ì •ê·œí™” (10ë¶„ í›„ ì˜ˆì¸¡ê°’)
            y_pred_10min = self.scaler_y.inverse_transform(
                y_pred_scaled.reshape(-1, 1)
            ).flatten()
            
            # ì‹¤ì œê°’ì€ 10ë¶„ í›„ ê°’ë§Œ ì¶”ì¶œ
            y_true_10min = y_actual[:, -1]  # ë§ˆì§€ë§‰ ì‹œì  (10ë¶„ í›„)
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            mae = mean_absolute_error(y_true_10min, y_pred_10min)
            mse = mean_squared_error(y_true_10min, y_pred_10min)
            rmse = np.sqrt(mse)
            r2 = r2_score(y_true_10min, y_pred_10min)
            
            # 300 ì´ìƒ ì˜ˆì¸¡ ë¶„ì„
            over_300_pred = np.sum(y_pred_10min >= 300)
            over_300_true = np.sum(y_true_10min >= 300)
            
            # 300 ì´ìƒì¼ ë•Œì˜ ì •í™•ë„
            mask_300 = y_true_10min >= 300
            if np.sum(mask_300) > 0:
                mae_300 = mean_absolute_error(y_true_10min[mask_300], y_pred_10min[mask_300])
                acc_300 = np.sum((y_pred_10min >= 300) & (y_true_10min >= 300)) / np.sum(mask_300)
            else:
                mae_300 = 0
                acc_300 = 0
            
            # ê²°ê³¼ ì €ì¥
            result = {
                'y_true': y_true_10min,
                'y_pred': y_pred_10min,
                'time_info': time_info,
                'mae': mae,
                'mse': mse,
                'rmse': rmse,
                'r2': r2,
                'over_300_pred': over_300_pred,
                'over_300_true': over_300_true,
                'mae_300': mae_300,
                'acc_300': acc_300
            }
            
            # ì„±ëŠ¥ ì¶œë ¥
            print(f"\nğŸ“ˆ ì „ì²´ ì„±ëŠ¥:")
            print(f"  - MAE: {mae:.4f}")
            print(f"  - RMSE: {rmse:.4f}")
            print(f"  - RÂ²: {r2:.4f}")
            
            print(f"\nğŸš¨ 300 ì´ìƒ ì˜ˆì¸¡ ë¶„ì„:")
            print(f"  - ì‹¤ì œ 300 ì´ìƒ: {over_300_true}ê°œ")
            print(f"  - ì˜ˆì¸¡ 300 ì´ìƒ: {over_300_pred}ê°œ")
            print(f"  - 300 ì´ìƒì¼ ë•Œ MAE: {mae_300:.4f}")
            print(f"  - 300 ê°ì§€ ì •í™•ë„: {acc_300:.2%}")
            
            # ìƒ˜í”Œ ì¶œë ¥
            print(f"\nğŸ“ ì˜ˆì¸¡ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):")
            for i in range(min(10, len(y_pred_10min))):
                status = "âš ï¸ ê²½ê³ " if y_pred_10min[i] >= 300 else "âœ… ì •ìƒ"
                print(f"  [{i+1}] ì‹œê°„: {time_info['predicted_target_time'][i]}, "
                      f"ì‹¤ì œ: {y_true_10min[i]:.1f}, ì˜ˆì¸¡: {y_pred_10min[i]:.1f} {status}")
            
            return result
            
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def visualize_results(self, result):
        """PatchTST ê²°ê³¼ ì‹œê°í™”"""
        if result is None:
            print("ì‹œê°í™”í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 4ê°œ ê·¸ë˜í”„ ìƒì„±
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('PatchTST HUBROOM ë°˜ì†¡ëŸ‰ ì˜ˆì¸¡ í‰ê°€ (2025ë…„ 9ì›”)', fontsize=16)
        
        # 1. ì‹œê³„ì—´ ì˜ˆì¸¡ ë¹„êµ (ì²˜ìŒ 200ê°œ)
        ax1 = axes[0, 0]
        ax1.plot(result['y_true'][:200], label='ì‹¤ì œê°’', alpha=0.7, linewidth=2, color='blue')
        ax1.plot(result['y_pred'][:200], label='PatchTST ì˜ˆì¸¡', alpha=0.7, linestyle='--', color='orange')
        ax1.axhline(y=300, color='red', linestyle=':', label='ìœ„í—˜ ì„ê³„ê°’ (300)')
        ax1.set_title('ì‹œê³„ì—´ ì˜ˆì¸¡ ë¹„êµ (ì²˜ìŒ 200ê°œ)')
        ax1.set_xlabel('ì‹œê°„ ì¸ë±ìŠ¤')
        ax1.set_ylabel('HUBROOM ë°˜ì†¡ëŸ‰')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ì‚°ì ë„
        ax2 = axes[0, 1]
        ax2.scatter(result['y_true'], result['y_pred'], alpha=0.5, color='blue', s=10)
        ax2.plot([0, 600], [0, 600], 'r--', alpha=0.5, label='Perfect Prediction')
        ax2.axvline(x=300, color='red', linestyle=':', alpha=0.5)
        ax2.axhline(y=300, color='red', linestyle=':', alpha=0.5)
        ax2.set_title(f'ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’ (RÂ²={result["r2"]:.3f})')
        ax2.set_xlabel('ì‹¤ì œê°’')
        ax2.set_ylabel('ì˜ˆì¸¡ê°’')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. ì˜¤ì°¨ ë¶„í¬
        ax3 = axes[1, 0]
        errors = result['y_pred'] - result['y_true']
        ax3.hist(errors, bins=50, alpha=0.7, color='green', edgecolor='black')
        ax3.axvline(x=0, color='red', linestyle='--', alpha=0.5)
        ax3.set_title(f'ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬ (MAE={result["mae"]:.2f})')
        ax3.set_xlabel('ì˜ˆì¸¡ ì˜¤ì°¨')
        ax3.set_ylabel('ë¹ˆë„')
        ax3.grid(True, alpha=0.3)
        
        # ì˜¤ì°¨ í†µê³„ í…ìŠ¤íŠ¸ ì¶”ê°€
        ax3.text(0.02, 0.95, f'í‰ê· : {np.mean(errors):.2f}\ní‘œì¤€í¸ì°¨: {np.std(errors):.2f}',
                transform=ax3.transAxes, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        # 4. ì„±ëŠ¥ ë©”íŠ¸ë¦­
        ax4 = axes[1, 1]
        metrics = ['MAE', 'RMSE', 'RÂ²Ã—100', 'MAE@300+']
        values = [
            result['mae'],
            result['rmse'],
            result['r2'] * 100,
            result['mae_300']
        ]
        
        bars = ax4.bar(metrics, values, color=['blue', 'green', 'orange', 'red'], alpha=0.7)
        ax4.set_title('ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­')
        ax4.set_ylabel('ê°’')
        ax4.grid(True, alpha=0.3, axis='y')
        
        # ê°’ í‘œì‹œ
        for bar, value in zip(bars, values):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{value:.2f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig('patchtst_evaluation_202509.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("\nâœ… ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: patchtst_evaluation_202509.png")
    
    def analyze_critical_predictions(self, result):
        """300 ì´ìƒ ì˜ˆì¸¡ ìƒì„¸ ë¶„ì„"""
        print("\n" + "="*60)
        print("ğŸš¨ 300 ì´ìƒ ì˜ˆì¸¡ ìƒì„¸ ë¶„ì„")
        print("="*60)
        
        y_true = result['y_true']
        y_pred = result['y_pred']
        
        # 300 ì´ìƒ ì¼€ì´ìŠ¤ ë¶„ì„
        true_over_300 = y_true >= 300
        pred_over_300 = y_pred >= 300
        
        # í˜¼ë™ í–‰ë ¬
        tp = np.sum(true_over_300 & pred_over_300)  # True Positive
        fp = np.sum(~true_over_300 & pred_over_300)  # False Positive
        tn = np.sum(~true_over_300 & ~pred_over_300)  # True Negative
        fn = np.sum(true_over_300 & ~pred_over_300)  # False Negative
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        if tp + fp > 0:
            precision = tp / (tp + fp)
        else:
            precision = 0
            
        if tp + fn > 0:
            recall = tp / (tp + fn)
        else:
            recall = 0
            
        if precision + recall > 0:
            f1 = 2 * (precision * recall) / (precision + recall)
        else:
            f1 = 0
        
        print(f"  - True Positive (ì •í™•íˆ ì˜ˆì¸¡í•œ ìœ„í—˜): {tp}ê°œ")
        print(f"  - False Positive (ì˜ëª»ëœ ê²½ë³´): {fp}ê°œ")
        print(f"  - True Negative (ì •í™•íˆ ì˜ˆì¸¡í•œ ì •ìƒ): {tn}ê°œ")
        print(f"  - False Negative (ë†“ì¹œ ìœ„í—˜): {fn}ê°œ")
        print(f"  - Precision (ì •ë°€ë„): {precision:.2%}")
        print(f"  - Recall (ì¬í˜„ìœ¨): {recall:.2%}")
        print(f"  - F1-Score: {f1:.2%}")
        
        # ê·¹ë‹¨ê°’ ë¶„ì„
        extreme_cases = y_true > 400
        if np.sum(extreme_cases) > 0:
            extreme_mae = mean_absolute_error(y_true[extreme_cases], y_pred[extreme_cases])
            print(f"  - 400 ì´ˆê³¼ ê·¹ë‹¨ê°’ MAE: {extreme_mae:.2f}")
            print(f"  - 400 ì´ˆê³¼ ì¼€ì´ìŠ¤ ìˆ˜: {np.sum(extreme_cases)}ê°œ")
    
    def save_predictions(self, result, output_path='predictions_202509.csv'):
        """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìš”ì²­ëœ í˜•ì‹ì˜ CSVë¡œ ì €ì¥"""
        print(f"\nğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        if result is None:
            print("âŒ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        time_info = result['time_info']
        
        # ìš”ì²­ëœ ì»¬ëŸ¼ í˜•ì‹ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df_results = pd.DataFrame({
            'timestamp': time_info['input_end'],  # í˜„ì¬ ì‹œê°„ (ì…ë ¥ ì¢…ë£Œ ì‹œê°„)
            'actual': result['y_true'],  # ì‹¤ì œ ê´€ì¸¡ê°’
            'predicted': result['y_pred'],  # PatchTST ì˜ˆì¸¡ê°’
            'predicted_Target_time': time_info['predicted_target_time'],  # ì˜ˆì¸¡ íƒ€ì¼“ ì‹œê°„ (10ë¶„ í›„)
            'input_start': time_info['input_start'],  # ì…ë ¥ ì‹œì‘ ì‹œê°„
            'input_end': time_info['input_end'],  # ì…ë ¥ ì¢…ë£Œ ì‹œê°„
            'input_max': time_info['input_max'],  # ì…ë ¥ ì‹œí€€ìŠ¤ ìµœëŒ€ê°’
            'input_min': time_info['input_min'],  # ì…ë ¥ ì‹œí€€ìŠ¤ ìµœì†Œê°’
            'error': result['y_true'] - result['y_pred'],  # actual - predicted
            'Patchtst_predicted_TIME': time_info['predicted_target_time']  # PatchTST ì˜ˆì¸¡ ì‹œê°„
        })
        
        # CSV ì €ì¥
        df_results.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        
        # ìš”ì•½ í†µê³„
        print(f"\nğŸ“Š ì €ì¥ëœ ë°ì´í„° ìš”ì•½:")
        print(f"  - ì „ì²´ ì˜ˆì¸¡ ìˆ˜: {len(df_results)}ê°œ")
        print(f"  - 300 ì´ìƒ ì‹¤ì œê°’: {(df_results['actual'] >= 300).sum()}ê°œ")
        print(f"  - 300 ì´ìƒ ì˜ˆì¸¡ê°’: {(df_results['predicted'] >= 300).sum()}ê°œ")
        print(f"  - í‰ê·  ì˜¤ì°¨: {df_results['error'].mean():.2f}")
        print(f"  - ì˜¤ì°¨ í‘œì¤€í¸ì°¨: {df_results['error'].std():.2f}")
        print(f"  - ê¸°ê°„: {df_results['timestamp'].min()} ~ {df_results['timestamp'].max()}")
        
        # ì²˜ìŒ 5ê°œ í–‰ ì¶œë ¥
        print(f"\nğŸ“‹ ì €ì¥ëœ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):")
        print(df_results.head())

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*80)
    print("ğŸ­ HUBROOM ë°˜ì†¡ëŸ‰ ì˜ˆì¸¡ í‰ê°€ ì‹œìŠ¤í…œ - PatchTST")
    print("ğŸ“… ëŒ€ìƒ: 2025ë…„ 9ì›” ë°ì´í„°")
    print("="*80)
    
    # TensorFlow ë¡œê·¸ ë ˆë²¨ ì¡°ì •
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    
    # í‰ê°€ê¸° ìƒì„±
    evaluator = HUBROOMEvaluator()
    
    # ìŠ¤ì¼€ì¼ëŸ¬ í™•ì¸
    if evaluator.scaler_X is None:
        print("\nâŒ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ìŠµë‹ˆë‹¤. save_scalers.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!")
        return
    
    try:
        # 1. ë°ì´í„° ì¤€ë¹„
        df, numeric_cols = evaluator.prepare_data()
        
        # 2. ì‹œí€€ìŠ¤ ìƒì„±
        X, y_actual, time_info = evaluator.create_evaluation_sequences(df, numeric_cols)
        
        # 3. ëª¨ë¸ ë¡œë“œ
        model = evaluator.load_model()
        
        if model is None:
            print("\nâŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨!")
            print("ğŸ’¡ í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì´ ./checkpoints/PatchTST_best.h5 ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
            return
        
        # 4. ì˜ˆì¸¡ ë° í‰ê°€
        result = evaluator.predict_and_evaluate(model, X, y_actual, time_info)
        
        if result is None:
            print("\nâŒ ì˜ˆì¸¡ ì‹¤íŒ¨!")
            return
        
        # 5. ê²°ê³¼ ì‹œê°í™”
        evaluator.visualize_results(result)
        
        # 6. 300 ì´ìƒ ìƒì„¸ ë¶„ì„
        evaluator.analyze_critical_predictions(result)
        
        # 7. ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
        evaluator.save_predictions(result)
        
        # 8. ìµœì¢… ìš”ì•½
        print("\n" + "="*80)
        print("ğŸ“Š PatchTST ëª¨ë¸ ìµœì¢… í‰ê°€ ìš”ì•½")
        print("="*80)
        
        print(f"\nì „ì²´ ì„±ëŠ¥:")
        print(f"  - MAE: {result['mae']:.2f}")
        print(f"  - RMSE: {result['rmse']:.2f}")
        print(f"  - RÂ²: {result['r2']:.4f}")
        print(f"  - 300+ ê°ì§€ ì •í™•ë„: {result['acc_300']:.2%}")
        
        print("\nâœ… í‰ê°€ ì™„ë£Œ!")
        print("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
        print("  - predictions_202509.csv (ì˜ˆì¸¡ ê²°ê³¼)")
        print("  - patchtst_evaluation_202509.png (ì‹œê°í™”)")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()