#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
HUBROOM 300 ì„ê³„ê°’ Sensing ë¶„ë¥˜ ì‹œìŠ¤í…œ
ê³¼ê±° 20ë¶„ ë°ì´í„°ì˜ 300 ì„ê³„ê°’ ìƒíƒœì™€ ì˜ˆì¸¡/ì‹¤ì œê°’ ë¹„êµë¥¼ í†µí•œ ê°ì§€ ì„±ëŠ¥ ë¶„ë¥˜
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta

def classify_sensing_performance(csv_file_path, output_file_path=None):
    """
    CSV íŒŒì¼ì„ ì½ì–´ Sensing ì„±ëŠ¥ì„ ë¶„ë¥˜í•˜ê³  ìƒˆ ì»¬ëŸ¼ ì¶”ê°€
    
    Parameters:
    -----------
    csv_file_path : str
        ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
    output_file_path : str, optional
        ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ '_sensing_analyzed.csv' ì¶”ê°€)
    
    Returns:
    --------
    pd.DataFrame : Sensing ì»¬ëŸ¼ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    
    print("="*80)
    print("ğŸ­ HUBROOM 300 ì„ê³„ê°’ Sensing ë¶„ë¥˜ ì‹œìŠ¤í…œ")
    print("="*80)
    
    # 1. CSV íŒŒì¼ ì½ê¸°
    print("\nğŸ“‚ CSV íŒŒì¼ ë¡œë“œ ì¤‘...")
    df = pd.read_csv(csv_file_path)
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,} í–‰")
    
    # 2. timestamp ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
    print("\nâ° ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.sort_values('timestamp').reset_index(drop=True)
    
    # 3. Sensing ì»¬ëŸ¼ ì´ˆê¸°í™”
    df['Sensing'] = ''
    
    # 4. ê° í–‰ì— ëŒ€í•´ ë¶„ë¥˜ ìˆ˜í–‰
    print("\nğŸ” Sensing ë¶„ë¥˜ ì‹œì‘...")
    threshold = 300
    lookback_minutes = 20
    
    total_rows = len(df)
    classified_count = 0
    
    # ë¶„ë¥˜ ì¹´ìš´í„°
    sensing_counts = {
        '300_Sensing_OK': 0,
        '300_Sensing_NG': 0,
        '200_Sensing_OK': 0,
        '200_Sensing_NG': 0,
        'No_Classification': 0
    }
    
    for idx in range(len(df)):
        if idx % 100 == 0:
            print(f"  ì§„í–‰: {idx}/{total_rows} ({idx/total_rows*100:.1f}%)", end='\r')
        
        current_time = df.loc[idx, 'timestamp']
        current_actual = df.loc[idx, 'actual']
        current_predicted = df.loc[idx, 'predicted']
        
        # ê³¼ê±° 20ë¶„ ë°ì´í„° ì°¾ê¸°
        past_time = current_time - timedelta(minutes=lookback_minutes)
        past_data = df[(df['timestamp'] > past_time) & (df['timestamp'] < current_time)]
        
        if len(past_data) == 0:
            df.loc[idx, 'Sensing'] = 'No_Past_Data'
            sensing_counts['No_Classification'] += 1
            continue
        
        # ê³¼ê±° 20ë¶„ ë°ì´í„°ì˜ ìµœëŒ€ê°’ í™•ì¸
        past_max = past_data['actual'].max()
        
        # ë¶„ë¥˜ ë¡œì§
        if past_max <= threshold:  # ê³¼ê±° 20ë¶„ì´ 300 ì´í•˜
            if current_predicted >= threshold:  # ì˜ˆì¸¡ì´ 300 ì´ìƒ
                if current_actual >= threshold:  # ì‹¤ì œë„ 300 ì´ìƒ
                    df.loc[idx, 'Sensing'] = '300_Sensing_OK'
                    sensing_counts['300_Sensing_OK'] += 1
                else:  # ì‹¤ì œëŠ” 300 ë¯¸ë§Œ
                    df.loc[idx, 'Sensing'] = '300_Sensing_NG'
                    sensing_counts['300_Sensing_NG'] += 1
            else:
                df.loc[idx, 'Sensing'] = 'No_Alert_Needed'
                sensing_counts['No_Classification'] += 1
                
        else:  # ê³¼ê±° 20ë¶„ì— 300 ì´ìƒ ì¡´ì¬
            if current_predicted < threshold:  # ì˜ˆì¸¡ì´ 300 ë¯¸ë§Œ
                if current_actual < threshold:  # ì‹¤ì œë„ 300 ë¯¸ë§Œ
                    df.loc[idx, 'Sensing'] = '200_Sensing_OK'
                    sensing_counts['200_Sensing_OK'] += 1
                else:  # ì‹¤ì œëŠ” 300 ì´ìƒ
                    df.loc[idx, 'Sensing'] = '200_Sensing_NG'
                    sensing_counts['200_Sensing_NG'] += 1
            else:
                df.loc[idx, 'Sensing'] = 'Maintaining_High'
                sensing_counts['No_Classification'] += 1
    
    print(f"\nâœ… Sensing ë¶„ë¥˜ ì™„ë£Œ!")
    
    # 5. ë¶„ë¥˜ ê²°ê³¼ í†µê³„ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š ë¶„ë¥˜ ê²°ê³¼ í†µê³„")
    print("="*60)
    
    for category, count in sensing_counts.items():
        if count > 0:
            percentage = (count / total_rows) * 100
            print(f"  {category:20}: {count:6,} ê±´ ({percentage:5.2f}%)")
    
    # ì£¼ìš” 4ê°€ì§€ ì¹´í…Œê³ ë¦¬ì˜ í•©ê³„
    main_categories = ['300_Sensing_OK', '300_Sensing_NG', '200_Sensing_OK', '200_Sensing_NG']
    main_total = sum(sensing_counts[cat] for cat in main_categories)
    print(f"\n  {'ì£¼ìš” ë¶„ë¥˜ í•©ê³„':20}: {main_total:6,} ê±´ ({main_total/total_rows*100:5.2f}%)")
    
    # 6. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    print("\n" + "="*60)
    print("ğŸ¯ ê°ì§€ ì„±ëŠ¥ ë¶„ì„")
    print("="*60)
    
    # 300 ìƒìŠ¹ ê°ì§€ ì„±ëŠ¥
    up_total = sensing_counts['300_Sensing_OK'] + sensing_counts['300_Sensing_NG']
    if up_total > 0:
        up_accuracy = (sensing_counts['300_Sensing_OK'] / up_total) * 100
        print(f"\nğŸ“ˆ 300 ìƒìŠ¹ ê°ì§€:")
        print(f"  - ì „ì²´ ê°ì§€ ì‹œë„: {up_total:,} ê±´")
        print(f"  - ì •í™• ê°ì§€ (OK): {sensing_counts['300_Sensing_OK']:,} ê±´")
        print(f"  - ì˜¤ê°ì§€ (NG): {sensing_counts['300_Sensing_NG']:,} ê±´")
        print(f"  - ì •í™•ë„: {up_accuracy:.2f}%")
    
    # 300 í•˜ë½ ê°ì§€ ì„±ëŠ¥
    down_total = sensing_counts['200_Sensing_OK'] + sensing_counts['200_Sensing_NG']
    if down_total > 0:
        down_accuracy = (sensing_counts['200_Sensing_OK'] / down_total) * 100
        print(f"\nğŸ“‰ 300 í•˜ë½ ê°ì§€:")
        print(f"  - ì „ì²´ ê°ì§€ ì‹œë„: {down_total:,} ê±´")
        print(f"  - ì •í™• ê°ì§€ (OK): {sensing_counts['200_Sensing_OK']:,} ê±´")
        print(f"  - ì˜¤ê°ì§€ (NG): {sensing_counts['200_Sensing_NG']:,} ê±´")
        print(f"  - ì •í™•ë„: {down_accuracy:.2f}%")
    
    # 7. ê²°ê³¼ ì €ì¥
    if output_file_path is None:
        output_file_path = csv_file_path.replace('.csv', '_sensing_analyzed.csv')
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    df.to_csv(output_file_path, index=False)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_file_path}")
    
    # 8. ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“ ë¶„ë¥˜ ê²°ê³¼ ìƒ˜í”Œ (ì£¼ìš” ì¹´í…Œê³ ë¦¬ë§Œ)")
    print("="*60)
    
    for category in main_categories:
        sample = df[df['Sensing'] == category].head(2)
        if len(sample) > 0:
            print(f"\nğŸ”¹ {category}:")
            for _, row in sample.iterrows():
                print(f"  ì‹œê°„: {row['timestamp']}")
                print(f"  ì‹¤ì œê°’: {row['actual']:.1f}, ì˜ˆì¸¡ê°’: {row['predicted']:.1f}")
                print()
    
    return df

# ì‹¤í–‰ í•¨ìˆ˜
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    input_file = 'your_data.csv'  # ì—¬ê¸°ì— ì‹¤ì œ CSV íŒŒì¼ ê²½ë¡œ ì…ë ¥
    output_file = 'your_data_sensing_analyzed.csv'  # ì¶œë ¥ íŒŒì¼ëª… (ì˜µì…˜)
    
    try:
        # ë¶„ì„ ì‹¤í–‰
        result_df = classify_sensing_performance(input_file, output_file)
        
        print("\n" + "="*80)
        print("âœ¨ ë¶„ì„ ì™„ë£Œ!")
        print("="*80)
        print(f"ğŸ“Š ì´ {len(result_df):,} í–‰ ì²˜ë¦¬ ì™„ë£Œ")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_file}")
        
        # ì¶”ê°€ ë¶„ì„ (ì˜µì…˜)
        print("\nğŸ’¡ ì¶”ê°€ ë¶„ì„ íŒ:")
        print("  - Sensing ì»¬ëŸ¼ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ìƒì„¸ ë¶„ì„ ê°€ëŠ¥")
        print("  - ì‹œê°„ëŒ€ë³„ ì„±ëŠ¥ ë³€í™” ì¶”ì  ê°€ëŠ¥")
        print("  - íŠ¹ì • êµ¬ê°„ì˜ ê°ì§€ ì„±ëŠ¥ ì§‘ì¤‘ ë¶„ì„ ê°€ëŠ¥")
        
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
        print("íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    print("ğŸ“Œ ì‚¬ìš©ë²•:")
    print("  1. input_file ë³€ìˆ˜ì— CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •")
    print("  2. main() í•¨ìˆ˜ ì‹¤í–‰")
    print("\në˜ëŠ” ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ:")
    print('  df = classify_sensing_performance("your_file.csv")')
    
    # ì‹¤ì œ ì‹¤í–‰í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
    # main()
    
    # ë˜ëŠ” ì§ì ‘ ì‹¤í–‰
    # df = classify_sensing_performance("your_data.csv", "output_sensing.csv")