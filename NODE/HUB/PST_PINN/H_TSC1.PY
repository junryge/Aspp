import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import pickle
import os

class ScalerSaver:
    """í•™ìŠµì— ì‚¬ìš©ëœ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.file_path = 'data/HUB_0509_TO_0730_DATA.CSV'
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        self.seq_len = 20
        self.pred_len = 10
        
        # ë¬¼ë¦¬ì  ê³„ì‚°ì„ ìœ„í•œ ì»¬ëŸ¼ ê·¸ë£¹
        self.inflow_cols = [
            'M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2',
            'M14A_3F_TO_HUB_JOB2', 'M14B_7F_TO_HUB_JOB2'
        ]
        
        self.outflow_cols = [
            'M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB',
            'M16A_3F_TO_M14A_3F_JOB', 'M16A_3F_TO_M14B_7F_JOB'
        ]
        
        # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('./checkpoints', exist_ok=True)
    
    def create_sequences(self, df, numeric_cols, seq_len=20, pred_len=10):
        """ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±"""
        X_list = []
        y_list = []
        physics_list = []
        
        data = df[numeric_cols].values
        target_idx = numeric_cols.index(self.target_col)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸
        available_inflow = [col for col in self.inflow_cols if col in numeric_cols]
        available_outflow = [col for col in self.outflow_cols if col in numeric_cols]
        
        print(f"ğŸ“Š ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        print(f"  - ìœ ì… ì»¬ëŸ¼: {len(available_inflow)}ê°œ")
        print(f"  - ìœ ì¶œ ì»¬ëŸ¼: {len(available_outflow)}ê°œ")
        
        for i in range(len(data) - seq_len - pred_len + 1):
            # ì…ë ¥ ì‹œí€€ìŠ¤
            X_seq = data[i:i+seq_len]
            
            # íƒ€ê²Ÿ (10ë¶„ í›„)
            y_val = data[i+seq_len+pred_len-1, target_idx]
            
            # ë¬¼ë¦¬ ë°ì´í„° (í˜„ì¬ ìƒíƒœ)
            current_state = data[i+seq_len-1]
            current_hubroom = current_state[target_idx]
            
            # ìœ ì…/ìœ ì¶œ í•©ê³„
            inflow_sum = sum([current_state[numeric_cols.index(col)] 
                            for col in available_inflow])
            outflow_sum = sum([current_state[numeric_cols.index(col)] 
                             for col in available_outflow])
            
            physics = [current_hubroom, inflow_sum, outflow_sum]
            
            X_list.append(X_seq)
            y_list.append(y_val)
            physics_list.append(physics)
        
        return np.array(X_list), np.array(y_list), np.array(physics_list)
    
    def save_scalers(self):
        """ìŠ¤ì¼€ì¼ëŸ¬ ìƒì„± ë° ì €ì¥"""
        print("="*60)
        print("ğŸ’¾ HUBROOM ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ í”„ë¡œê·¸ë¨")
        print("="*60)
        
        # 1. ë°ì´í„° ë¡œë“œ
        print("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
        df = pd.read_csv(self.file_path)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape[0]:,} í–‰ Ã— {df.shape[1]} ì»¬ëŸ¼")
        
        # 2. ì „ì²˜ë¦¬
        print("\nğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        time_col = df.columns[0]
        df['timestamp'] = pd.to_datetime(df[time_col], format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('timestamp').reset_index(drop=True)
        df = df.fillna(method='ffill').fillna(0)
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(numeric_cols)}ê°œ ìˆ«ìí˜• ì»¬ëŸ¼")
        
        # 3. ì‹œí€€ìŠ¤ ìƒì„±
        print("\nğŸ“Š ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        X, y, physics_data = self.create_sequences(df, numeric_cols, self.seq_len, self.pred_len)
        
        print(f"âœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ:")
        print(f"  - X shape: {X.shape}")
        print(f"  - y shape: {y.shape}")
        print(f"  - physics shape: {physics_data.shape}")
        
        # 4. ë°ì´í„° ë¶„í•  (í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ë°©ì‹)
        print("\nğŸ”€ ë°ì´í„° ë¶„í•  ì¤‘...")
        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
        physics_train = physics_data[:len(X_train)]
        
        print(f"  - Train ë°ì´í„°: {len(X_train):,} samples")
        
        # 5. ìŠ¤ì¼€ì¼ëŸ¬ ìƒì„± ë° fitting
        print("\nğŸ“ ìŠ¤ì¼€ì¼ëŸ¬ ìƒì„± ë° fitting...")
        
        # X ìŠ¤ì¼€ì¼ëŸ¬
        scaler_X = StandardScaler()
        n_samples_train, seq_len, n_features = X_train.shape
        X_train_reshaped = X_train.reshape(-1, n_features)
        scaler_X.fit(X_train_reshaped)
        
        # y ìŠ¤ì¼€ì¼ëŸ¬
        scaler_y = StandardScaler()
        y_train_reshaped = y_train.reshape(-1, 1)
        scaler_y.fit(y_train_reshaped)
        
        # physics ìŠ¤ì¼€ì¼ëŸ¬
        scaler_physics = StandardScaler()
        scaler_physics.fit(physics_train)
        
        print("âœ… ìŠ¤ì¼€ì¼ëŸ¬ fitting ì™„ë£Œ")
        
        # 6. ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        print("\nğŸ’¾ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì¤‘...")
        
        # scaler_X ì €ì¥
        with open('./checkpoints/scaler_X.pkl', 'wb') as f:
            pickle.dump(scaler_X, f)
        print("  - scaler_X.pkl ì €ì¥ ì™„ë£Œ")
        
        # scaler_y ì €ì¥
        with open('./checkpoints/scaler_y.pkl', 'wb') as f:
            pickle.dump(scaler_y, f)
        print("  - scaler_y.pkl ì €ì¥ ì™„ë£Œ")
        
        # scaler_physics ì €ì¥
        with open('./checkpoints/scaler_physics.pkl', 'wb') as f:
            pickle.dump(scaler_physics, f)
        print("  - scaler_physics.pkl ì €ì¥ ì™„ë£Œ")
        
        # 7. ê²€ì¦
        print("\nğŸ” ì €ì¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ ê²€ì¦...")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë‹¤ì‹œ ë¡œë“œ
        with open('./checkpoints/scaler_X.pkl', 'rb') as f:
            loaded_scaler_X = pickle.load(f)
        with open('./checkpoints/scaler_y.pkl', 'rb') as f:
            loaded_scaler_y = pickle.load(f)
        with open('./checkpoints/scaler_physics.pkl', 'rb') as f:
            loaded_scaler_physics = pickle.load(f)
        
        # ê²€ì¦ í…ŒìŠ¤íŠ¸
        test_X = X_train[0:1].reshape(-1, n_features)
        test_y = y_train[0:1].reshape(-1, 1)
        test_physics = physics_train[0:1]
        
        # ë³€í™˜ í…ŒìŠ¤íŠ¸
        X_scaled = loaded_scaler_X.transform(test_X)
        y_scaled = loaded_scaler_y.transform(test_y)
        physics_scaled = loaded_scaler_physics.transform(test_physics)
        
        print("âœ… ìŠ¤ì¼€ì¼ëŸ¬ ê²€ì¦ ì™„ë£Œ")
        print(f"  - X í‰ê· : {loaded_scaler_X.mean_[:3]}... (ì²˜ìŒ 3ê°œ)")
        print(f"  - y í‰ê· : {loaded_scaler_y.mean_[0]:.4f}")
        print(f"  - physics í‰ê· : {loaded_scaler_physics.mean_}")
        
        print("\nâœ… ëª¨ë“  ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: ./checkpoints/")
        
        return scaler_X, scaler_y, scaler_physics

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    saver = ScalerSaver()
    
    try:
        scaler_X, scaler_y, scaler_physics = saver.save_scalers()
        
        print("\n" + "="*60)
        print("ğŸ“‹ ì €ì¥ëœ íŒŒì¼ ëª©ë¡:")
        print("  1. ./checkpoints/scaler_X.pkl")
        print("  2. ./checkpoints/scaler_y.pkl")
        print("  3. ./checkpoints/scaler_physics.pkl")
        print("\nì´ì œ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì´ ìŠ¤ì¼€ì¼ëŸ¬ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()