import tensorflow as tf
import numpy as np
import os
import h5py

def check_saved_model_structure():
    """ì €ì¥ëœ ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
    
    print("="*60)
    print("ğŸ” ì €ì¥ëœ ëª¨ë¸ êµ¬ì¡° í™•ì¸")
    print("="*60)
    
    # 1. PatchTST ëª¨ë¸ í™•ì¸
    if os.path.exists('./checkpoints/PatchTST_best.h5'):
        print("\nğŸ“Š PatchTST_best.h5 íŒŒì¼ ë¶„ì„:")
        try:
            # H5 íŒŒì¼ êµ¬ì¡° í™•ì¸
            with h5py.File('./checkpoints/PatchTST_best.h5', 'r') as f:
                print("\níŒŒì¼ êµ¬ì¡°:")
                def print_structure(name, obj):
                    print(f"  {name}")
                f.visititems(print_structure)
                
                # ë ˆì´ì–´ ì •ë³´ í™•ì¸
                if 'layer_names' in f.attrs:
                    layer_names = f.attrs['layer_names']
                    print(f"\në ˆì´ì–´ ìˆ˜: {len(layer_names)}")
                    print("ë ˆì´ì–´ ì´ë¦„ë“¤:")
                    for i, name in enumerate(layer_names):
                        if isinstance(name, bytes):
                            name = name.decode('utf-8')
                        print(f"  [{i}] {name}")
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            
    # 2. PatchTST_PINN ëª¨ë¸ í™•ì¸
    if os.path.exists('./checkpoints/PatchTST_PINN_best.h5'):
        print("\nğŸ“Š PatchTST_PINN_best.h5 íŒŒì¼ ë¶„ì„:")
        try:
            with h5py.File('./checkpoints/PatchTST_PINN_best.h5', 'r') as f:
                print("\níŒŒì¼ êµ¬ì¡°:")
                def print_structure(name, obj):
                    print(f"  {name}")
                f.visititems(print_structure)
                
                if 'layer_names' in f.attrs:
                    layer_names = f.attrs['layer_names']
                    print(f"\në ˆì´ì–´ ìˆ˜: {len(layer_names)}")
                    print("ë ˆì´ì–´ ì´ë¦„ë“¤:")
                    for i, name in enumerate(layer_names):
                        if isinstance(name, bytes):
                            name = name.decode('utf-8')
                        print(f"  [{i}] {name}")
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
    
    # 3. ì „ì²´ ëª¨ë¸ë¡œ ë¡œë“œ ì‹œë„
    print("\n" + "="*60)
    print("ğŸ”§ ì „ì²´ ëª¨ë¸ ë¡œë“œ ì‹œë„")
    print("="*60)
    
    # PatchTST ì „ì²´ ëª¨ë¸ ë¡œë“œ
    if os.path.exists('./checkpoints/PatchTST_best.h5'):
        print("\nğŸ“Œ PatchTST ì „ì²´ ëª¨ë¸ ë¡œë“œ ì‹œë„:")
        try:
            # ì»¤ìŠ¤í…€ ê°ì²´ ì—†ì´ ë¡œë“œ
            model = tf.keras.models.load_model('./checkpoints/PatchTST_best.h5', compile=False)
            print("âœ… ì„±ê³µ! ëª¨ë¸ êµ¬ì¡°:")
            model.summary()
            
            # ì…ë ¥ í˜•íƒœ í™•ì¸
            print(f"\nì…ë ¥ í˜•íƒœ: {model.input_shape}")
            print(f"ì¶œë ¥ í˜•íƒœ: {model.output_shape}")
            
            return model
        except Exception as e:
            print(f"âŒ ì „ì²´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ê°€ì¤‘ì¹˜ë§Œ ìˆëŠ”ì§€ í™•ì¸
            try:
                # ê°„ë‹¨í•œ ëª¨ë¸ë¡œ ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ ì‹œë„
                print("\nê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ ì‹œë„...")
                # ì—¬ê¸°ì„œëŠ” êµ¬ì¡°ë¥¼ ì•Œì•„ì•¼ í•¨
            except:
                pass
    
    # 4. íŒŒì¼ ì •ë³´ í™•ì¸
    print("\n" + "="*60)
    print("ğŸ“ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ë‚´ìš©")
    print("="*60)
    
    checkpoint_dir = './checkpoints'
    if os.path.exists(checkpoint_dir):
        files = os.listdir(checkpoint_dir)
        for file in files:
            filepath = os.path.join(checkpoint_dir, file)
            size = os.path.getsize(filepath) / (1024 * 1024)  # MB
            print(f"  - {file}: {size:.2f} MB")
    
    # 5. ëª¨ë¸ êµ¬ì¡° ì¶”ì •
    print("\nğŸ’¡ ëª¨ë¸ êµ¬ì¡° íŒíŠ¸:")
    print("- ì…ë ¥: (batch_size, 20, 39) - 20ë¶„ ì‹œí€€ìŠ¤, 39ê°œ íŠ¹ì„±")
    print("- ì¶œë ¥: (batch_size, 1) - 10ë¶„ í›„ ì˜ˆì¸¡ê°’")
    print("- PatchTST: ì‹œí€€ìŠ¤ ë°ì´í„°ë§Œ ì‚¬ìš©")
    print("- PatchTST_PINN: ì‹œí€€ìŠ¤ + ë¬¼ë¦¬ ë°ì´í„° (3ê°œ íŠ¹ì„±)")

def load_model_with_custom_objects():
    """ì»¤ìŠ¤í…€ ê°ì²´ë¥¼ í¬í•¨í•œ ëª¨ë¸ ë¡œë“œ"""
    
    print("\n" + "="*60)
    print("ğŸ”§ ì»¤ìŠ¤í…€ ê°ì²´ë¡œ ëª¨ë¸ ë¡œë“œ ì‹œë„")
    print("="*60)
    
    # TransformerEncoderLayer ì •ì˜
    from tensorflow.keras import layers
    
    class TransformerEncoderLayer(layers.Layer):
        def __init__(self, d_model, num_heads, dff, dropout_rate=0.1, **kwargs):
            super().__init__(**kwargs)
            self.d_model = d_model
            self.num_heads = num_heads
            self.dff = dff
            self.dropout_rate = dropout_rate
            
            self.mha = layers.MultiHeadAttention(
                num_heads=num_heads,
                key_dim=d_model // num_heads,
                dropout=dropout_rate
            )
            self.ffn = tf.keras.Sequential([
                layers.Dense(dff, activation='relu'),
                layers.Dense(d_model)
            ])
            self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
            self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
            self.dropout1 = layers.Dropout(dropout_rate)
            self.dropout2 = layers.Dropout(dropout_rate)
        
        def call(self, inputs, training=False):
            attn_output = self.mha(inputs, inputs, training=training)
            attn_output = self.dropout1(attn_output, training=training)
            out1 = self.layernorm1(inputs + attn_output)
            
            ffn_output = self.ffn(out1)
            ffn_output = self.dropout2(ffn_output, training=training)
            out2 = self.layernorm2(out1 + ffn_output)
            
            return out2
        
        def get_config(self):
            config = super().get_config()
            config.update({
                'd_model': self.d_model,
                'num_heads': self.num_heads,
                'dff': self.dff,
                'dropout_rate': self.dropout_rate
            })
            return config
    
    # ì»¤ìŠ¤í…€ ê°ì²´ë¡œ ë¡œë“œ
    custom_objects = {
        'TransformerEncoderLayer': TransformerEncoderLayer
    }
    
    try:
        if os.path.exists('./checkpoints/PatchTST_best.h5'):
            print("\nPatchTST ëª¨ë¸ ë¡œë“œ ì¤‘...")
            model = tf.keras.models.load_model(
                './checkpoints/PatchTST_best.h5',
                custom_objects=custom_objects,
                compile=False
            )
            print("âœ… PatchTST ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
            return model
    except Exception as e:
        print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ë‹¤ë¥¸ ë°©ë²• ì‹œë„
        print("\në‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹œë„...")
        try:
            # SavedModel í˜•ì‹ì¸ì§€ í™•ì¸
            model = tf.saved_model.load('./checkpoints/PatchTST_best.h5')
            print("âœ… SavedModel í˜•ì‹ìœ¼ë¡œ ë¡œë“œ ì„±ê³µ!")
            return model
        except:
            pass

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” HUBROOM ëª¨ë¸ êµ¬ì¡° í™•ì¸ ë„êµ¬")
    print("="*60)
    
    # 1. ì €ì¥ëœ ëª¨ë¸ êµ¬ì¡° í™•ì¸
    check_saved_model_structure()
    
    # 2. ì»¤ìŠ¤í…€ ê°ì²´ë¡œ ë¡œë“œ ì‹œë„
    model = load_model_with_custom_objects()
    
    if model:
        print("\nâœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        print("ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.")
    else:
        print("\nğŸ’¡ ì œì•ˆì‚¬í•­:")
        print("1. í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì •í™•í•œ ëª¨ë¸ êµ¬ì¡°ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        print("2. ë˜ëŠ” í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ëª¨ë¸ì„ ë‹¤ì‹œ ë¹Œë“œí•˜ê³  ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤")
        print("3. checkpoint íŒŒì¼ì´ ì™„ì „í•œ ëª¨ë¸ì¸ì§€ ê°€ì¤‘ì¹˜ë§Œì¸ì§€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤")

if __name__ == "__main__":
    main()