# -*- coding: utf-8 -*-
"""
HUBROOM ë°˜ì†¡ëŸ‰ ì˜ˆì¸¡ í‰ê°€ ì‹œìŠ¤í…œ - ì¸ë±ì‹± ë²„ê·¸ ìˆ˜ì • ë²„ì „
Created on Mon Sep 1 15:13:16 2025
@author: X0163954
ìˆ˜ì •: ê³¼ê±° 20ë¶„ ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡ - ì •í™•í•œ ì¸ë±ì‹±
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.layers import Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D, Flatten, Embedding
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle
import os
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ===========================
# ğŸ”§ ëª¨ë¸ ì¬êµ¬ì„± (ì‹¤ì œ ì €ì¥ëœ êµ¬ì¡°ì— ë§ì¶¤)
# ===========================

class TransformerEncoderLayer(layers.Layer):
    """ì»¤ìŠ¤í…€ Transformer Encoder Layer"""
    
    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1, **kwargs):
        super(TransformerEncoderLayer, self).__init__(**kwargs)
        
        self.mha = MultiHeadAttention(
            num_heads=num_heads, 
            key_dim=d_model // num_heads,
            dropout=dropout_rate
        )
        
        self.ffn = keras.Sequential([
            Dense(dff, activation='relu'),
            Dense(d_model)
        ])
        
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        
        self.dropout1 = Dropout(dropout_rate)
        self.dropout2 = Dropout(dropout_rate)
    
    def call(self, inputs, training=False):
        attn_output = self.mha(inputs, inputs, training=training)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        out2 = self.layernorm2(out1 + ffn_output)
        
        return out2

def build_patchtst_model(seq_len=20, n_features=39, patch_len=5, d_model=128, 
                        n_heads=8, d_ff=256, n_layers=3, dropout=0.1):
    """ì‹¤ì œ ì €ì¥ëœ êµ¬ì¡°ì— ë§ëŠ” PatchTST ëª¨ë¸ ì¬êµ¬ì„±"""
    
    inputs = Input(shape=(seq_len, n_features))
    
    # Patching
    n_patches = seq_len // patch_len
    patches = tf.reshape(inputs, (-1, n_patches, patch_len * n_features))
    
    # Linear projection (dense)
    x = Dense(d_model, name='dense')(patches)
    
    # Positional encoding (ì„ë² ë”©ì€ ë³„ë„ë¡œ ì¶”ê°€)
    positions = tf.range(start=0, limit=n_patches, delta=1)
    pos_embedding = Embedding(input_dim=n_patches, output_dim=d_model, name='pos_embedding')(positions)
    x = x + pos_embedding
    
    # Transformer layers (3ê°œ)
    x = TransformerEncoderLayer(d_model, n_heads, d_ff, dropout, name='transformer_encoder_layer')(x)
    x = TransformerEncoderLayer(d_model, n_heads, d_ff, dropout, name='transformer_encoder_layer_1')(x)
    x = TransformerEncoderLayer(d_model, n_heads, d_ff, dropout, name='transformer_encoder_layer_2')(x)
    
    # Flatten
    x = Flatten(name='flatten')(x)
    
    # Dense layers
    x = Dense(128, activation='relu', name='dense_7')(x)
    x = Dropout(dropout, name='dropout_6')(x)
    x = Dense(64, activation='relu', name='dense_8')(x)
    outputs = Dense(1, name='dense_9')(x)
    
    model = Model(inputs=inputs, outputs=outputs, name='patch_tst')
    return model

def build_patchtst_pinn_model(seq_len=20, n_features=39, patch_len=5, d_model=128,
                             n_heads=8, d_ff=256, n_layers=3, dropout=0.1):
    """ì‹¤ì œ ì €ì¥ëœ êµ¬ì¡°ì— ë§ëŠ” PatchTST+PINN ëª¨ë¸ ì¬êµ¬ì„±"""
    
    # ë‘ ê°œì˜ ì…ë ¥
    seq_input = Input(shape=(seq_len, n_features), name='sequence_input')
    physics_input = Input(shape=(3,), name='physics_input')
    
    # PatchTST ë¶€ë¶„ (patch_tst_1ìœ¼ë¡œ ë˜í•‘)
    # Patching
    n_patches = seq_len // patch_len
    patches = tf.reshape(seq_input, (-1, n_patches, patch_len * n_features))
    
    # Linear projection
    x = Dense(d_model, name='dense_10')(patches)
    
    # Positional encoding
    positions = tf.range(start=0, limit=n_patches, delta=1)
    pos_embedding = Embedding(input_dim=n_patches, output_dim=d_model, name='pos_embedding')(positions)
    x = x + pos_embedding
    
    # Transformer layers
    for i in range(3):
        x = TransformerEncoderLayer(
            d_model, n_heads, d_ff, dropout,
            name=f'transformer_encoder_layer_{i+3}'
        )(x)
    
    # Global average pooling
    x = GlobalAveragePooling1D()(x)
    
    # Dense layers for TST output
    tst_out = Dense(128, activation='relu', name='dense_17')(x)
    tst_out = Dense(64, activation='relu', name='dense_18')(tst_out)
    tst_out = Dense(1, name='dense_19')(tst_out)
    
    # Physics network
    physics_x = Dense(64, activation='relu', name='dense_20')(physics_input)
    physics_x = Dense(32, activation='relu', name='dense_21')(physics_x)
    
    # Combine
    combined = layers.concatenate([tst_out, physics_x])
    x = Dense(64, activation='relu', name='dense_22')(combined)
    x = Dense(32, activation='relu', name='dense_23')(x)
    outputs = Dense(1, name='dense_24')(x)
    
    # Dropout layer
    outputs = Dropout(dropout, name='dropout_14')(outputs)
    
    model = Model(
        inputs=[seq_input, physics_input],
        outputs=outputs,
        name='patch_tst_pinn_hybrid'
    )
    return model

# ===========================
# ğŸ“Š í‰ê°€ í´ë˜ìŠ¤
# ===========================

class HUBROOMEvaluator:
    """HUBROOM ì˜ˆì¸¡ ëª¨ë¸ í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self, data_path='20250801_to_20250831.csv'):
        self.data_path = data_path
        self.seq_len = 20
        self.pred_len = 10
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        self.critical_threshold = 300
        
        # ëª¨ë¸ ê²½ë¡œ
        self.patchtst_weights = './checkpoints/PatchTST_best.h5'
        self.pinn_weights = './checkpoints/PatchTST_PINN_best.h5'
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self.scaler_X = self.load_scaler('scaler_X.pkl')
        self.scaler_y = self.load_scaler('scaler_y.pkl')
        self.scaler_physics = self.load_scaler('scaler_physics.pkl')
        
        # ë¬¼ë¦¬ ì»¬ëŸ¼
        self.inflow_cols = [
            'M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2',
            'M14A_3F_TO_HUB_JOB2', 'M14B_7F_TO_HUB_JOB2'
        ]
        self.outflow_cols = [
            'M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB',
            'M16A_3F_TO_M14A_3F_JOB', 'M16A_3F_TO_M14B_7F_JOB'
        ]
        
        self.n_features = None  # ë°ì´í„° ë¡œë“œ í›„ ì„¤ì •
    
    def load_scaler(self, filename):
        """ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ"""
        filepath = f'./checkpoints/{filename}'
        if os.path.exists(filepath):
            with open(filepath, 'rb') as f:
                print(f"âœ… {filename} ë¡œë“œ ì™„ë£Œ")
                return pickle.load(f)
        else:
            print(f"âš ï¸ {filename}ì´ ì—†ìŠµë‹ˆë‹¤. save_scalers.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!")
            return None
    
    def prepare_data(self):
        """2025ë…„ 9ì›” ë°ì´í„° ì¤€ë¹„"""
        print("\nğŸ“‚ 2025ë…„ 9ì›” ë°ì´í„° ë¡œë“œ ì¤‘...")
        df = pd.read_csv(self.data_path)
        
        # ì‹œê°„ ì»¬ëŸ¼ ì²˜ë¦¬
        time_col = df.columns[0]
        df['timestamp'] = pd.to_datetime(df[time_col], format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('timestamp').reset_index(drop=True)
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = df.fillna(method='ffill').fillna(0)
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        self.n_features = len(numeric_cols)
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰")
        print(f"ğŸ“… ê¸°ê°„: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        print(f"ğŸ“Š íŠ¹ì„± ìˆ˜: {self.n_features}ê°œ")
        
        return df, numeric_cols
    
    def create_evaluation_sequences(self, df, numeric_cols):
        """í‰ê°€ìš© ì‹œí€€ìŠ¤ ìƒì„± - ì •í™•í•œ ì¸ë±ì‹± ë²„ì „"""
        X_list = []
        y_actual_list = []
        physics_list = []
        
        # ì‹œê°„ ê´€ë ¨ ì •ë³´ ì €ì¥
        current_times = []  # í˜„ì¬ ì‹œê°„ (ì…ë ¥ì˜ ë§ˆì§€ë§‰ ì‹œì )
        predicted_target_times = []  # ì˜ˆì¸¡ íƒ€ê²Ÿ ì‹œê°„ (10ë¶„ í›„)
        input_start_times = []  # ì…ë ¥ ì‹œì‘ ì‹œê°„
        input_end_times = []  # ì…ë ¥ ë ì‹œê°„
        
        # ì…ë ¥ ë°ì´í„° í†µê³„ ì •ë³´
        input_max_values = []
        input_min_values = []
        
        # í˜„ì¬ ì‹œì  ê°’ ì €ì¥ (ë””ë²„ê¹…ìš©)
        current_values = []
        
        data = df[numeric_cols].values
        target_idx = numeric_cols.index(self.target_col)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸
        available_inflow = [col for col in self.inflow_cols if col in numeric_cols]
        available_outflow = [col for col in self.outflow_cols if col in numeric_cols]
        
        print(f"\nğŸ“Š ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        print(f"   - ì…ë ¥: ê³¼ê±° 20ë¶„ (seq_len={self.seq_len})")
        print(f"   - ì˜ˆì¸¡: 10ë¶„ í›„ ê°’ (pred_len={self.pred_len})")
        
        # ì „ì²´ ì‹œí€€ìŠ¤ ìˆ˜ ê³„ì‚°
        total_sequences = len(data) - self.seq_len - self.pred_len + 1
        
        # ì‹œí€€ìŠ¤ ìƒì„±
        for i in range(total_sequences):
            # ===================
            # 1. ì…ë ¥ ì‹œí€€ìŠ¤ (ê³¼ê±° 20ë¶„: i ~ i+19)
            # ===================
            X_seq = data[i:i+self.seq_len]
            
            # ===================
            # 2. ì‹¤ì œê°’ (10ë¶„ í›„ì˜ ê°’)
            # ===================
            # ìˆ˜ì •ëœ ì¸ë±ì‹±: í˜„ì¬(i+19)ë¡œë¶€í„° 10ë¶„ í›„ = i+29
            actual_10min_later = data[i+self.seq_len+self.pred_len-1, target_idx]
            
            # ===================
            # 3. ì‹œê°„ ì •ë³´
            # ===================
            input_start = df['timestamp'].iloc[i]  # ì…ë ¥ ì‹œì‘ ì‹œê°„
            input_end = df['timestamp'].iloc[i+self.seq_len-1]  # ì…ë ¥ ë ì‹œê°„ (í˜„ì¬ ì‹œê°„)
            current_time = input_end  # í˜„ì¬ ì‹œê°„ì€ ì…ë ¥ì˜ ë§ˆì§€ë§‰ ì‹œì 
            # ìˆ˜ì •ëœ ì¸ë±ì‹±: 10ë¶„ í›„ ì‹œê°„
            target_time = df['timestamp'].iloc[i+self.seq_len+self.pred_len-1]
            
            # ===================
            # 4. ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ìµœëŒ€/ìµœì†Œê°’ (ê³¼ê±° 20ë¶„ ë°ì´í„°ì—ì„œ)
            # ===================
            input_target_values = X_seq[:, target_idx]  # ê³¼ê±° 20ë¶„ê°„ì˜ íƒ€ê²Ÿ ì»¬ëŸ¼ ê°’ë“¤
            input_max = np.max(input_target_values)
            input_min = np.min(input_target_values)
            
            # í˜„ì¬ ì‹œì  ê°’ ì €ì¥ (ë””ë²„ê¹…ìš©)
            current_value = X_seq[-1, target_idx]
            current_values.append(current_value)
            
            # ===================
            # 5. ë¬¼ë¦¬ ë°ì´í„° (í˜„ì¬ ìƒíƒœ = ì…ë ¥ì˜ ë§ˆì§€ë§‰ ì‹œì )
            # ===================
            current_state = X_seq[-1]  # ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ë§ˆì§€ë§‰ ìƒíƒœ (í˜„ì¬)
            current_hubroom = current_state[target_idx]
            
            inflow_sum = sum([current_state[numeric_cols.index(col)] 
                            for col in available_inflow])
            outflow_sum = sum([current_state[numeric_cols.index(col)] 
                             for col in available_outflow])
            
            physics = np.array([current_hubroom, inflow_sum, outflow_sum])
            
            # ===================
            # 6. ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            # ===================
            X_list.append(X_seq)
            y_actual_list.append(actual_10min_later)  # 10ë¶„ í›„ ë‹¨ì¼ ê°’
            physics_list.append(physics)
            
            current_times.append(current_time)
            predicted_target_times.append(target_time)
            input_start_times.append(input_start)
            input_end_times.append(input_end)
            input_max_values.append(input_max)
            input_min_values.append(input_min)
        
        print(f"âœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ: {len(X_list)}ê°œ")
        
        # ë°ì´í„° ê²€ì¦ ì¶œë ¥ (ë” ìì„¸íˆ)
        print(f"\nğŸ“‹ ë°ì´í„° ê²€ì¦ (ì²˜ìŒ 5ê°œ ìƒ˜í”Œ):")
        for i in range(min(5, len(X_list))):
            print(f"\n  [{i+1}ë²ˆì§¸ ìƒ˜í”Œ]")
            print(f"    - ì…ë ¥ ê¸°ê°„: {input_start_times[i]} ~ {input_end_times[i]}")
            print(f"    - í˜„ì¬ ì‹œê°„: {current_times[i]}")
            print(f"    - í˜„ì¬ HUBROOM ê°’: {current_values[i]:.1f}")
            print(f"    - ì˜ˆì¸¡ íƒ€ê²Ÿ ì‹œê°„: {predicted_target_times[i]}")
            print(f"    - ì…ë ¥ ìµœëŒ€ê°’: {input_max_values[i]:.1f}")
            print(f"    - ì…ë ¥ ìµœì†Œê°’: {input_min_values[i]:.1f}")
            print(f"    - 10ë¶„ í›„ ì‹¤ì œê°’: {y_actual_list[i]:.1f}")
            
            # ì‹œê°„ ì°¨ì´ ê²€ì¦
            time_diff = predicted_target_times[i] - current_times[i]
            print(f"    - ì‹œê°„ ì°¨ì´ ê²€ì¦: {time_diff.total_seconds()/60:.0f}ë¶„ (10ë¶„ì´ì–´ì•¼ í•¨)")
        
        # ì¸ë±ì‹± ê²€ì¦
        print(f"\nğŸ” ì¸ë±ì‹± ê²€ì¦ (ì²« ë²ˆì§¸ ìƒ˜í”Œ):")
        print(f"  - i=0ì¼ ë•Œ:")
        print(f"  - ì…ë ¥ ì¸ë±ìŠ¤: 0 ~ 19 (20ê°œ)")
        print(f"  - í˜„ì¬ ì‹œì  ì¸ë±ìŠ¤: 19")
        print(f"  - 10ë¶„ í›„ ì¸ë±ìŠ¤: 29 (19 + 10)")
        print(f"  - ì‹¤ì œ ì‚¬ìš©ëœ ì¸ë±ìŠ¤: {self.seq_len + self.pred_len - 1}")
        
        # ì‹œê°„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        time_info = {
            'timestamp': current_times,  # í˜„ì¬ ì‹œê°„
            'predicted_target_time': predicted_target_times,  # 10ë¶„ í›„ ì‹œê°„
            'input_start': input_start_times,
            'input_end': input_end_times,
            'input_max': input_max_values,
            'input_min': input_min_values,
            'current_value': current_values  # ë””ë²„ê¹…ìš© ì¶”ê°€
        }
        
        return (np.array(X_list), np.array(y_actual_list), 
                np.array(physics_list), time_info)
    
    def load_models(self):
        """ëª¨ë¸ ì¬êµ¬ì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ"""
        print("\nğŸ¤– ëª¨ë¸ ì¬êµ¬ì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘...")
        
        models = {}
        
        # PatchTST ëª¨ë¸ ë¡œë“œ
        if os.path.exists(self.patchtst_weights):
            try:
                print("ğŸ“Œ PatchTST ëª¨ë¸ ì¬êµ¬ì„± ì¤‘...")
                model = build_patchtst_model(
                    seq_len=self.seq_len,
                    n_features=self.n_features,
                    patch_len=5,
                    d_model=128,
                    n_heads=8,
                    d_ff=256,
                    n_layers=3,
                    dropout=0.1
                )
                
                # ë”ë¯¸ ë°ì´í„°ë¡œ ëª¨ë¸ ë¹Œë“œ
                dummy_input = np.zeros((1, self.seq_len, self.n_features))
                _ = model(dummy_input)
                
                # ê°€ì¤‘ì¹˜ ë¡œë“œ
                model.load_weights(self.patchtst_weights, by_name=True, skip_mismatch=True)
                models['PatchTST'] = model
                print("âœ… PatchTST ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ PatchTST ë¡œë“œ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
        
        # PatchTST+PINN ëª¨ë¸ ë¡œë“œ
        if os.path.exists(self.pinn_weights):
            try:
                print("ğŸ“Œ PatchTST+PINN ëª¨ë¸ ì¬êµ¬ì„± ì¤‘...")
                model = build_patchtst_pinn_model(
                    seq_len=self.seq_len,
                    n_features=self.n_features,
                    patch_len=5,
                    d_model=128,
                    n_heads=8,
                    d_ff=256,
                    n_layers=3,
                    dropout=0.1
                )
                
                # ë”ë¯¸ ë°ì´í„°ë¡œ ëª¨ë¸ ë¹Œë“œ
                dummy_seq = np.zeros((1, self.seq_len, self.n_features))
                dummy_physics = np.zeros((1, 3))
                _ = model([dummy_seq, dummy_physics])
                
                # ê°€ì¤‘ì¹˜ ë¡œë“œ
                model.load_weights(self.pinn_weights, by_name=True, skip_mismatch=True)
                models['PatchTST_PINN'] = model
                print("âœ… PatchTST+PINN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ PatchTST+PINN ë¡œë“œ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
        
        return models
    
    def predict_and_evaluate(self, models, X, y_actual, physics_data, time_info):
        """ëª¨ë¸ë³„ ì˜ˆì¸¡ ë° í‰ê°€"""
        results = {}
        
        # ë°ì´í„° ì •ê·œí™”
        n_samples, seq_len, n_features = X.shape
        
        # ìŠ¤ì¼€ì¼ëŸ¬ í™•ì¸
        if self.scaler_X is None or self.scaler_y is None:
            print("âŒ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return results
        
        X_scaled = self.scaler_X.transform(X.reshape(-1, n_features)).reshape(n_samples, seq_len, n_features)
        physics_scaled = self.scaler_physics.transform(physics_data) if self.scaler_physics else physics_data
        
        for model_name, model in models.items():
            print(f"\n{'='*60}")
            print(f"ğŸ“Š {model_name} ëª¨ë¸ í‰ê°€")
            print(f"{'='*60}")
            
            try:
                # ì˜ˆì¸¡
                if model_name == 'PatchTST_PINN':
                    # PINN ëª¨ë¸ì€ ë¬¼ë¦¬ ë°ì´í„°ë„ í•„ìš”
                    y_pred_scaled = model.predict([X_scaled, physics_scaled], verbose=1, batch_size=32)
                else:
                    # PatchTSTëŠ” ì‹œí€€ìŠ¤ ë°ì´í„°ë§Œ
                    y_pred_scaled = model.predict(X_scaled, verbose=1, batch_size=32)
                
                # ëª¨ë¸ ì¶œë ¥ í˜•íƒœ í™•ì¸
                print(f"ì˜ˆì¸¡ ì¶œë ¥ í˜•íƒœ: {y_pred_scaled.shape}")
                
                # ì—­ì •ê·œí™” (10ë¶„ í›„ ì˜ˆì¸¡ê°’)
                y_pred_10min = self.scaler_y.inverse_transform(
                    y_pred_scaled.reshape(-1, 1)
                ).flatten()
                
                # ì‹¤ì œê°’ì€ ì´ë¯¸ 10ë¶„ í›„ ë‹¨ì¼ ê°’
                y_true_10min = y_actual
                
                # ë©”íŠ¸ë¦­ ê³„ì‚°
                mae = mean_absolute_error(y_true_10min, y_pred_10min)
                mse = mean_squared_error(y_true_10min, y_pred_10min)
                rmse = np.sqrt(mse)
                r2 = r2_score(y_true_10min, y_pred_10min)
                
                # 300 ì´ìƒ ì˜ˆì¸¡ ë¶„ì„
                over_300_pred = np.sum(y_pred_10min >= 300)
                over_300_true = np.sum(y_true_10min >= 300)
                
                # 300 ì´ìƒì¼ ë•Œì˜ ì •í™•ë„
                mask_300 = y_true_10min >= 300
                if np.sum(mask_300) > 0:
                    mae_300 = mean_absolute_error(y_true_10min[mask_300], y_pred_10min[mask_300])
                    acc_300 = np.sum((y_pred_10min >= 300) & (y_true_10min >= 300)) / np.sum(mask_300)
                else:
                    mae_300 = 0
                    acc_300 = 0
                
                # ê²°ê³¼ ì €ì¥ (ì‹œê°„ ì •ë³´ í¬í•¨)
                results[model_name] = {
                    'y_true': y_true_10min,
                    'y_pred': y_pred_10min,
                    'time_info': time_info,  # ì‹œê°„ ì •ë³´ ì¶”ê°€
                    'mae': mae,
                    'mse': mse,
                    'rmse': rmse,
                    'r2': r2,
                    'over_300_pred': over_300_pred,
                    'over_300_true': over_300_true,
                    'mae_300': mae_300,
                    'acc_300': acc_300
                }
                
                # ì„±ëŠ¥ ì¶œë ¥
                print(f"\nğŸ“ˆ ì „ì²´ ì„±ëŠ¥:")
                print(f"  - MAE: {mae:.4f}")
                print(f"  - RMSE: {rmse:.4f}")
                print(f"  - RÂ²: {r2:.4f}")
                
                print(f"\nğŸš¨ 300 ì´ìƒ ì˜ˆì¸¡ ë¶„ì„:")
                print(f"  - ì‹¤ì œ 300 ì´ìƒ: {over_300_true}ê°œ")
                print(f"  - ì˜ˆì¸¡ 300 ì´ìƒ: {over_300_pred}ê°œ")
                print(f"  - 300 ì´ìƒì¼ ë•Œ MAE: {mae_300:.4f}")
                print(f"  - 300 ê°ì§€ ì •í™•ë„: {acc_300:.2%}")
                
                # ìƒ˜í”Œ ì¶œë ¥ (ê°œì„ ëœ ë²„ì „)
                print(f"\nğŸ“ ì˜ˆì¸¡ ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):")
                for i in range(min(5, len(y_pred_10min))):
                    status = "âš ï¸ ê²½ê³ " if y_pred_10min[i] >= 300 else "âœ… ì •ìƒ"
                    print(f"\n  [{i+1}] í˜„ì¬: {time_info['timestamp'][i]}")
                    print(f"       í˜„ì¬ HUBROOM: {time_info['current_value'][i]:.1f}")
                    print(f"       â†’ 10ë¶„ í›„: {time_info['predicted_target_time'][i]}")
                    print(f"       ì‹¤ì œ: {y_true_10min[i]:.1f}, ì˜ˆì¸¡: {y_pred_10min[i]:.1f} {status}")
                    print(f"       (ê³¼ê±° 20ë¶„ ë²”ìœ„: {time_info['input_min'][i]:.1f} ~ {time_info['input_max'][i]:.1f})")
                
            except Exception as e:
                print(f"âŒ {model_name} ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        return results
    
    def save_predictions(self, results, output_path='predictions_202509.csv'):
        """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìš”ì²­ëœ í˜•ì‹ì˜ CSVë¡œ ì €ì¥"""
        print(f"\nğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        # PatchTST ëª¨ë¸ ê²°ê³¼ë§Œ ì‚¬ìš©
        if 'PatchTST' not in results:
            print("âŒ PatchTST ëª¨ë¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        patchtst_result = results['PatchTST']
        time_info = patchtst_result['time_info']
        
        # ìš”ì²­ëœ ì»¬ëŸ¼ í˜•ì‹ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df_results = pd.DataFrame({
            'timestamp': time_info['timestamp'],  # í˜„ì¬ ì‹œê°„ (ì…ë ¥ì˜ ë§ˆì§€ë§‰ ì‹œì )
            'current_value': time_info['current_value'],  # í˜„ì¬ ì‹œì ì˜ ì‹¤ì œ HUBROOM ê°’
            'actual': patchtst_result['y_true'],  # 10ë¶„ í›„ ì‹¤ì œê°’
            'predicted': patchtst_result['y_pred'],  # 10ë¶„ í›„ ì˜ˆì¸¡ê°’
            'predicted_Target_time': time_info['predicted_target_time'],  # ì˜ˆì¸¡ íƒ€ê²Ÿ ì‹œê°„ (10ë¶„ í›„)
            'input_start': time_info['input_start'],  # ì…ë ¥ ì‹œì‘ ì‹œê°„ (20ë¶„ ì „)
            'input_end': time_info['input_end'],  # ì…ë ¥ ì¢…ë£Œ ì‹œê°„ (í˜„ì¬)
            'input_max': time_info['input_max'],  # ê³¼ê±° 20ë¶„ ì¤‘ ìµœëŒ€ê°’
            'input_min': time_info['input_min'],  # ê³¼ê±° 20ë¶„ ì¤‘ ìµœì†Œê°’
            'error': patchtst_result['y_true'] - patchtst_result['y_pred'],  # ì˜¤ì°¨
            'Patchtst_predicted_TIME': time_info['predicted_target_time']  # PatchTST ì˜ˆì¸¡ ì‹œê°„
        })
        
        # CSV ì €ì¥
        df_results.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        
        # ìš”ì•½ í†µê³„
        print(f"\nğŸ“Š ì €ì¥ëœ ë°ì´í„° ìš”ì•½:")
        print(f"  - ì „ì²´ ì˜ˆì¸¡ ìˆ˜: {len(df_results)}ê°œ")
        print(f"  - 300 ì´ìƒ ì‹¤ì œê°’: {(df_results['actual'] >= 300).sum()}ê°œ")
        print(f"  - 300 ì´ìƒ ì˜ˆì¸¡ê°’: {(df_results['predicted'] >= 300).sum()}ê°œ")
        print(f"  - í‰ê·  ì˜¤ì°¨: {df_results['error'].mean():.2f}")
        print(f"  - ì˜¤ì°¨ í‘œì¤€í¸ì°¨: {df_results['error'].std():.2f}")
        print(f"  - ê¸°ê°„: {df_results['timestamp'].min()} ~ {df_results['timestamp'].max()}")
        
        # ë°ì´í„° ì •í•©ì„± ê²€ì¦ (ë” ìì„¸íˆ)
        print(f"\nâœ… ë°ì´í„° ì •í•©ì„± ê²€ì¦:")
        for sample_idx in [0, len(df_results)//2, len(df_results)-1]:
            if sample_idx < len(df_results):
                print(f"\n  [ìƒ˜í”Œ {sample_idx+1}]")
                row = df_results.iloc[sample_idx]
                print(f"    - í˜„ì¬ ì‹œê°„: {row['timestamp']}")
                print(f"    - í˜„ì¬ HUBROOM ê°’: {row['current_value']:.1f}")
                print(f"    - ì…ë ¥ ê¸°ê°„: {row['input_start']} ~ {row['input_end']}")
                print(f"    - ê³¼ê±° 20ë¶„ ë²”ìœ„: {row['input_min']:.1f} ~ {row['input_max']:.1f}")
                print(f"    - ì˜ˆì¸¡ íƒ€ê²Ÿ ì‹œê°„: {row['predicted_Target_time']}")
                print(f"    - 10ë¶„ í›„ ì‹¤ì œê°’: {row['actual']:.1f}")
                print(f"    - 10ë¶„ í›„ ì˜ˆì¸¡ê°’: {row['predicted']:.1f}")
                print(f"    - ì˜¤ì°¨: {row['error']:.1f}")
                
                # í˜„ì¬ê°’ê³¼ ê³¼ê±° ë²”ìœ„ ê´€ê³„ í™•ì¸
                if row['input_min'] <= row['current_value'] <= row['input_max']:
                    print(f"    âœ… í˜„ì¬ê°’ì´ ê³¼ê±° 20ë¶„ ë²”ìœ„ ë‚´ì— ìˆìŒ")
                else:
                    print(f"    âš ï¸ í˜„ì¬ê°’ì´ ê³¼ê±° 20ë¶„ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨")
        
        # ì²˜ìŒ 5ê°œ í–‰ ì¶œë ¥
        print(f"\nğŸ“‹ ì €ì¥ëœ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):")
        print(df_results.head())
    
    def visualize_results(self, results):
        """ê²°ê³¼ ì‹œê°í™”"""
        if not results:
            print("ì‹œê°í™”í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ëª¨ë¸ë³„ ë¹„êµ ê·¸ë˜í”„
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('HUBROOM ë°˜ì†¡ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ ë¹„êµ (2025ë…„ 9ì›”)', fontsize=16)
        
        # 1. ì‹œê³„ì—´ ì˜ˆì¸¡ ë¹„êµ (ì²˜ìŒ 100ê°œ)
        ax1 = axes[0, 0]
        ax1.plot(results[list(results.keys())[0]]['y_true'][:100], label=f'ì‹¤ì œê°’', alpha=0.7, linewidth=2)
        for model_name, result in results.items():
            ax1.plot(result['y_pred'][:100], label=f'{model_name} ì˜ˆì¸¡', alpha=0.7, linestyle='--')
        ax1.axhline(y=300, color='red', linestyle=':', label='ìœ„í—˜ ì„ê³„ê°’ (300)')
        ax1.set_title('ì‹œê³„ì—´ ì˜ˆì¸¡ ë¹„êµ (ì²˜ìŒ 100ê°œ)')
        ax1.set_xlabel('ì‹œê°„ ì¸ë±ìŠ¤')
        ax1.set_ylabel('HUBROOM ë°˜ì†¡ëŸ‰')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ì‚°ì ë„
        ax2 = axes[0, 1]
        colors = ['blue', 'green', 'orange']
        for idx, (model_name, result) in enumerate(results.items()):
            ax2.scatter(result['y_true'], result['y_pred'], 
                       alpha=0.5, label=model_name, color=colors[idx % len(colors)])
        ax2.plot([0, 600], [0, 600], 'r--', alpha=0.5, label='Perfect Prediction')
        ax2.axvline(x=300, color='red', linestyle=':', alpha=0.5)
        ax2.axhline(y=300, color='red', linestyle=':', alpha=0.5)
        ax2.set_title('ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’')
        ax2.set_xlabel('ì‹¤ì œê°’')
        ax2.set_ylabel('ì˜ˆì¸¡ê°’')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. ì˜¤ì°¨ ë¶„í¬
        ax3 = axes[1, 0]
        for model_name, result in results.items():
            errors = result['y_pred'] - result['y_true']
            ax3.hist(errors, bins=50, alpha=0.5, label=f'{model_name} (MAE: {result["mae"]:.2f})')
        ax3.set_title('ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬')
        ax3.set_xlabel('ì˜ˆì¸¡ ì˜¤ì°¨')
        ax3.set_ylabel('ë¹ˆë„')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¹„êµ
        ax4 = axes[1, 1]
        metrics = ['MAE', 'RMSE', 'RÂ²', 'MAE@300+']
        model_names = list(results.keys())
        
        x = np.arange(len(metrics))
        width = 0.35
        
        for idx, model_name in enumerate(model_names):
            values = [
                results[model_name]['mae'],
                results[model_name]['rmse'],
                results[model_name]['r2'] * 100,  # RÂ²ë¥¼ ë°±ë¶„ìœ¨ë¡œ
                results[model_name]['mae_300']
            ]
            ax4.bar(x + idx * width, values, width, label=model_name)
        
        ax4.set_title('ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¹„êµ')
        ax4.set_xlabel('ë©”íŠ¸ë¦­')
        ax4.set_ylabel('ê°’')
        ax4.set_xticks(x + width / 2)
        ax4.set_xticklabels(metrics)
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('hubroom_evaluation_202509.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # 300 ì´ìƒ ì˜ˆì¸¡ ìƒì„¸ ë¶„ì„
        self.analyze_critical_predictions(results)
    
    def analyze_critical_predictions(self, results):
        """300 ì´ìƒ ì˜ˆì¸¡ ìƒì„¸ ë¶„ì„"""
        print("\n" + "="*60)
        print("ğŸš¨ 300 ì´ìƒ ì˜ˆì¸¡ ìƒì„¸ ë¶„ì„")
        print("="*60)
        
        for model_name, result in results.items():
            print(f"\nğŸ“Š {model_name} ëª¨ë¸:")
            
            y_true = result['y_true']
            y_pred = result['y_pred']
            
            # 300 ì´ìƒ ì¼€ì´ìŠ¤ ë¶„ì„
            true_over_300 = y_true >= 300
            pred_over_300 = y_pred >= 300
            
            # í˜¼ë™ í–‰ë ¬
            tp = np.sum(true_over_300 & pred_over_300)  # True Positive
            fp = np.sum(~true_over_300 & pred_over_300)  # False Positive
            tn = np.sum(~true_over_300 & ~pred_over_300)  # True Negative
            fn = np.sum(true_over_300 & ~pred_over_300)  # False Negative
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            if tp + fp > 0:
                precision = tp / (tp + fp)
            else:
                precision = 0
                
            if tp + fn > 0:
                recall = tp / (tp + fn)
            else:
                recall = 0
                
            if precision + recall > 0:
                f1 = 2 * (precision * recall) / (precision + recall)
            else:
                f1 = 0
            
            print(f"  - True Positive (ì •í™•íˆ ì˜ˆì¸¡í•œ ìœ„í—˜): {tp}ê°œ")
            print(f"  - False Positive (ì˜ëª»ëœ ê²½ë³´): {fp}ê°œ")
            print(f"  - True Negative (ì •í™•íˆ ì˜ˆì¸¡í•œ ì •ìƒ): {tn}ê°œ")
            print(f"  - False Negative (ë†“ì¹œ ìœ„í—˜): {fn}ê°œ")
            print(f"  - Precision (ì •ë°€ë„): {precision:.2%}")
            print(f"  - Recall (ì¬í˜„ìœ¨): {recall:.2%}")
            print(f"  - F1-Score: {f1:.2%}")
            
            # ê·¹ë‹¨ê°’ ë¶„ì„
            extreme_cases = y_true > 400
            if np.sum(extreme_cases) > 0:
                extreme_mae = mean_absolute_error(y_true[extreme_cases], y_pred[extreme_cases])
                print(f"  - 400 ì´ˆê³¼ ê·¹ë‹¨ê°’ MAE: {extreme_mae:.2f}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*80)
    print("ğŸ­ HUBROOM ë°˜ì†¡ëŸ‰ ì˜ˆì¸¡ í‰ê°€ ì‹œìŠ¤í…œ")
    print("ğŸ“… ëŒ€ìƒ: 2025ë…„ 9ì›” ë°ì´í„°")
    print("ğŸ”§ ë²„ê·¸ ìˆ˜ì •: ì •í™•í•œ ì¸ë±ì‹±ìœ¼ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡")
    print("="*80)
    
    # TensorFlow ë¡œê·¸ ë ˆë²¨ ì¡°ì •
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    
    # í‰ê°€ê¸° ìƒì„±
    evaluator = HUBROOMEvaluator()
    
    # ìŠ¤ì¼€ì¼ëŸ¬ í™•ì¸
    if evaluator.scaler_X is None:
        print("\nâŒ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ìŠµë‹ˆë‹¤. save_scalers.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!")
        return
    
    try:
        # 1. ë°ì´í„° ì¤€ë¹„
        df, numeric_cols = evaluator.prepare_data()
        
        # 2. ì‹œí€€ìŠ¤ ìƒì„± (ìˆ˜ì •ëœ ë²„ì „)
        X, y_actual, physics_data, time_info = evaluator.create_evaluation_sequences(df, numeric_cols)
        
        # 3. ëª¨ë¸ ë¡œë“œ
        models = evaluator.load_models()
        
        if not models:
            print("\nâŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
            print("ğŸ’¡ í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì´ ./checkpoints/ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
            print("   - PatchTST_best.h5")
            print("   - PatchTST_PINN_best.h5")
            return
        
        # 4. ì˜ˆì¸¡ ë° í‰ê°€
        results = evaluator.predict_and_evaluate(models, X, y_actual, physics_data, time_info)
        
        if not results:
            print("\nâŒ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        # 5. ê²°ê³¼ ì‹œê°í™”
        evaluator.visualize_results(results)
        
        # 6. ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ (ìˆ˜ì •ëœ í˜•ì‹)
        evaluator.save_predictions(results)
        
        # 7. ìµœì¢… ìš”ì•½
        print("\n" + "="*80)
        print("ğŸ“Š ìµœì¢… ëª¨ë¸ ë¹„êµ ìš”ì•½")
        print("="*80)
        
        print(f"\n{'ëª¨ë¸':<20} {'MAE':<10} {'RMSE':<10} {'RÂ²':<10} {'300+ ì •í™•ë„':<15}")
        print("-"*65)
        
        for model_name, result in results.items():
            print(f"{model_name:<20} {result['mae']:<10.2f} {result['rmse']:<10.2f} "
                  f"{result['r2']:<10.2f} {result['acc_300']:<15.2%}")
        
        print("\nâœ… í‰ê°€ ì™„ë£Œ!")
        print("ğŸ“ predictions_202509.csv íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("\nğŸ“Œ ë°ì´í„° êµ¬ì¡°:")
        print("   - timestamp: í˜„ì¬ ì‹œê°„ (ì…ë ¥ì˜ ë§ˆì§€ë§‰ ì‹œì )")
        print("   - current_value: í˜„ì¬ ì‹œì ì˜ HUBROOM ê°’")
        print("   - actual: 10ë¶„ í›„ ì‹¤ì œê°’")
        print("   - predicted: 10ë¶„ í›„ ì˜ˆì¸¡ê°’")
        print("   - input_max/min: ê³¼ê±° 20ë¶„ ë°ì´í„°ì˜ ìµœëŒ€/ìµœì†Œê°’")
        print("   - predicted_Target_time: ì˜ˆì¸¡ íƒ€ê²Ÿ ì‹œê°„ (10ë¶„ í›„)")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()