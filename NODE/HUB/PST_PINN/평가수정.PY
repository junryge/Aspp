# -*- coding: utf-8 -*-
"""
HUBROOM ë°˜ì†¡ëŸ‰ ì˜ˆì¸¡ í‰ê°€ ì‹œìŠ¤í…œ - 10ë¶„ ë‹¨ìœ„ ê²°ê³¼
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.layers import Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D, Flatten, Embedding
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle
import os
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ===========================
# ğŸ”§ ëª¨ë¸ ì¬êµ¬ì„± (ì‹¤ì œ ì €ì¥ëœ êµ¬ì¡°ì— ë§ì¶¤)
# ===========================

class TransformerEncoderLayer(layers.Layer):
    """ì»¤ìŠ¤í…€ Transformer Encoder Layer"""
    
    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1, **kwargs):
        super(TransformerEncoderLayer, self).__init__(**kwargs)
        
        self.mha = MultiHeadAttention(
            num_heads=num_heads, 
            key_dim=d_model // num_heads,
            dropout=dropout_rate
        )
        
        self.ffn = keras.Sequential([
            Dense(dff, activation='relu'),
            Dense(d_model)
        ])
        
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        
        self.dropout1 = Dropout(dropout_rate)
        self.dropout2 = Dropout(dropout_rate)
    
    def call(self, inputs, training=False):
        attn_output = self.mha(inputs, inputs, training=training)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        out2 = self.layernorm2(out1 + ffn_output)
        
        return out2

def build_patchtst_model(seq_len=20, n_features=39, patch_len=5, d_model=128, 
                        n_heads=8, d_ff=256, n_layers=3, dropout=0.1):
    """ì‹¤ì œ ì €ì¥ëœ êµ¬ì¡°ì— ë§ëŠ” PatchTST ëª¨ë¸ ì¬êµ¬ì„±"""
    
    inputs = Input(shape=(seq_len, n_features))
    
    # Patching
    n_patches = seq_len // patch_len
    patches = tf.reshape(inputs, (-1, n_patches, patch_len * n_features))
    
    # Linear projection (dense)
    x = Dense(d_model, name='dense')(patches)
    
    # Positional encoding (ì„ë² ë”©ì€ ë³„ë„ë¡œ ì¶”ê°€)
    positions = tf.range(start=0, limit=n_patches, delta=1)
    pos_embedding = Embedding(input_dim=n_patches, output_dim=d_model, name='pos_embedding')(positions)
    x = x + pos_embedding
    
    # Transformer layers (3ê°œ)
    x = TransformerEncoderLayer(d_model, n_heads, d_ff, dropout, name='transformer_encoder_layer')(x)
    x = TransformerEncoderLayer(d_model, n_heads, d_ff, dropout, name='transformer_encoder_layer_1')(x)
    x = TransformerEncoderLayer(d_model, n_heads, d_ff, dropout, name='transformer_encoder_layer_2')(x)
    
    # Flatten
    x = Flatten(name='flatten')(x)
    
    # Dense layers
    x = Dense(128, activation='relu', name='dense_7')(x)
    x = Dropout(dropout, name='dropout_6')(x)
    x = Dense(64, activation='relu', name='dense_8')(x)
    outputs = Dense(1, name='dense_9')(x)
    
    model = Model(inputs=inputs, outputs=outputs, name='patch_tst')
    return model

def build_patchtst_pinn_model(seq_len=20, n_features=39, patch_len=5, d_model=128,
                             n_heads=8, d_ff=256, n_layers=3, dropout=0.1):
    """ì‹¤ì œ ì €ì¥ëœ êµ¬ì¡°ì— ë§ëŠ” PatchTST+PINN ëª¨ë¸ ì¬êµ¬ì„±"""
    
    # ë‘ ê°œì˜ ì…ë ¥
    seq_input = Input(shape=(seq_len, n_features), name='sequence_input')
    physics_input = Input(shape=(3,), name='physics_input')
    
    # PatchTST ë¶€ë¶„ (patch_tst_1ìœ¼ë¡œ ë˜í•‘)
    # Patching
    n_patches = seq_len // patch_len
    patches = tf.reshape(seq_input, (-1, n_patches, patch_len * n_features))
    
    # Linear projection
    x = Dense(d_model, name='dense_10')(patches)
    
    # Positional encoding
    positions = tf.range(start=0, limit=n_patches, delta=1)
    pos_embedding = Embedding(input_dim=n_patches, output_dim=d_model, name='pos_embedding')(positions)
    x = x + pos_embedding
    
    # Transformer layers
    for i in range(3):
        x = TransformerEncoderLayer(
            d_model, n_heads, d_ff, dropout,
            name=f'transformer_encoder_layer_{i+3}'
        )(x)
    
    # Global average pooling
    x = GlobalAveragePooling1D()(x)
    
    # Dense layers for TST output
    tst_out = Dense(128, activation='relu', name='dense_17')(x)
    tst_out = Dense(64, activation='relu', name='dense_18')(tst_out)
    tst_out = Dense(1, name='dense_19')(tst_out)
    
    # Physics network
    physics_x = Dense(64, activation='relu', name='dense_20')(physics_input)
    physics_x = Dense(32, activation='relu', name='dense_21')(physics_x)
    
    # Combine
    combined = layers.concatenate([tst_out, physics_x])
    x = Dense(64, activation='relu', name='dense_22')(combined)
    x = Dense(32, activation='relu', name='dense_23')(x)
    outputs = Dense(1, name='dense_24')(x)
    
    # Dropout layer
    outputs = Dropout(dropout, name='dropout_14')(outputs)
    
    model = Model(
        inputs=[seq_input, physics_input],
        outputs=outputs,
        name='patch_tst_pinn_hybrid'
    )
    return model

# ===========================
# ğŸ“Š 10ë¶„ ë‹¨ìœ„ í‰ê°€ í´ë˜ìŠ¤
# ===========================

class HUBROOM10MinEvaluator:
    """HUBROOM ì˜ˆì¸¡ ëª¨ë¸ í‰ê°€ í´ë˜ìŠ¤ - 10ë¶„ ë‹¨ìœ„"""
    
    def __init__(self, data_path='20250801_to_20250831.csv'):
        self.data_path = data_path
        self.seq_len = 20
        self.pred_len = 10
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        self.critical_threshold = 300
        
        # ëª¨ë¸ ê²½ë¡œ
        self.patchtst_weights = './checkpoints/PatchTST_best.h5'
        self.pinn_weights = './checkpoints/PatchTST_PINN_best.h5'
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self.scaler_X = self.load_scaler('scaler_X.pkl')
        self.scaler_y = self.load_scaler('scaler_y.pkl')
        self.scaler_physics = self.load_scaler('scaler_physics.pkl')
        
        # ë¬¼ë¦¬ ì»¬ëŸ¼
        self.inflow_cols = [
            'M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2',
            'M14A_3F_TO_HUB_JOB2', 'M14B_7F_TO_HUB_JOB2'
        ]
        self.outflow_cols = [
            'M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB',
            'M16A_3F_TO_M14A_3F_JOB', 'M16A_3F_TO_M14B_7F_JOB'
        ]
        
        self.n_features = None  # ë°ì´í„° ë¡œë“œ í›„ ì„¤ì •
    
    def load_scaler(self, filename):
        """ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ"""
        filepath = f'./checkpoints/{filename}'
        if os.path.exists(filepath):
            with open(filepath, 'rb') as f:
                print(f"âœ… {filename} ë¡œë“œ ì™„ë£Œ")
                return pickle.load(f)
        else:
            print(f"âš ï¸ {filename}ì´ ì—†ìŠµë‹ˆë‹¤. save_scalers.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!")
            return None
    
    def prepare_data(self):
        """2025ë…„ 9ì›” ë°ì´í„° ì¤€ë¹„"""
        print("\nğŸ“‚ 2025ë…„ 9ì›” ë°ì´í„° ë¡œë“œ ì¤‘...")
        df = pd.read_csv(self.data_path)
        
        # ì‹œê°„ ì»¬ëŸ¼ ì²˜ë¦¬
        time_col = df.columns[0]
        df['timestamp'] = pd.to_datetime(df[time_col], format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('timestamp').reset_index(drop=True)
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = df.fillna(method='ffill').fillna(0)
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        self.n_features = len(numeric_cols)
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰")
        print(f"ğŸ“… ê¸°ê°„: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        print(f"ğŸ“Š íŠ¹ì„± ìˆ˜: {self.n_features}ê°œ")
        
        return df, numeric_cols
    
    def create_10min_evaluation_sequences(self, df, numeric_cols):
        """10ë¶„ ë‹¨ìœ„ë¡œ í‰ê°€ìš© ì‹œí€€ìŠ¤ ìƒì„±"""
        results_list = []
        
        data = df[numeric_cols].values
        target_idx = numeric_cols.index(self.target_col)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸
        available_inflow = [col for col in self.inflow_cols if col in numeric_cols]
        available_outflow = [col for col in self.outflow_cols if col in numeric_cols]
        
        print(f"\nğŸ“Š 10ë¶„ ë‹¨ìœ„ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        
        # 10ë¶„ ê°„ê²©ìœ¼ë¡œ ì‹œí€€ìŠ¤ ìƒì„±
        i = 0
        while i + self.seq_len + self.pred_len <= len(data):
            # ì…ë ¥ ì‹œí€€ìŠ¤ (ê³¼ê±° 20ë¶„)
            X_seq = data[i:i+self.seq_len]
            
            # ì‹¤ì œ ê°’ (10ë¶„ í›„ ë‹¨ì¼ ê°’)
            actual_10min_value = data[i+self.seq_len+self.pred_len-1, target_idx]
            
            # ì˜ˆì¸¡ ì‹œì  (10ë¶„ í›„)
            pred_time = df['timestamp'].iloc[i+self.seq_len+self.pred_len-1]
            input_start_time = df['timestamp'].iloc[i]
            input_end_time = df['timestamp'].iloc[i+self.seq_len-1]
            
            # ë¬¼ë¦¬ ë°ì´í„° (ë§ˆì§€ë§‰ ì…ë ¥ ì‹œì ì˜ ìƒíƒœ)
            current_state = data[i+self.seq_len-1]
            current_hubroom = current_state[target_idx]
            
            inflow_sum = sum([current_state[numeric_cols.index(col)] 
                            for col in available_inflow])
            outflow_sum = sum([current_state[numeric_cols.index(col)] 
                             for col in available_outflow])
            
            physics = np.array([current_hubroom, inflow_sum, outflow_sum])
            
            # ê²°ê³¼ ì €ì¥
            results_list.append({
                'X_seq': X_seq,
                'physics': physics,
                'actual_value': actual_10min_value,
                'pred_time': pred_time,
                'input_period': f"{input_start_time.strftime('%H:%M')}~{input_end_time.strftime('%H:%M')}",
                'input_start': input_start_time,
                'input_end': input_end_time
            })
            
            # 10ë¶„ í›„ë¡œ ì´ë™
            i += 10
        
        print(f"âœ… 10ë¶„ ë‹¨ìœ„ ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ: {len(results_list)}ê°œ")
        
        return results_list
    
    def load_models(self):
        """ëª¨ë¸ ì¬êµ¬ì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ"""
        print("\nğŸ¤– ëª¨ë¸ ì¬êµ¬ì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘...")
        
        models = {}
        
        # PatchTST ëª¨ë¸
        if os.path.exists(self.patchtst_weights):
            try:
                print("ğŸ“Œ PatchTST ëª¨ë¸ ì¬êµ¬ì„± ì¤‘...")
                model = build_patchtst_model(
                    seq_len=self.seq_len,
                    n_features=self.n_features,
                    patch_len=5,
                    d_model=128,
                    n_heads=8,
                    d_ff=256,
                    n_layers=3,
                    dropout=0.1
                )
                
                # ë”ë¯¸ ë°ì´í„°ë¡œ ëª¨ë¸ ë¹Œë“œ
                dummy_input = np.zeros((1, self.seq_len, self.n_features))
                _ = model(dummy_input)
                
                # ê°€ì¤‘ì¹˜ ë¡œë“œ
                model.load_weights(self.patchtst_weights, by_name=True, skip_mismatch=True)
                models['PatchTST'] = model
                print("âœ… PatchTST ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ PatchTST ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # PatchTST+PINN ëª¨ë¸
        if os.path.exists(self.pinn_weights):
            try:
                print("ğŸ“Œ PatchTST+PINN ëª¨ë¸ ì¬êµ¬ì„± ì¤‘...")
                model = build_patchtst_pinn_model(
                    seq_len=self.seq_len,
                    n_features=self.n_features,
                    patch_len=5,
                    d_model=128,
                    n_heads=8,
                    d_ff=256,
                    n_layers=3,
                    dropout=0.1
                )
                
                # ë”ë¯¸ ë°ì´í„°ë¡œ ëª¨ë¸ ë¹Œë“œ
                dummy_seq = np.zeros((1, self.seq_len, self.n_features))
                dummy_physics = np.zeros((1, 3))
                _ = model([dummy_seq, dummy_physics])
                
                # ê°€ì¤‘ì¹˜ ë¡œë“œ
                model.load_weights(self.pinn_weights, by_name=True, skip_mismatch=True)
                models['PatchTST_PINN'] = model
                print("âœ… PatchTST+PINN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ PatchTST+PINN ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return models
    
    def predict_10min_intervals(self, models, results_list):
        """10ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰"""
        # ë°ì´í„° ì¤€ë¹„
        X_list = np.array([r['X_seq'] for r in results_list])
        physics_list = np.array([r['physics'] for r in results_list])
        actual_values = np.array([r['actual_value'] for r in results_list])
        
        # ì •ê·œí™”
        n_samples, seq_len, n_features = X_list.shape
        X_scaled = self.scaler_X.transform(X_list.reshape(-1, n_features)).reshape(n_samples, seq_len, n_features)
        physics_scaled = self.scaler_physics.transform(physics_list) if self.scaler_physics else physics_list
        
        predictions = {}
        
        for model_name, model in models.items():
            print(f"\nğŸ“Š {model_name} ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì¤‘...")
            
            try:
                # ì˜ˆì¸¡
                if model_name == 'PatchTST_PINN':
                    y_pred_scaled = model.predict([X_scaled, physics_scaled], verbose=0, batch_size=32)
                else:
                    y_pred_scaled = model.predict(X_scaled, verbose=0, batch_size=32)
                
                # ì—­ì •ê·œí™”
                y_pred = self.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
                predictions[model_name] = y_pred
                
            except Exception as e:
                print(f"âŒ {model_name} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                predictions[model_name] = np.zeros(len(actual_values))
        
        # ê²°ê³¼ í†µí•©
        for i, result in enumerate(results_list):
            for model_name, pred_values in predictions.items():
                result[f'pred_{model_name}'] = pred_values[i]
        
        return results_list
    
    def create_10min_report(self, results_with_predictions):
        """10ë¶„ ë‹¨ìœ„ ë³´ê³ ì„œ ìƒì„±"""
        print("\n" + "="*80)
        print("ğŸ“Š 10ë¶„ ë‹¨ìœ„ ì˜ˆì¸¡ ê²°ê³¼ ë³´ê³ ì„œ")
        print("="*80)
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        report_data = []
        
        for result in results_with_predictions:
            row = {
                'ì˜ˆì¸¡ì‹œê°„': result['pred_time'].strftime('%Y-%m-%d %H:%M'),
                'ì…ë ¥êµ¬ê°„': result['input_period'],
                'ì‹¤ì œê°’': f"{result['actual_value']:.1f}",
            }
            
            # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ì¶”ê°€
            for model_name in ['PatchTST', 'PatchTST_PINN']:
                if f'pred_{model_name}' in result:
                    pred_val = result[f'pred_{model_name}']
                    error = pred_val - result['actual_value']
                    row[f'{model_name}_ì˜ˆì¸¡'] = f"{pred_val:.1f}"
                    row[f'{model_name}_ì˜¤ì°¨'] = f"{error:+.1f}"
            
            # ìœ„í—˜ ì—¬ë¶€
            if result['actual_value'] >= 300:
                row['ìƒíƒœ'] = 'âš ï¸ ìœ„í—˜'
            else:
                row['ìƒíƒœ'] = 'âœ… ì •ìƒ'
            
            report_data.append(row)
        
        df_report = pd.DataFrame(report_data)
        
        # ì²˜ìŒ 20ê°œ ì¶œë ¥
        print("\nğŸ“‹ ì²˜ìŒ 20ê°œ ì˜ˆì¸¡ ê²°ê³¼:")
        print("-"*80)
        print(df_report.head(20).to_string(index=False))
        
        # í†µê³„ ìš”ì•½
        print("\nğŸ“ˆ ì„±ëŠ¥ í†µê³„:")
        print("-"*80)
        
        for model_name in ['PatchTST', 'PatchTST_PINN']:
            if f'pred_{model_name}' in results_with_predictions[0]:
                actual = np.array([r['actual_value'] for r in results_with_predictions])
                pred = np.array([r[f'pred_{model_name}'] for r in results_with_predictions])
                
                mae = mean_absolute_error(actual, pred)
                rmse = np.sqrt(mean_squared_error(actual, pred))
                r2 = r2_score(actual, pred)
                
                # 300 ì´ìƒ ì •í™•ë„
                mask_300 = actual >= 300
                if np.sum(mask_300) > 0:
                    tp = np.sum((pred >= 300) & (actual >= 300))
                    recall = tp / np.sum(mask_300)
                else:
                    recall = 0
                
                print(f"\n{model_name}:")
                print(f"  - MAE: {mae:.2f}")
                print(f"  - RMSE: {rmse:.2f}")
                print(f"  - RÂ²: {r2:.3f}")
                print(f"  - 300 ì´ìƒ ê°ì§€ìœ¨: {recall:.1%}")
        
        # CSV ì €ì¥
        df_report.to_csv('hubroom_10min_predictions.csv', index=False, encoding='utf-8-sig')
        print("\nâœ… ê²°ê³¼ê°€ 'hubroom_10min_predictions.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return df_report
    
    def visualize_10min_results(self, results_with_predictions):
        """10ë¶„ ë‹¨ìœ„ ê²°ê³¼ ì‹œê°í™”"""
        # ë°ì´í„° ì¶”ì¶œ
        times = [r['pred_time'] for r in results_with_predictions]
        actual = np.array([r['actual_value'] for r in results_with_predictions])
        
        fig, axes = plt.subplots(2, 1, figsize=(15, 10))
        fig.suptitle('HUBROOM ë°˜ì†¡ëŸ‰ 10ë¶„ ë‹¨ìœ„ ì˜ˆì¸¡ ê²°ê³¼', fontsize=16)
        
        # 1. ì‹œê³„ì—´ ê·¸ë˜í”„
        ax1 = axes[0]
        ax1.plot(times, actual, 'k-', label='ì‹¤ì œê°’', linewidth=2)
        
        colors = {'PatchTST': 'blue', 'PatchTST_PINN': 'green'}
        for model_name, color in colors.items():
            if f'pred_{model_name}' in results_with_predictions[0]:
                pred = [r[f'pred_{model_name}'] for r in results_with_predictions]
                ax1.plot(times, pred, '--', color=color, label=f'{model_name} ì˜ˆì¸¡', alpha=0.8)
        
        ax1.axhline(y=300, color='red', linestyle=':', label='ìœ„í—˜ ì„ê³„ê°’')
        ax1.set_xlabel('ì‹œê°„')
        ax1.set_ylabel('HUBROOM ë°˜ì†¡ëŸ‰')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.set_title('10ë¶„ ë‹¨ìœ„ ì˜ˆì¸¡ ì‹œê³„ì—´')
        
        # 2. ì‚°ì ë„
        ax2 = axes[1]
        for model_name, color in colors.items():
            if f'pred_{model_name}' in results_with_predictions[0]:
                pred = np.array([r[f'pred_{model_name}'] for r in results_with_predictions])
                ax2.scatter(actual, pred, alpha=0.6, label=model_name, color=color)
        
        # ëŒ€ê°ì„ 
        max_val = max(actual.max(), 400)
        ax2.plot([0, max_val], [0, max_val], 'r--', alpha=0.5, label='Perfect Prediction')
        ax2.axvline(x=300, color='red', linestyle=':', alpha=0.5)
        ax2.axhline(y=300, color='red', linestyle=':', alpha=0.5)
        
        ax2.set_xlabel('ì‹¤ì œê°’')
        ax2.set_ylabel('ì˜ˆì¸¡ê°’')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_title('ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’')
        
        plt.tight_layout()
        plt.savefig('hubroom_10min_visualization.png', dpi=300, bbox_inches='tight')
        plt.show()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*80)
    print("ğŸ­ HUBROOM ë°˜ì†¡ëŸ‰ 10ë¶„ ë‹¨ìœ„ ì˜ˆì¸¡ í‰ê°€ ì‹œìŠ¤í…œ")
    print("ğŸ“… ëŒ€ìƒ: 2025ë…„ 9ì›” ë°ì´í„°")
    print("="*80)
    
    # TensorFlow ë¡œê·¸ ë ˆë²¨ ì¡°ì •
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    
    # í‰ê°€ê¸° ìƒì„±
    evaluator = HUBROOM10MinEvaluator()
    
    # ìŠ¤ì¼€ì¼ëŸ¬ í™•ì¸
    if evaluator.scaler_X is None:
        print("\nâŒ ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ìŠµë‹ˆë‹¤. save_scalers.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!")
        return
    
    try:
        # 1. ë°ì´í„° ì¤€ë¹„
        df, numeric_cols = evaluator.prepare_data()
        
        # 2. 10ë¶„ ë‹¨ìœ„ ì‹œí€€ìŠ¤ ìƒì„±
        results_list = evaluator.create_10min_evaluation_sequences(df, numeric_cols)
        
        # 3. ëª¨ë¸ ë¡œë“œ
        models = evaluator.load_models()
        
        if not models:
            print("\nâŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        # 4. 10ë¶„ ë‹¨ìœ„ ì˜ˆì¸¡
        results_with_predictions = evaluator.predict_10min_intervals(models, results_list)
        
        # 5. ë³´ê³ ì„œ ìƒì„±
        df_report = evaluator.create_10min_report(results_with_predictions)
        
        # 6. ì‹œê°í™”
        evaluator.visualize_10min_results(results_with_predictions)
        
        print("\nâœ… í‰ê°€ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()