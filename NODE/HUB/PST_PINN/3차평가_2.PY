# -*- coding: utf-8 -*-
"""
HUBROOM ëª¨ë¸ í‰ê°€ - 2025ë…„ 8ì›” ë°ì´í„°
- data/20250801_TO_20250831.CSVì—ì„œ ì‹¤ì œê°’ ë¡œë“œ (ì „ì²´)
- ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¶€ë¶„ë§Œ ì˜ˆì¸¡ê°’ í‘œê¸°
- ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ë¶€ë¶„ì€ ì‹¤ì œê°’ë§Œ í‘œê¸°
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import joblib
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import os
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("ğŸ¯ HUBROOM ëª¨ë¸ í‰ê°€ ì‹œìŠ¤í…œ")
print("ğŸ“… 2025ë…„ 8ì›” ë°ì´í„° (20250801_TO_20250831.CSV)")
print("="*80)

# ========================================
# Model 1: PatchTST
# ========================================

class PatchTSTModel(keras.Model):
    def __init__(self, config):
        super().__init__()
        
        self.seq_len = config['seq_len']
        self.n_features = config['n_features']
        self.patch_len = config['patch_len']
        self.n_patches = self.seq_len // self.patch_len
        
        self.patch_embedding = layers.Dense(128, activation='relu')
        self.attention = layers.MultiHeadAttention(num_heads=8, key_dim=16)
        self.norm1 = layers.LayerNormalization()
        self.norm2 = layers.LayerNormalization()
        
        self.ffn = keras.Sequential([
            layers.Dense(256, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(128)
        ])
        
        self.flatten = layers.Flatten()
        self.dense1 = layers.Dense(128, activation='relu')
        self.dropout = layers.Dropout(0.3)
        self.dense2 = layers.Dense(64, activation='relu')
        self.output_layer = layers.Dense(1)
        
    def call(self, x, training=False):
        batch_size = tf.shape(x)[0]
        x = tf.reshape(x, [batch_size, self.n_patches, self.patch_len * self.n_features])
        x = self.patch_embedding(x)
        attn = self.attention(x, x, training=training)
        x = self.norm1(x + attn)
        ffn_out = self.ffn(x)
        x = self.norm2(x + ffn_out)
        x = self.flatten(x)
        x = self.dense1(x)
        x = self.dropout(x, training=training)
        x = self.dense2(x)
        output = self.output_layer(x)
        return tf.squeeze(output, axis=-1)

# ========================================
# Model 2: PatchTST + PINN
# ========================================

class PatchTSTPINN(keras.Model):
    def __init__(self, config):
        super().__init__()
        
        self.seq_len = config['seq_len']
        self.n_features = config['n_features']
        self.patch_len = config['patch_len']
        self.n_patches = self.seq_len // self.patch_len
        
        self.patch_embedding = layers.Dense(128, activation='relu')
        self.attention = layers.MultiHeadAttention(num_heads=8, key_dim=16)
        self.norm = layers.LayerNormalization()
        self.flatten = layers.Flatten()
        self.temporal_dense = layers.Dense(64, activation='relu')
        
        self.physics_net = keras.Sequential([
            layers.Dense(32, activation='relu'),
            layers.BatchNormalization(),
            layers.Dense(16, activation='relu')
        ])
        
        self.fusion = keras.Sequential([
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.3),
            layers.Dense(32, activation='relu'),
            layers.Dense(16, activation='relu'),
            layers.Dense(1)
        ])
        
        self.extreme_boost = layers.Dense(1, activation='sigmoid')
        
    def call(self, inputs, training=False):
        x_seq, x_physics = inputs
        batch_size = tf.shape(x_seq)[0]
        
        x = tf.reshape(x_seq, [batch_size, self.n_patches, self.patch_len * self.n_features])
        x = self.patch_embedding(x)
        attn = self.attention(x, x, training=training)
        x = self.norm(x + attn)
        x = self.flatten(x)
        temporal_features = self.temporal_dense(x)
        
        physics_features = self.physics_net(x_physics)
        combined = tf.concat([temporal_features, physics_features], axis=-1)
        output = self.fusion(combined)
        
        boost_factor = self.extreme_boost(combined)
        output = output * (1 + boost_factor * 0.2)
        
        return tf.squeeze(output, axis=-1)

# ========================================
# ë©”ì¸ í‰ê°€ í•¨ìˆ˜
# ========================================

def evaluate_august_data():
    """8ì›” CSVì—ì„œ ì‹¤ì œê°’ ë¡œë“œí•˜ì—¬ ì˜ˆì¸¡ê°’ê³¼ ë¹„êµ"""
    
    # 8ì›” CSV íŒŒì¼ ê²½ë¡œ
    csv_path = 'data/20250801_TO_20250831.CSV'
    
    print(f"\nğŸ“‚ 8ì›” CSV ë°ì´í„° ë¡œë“œ ì¤‘: {csv_path}")
    
    # CSV ë¡œë“œ
    try:
        df_august = pd.read_csv(csv_path)
        print(f"âœ… 8ì›” ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df_august.shape}")
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        return None
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ì²˜ë¦¬
    df_august['timestamp'] = pd.to_datetime(df_august.iloc[:, 0], format='%Y%m%d%H%M', errors='coerce')
    df_august = df_august.sort_values('timestamp').reset_index(drop=True)
    df_august = df_august.fillna(method='ffill').fillna(0)
    
    # íƒ€ê²Ÿ ì»¬ëŸ¼ ì°¾ê¸°
    target_col = 'CURRENT_M16A_3F_JOB_2'
    if target_col not in df_august.columns:
        # íƒ€ê²Ÿ ì»¬ëŸ¼ ì°¾ê¸° ì‹œë„
        possible = [col for col in df_august.columns if 'CURRENT' in col and 'M16A_3F' in col]
        if possible:
            target_col = possible[0]
        else:
            # ë³´í†µ 27ë²ˆì§¸ ì»¬ëŸ¼
            numeric_cols = df_august.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 26:
                target_col = numeric_cols[26]
    
    print(f"âœ… íƒ€ê²Ÿ ì»¬ëŸ¼: {target_col}")
    
    # ì „ì²´ ì‹¤ì œê°’ ë¶„ì„
    actual_values_all = df_august[target_col].values
    print(f"\nğŸ¯ 8ì›” ì „ì²´ ì‹¤ì œê°’ ë¶„ì„:")
    print(f"  - ì „ì²´ ë°ì´í„° ìˆ˜: {len(actual_values_all)}ê°œ")
    print(f"  - ë²”ìœ„: {actual_values_all.min():.0f} ~ {actual_values_all.max():.0f}")
    print(f"  - í‰ê· : {actual_values_all.mean():.1f}")
    print(f"  - ê·¹ë‹¨ê°’(310+): {(actual_values_all >= 310).sum()}ê°œ")
    print(f"  - ì´ˆê·¹ë‹¨ê°’(335+): {(actual_values_all >= 335).sum()}ê°œ")
    
    # íŠ¹ì§• ì»¬ëŸ¼ ì„ íƒ
    feature_cols = df_august.select_dtypes(include=[np.number]).columns.tolist()
    
    # ë¬¼ë¦¬ ë²•ì¹™ ì»¬ëŸ¼ (ìœ ì…/ìœ ì¶œ)
    inflow_cols = [col for col in feature_cols if 'TO_HUB' in col][:4]
    outflow_cols = [col for col in feature_cols if 'M16A_3F_TO' in col and 'HUB' not in col][:4]
    
    if not inflow_cols:
        inflow_cols = feature_cols[1:5]
    if not outflow_cols:
        outflow_cols = feature_cols[30:34]
    
    # ========================================
    # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¶€ë¶„ ì‹œí€€ìŠ¤ ìƒì„±
    # ========================================
    
    print("\nğŸ“ˆ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
    
    X_august = []
    X_physics_august = []
    predictable_indices = []  # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì¸ë±ìŠ¤ ì €ì¥
    
    seq_len = 20  # ê³¼ê±° 20ë¶„
    pred_len = 10  # 10ë¶„ í›„ ì˜ˆì¸¡
    
    # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‹œì ë§Œ ì¶”ì¶œ
    for i in range(len(df_august) - seq_len - pred_len + 1):
        # ì…ë ¥: i ~ i+seq_len (20ê°œ ì‹œì )
        X_august.append(df_august[feature_cols].iloc[i:i+seq_len].values)
        
        # ì˜ˆì¸¡ ì‹œì  ì¸ë±ìŠ¤ ì €ì¥
        predictable_indices.append(i + seq_len + pred_len - 1)
        
        # ë¬¼ë¦¬ íŠ¹ì§•
        inflow = df_august[inflow_cols].iloc[i+seq_len-1].sum()
        outflow = df_august[outflow_cols].iloc[i+seq_len-1].sum()
        net_flow = inflow - outflow
        X_physics_august.append([inflow, outflow, net_flow])
    
    X_august = np.array(X_august)
    X_physics_august = np.array(X_physics_august)
    
    print(f"âœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ:")
    print(f"  - ì˜ˆì¸¡ ê°€ëŠ¥í•œ ìƒ˜í”Œ ìˆ˜: {len(X_august)}ê°œ")
    print(f"  - ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ìƒ˜í”Œ ìˆ˜: {len(df_august) - len(X_august)}ê°œ")
    
    # ========================================
    # ì €ì¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    # ========================================
    
    print("\nğŸ”§ ì €ì¥ëœ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ...")
    
    scaler_X = joblib.load('./scalers/scaler_X.pkl')
    scaler_y = joblib.load('./scalers/scaler_y.pkl')
    scaler_physics = joblib.load('./scalers/scaler_physics.pkl')
    print("âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
    
    # Transformë§Œ ìˆ˜í–‰ (Fit í•˜ì§€ ì•ŠìŒ!)
    X_august_scaled = scaler_X.transform(X_august.reshape(-1, X_august.shape[2])).reshape(X_august.shape)
    X_physics_august_scaled = scaler_physics.transform(X_physics_august)
    
    # ========================================
    # ëª¨ë¸ ì˜ˆì¸¡
    # ========================================
    
    n_features = X_august.shape[2]
    config = {
        'seq_len': 20,
        'n_features': n_features,
        'patch_len': 5
    }
    
    # Model 1 ì˜ˆì¸¡
    print("\nğŸ¤– Model 1 (PatchTST) ì˜ˆì¸¡ ì¤‘...")
    model1 = PatchTSTModel(config)
    model1.compile(optimizer='adam', loss='mse')
    dummy_input = np.zeros((1, 20, n_features))
    _ = model1(dummy_input)
    model1.load_weights('./checkpoints/model1_v3.h5')
    
    y_pred1_scaled = model1.predict(X_august_scaled, batch_size=32, verbose=0)
    y_pred1 = scaler_y.inverse_transform(y_pred1_scaled.reshape(-1, 1)).flatten()
    print("âœ… Model 1 ì˜ˆì¸¡ ì™„ë£Œ")
    
    # Model 2 ì˜ˆì¸¡
    print("\nğŸ¤– Model 2 (PINN) ì˜ˆì¸¡ ì¤‘...")
    model2 = PatchTSTPINN(config)
    model2.compile(optimizer='adam', loss='mse')
    dummy_seq = np.zeros((1, 20, n_features))
    dummy_physics = np.zeros((1, 3))
    _ = model2([dummy_seq, dummy_physics])
    model2.load_weights('./checkpoints/model2_v3.h5')
    
    y_pred2_scaled = model2.predict([X_august_scaled, X_physics_august_scaled], batch_size=32, verbose=0)
    y_pred2 = scaler_y.inverse_transform(y_pred2_scaled.reshape(-1, 1)).flatten()
    print("âœ… Model 2 ì˜ˆì¸¡ ì™„ë£Œ")
    
    # ì•™ìƒë¸”
    y_ensemble = 0.4 * y_pred1 + 0.6 * y_pred2
    print("âœ… Ensemble ì˜ˆì¸¡ ì™„ë£Œ")
    
    # ========================================
    # ì „ì²´ ê²°ê³¼ ìƒì„± (ì‹¤ì œê°’ì€ ëª¨ë‘, ì˜ˆì¸¡ê°’ì€ ê°€ëŠ¥í•œ ë¶€ë¶„ë§Œ)
    # ========================================
    
    print("\nğŸ“Š ì „ì²´ ê²°ê³¼ ì •ë¦¬ ì¤‘...")
    
    results = []
    pred_idx = 0  # ì˜ˆì¸¡ê°’ ì¸ë±ìŠ¤
    
    for i in range(len(df_august)):
        # ê¸°ë³¸ ì •ë³´
        timestamp = df_august['timestamp'].iloc[i]
        
        if pd.notna(timestamp):
            timestamp_str = timestamp.strftime('%Y%m%d%H%M')
            readable_time = timestamp.strftime('%Y-%m-%d %H:%M')
        else:
            timestamp_str = f"index_{i}"
            readable_time = f"Index {i}"
        
        # ì‹¤ì œê°’ì€ í•­ìƒ ìˆìŒ
        actual = float(df_august[target_col].iloc[i])
        
        # ì˜ˆì¸¡ê°’ì€ ê°€ëŠ¥í•œ ê²½ìš°ë§Œ
        if i in predictable_indices:
            # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê²½ìš°
            target_time = df_august['timestamp'].iloc[i]
            input_start = (target_time - timedelta(minutes=30)).strftime('%Y-%m-%d %H:%M') if pd.notna(target_time) else "N/A"
            input_end = (target_time - timedelta(minutes=10)).strftime('%Y-%m-%d %H:%M') if pd.notna(target_time) else "N/A"
            
            result = {
                'index': i,
                'timestamp': timestamp_str,
                'readable_time': readable_time,
                'actual': actual,
                'predicted_model1': float(y_pred1[pred_idx]),
                'predicted_model2': float(y_pred2[pred_idx]),
                'predicted_ensemble': float(y_ensemble[pred_idx]),
                'input_start': input_start,
                'input_end': input_end,
                'error_model1': abs(actual - float(y_pred1[pred_idx])),
                'error_model2': abs(actual - float(y_pred2[pred_idx])),
                'error_ensemble': abs(actual - float(y_ensemble[pred_idx])),
                'is_predictable': True
            }
            
            # ìµœì  ëª¨ë¸
            min_error = min(result['error_model1'], result['error_model2'], result['error_ensemble'])
            if result['error_model1'] == min_error:
                result['best_model'] = 'Model1'
            elif result['error_model2'] == min_error:
                result['best_model'] = 'Model2'
            else:
                result['best_model'] = 'Ensemble'
            
            pred_idx += 1
        else:
            # ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ê²½ìš° (ì²˜ìŒ 29ê°œ ë˜ëŠ” ë§ˆì§€ë§‰ ë¶€ë¶„)
            result = {
                'index': i,
                'timestamp': timestamp_str,
                'readable_time': readable_time,
                'actual': actual,
                'predicted_model1': np.nan,
                'predicted_model2': np.nan,
                'predicted_ensemble': np.nan,
                'input_start': "N/A",
                'input_end': "N/A",
                'error_model1': np.nan,
                'error_model2': np.nan,
                'error_ensemble': np.nan,
                'is_predictable': False,
                'best_model': "N/A"
            }
        
        results.append(result)
    
    results_df = pd.DataFrame(results)
    
    # ì €ì¥
    os.makedirs('./evaluation_results', exist_ok=True)
    results_df.to_csv('./evaluation_results/august_complete_results.csv', index=False)
    print(f"âœ… ì „ì²´ ê²°ê³¼ ì €ì¥: ./evaluation_results/august_complete_results.csv ({len(results_df)}ê°œ)")
    
    # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¶€ë¶„ë§Œ
    predictable_df = results_df[results_df['is_predictable']].copy()
    predictable_df.to_csv('./evaluation_results/august_predictable_only.csv', index=False)
    print(f"âœ… ì˜ˆì¸¡ ê°€ëŠ¥ ê²°ê³¼ ì €ì¥: ./evaluation_results/august_predictable_only.csv ({len(predictable_df)}ê°œ)")
    
    # ê·¹ë‹¨ê°’ë§Œ
    extreme_df = results_df[(results_df['actual'] >= 310) & (results_df['is_predictable'])].copy()
    if len(extreme_df) > 0:
        extreme_df.to_csv('./evaluation_results/august_extreme_predictions.csv', index=False)
        print(f"âœ… ê·¹ë‹¨ê°’ ì˜ˆì¸¡ ì €ì¥: ./evaluation_results/august_extreme_predictions.csv ({len(extreme_df)}ê°œ)")
    
    # ========================================
    # ì„±ëŠ¥ í‰ê°€ (ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¶€ë¶„ë§Œ)
    # ========================================
    
    print("\n" + "="*80)
    print("ğŸ“ˆ ì„±ëŠ¥ í‰ê°€ (ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¶€ë¶„)")
    print("="*80)
    
    # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‹¤ì œê°’
    y_actual_predictable = predictable_df['actual'].values
    y_pred1_eval = predictable_df['predicted_model1'].values
    y_pred2_eval = predictable_df['predicted_model2'].values
    y_ensemble_eval = predictable_df['predicted_ensemble'].values
    
    mae1 = mean_absolute_error(y_actual_predictable, y_pred1_eval)
    mae2 = mean_absolute_error(y_actual_predictable, y_pred2_eval)
    mae_ens = mean_absolute_error(y_actual_predictable, y_ensemble_eval)
    
    rmse1 = np.sqrt(mean_squared_error(y_actual_predictable, y_pred1_eval))
    rmse2 = np.sqrt(mean_squared_error(y_actual_predictable, y_pred2_eval))
    rmse_ens = np.sqrt(mean_squared_error(y_actual_predictable, y_ensemble_eval))
    
    print(f"\nğŸ“Š ì˜ˆì¸¡ ê°€ëŠ¥ ìƒ˜í”Œ: {len(predictable_df)}ê°œ")
    print(f"\n              MAE     RMSE")
    print(f"Model 1:   {mae1:7.2f} {rmse1:7.2f}")
    print(f"Model 2:   {mae2:7.2f} {rmse2:7.2f}")
    print(f"Ensemble:  {mae_ens:7.2f} {rmse_ens:7.2f}")
    
    # ê·¹ë‹¨ê°’ ì„±ëŠ¥
    if len(extreme_df) > 0:
        print(f"\nğŸ”´ ê·¹ë‹¨ê°’ ì„±ëŠ¥ ({len(extreme_df)}ê°œ):")
        print(f"  Model 1 MAE: {extreme_df['error_model1'].mean():.2f}")
        print(f"  Model 2 MAE: {extreme_df['error_model2'].mean():.2f}")
        print(f"  Ensemble MAE: {extreme_df['error_ensemble'].mean():.2f}")
        
        # ê°ì§€ìœ¨
        threshold = 305
        detected_m1 = (extreme_df['predicted_model1'] >= threshold).sum()
        detected_m2 = (extreme_df['predicted_model2'] >= threshold).sum()
        detected_ens = (extreme_df['predicted_ensemble'] >= threshold).sum()
        
        print(f"\nê·¹ë‹¨ê°’ ê°ì§€ìœ¨ (ì˜ˆì¸¡ >= {threshold}):")
        print(f"  Model 1: {detected_m1}/{len(extreme_df)} ({detected_m1/len(extreme_df)*100:.1f}%)")
        print(f"  Model 2: {detected_m2}/{len(extreme_df)} ({detected_m2/len(extreme_df)*100:.1f}%)")
        print(f"  Ensemble: {detected_ens}/{len(extreme_df)} ({detected_ens/len(extreme_df)*100:.1f}%)")
    
    # ========================================
    # ê²°ê³¼ ì¶œë ¥ ìƒ˜í”Œ
    # ========================================
    
    print("\n" + "="*80)
    print("ğŸ“‹ ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ (1ê°œ)")
    print("="*80)
    
    # ê·¹ë‹¨ê°’ ìƒ˜í”Œ ìš°ì„ 
    if len(extreme_df) > 0:
        sample = extreme_df.iloc[0]
    else:
        sample = predictable_df.iloc[0]
    
    print(f"""
ğŸ“… 8ì›” ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Timestamp: {sample['timestamp']}
Readable_time: {sample['readable_time']}
Input_start: {sample['input_start']}
Input_end: {sample['input_end']}

CURRENT_M16A_3F_JOB_2:
- Actual: {sample['actual']:.0f}
- Predicted_Model1: {sample['predicted_model1']:.0f}
- Predicted_Model2: {sample['predicted_model2']:.0f}
- Predicted_Ensemble: {sample['predicted_ensemble']:.0f}

Error:
- Model1: {sample['error_model1']:.1f}
- Model2: {sample['error_model2']:.1f}
- Ensemble: {sample['error_ensemble']:.1f}

Best: {sample['best_model']}
""")
    
    # ì „ì²´ ìš”ì•½
    print("\n" + "="*80)
    print("ğŸ“Š ì „ì²´ ìš”ì•½")
    print("="*80)
    print(f"  - ì „ì²´ ë°ì´í„°: {len(results_df)}ê°œ")
    print(f"  - ì˜ˆì¸¡ ê°€ëŠ¥: {len(predictable_df)}ê°œ")
    print(f"  - ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥: {len(results_df) - len(predictable_df)}ê°œ (ì²˜ìŒ 29ê°œ + ë§ˆì§€ë§‰ ë¶€ë¶„)")
    print(f"  - ê·¹ë‹¨ê°’ ì˜ˆì¸¡: {len(extreme_df)}ê°œ")
    
    print("\nâœ… 8ì›” ë°ì´í„° í‰ê°€ ì™„ë£Œ!")
    return results_df

# ========================================
# ë©”ì¸ ì‹¤í–‰
# ========================================

if __name__ == "__main__":
    try:
        print("\n8ì›” ë°ì´í„°(20250801_TO_20250831.CSV) í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # í‰ê°€ ì‹¤í–‰
        results = evaluate_august_data()
        
        if results is not None:
            print("\nğŸ‰ í‰ê°€ ì™„ë£Œ!")
            print("\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
            print("  1. august_complete_results.csv - ì „ì²´ ê²°ê³¼ (ì‹¤ì œê°’ ì „ì²´ + ì˜ˆì¸¡ ê°€ëŠ¥ ë¶€ë¶„)")
            print("  2. august_predictable_only.csv - ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¶€ë¶„ë§Œ")
            print("  3. august_extreme_predictions.csv - ê·¹ë‹¨ê°’ ì˜ˆì¸¡ ê²°ê³¼")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()