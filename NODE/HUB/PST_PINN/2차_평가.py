# -*- coding: utf-8 -*-
"""
HUBROOM ê·¹ë‹¨ê°’ ì˜ˆì¸¡ í‰ê°€ ì‹œìŠ¤í…œ
ExtremePatchTST & ImprovedPINN ëª¨ë¸ í‰ê°€
2025ë…„ 9ì›” ë°ì´í„° ëŒ€ìƒ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.metrics import confusion_matrix, classification_report
import joblib
import os
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

print("="*80)
print("ğŸ­ HUBROOM ê·¹ë‹¨ê°’ ì˜ˆì¸¡ í‰ê°€ ì‹œìŠ¤í…œ")
print("ğŸ¯ ëª¨ë¸: ExtremePatchTST & ImprovedPINN")
print("="*80)

# ========================================
# ëª¨ë¸ ì¬êµ¬ì„±
# ========================================

class ExtremePatchTST(keras.Model):
    """ê·¹ë‹¨ê°’ ì˜ˆì¸¡ íŠ¹í™” PatchTST"""
    def __init__(self, config):
        super().__init__()
        
        self.seq_len = config['seq_len']
        self.n_features = config['n_features']
        self.patch_len = config['patch_len']
        self.n_patches = self.seq_len // self.patch_len
        
        # íŒ¨ì¹˜ ì„ë² ë”©
        self.patch_embedding = layers.Dense(128, activation='relu')
        
        # Transformer
        self.attention = layers.MultiHeadAttention(num_heads=8, key_dim=16)
        self.norm1 = layers.LayerNormalization()
        self.norm2 = layers.LayerNormalization()
        
        self.ffn = keras.Sequential([
            layers.Dense(256, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(128)
        ])
        
        # ì¶œë ¥
        self.flatten = layers.Flatten()
        self.dense1 = layers.Dense(128, activation='relu')
        self.dropout = layers.Dropout(0.3)
        self.dense2 = layers.Dense(64, activation='relu')
        self.output_layer = layers.Dense(1)
        
    def call(self, x, training=False):
        batch_size = tf.shape(x)[0]
        
        # íŒ¨ì¹˜ ìƒì„±
        x = tf.reshape(x, [batch_size, self.n_patches, self.patch_len * self.n_features])
        
        # íŒ¨ì¹˜ ì„ë² ë”©
        x = self.patch_embedding(x)
        
        # Transformer
        attn = self.attention(x, x, training=training)
        x = self.norm1(x + attn)
        
        ffn_out = self.ffn(x)
        x = self.norm2(x + ffn_out)
        
        # ì¶œë ¥
        x = self.flatten(x)
        x = self.dense1(x)
        x = self.dropout(x, training=training)
        x = self.dense2(x)
        output = self.output_layer(x)
        
        return tf.squeeze(output, axis=-1)

class ImprovedPINN(keras.Model):
    """ë¬¼ë¦¬ ë²•ì¹™ ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸"""
    def __init__(self, config):
        super().__init__()
        
        # LSTM for ì‹œê³„ì—´
        self.lstm = layers.LSTM(64, return_sequences=False)
        
        # ë¬¼ë¦¬ ì •ë³´ ì²˜ë¦¬
        self.physics_net = keras.Sequential([
            layers.Dense(32, activation='relu'),
            layers.BatchNormalization(),
            layers.Dense(16, activation='relu')
        ])
        
        # ìœµí•©
        self.fusion = keras.Sequential([
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.3),
            layers.Dense(32, activation='relu'),
            layers.Dense(1)
        ])
        
    def call(self, inputs, training=False):
        x_seq, x_physics = inputs
        
        # ì‹œê³„ì—´ ì²˜ë¦¬
        seq_features = self.lstm(x_seq)
        
        # ë¬¼ë¦¬ ì •ë³´ ì²˜ë¦¬
        physics_features = self.physics_net(x_physics)
        
        # ê²°í•©
        combined = tf.concat([seq_features, physics_features], axis=-1)
        
        # ì¶œë ¥
        output = self.fusion(combined)
        
        return tf.squeeze(output, axis=-1)

# ========================================
# í‰ê°€ í´ë˜ìŠ¤
# ========================================

class ExtremePredictionEvaluator:
    def __init__(self, data_path='data/202509.csv'):
        self.data_path = data_path
        self.seq_len = 20
        self.pred_len = 10
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        
        # ì„ê³„ê°’
        self.thresholds = {
            'warning': 300,
            'critical': 310,
            'extreme': 350
        }
        
        # ëª¨ë¸ ê²½ë¡œ
        self.model1_path = './checkpoints/model1_final.h5'
        self.model2_path = './checkpoints/model2_final.h5'
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ê²½ë¡œ
        self.scaler_dir = './scalers'
        
        # ë¬¼ë¦¬ ì»¬ëŸ¼
        self.inflow_cols = [
            'M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2',
            'M14A_3F_TO_HUB_JOB2', 'M14B_7F_TO_HUB_JOB2'
        ]
        self.outflow_cols = [
            'M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB',
            'M16A_3F_TO_M14A_3F_JOB', 'M16A_3F_TO_M14B_7F_JOB'
        ]
        
    def load_scalers(self):
        """ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ"""
        try:
            self.scaler_X = joblib.load(f'{self.scaler_dir}/scaler_X.pkl')
            self.scaler_y = joblib.load(f'{self.scaler_dir}/scaler_y.pkl')
            self.scaler_physics = joblib.load(f'{self.scaler_dir}/scaler_physics.pkl')
            print("âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"âŒ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def prepare_data(self):
        """ë°ì´í„° ì¤€ë¹„"""
        print("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # CSV ë¡œë“œ
        df = pd.read_csv(self.data_path)
        print(f"  ë°ì´í„° í¬ê¸°: {df.shape}")
        
        # ì‹œê°„ ì²˜ë¦¬
        time_col = df.columns[0]
        df['timestamp'] = pd.to_datetime(df[time_col], format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('timestamp').reset_index(drop=True)
        
        # ì „ì²˜ë¦¬
        df = df.fillna(method='ffill').fillna(0)
        
        # íƒ€ê²Ÿ ë¶„ì„
        target = df[self.target_col]
        print(f"\nğŸ“Š íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ì„:")
        print(f"  ë²”ìœ„: {target.min():.0f} ~ {target.max():.0f}")
        print(f"  í‰ê· : {target.mean():.1f}")
        print(f"  310+ ë¹„ìœ¨: {(target >= 310).sum() / len(target) * 100:.2f}%")
        print(f"  350+ ë¹„ìœ¨: {(target >= 350).sum() / len(target) * 100:.2f}%")
        
        return df
    
    def create_test_sequences(self, df):
        """í…ŒìŠ¤íŠ¸ ì‹œí€€ìŠ¤ ìƒì„±"""
        print("\nğŸ”„ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        n_features = len(numeric_cols)
        
        X, y, X_physics = [], [], []
        timestamps = []
        
        # ë¬¼ë¦¬ ì»¬ëŸ¼ í™•ì¸
        available_inflow = [col for col in self.inflow_cols if col in df.columns]
        available_outflow = [col for col in self.outflow_cols if col in df.columns]
        
        total = len(df) - self.seq_len - self.pred_len + 1
        
        for i in range(total):
            # ì‹œê³„ì—´ ë°ì´í„°
            X.append(df[numeric_cols].iloc[i:i+self.seq_len].values)
            
            # íƒ€ê²Ÿ (10ë¶„ í›„)
            y_val = df[self.target_col].iloc[i + self.seq_len + self.pred_len - 1]
            y.append(y_val)
            
            # ë¬¼ë¦¬ ë°ì´í„°
            current_val = df[self.target_col].iloc[i + self.seq_len - 1]
            inflow = df[available_inflow].iloc[i+self.seq_len:i+self.seq_len+self.pred_len].sum().sum() if available_inflow else 0
            outflow = df[available_outflow].iloc[i+self.seq_len:i+self.seq_len+self.pred_len].sum().sum() if available_outflow else 0
            
            X_physics.append([current_val, inflow, outflow])
            
            # íƒ€ì„ìŠ¤íƒ¬í”„
            timestamps.append(df['timestamp'].iloc[i + self.seq_len - 1])
        
        print(f"  ìƒì„±ëœ ì‹œí€€ìŠ¤: {len(X)}ê°œ")
        
        return np.array(X), np.array(y), np.array(X_physics), timestamps, n_features
    
    def load_models(self, n_features):
        """ëª¨ë¸ ë¡œë“œ"""
        print("\nğŸ¤– ëª¨ë¸ ë¡œë“œ ì¤‘...")
        
        config = {
            'seq_len': 20,
            'n_features': n_features,
            'patch_len': 5
        }
        
        models = {}
        
        # ExtremePatchTST
        if os.path.exists(self.model1_path):
            try:
                model1 = ExtremePatchTST(config)
                dummy = np.zeros((1, 20, n_features))
                _ = model1(dummy)
                model1.load_weights(self.model1_path)
                models['ExtremePatchTST'] = model1
                print("  âœ… ExtremePatchTST ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"  âŒ ExtremePatchTST ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ImprovedPINN
        if os.path.exists(self.model2_path):
            try:
                model2 = ImprovedPINN(config)
                dummy_seq = np.zeros((1, 20, n_features))
                dummy_physics = np.zeros((1, 3))
                _ = model2([dummy_seq, dummy_physics])
                model2.load_weights(self.model2_path)
                models['ImprovedPINN'] = model2
                print("  âœ… ImprovedPINN ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"  âŒ ImprovedPINN ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return models
    
    def evaluate_model(self, model, model_name, X, y, X_physics=None):
        """ëª¨ë¸ í‰ê°€"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š {model_name} í‰ê°€")
        print('='*60)
        
        # ìŠ¤ì¼€ì¼ë§
        n_samples, seq_len, n_features = X.shape
        X_scaled = self.scaler_X.transform(X.reshape(-1, n_features)).reshape(n_samples, seq_len, n_features)
        y_scaled = self.scaler_y.transform(y.reshape(-1, 1)).flatten()
        
        # ì˜ˆì¸¡
        if model_name == 'ImprovedPINN':
            X_physics_scaled = self.scaler_physics.transform(X_physics)
            y_pred_scaled = model.predict([X_scaled, X_physics_scaled], batch_size=32, verbose=0)
        else:
            y_pred_scaled = model.predict(X_scaled, batch_size=32, verbose=0)
        
        # ì—­ë³€í™˜
        y_pred = self.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        mae = mean_absolute_error(y, y_pred)
        rmse = np.sqrt(mean_squared_error(y, y_pred))
        r2 = r2_score(y, y_pred)
        
        print(f"\nğŸ“ˆ ì „ì²´ ì„±ëŠ¥:")
        print(f"  MAE: {mae:.2f}")
        print(f"  RMSE: {rmse:.2f}")
        print(f"  RÂ²: {r2:.4f}")
        
        # ì„ê³„ê°’ë³„ ë¶„ì„
        print(f"\nğŸ¯ ì„ê³„ê°’ë³„ ë¶„ì„:")
        for name, threshold in self.thresholds.items():
            mask = y >= threshold
            if mask.sum() > 0:
                mae_th = mean_absolute_error(y[mask], y_pred[mask])
                detected = (y_pred >= threshold)[mask].sum()
                detection_rate = detected / mask.sum() * 100
                
                print(f"\n  {name.upper()} ({threshold}+):")
                print(f"    ì‹¤ì œ: {mask.sum()}ê°œ")
                print(f"    ê°ì§€: {detected}ê°œ ({detection_rate:.1f}%)")
                print(f"    MAE: {mae_th:.2f}")
        
        # í˜¼ë™ í–‰ë ¬ (310 ê¸°ì¤€)
        y_true_binary = (y >= 310).astype(int)
        y_pred_binary = (y_pred >= 310).astype(int)
        
        tn, fp, fn, tp = confusion_matrix(y_true_binary, y_pred_binary).ravel()
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        print(f"\nğŸ¯ 310+ ì´ì§„ ë¶„ë¥˜ ì„±ëŠ¥:")
        print(f"  Precision: {precision:.2%}")
        print(f"  Recall: {recall:.2%}")
        print(f"  F1-Score: {f1:.2%}")
        
        return {
            'y_true': y,
            'y_pred': y_pred,
            'mae': mae,
            'rmse': rmse,
            'r2': r2,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    def visualize_results(self, results, timestamps):
        """ê²°ê³¼ ì‹œê°í™”"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        fig.suptitle('HUBROOM ê·¹ë‹¨ê°’ ì˜ˆì¸¡ ëª¨ë¸ í‰ê°€', fontsize=16)
        
        for idx, (model_name, result) in enumerate(results.items()):
            row = idx // 3
            col = idx % 3
            
            if row < 2 and col < 3:
                ax = axes[row, col] if len(results) > 3 else axes[col]
                
                # ì‹œê³„ì—´ í”Œë¡¯
                sample_size = min(500, len(result['y_true']))
                ax.plot(result['y_true'][:sample_size], label='ì‹¤ì œê°’', alpha=0.7)
                ax.plot(result['y_pred'][:sample_size], label='ì˜ˆì¸¡ê°’', alpha=0.7)
                ax.axhline(y=310, color='red', linestyle='--', alpha=0.5, label='ì„ê³„ê°’(310)')
                ax.set_title(f'{model_name}\nMAE={result["mae"]:.2f}, F1={result["f1"]:.2%}')
                ax.set_xlabel('ì‹œê°„ ì¸ë±ìŠ¤')
                ax.set_ylabel('HUBROOM ë°˜ì†¡ëŸ‰')
                ax.legend()
                ax.grid(True, alpha=0.3)
        
        # ëª¨ë¸ ë¹„êµ (ì˜¤ë¥¸ìª½ í•˜ë‹¨)
        ax_comp = axes[1, 2]
        metrics = ['MAE', 'RMSE', 'Precision', 'Recall', 'F1']
        model_names = list(results.keys())
        
        x = np.arange(len(metrics))
        width = 0.35
        
        for i, model_name in enumerate(model_names):
            values = [
                results[model_name]['mae'],
                results[model_name]['rmse'],
                results[model_name]['precision'] * 100,
                results[model_name]['recall'] * 100,
                results[model_name]['f1'] * 100
            ]
            ax_comp.bar(x + i * width, values, width, label=model_name)
        
        ax_comp.set_xlabel('ë©”íŠ¸ë¦­')
        ax_comp.set_ylabel('ê°’')
        ax_comp.set_title('ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ')
        ax_comp.set_xticks(x + width / 2)
        ax_comp.set_xticklabels(metrics)
        ax_comp.legend()
        ax_comp.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('extreme_model_evaluation.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def save_results(self, results, timestamps):
        """ê²°ê³¼ ì €ì¥"""
        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        df_results = pd.DataFrame({'timestamp': timestamps})
        
        for model_name, result in results.items():
            df_results[f'actual'] = result['y_true']
            df_results[f'pred_{model_name}'] = result['y_pred']
            df_results[f'error_{model_name}'] = result['y_pred'] - result['y_true']
        
        df_results['is_extreme'] = df_results['actual'] >= 310
        
        output_path = 'extreme_predictions_202509.csv'
        df_results.to_csv(output_path, index=False)
        print(f"  âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
        
        return df_results

# ========================================
# ë©”ì¸ ì‹¤í–‰
# ========================================

def main():
    # í‰ê°€ê¸° ìƒì„±
    evaluator = ExtremePredictionEvaluator()
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    if not evaluator.load_scalers():
        print("ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”!")
        return
    
    # ë°ì´í„° ì¤€ë¹„
    df = evaluator.prepare_data()
    
    # ì‹œí€€ìŠ¤ ìƒì„±
    X, y, X_physics, timestamps, n_features = evaluator.create_test_sequences(df)
    
    # ëª¨ë¸ ë¡œë“œ
    models = evaluator.load_models(n_features)
    
    if not models:
        print("ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # í‰ê°€ ìˆ˜í–‰
    results = {}
    
    if 'ExtremePatchTST' in models:
        results['ExtremePatchTST'] = evaluator.evaluate_model(
            models['ExtremePatchTST'], 'ExtremePatchTST', X, y
        )
    
    if 'ImprovedPINN' in models:
        results['ImprovedPINN'] = evaluator.evaluate_model(
            models['ImprovedPINN'], 'ImprovedPINN', X, y, X_physics
        )
    
    # ì‹œê°í™”
    evaluator.visualize_results(results, timestamps)
    
    # ê²°ê³¼ ì €ì¥
    df_results = evaluator.save_results(results, timestamps)
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "="*80)
    print("ğŸ“Š ìµœì¢… í‰ê°€ ìš”ì•½")
    print("="*80)
    
    print(f"\n{'ëª¨ë¸':<20} {'MAE':<10} {'310+ ê°ì§€ìœ¨':<15} {'F1-Score':<10}")
    print("-"*60)
    
    for model_name, result in results.items():
        detection_rate = (result['recall'] * 100)
        print(f"{model_name:<20} {result['mae']:<10.2f} {detection_rate:<15.1f}% {result['f1']:<10.2%}")
    
    # ìš°ìˆ˜ ëª¨ë¸ ì„ ì •
    best_model = min(results.items(), key=lambda x: x[1]['mae'])
    print(f"\nğŸ† ìµœìš°ìˆ˜ ëª¨ë¸: {best_model[0]} (MAE: {best_model[1]['mae']:.2f})")
    
    print("\nâœ… í‰ê°€ ì™„ë£Œ!")

if __name__ == "__main__":
    main()