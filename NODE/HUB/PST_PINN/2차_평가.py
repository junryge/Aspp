# -*- coding: utf-8 -*-
"""
202509ì›” CSV íŒŒì¼ í‰ê°€ ì‹œìŠ¤í…œ
ê³¼ê±° 20ë¶„ ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡ â†’ CSV ì €ì¥
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib
import os
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("ğŸ“Š 202509ì›” CSV í‰ê°€ ì‹œìŠ¤í…œ")
print("ğŸ¯ ê³¼ê±° 20ë¶„ â†’ 10ë¶„ í›„ ì˜ˆì¸¡")
print("="*80)

# ========================================
# ëª¨ë¸ ì •ì˜
# ========================================

class ExtremePatchTST(keras.Model):
    def __init__(self, config):
        super().__init__()
        
        self.seq_len = config['seq_len']
        self.n_features = config['n_features']
        self.patch_len = config['patch_len']
        self.n_patches = self.seq_len // self.patch_len
        
        self.patch_embedding = layers.Dense(128, activation='relu')
        self.attention = layers.MultiHeadAttention(num_heads=8, key_dim=16)
        self.norm1 = layers.LayerNormalization()
        self.norm2 = layers.LayerNormalization()
        
        self.ffn = keras.Sequential([
            layers.Dense(256, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(128)
        ])
        
        self.flatten = layers.Flatten()
        self.dense1 = layers.Dense(128, activation='relu')
        self.dropout = layers.Dropout(0.3)
        self.dense2 = layers.Dense(64, activation='relu')
        self.output_layer = layers.Dense(1)
        
    def call(self, x, training=False):
        batch_size = tf.shape(x)[0]
        x = tf.reshape(x, [batch_size, self.n_patches, self.patch_len * self.n_features])
        x = self.patch_embedding(x)
        attn = self.attention(x, x, training=training)
        x = self.norm1(x + attn)
        ffn_out = self.ffn(x)
        x = self.norm2(x + ffn_out)
        x = self.flatten(x)
        x = self.dense1(x)
        x = self.dropout(x, training=training)
        x = self.dense2(x)
        output = self.output_layer(x)
        return tf.squeeze(output, axis=-1)

class ImprovedPINN(keras.Model):
    def __init__(self, config):
        super().__init__()
        
        self.lstm = layers.LSTM(64, return_sequences=False)
        self.physics_net = keras.Sequential([
            layers.Dense(32, activation='relu'),
            layers.BatchNormalization(),
            layers.Dense(16, activation='relu')
        ])
        self.fusion = keras.Sequential([
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.3),
            layers.Dense(32, activation='relu'),
            layers.Dense(1)
        ])
        
    def call(self, inputs, training=False):
        x_seq, x_physics = inputs
        seq_features = self.lstm(x_seq)
        physics_features = self.physics_net(x_physics)
        combined = tf.concat([seq_features, physics_features], axis=-1)
        output = self.fusion(combined)
        return tf.squeeze(output, axis=-1)

# ========================================
# í‰ê°€ í´ë˜ìŠ¤
# ========================================

class CSVEvaluator:
    def __init__(self):
        self.seq_len = 20  # ê³¼ê±° 20ë¶„
        self.pred_len = 10  # 10ë¶„ í›„ ì˜ˆì¸¡
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        
        # ë¬¼ë¦¬ ì»¬ëŸ¼
        self.inflow_cols = [
            'M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2',
            'M14A_3F_TO_HUB_JOB2', 'M14B_7F_TO_HUB_JOB2'
        ]
        self.outflow_cols = [
            'M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB',
            'M16A_3F_TO_M14A_3F_JOB', 'M16A_3F_TO_M14B_7F_JOB'
        ]
        
    def load_data(self, csv_path):
        """CSV ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print(f"\nğŸ“‚ CSV ë¡œë“œ: {csv_path}")
        df = pd.read_csv(csv_path)
        
        # ì‹œê°„ ì²˜ë¦¬
        df['timestamp'] = pd.to_datetime(df.iloc[:, 0], format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('timestamp').reset_index(drop=True)
        df = df.fillna(method='ffill').fillna(0)
        
        print(f"  ë°ì´í„° í¬ê¸°: {df.shape}")
        print(f"  ê¸°ê°„: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        
        return df
    
    def prepare_sequences(self, df):
        """ì˜ˆì¸¡ì„ ìœ„í•œ ì‹œí€€ìŠ¤ ì¤€ë¹„"""
        print("\nğŸ”„ ì‹œí€€ìŠ¤ ì¤€ë¹„ ì¤‘...")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        n_features = len(numeric_cols)
        
        # ë¬¼ë¦¬ ì»¬ëŸ¼ í™•ì¸
        available_inflow = [col for col in self.inflow_cols if col in df.columns]
        available_outflow = [col for col in self.outflow_cols if col in df.columns]
        
        X_list = []
        X_physics_list = []
        y_actual_list = []
        valid_indices = []
        
        # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë²”ìœ„ ê³„ì‚°
        total = len(df) - self.seq_len - self.pred_len + 1
        
        for i in tqdm(range(total), desc="ì‹œí€€ìŠ¤ ìƒì„±"):
            # ê³¼ê±° 20ë¶„ ë°ì´í„°
            X = df[numeric_cols].iloc[i:i+self.seq_len].values
            
            # 10ë¶„ í›„ ì‹¤ì œê°’
            y_actual = df[self.target_col].iloc[i + self.seq_len + self.pred_len - 1]
            
            # ë¬¼ë¦¬ ë°ì´í„° (í˜„ì¬ ìƒíƒœ + ë¯¸ë˜ ìœ ì…/ìœ ì¶œ)
            current_val = df[self.target_col].iloc[i + self.seq_len - 1]
            inflow = df[available_inflow].iloc[i+self.seq_len:i+self.seq_len+self.pred_len].sum().sum() if available_inflow else 0
            outflow = df[available_outflow].iloc[i+self.seq_len:i+self.seq_len+self.pred_len].sum().sum() if available_outflow else 0
            
            X_list.append(X)
            X_physics_list.append([current_val, inflow, outflow])
            y_actual_list.append(y_actual)
            valid_indices.append(i + self.seq_len + self.pred_len - 1)
        
        print(f"  ìƒì„±ëœ ì‹œí€€ìŠ¤: {len(X_list)}ê°œ")
        
        return (np.array(X_list), np.array(X_physics_list), 
                np.array(y_actual_list), valid_indices, n_features)
    
    def load_models(self, n_features):
        """ë‘ ëª¨ë¸ ëª¨ë‘ ë¡œë“œ"""
        print("\nğŸ¤– ëª¨ë¸ ë¡œë“œ ì¤‘...")
        
        config = {
            'seq_len': 20,
            'n_features': n_features,
            'patch_len': 5
        }
        
        models = {}
        
        # ExtremePatchTST
        try:
            model1 = ExtremePatchTST(config)
            dummy = np.zeros((1, 20, n_features))
            _ = model1(dummy)
            model1.load_weights('./checkpoints/model1_final.h5')
            models['ExtremePatchTST'] = model1
            print("  âœ… ExtremePatchTST ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"  âŒ ExtremePatchTST ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ImprovedPINN
        try:
            model2 = ImprovedPINN(config)
            dummy_seq = np.zeros((1, 20, n_features))
            dummy_physics = np.zeros((1, 3))
            _ = model2([dummy_seq, dummy_physics])
            model2.load_weights('./checkpoints/model2_final.h5')
            models['ImprovedPINN'] = model2
            print("  âœ… ImprovedPINN ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"  âŒ ImprovedPINN ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return models
    
    def load_scalers(self):
        """ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ"""
        print("\nğŸ“‚ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì¤‘...")
        try:
            scaler_X = joblib.load('./scalers/scaler_X.pkl')
            scaler_y = joblib.load('./scalers/scaler_y.pkl')
            scaler_physics = joblib.load('./scalers/scaler_physics.pkl')
            print("  âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
            return scaler_X, scaler_y, scaler_physics
        except Exception as e:
            print(f"  âŒ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None, None
    
    def predict_and_evaluate(self, models, X, X_physics, y_actual, n_features):
        """ì˜ˆì¸¡ ìˆ˜í–‰ ë° í‰ê°€"""
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        scaler_X, scaler_y, scaler_physics = self.load_scalers()
        if scaler_X is None:
            return None
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        print("\nğŸ“ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì¤‘...")
        X_scaled = scaler_X.transform(X.reshape(-1, n_features)).reshape(X.shape[0], 20, n_features)
        X_physics_scaled = scaler_physics.transform(X_physics)
        
        results = {}
        
        # ê° ëª¨ë¸ë¡œ ì˜ˆì¸¡
        for model_name, model in models.items():
            print(f"\nğŸ”® {model_name} ì˜ˆì¸¡ ì¤‘...")
            
            if model_name == 'ImprovedPINN':
                y_pred_scaled = model.predict([X_scaled, X_physics_scaled], batch_size=32, verbose=1)
            else:
                y_pred_scaled = model.predict(X_scaled, batch_size=32, verbose=1)
            
            # ì—­ë³€í™˜
            y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
            
            # í‰ê°€
            mae = mean_absolute_error(y_actual, y_pred)
            rmse = np.sqrt(mean_squared_error(y_actual, y_pred))
            r2 = r2_score(y_actual, y_pred)
            
            # 310+ ë¶„ì„
            mask_310 = y_actual >= 310
            if mask_310.sum() > 0:
                mae_310 = mean_absolute_error(y_actual[mask_310], y_pred[mask_310])
                detected_310 = (y_pred >= 310)[mask_310].sum()
                rate_310 = detected_310 / mask_310.sum() * 100
            else:
                mae_310 = 0
                detected_310 = 0
                rate_310 = 0
            
            results[model_name] = {
                'predictions': y_pred,
                'mae': mae,
                'rmse': rmse,
                'r2': r2,
                'mae_310': mae_310,
                'detection_rate_310': rate_310
            }
            
            print(f"\nğŸ“Š {model_name} ì„±ëŠ¥:")
            print(f"  MAE: {mae:.2f}")
            print(f"  RMSE: {rmse:.2f}")
            print(f"  RÂ²: {r2:.4f}")
            print(f"  310+ MAE: {mae_310:.2f}")
            print(f"  310+ ê°ì§€ìœ¨: {rate_310:.1f}%")
        
        return results
    
    def save_results(self, df, results, y_actual, valid_indices):
        """ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥"""
        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        # ì „ì²´ ë°ì´í„°í”„ë ˆì„ ë³µì‚¬
        df_result = df.copy()
        
        # ì˜ˆì¸¡ ì»¬ëŸ¼ ì´ˆê¸°í™”
        df_result['actual_10min_later'] = np.nan
        df_result['pred_ExtremePatchTST'] = np.nan
        df_result['pred_ImprovedPINN'] = np.nan
        df_result['error_ExtremePatchTST'] = np.nan
        df_result['error_ImprovedPINN'] = np.nan
        
        # ìœ íš¨í•œ ì¸ë±ìŠ¤ì—ë§Œ ê°’ ì±„ìš°ê¸°
        df_result.loc[valid_indices, 'actual_10min_later'] = y_actual
        
        if 'ExtremePatchTST' in results:
            df_result.loc[valid_indices, 'pred_ExtremePatchTST'] = results['ExtremePatchTST']['predictions']
            df_result.loc[valid_indices, 'error_ExtremePatchTST'] = results['ExtremePatchTST']['predictions'] - y_actual
        
        if 'ImprovedPINN' in results:
            df_result.loc[valid_indices, 'pred_ImprovedPINN'] = results['ImprovedPINN']['predictions']
            df_result.loc[valid_indices, 'error_ImprovedPINN'] = results['ImprovedPINN']['predictions'] - y_actual
        
        # ì•ŒëŒ ìƒíƒœ ì¶”ê°€
        df_result['alarm_status'] = df_result.apply(
            lambda row: 'CRITICAL' if row['actual_10min_later'] >= 350 
            else 'WARNING' if row['actual_10min_later'] >= 310
            else 'NORMAL' if pd.notna(row['actual_10min_later'])
            else 'NO_DATA', axis=1
        )
        
        # ì €ì¥
        output_path = '202509_evaluation_results.csv'
        df_result.to_csv(output_path, index=False)
        
        print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        print(f"  ì „ì²´ í–‰: {len(df_result)}")
        print(f"  ì˜ˆì¸¡ ê°€ëŠ¥í•œ í–‰: {len(valid_indices)}")
        print(f"  310+ ë°ì´í„°: {(y_actual >= 310).sum()}ê°œ")
        
        return df_result

# ========================================
# ë©”ì¸ ì‹¤í–‰
# ========================================

def main():
    # í‰ê°€ê¸° ìƒì„±
    evaluator = CSVEvaluator()
    
    # 1. ë°ì´í„° ë¡œë“œ
    csv_path = '202509.csv'  # ë˜ëŠ” ì…ë ¥ë°›ê¸°
    if not os.path.exists(csv_path):
        csv_path = input("CSV íŒŒì¼ ê²½ë¡œ ì…ë ¥: ").strip()
    
    df = evaluator.load_data(csv_path)
    
    # 2. ì‹œí€€ìŠ¤ ì¤€ë¹„
    X, X_physics, y_actual, valid_indices, n_features = evaluator.prepare_sequences(df)
    
    # 3. ëª¨ë¸ ë¡œë“œ
    models = evaluator.load_models(n_features)
    
    if not models:
        print("âŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # 4. ì˜ˆì¸¡ ë° í‰ê°€
    results = evaluator.predict_and_evaluate(models, X, X_physics, y_actual, n_features)
    
    if results:
        # 5. ê²°ê³¼ ì €ì¥
        df_result = evaluator.save_results(df, results, y_actual, valid_indices)
        
        # 6. ìµœì¢… ìš”ì•½
        print("\n" + "="*80)
        print("ğŸ“Š ìµœì¢… í‰ê°€ ìš”ì•½")
        print("="*80)
        
        for model_name, result in results.items():
            print(f"\n[{model_name}]")
            print(f"  MAE: {result['mae']:.2f}")
            print(f"  RMSE: {result['rmse']:.2f}")
            print(f"  RÂ²: {result['r2']:.4f}")
            print(f"  310+ ê°ì§€ìœ¨: {result['detection_rate_310']:.1f}%")
        
        print("\nâœ… í‰ê°€ ì™„ë£Œ!")
        print("ğŸ“ ê²°ê³¼ íŒŒì¼: 202509_evaluation_results.csv")

if __name__ == "__main__":
    main()