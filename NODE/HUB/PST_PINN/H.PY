# -*- coding: utf-8 -*-
"""
HUBROOM ë°˜ì†¡ëŸ‰ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
Model 1: PatchTST (ìˆœìˆ˜ ë°ì´í„° ê¸°ë°˜)
Model 2: PatchTST + PINN (ë¬¼ë¦¬ ì œì•½ í†µí•©)

ì‹œë‚˜ë¦¬ì˜¤: ê³¼ê±° 20ë¶„ ë°ì´í„° â†’ 10ë¶„ í›„ CURRENT_M16A_3F_JOB_2 ì˜ˆì¸¡
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import math
import warnings
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
warnings.filterwarnings('ignore')

# ===========================
# ğŸ“Š ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬
# ===========================

class HUBROOMDataProcessor:
    """HUBROOM ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, file_path='data/HUB_0509_TO_0730_DATA.CSV'):
        self.file_path = file_path
        self.scaler = StandardScaler()
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        
        # ë¬¼ë¦¬ì  ê³„ì‚°ì„ ìœ„í•œ ì»¬ëŸ¼ ê·¸ë£¹ ì •ì˜
        self.inflow_cols = [
            'M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2',
            'M14A_3F_TO_HUB_JOB2', 'M14B_7F_TO_HUB_JOB2',
            'M16B_10F_TO_HUB_JOB'
        ]
        
        self.outflow_cols = [
            'M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB',
            'M16A_3F_TO_M14A_3F_JOB', 'M16A_3F_TO_M14B_7F_JOB',
            'M16A_3F_TO_3F_MLUD_JOB'
        ]
        
        self.capacity_cols = [
            'M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA',
            'M14A_3F_CNV_MAXCAPA', 'M14B_7F_LFT_MAXCAPA'
        ]
        
    def load_and_preprocess(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")
        df = pd.read_csv(self.file_path)
        
        # ì‹œê°„ ì»¬ëŸ¼ ì²˜ë¦¬
        time_col = df.columns[0]
        df['timestamp'] = pd.to_datetime(df[time_col], format='%Y%m%d%H%M')
        df = df.sort_values('timestamp')
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = df.fillna(method='ffill').fillna(0)
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape[0]} í–‰ Ã— {len(numeric_cols)} íŠ¹ì„±")
        
        return df, numeric_cols
    
    def create_sequences(self, df, numeric_cols, seq_len=20, pred_len=10):
        """
        ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
        - seq_len: ê³¼ê±° ê´€ì¸¡ ê¸¸ì´ (20ë¶„)
        - pred_len: ë¯¸ë˜ ì˜ˆì¸¡ ê¸¸ì´ (10ë¶„)
        """
        X, y = [], []
        X_physics = []  # ë¬¼ë¦¬ ê³„ì‚°ìš© ë°ì´í„°
        
        # í•„ìš”í•œ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
        available_inflow = [col for col in self.inflow_cols if col in df.columns]
        available_outflow = [col for col in self.outflow_cols if col in df.columns]
        
        for i in range(len(df) - seq_len - pred_len + 1):
            # ì…ë ¥: ê³¼ê±° 20ë¶„
            X_seq = df[numeric_cols].iloc[i:i+seq_len].values
            X.append(X_seq)
            
            # íƒ€ê²Ÿ: 10ë¶„ í›„ ê°’
            if self.target_col in df.columns:
                y_val = df[self.target_col].iloc[i+seq_len+pred_len-1]
            else:
                # íƒ€ê²Ÿ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì„ì˜ ìƒì„± (ì˜ˆì‹œ)
                y_val = df[numeric_cols[0]].iloc[i+seq_len+pred_len-1]
            y.append(y_val)
            
            # ë¬¼ë¦¬ ë°ì´í„° (ìœ ì…/ìœ ì¶œ)
            physics_data = {
                'current_hubroom': df[numeric_cols[0]].iloc[i+seq_len-1],
                'inflow_sum': df[available_inflow].iloc[i+seq_len:i+seq_len+pred_len].sum().sum() if available_inflow else 0,
                'outflow_sum': df[available_outflow].iloc[i+seq_len:i+seq_len+pred_len].sum().sum() if available_outflow else 0,
            }
            X_physics.append(physics_data)
        
        return np.array(X), np.array(y), X_physics

# ===========================
# ğŸ§  Model 1: PatchTST
# ===========================

class PatchTST(nn.Module):
    """
    PatchTST: íŒ¨ì¹˜ ê¸°ë°˜ ì‹œê³„ì—´ Transformer
    - 20ë¶„ì„ 5ë¶„ì”© 4ê°œ íŒ¨ì¹˜ë¡œ ë¶„í• 
    - Multi-head Attentionìœ¼ë¡œ íŒ¨í„´ í•™ìŠµ
    """
    
    def __init__(self, config):
        super().__init__()
        
        self.seq_len = config['seq_len']  # 20
        self.n_features = config['n_features']
        self.patch_len = config['patch_len']  # 5
        self.n_patches = self.seq_len // self.patch_len  # 4
        
        self.d_model = config['d_model']
        self.n_heads = config['n_heads']
        self.d_ff = config['d_ff']
        self.n_layers = config['n_layers']
        self.dropout = config['dropout']
        
        # íŒ¨ì¹˜ ì„ë² ë”©
        self.patch_embedding = nn.Linear(
            self.patch_len * self.n_features, 
            self.d_model
        )
        
        # ìœ„ì¹˜ ì¸ì½”ë”©
        self.pos_embedding = nn.Parameter(
            torch.randn(1, self.n_patches, self.d_model)
        )
        
        # Transformer ì¸ì½”ë”
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=self.d_model,
            nhead=self.n_heads,
            dim_feedforward=self.d_ff,
            dropout=self.dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(
            encoder_layer, 
            num_layers=self.n_layers
        )
        
        # ì¶œë ¥ ë ˆì´ì–´
        self.flatten = nn.Flatten()
        self.output_layer = nn.Sequential(
            nn.Linear(self.d_model * self.n_patches, 128),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )
        
    def create_patches(self, x):
        """ì‹œê³„ì—´ì„ íŒ¨ì¹˜ë¡œ ë¶„í• """
        batch_size = x.shape[0]
        
        # (batch, seq_len, features) -> (batch, n_patches, patch_len, features)
        x = x.unfold(dimension=1, size=self.patch_len, step=self.patch_len)
        
        # (batch, n_patches, features, patch_len) -> (batch, n_patches, patch_len*features)
        x = x.permute(0, 1, 3, 2)
        x = x.contiguous().view(batch_size, self.n_patches, -1)
        
        return x
    
    def forward(self, x):
        # íŒ¨ì¹˜ ìƒì„±
        x_patches = self.create_patches(x)
        
        # íŒ¨ì¹˜ ì„ë² ë”©
        x_embed = self.patch_embedding(x_patches)
        
        # ìœ„ì¹˜ ì¸ì½”ë”© ì¶”ê°€
        x_embed = x_embed + self.pos_embedding
        
        # Transformer ì¸ì½”ë”
        x_transformed = self.transformer(x_embed)
        
        # ì¶œë ¥ ìƒì„±
        x_flat = self.flatten(x_transformed)
        output = self.output_layer(x_flat)
        
        return output.squeeze(-1)

# ===========================
# ğŸ”¬ Model 2: PatchTST + PINN
# ===========================

class PhysicsInformedLoss(nn.Module):
    """
    ë¬¼ë¦¬ ì •ë³´ ì†ì‹¤ í•¨ìˆ˜
    - ì§ˆëŸ‰ ë³´ì¡´: HUBROOM_ë³€í™” = ìœ ì… - ìœ ì¶œ
    - ìš©ëŸ‰ ì œì•½: 0 â‰¤ HUBROOM â‰¤ MAX_CAPACITY
    """
    
    def __init__(self, max_capacity=200, alpha_physics=0.3, alpha_capacity=0.2):
        super().__init__()
        self.max_capacity = max_capacity
        self.alpha_physics = alpha_physics
        self.alpha_capacity = alpha_capacity
        
    def forward(self, pred, target, physics_data):
        # ê¸°ë³¸ ì˜ˆì¸¡ ì†ì‹¤ (MSE)
        mse_loss = nn.MSELoss()(pred, target)
        
        # ë¬¼ë¦¬ ì†ì‹¤ ê³„ì‚°
        physics_loss = 0
        capacity_loss = 0
        
        if physics_data is not None:
            # ì§ˆëŸ‰ ë³´ì¡´ ê²€ì¦
            expected = physics_data['current'] + physics_data['inflow'] - physics_data['outflow']
            physics_violation = torch.abs(pred - expected)
            physics_loss = torch.mean(physics_violation)
            
            # ìš©ëŸ‰ ì œì•½ ê²€ì¦
            over_capacity = torch.relu(pred - self.max_capacity)
            under_zero = torch.relu(-pred)
            capacity_loss = torch.mean(over_capacity + under_zero)
        
        # ì „ì²´ ì†ì‹¤
        total_loss = mse_loss + self.alpha_physics * physics_loss + self.alpha_capacity * capacity_loss
        
        return total_loss, {
            'mse': mse_loss.item(),
            'physics': physics_loss.item() if isinstance(physics_loss, torch.Tensor) else 0,
            'capacity': capacity_loss.item() if isinstance(capacity_loss, torch.Tensor) else 0
        }

class PatchTST_PINN(nn.Module):
    """
    PatchTST + PINN í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸
    - PatchTST ë°±ë³¸ + ë¬¼ë¦¬ ì œì•½ ë ˆì´ì–´
    """
    
    def __init__(self, config):
        super().__init__()
        
        # PatchTST ë°±ë³¸
        self.patchtst = PatchTST(config)
        
        # ë¬¼ë¦¬ ë³´ì • ë ˆì´ì–´
        self.physics_correction = nn.Sequential(
            nn.Linear(1, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Sigmoid()  # 0-1 ìŠ¤ì¼€ì¼ë§
        )
        
        self.max_capacity = config.get('max_capacity', 200)
        
    def forward(self, x, physics_data=None):
        # PatchTST ì˜ˆì¸¡
        base_pred = self.patchtst(x)
        
        # ë¬¼ë¦¬ ë³´ì • ì ìš©
        if physics_data is not None and self.training:
            # ë¬¼ë¦¬ ê¸°ë°˜ ì˜ˆìƒê°’ ê³„ì‚°
            expected = physics_data['current'] + physics_data['inflow'] - physics_data['outflow']
            
            # ë³´ì • ê³„ìˆ˜ ê³„ì‚°
            correction = self.physics_correction(base_pred.unsqueeze(-1)).squeeze(-1)
            
            # ê°€ì¤‘ í‰ê· : ë°ì´í„° ê¸°ë°˜ ì˜ˆì¸¡ê³¼ ë¬¼ë¦¬ ê¸°ë°˜ ì˜ˆì¸¡
            pred = base_pred * (1 - correction) + expected * correction
        else:
            pred = base_pred
        
        # ìš©ëŸ‰ ì œì•½ ì ìš© (í´ë¦¬í•‘)
        pred = torch.clamp(pred, min=0, max=self.max_capacity)
        
        return pred

# ===========================
# ğŸ“ˆ í•™ìŠµ ë° í‰ê°€
# ===========================

class HUBROOMTrainer:
    """ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self, model, model_name, device='cpu'):
        self.model = model.to(device)
        self.model_name = model_name
        self.device = device
        self.history = {'train_loss': [], 'val_loss': []}
        
    def train(self, train_loader, val_loader, epochs=50, lr=0.001, use_physics=False):
        """ëª¨ë¸ í•™ìŠµ"""
        optimizer = optim.Adam(self.model.parameters(), lr=lr)
        
        if use_physics:
            criterion = PhysicsInformedLoss()
        else:
            criterion = nn.MSELoss()
        
        print(f"\nğŸš€ {self.model_name} í•™ìŠµ ì‹œì‘...")
        
        for epoch in range(epochs):
            # Training
            self.model.train()
            train_loss = 0
            
            for batch_x, batch_y, batch_physics in train_loader:
                batch_x = batch_x.to(self.device)
                batch_y = batch_y.to(self.device)
                
                optimizer.zero_grad()
                
                if use_physics:
                    # Physics-informed í•™ìŠµ
                    physics_tensor = {
                        'current': torch.tensor([p['current_hubroom'] for p in batch_physics]).to(self.device),
                        'inflow': torch.tensor([p['inflow_sum'] for p in batch_physics]).to(self.device),
                        'outflow': torch.tensor([p['outflow_sum'] for p in batch_physics]).to(self.device)
                    }
                    pred = self.model(batch_x, physics_tensor)
                    loss, loss_components = criterion(pred, batch_y, physics_tensor)
                else:
                    # ì¼ë°˜ í•™ìŠµ
                    pred = self.model(batch_x)
                    loss = criterion(pred, batch_y)
                
                loss.backward()
                optimizer.step()
                train_loss += loss.item()
            
            # Validation
            self.model.eval()
            val_loss = 0
            
            with torch.no_grad():
                for batch_x, batch_y, _ in val_loader:
                    batch_x = batch_x.to(self.device)
                    batch_y = batch_y.to(self.device)
                    
                    pred = self.model(batch_x)
                    
                    if use_physics:
                        loss = nn.MSELoss()(pred, batch_y)
                    else:
                        loss = criterion(pred, batch_y)
                    
                    val_loss += loss.item()
            
            avg_train_loss = train_loss / len(train_loader)
            avg_val_loss = val_loss / len(val_loader)
            
            self.history['train_loss'].append(avg_train_loss)
            self.history['val_loss'].append(avg_val_loss)
            
            if (epoch + 1) % 10 == 0:
                print(f"Epoch [{epoch+1}/{epochs}] Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")
    
    def evaluate(self, test_loader):
        """ëª¨ë¸ í‰ê°€"""
        self.model.eval()
        predictions = []
        actuals = []
        
        with torch.no_grad():
            for batch_x, batch_y, _ in test_loader:
                batch_x = batch_x.to(self.device)
                pred = self.model(batch_x).cpu().numpy()
                predictions.extend(pred)
                actuals.extend(batch_y.numpy())
        
        predictions = np.array(predictions)
        actuals = np.array(actuals)
        
        # í‰ê°€ ë©”íŠ¸ë¦­
        mae = np.mean(np.abs(predictions - actuals))
        rmse = np.sqrt(np.mean((predictions - actuals)**2))
        mape = np.mean(np.abs((actuals - predictions) / (actuals + 1e-8))) * 100
        
        print(f"\nğŸ“Š {self.model_name} í‰ê°€ ê²°ê³¼:")
        print(f"  - MAE: {mae:.2f}")
        print(f"  - RMSE: {rmse:.2f}")
        print(f"  - MAPE: {mape:.2f}%")
        
        return predictions, actuals, {'mae': mae, 'rmse': rmse, 'mape': mape}

# ===========================
# ğŸ¯ ë©”ì¸ ì‹¤í–‰ ì‹œë‚˜ë¦¬ì˜¤
# ===========================

def main_scenario():
    """
    ì‹œë‚˜ë¦¬ì˜¤: ê³¼ê±° 20ë¶„ ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡
    Model 1: PatchTST (ë°ì´í„° ê¸°ë°˜)
    Model 2: PatchTST + PINN (ë¬¼ë¦¬ ì œì•½ í†µí•©)
    """
    
    print("=" * 80)
    print("ğŸ­ HUBROOM ë°˜ì†¡ëŸ‰ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
    print("ì‹œë‚˜ë¦¬ì˜¤: ê³¼ê±° 20ë¶„ â†’ 10ë¶„ í›„ ì˜ˆì¸¡")
    print("=" * 80)
    
    # 1. ë°ì´í„° ì¤€ë¹„
    processor = HUBROOMDataProcessor()
    df, numeric_cols = processor.load_and_preprocess()
    
    # ì‹œë®¬ë ˆì´ì…˜ìš© ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°)
    if len(df) < 100:
        print("âš ï¸ ë°ì´í„° ë¶€ì¡±, ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±...")
        # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
        n_samples = 1000
        n_features = 38
        
        # ê°€ìƒì˜ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
        data = np.random.randn(n_samples, n_features) * 10 + 100
        df = pd.DataFrame(data, columns=[f'feature_{i}' for i in range(n_features)])
        numeric_cols = df.columns.tolist()
    
    # 2. ì‹œí€€ìŠ¤ ìƒì„±
    X, y, physics_data = processor.create_sequences(df, numeric_cols, seq_len=20, pred_len=10)
    
    print(f"\nğŸ“¦ ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± ì™„ë£Œ:")
    print(f"  - X shape: {X.shape} (ìƒ˜í”Œ, ì‹œí€€ìŠ¤, íŠ¹ì„±)")
    print(f"  - y shape: {y.shape} (ìƒ˜í”Œ,)")
    
    # 3. ë°ì´í„° ë¶„í• 
    X_train, X_temp, y_train, y_temp, physics_train, physics_temp = train_test_split(
        X, y, physics_data, test_size=0.3, random_state=42
    )
    X_val, X_test, y_val, y_test, physics_val, physics_test = train_test_split(
        X_temp, y_temp, physics_temp, test_size=0.5, random_state=42
    )
    
    # 4. ë°ì´í„° ì •ê·œí™”
    scaler_X = StandardScaler()
    scaler_y = StandardScaler()
    
    # Reshape for scaling
    n_samples_train, seq_len, n_features = X_train.shape
    X_train_reshaped = X_train.reshape(-1, n_features)
    X_train_scaled = scaler_X.fit_transform(X_train_reshaped).reshape(n_samples_train, seq_len, n_features)
    
    X_val_scaled = scaler_X.transform(X_val.reshape(-1, n_features)).reshape(X_val.shape[0], seq_len, n_features)
    X_test_scaled = scaler_X.transform(X_test.reshape(-1, n_features)).reshape(X_test.shape[0], seq_len, n_features)
    
    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()
    y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1)).flatten()
    y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()
    
    # 5. ë°ì´í„°ë¡œë” ìƒì„±
    class HUBROOMDataset(Dataset):
        def __init__(self, X, y, physics_data=None):
            self.X = torch.FloatTensor(X)
            self.y = torch.FloatTensor(y)
            self.physics_data = physics_data if physics_data else [None] * len(X)
            
        def __len__(self):
            return len(self.X)
        
        def __getitem__(self, idx):
            return self.X[idx], self.y[idx], self.physics_data[idx]
    
    train_dataset = HUBROOMDataset(X_train_scaled, y_train_scaled, physics_train)
    val_dataset = HUBROOMDataset(X_val_scaled, y_val_scaled, physics_val)
    test_dataset = HUBROOMDataset(X_test_scaled, y_test_scaled, physics_test)
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    # 6. ëª¨ë¸ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    config = {
        'seq_len': 20,
        'n_features': n_features,
        'patch_len': 5,
        'd_model': 128,
        'n_heads': 8,
        'd_ff': 256,
        'n_layers': 3,
        'dropout': 0.1,
        'max_capacity': 200
    }
    
    # 7. Model 1: PatchTST í•™ìŠµ
    print("\n" + "="*60)
    print("ğŸ”· Model 1: PatchTST (ìˆœìˆ˜ ë°ì´í„° ê¸°ë°˜)")
    print("="*60)
    
    model1 = PatchTST(config)
    trainer1 = HUBROOMTrainer(model1, "PatchTST", device)
    trainer1.train(train_loader, val_loader, epochs=30, lr=0.001, use_physics=False)
    
    # í‰ê°€
    pred1, actual1, metrics1 = trainer1.evaluate(test_loader)
    
    # 8. Model 2: PatchTST + PINN í•™ìŠµ
    print("\n" + "="*60)
    print("ğŸ”¶ Model 2: PatchTST + PINN (ë¬¼ë¦¬ ì œì•½ í†µí•©)")
    print("="*60)
    
    model2 = PatchTST_PINN(config)
    trainer2 = HUBROOMTrainer(model2, "PatchTST+PINN", device)
    trainer2.train(train_loader, val_loader, epochs=30, lr=0.001, use_physics=True)
    
    # í‰ê°€
    pred2, actual2, metrics2 = trainer2.evaluate(test_loader)
    
    # 9. ê²°ê³¼ ë¹„êµ
    print("\n" + "="*60)
    print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    print("="*60)
    
    comparison_df = pd.DataFrame({
        'Model': ['PatchTST', 'PatchTST+PINN'],
        'MAE': [metrics1['mae'], metrics2['mae']],
        'RMSE': [metrics1['rmse'], metrics2['rmse']],
        'MAPE(%)': [metrics1['mape'], metrics2['mape']]
    })
    
    print(comparison_df.to_string(index=False))
    
    # 10. ì˜ˆì¸¡ ì‹œê°í™”
    plt.figure(figsize=(15, 5))
    
    # ì‹¤ì œ vs ì˜ˆì¸¡ (ì²˜ìŒ 100ê°œë§Œ)
    n_show = min(100, len(actual1))
    
    plt.subplot(1, 3, 1)
    plt.plot(actual1[:n_show], label='ì‹¤ì œê°’', alpha=0.7)
    plt.plot(pred1[:n_show], label='PatchTST', alpha=0.7)
    plt.title('Model 1: PatchTST')
    plt.legend()
    plt.xlabel('ì‹œê°„')
    plt.ylabel('HUBROOM JOB ìˆ˜')
    
    plt.subplot(1, 3, 2)
    plt.plot(actual2[:n_show], label='ì‹¤ì œê°’', alpha=0.7)
    plt.plot(pred2[:n_show], label='PatchTST+PINN', alpha=0.7)
    plt.title('Model 2: PatchTST+PINN')
    plt.legend()
    plt.xlabel('ì‹œê°„')
    plt.ylabel('HUBROOM JOB ìˆ˜')
    
    plt.subplot(1, 3, 3)
    # í•™ìŠµ ê³¡ì„ 
    epochs_range = range(1, len(trainer1.history['train_loss']) + 1)
    plt.plot(epochs_range, trainer1.history['val_loss'], label='PatchTST Val Loss')
    plt.plot(epochs_range, trainer2.history['val_loss'], label='PatchTST+PINN Val Loss')
    plt.title('ê²€ì¦ ì†ì‹¤ ë¹„êµ')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig('hubroom_prediction_results.png', dpi=100)
    plt.show()
    
    # 11. ë¬¼ë¦¬ ì œì•½ ê²€ì¦
    print("\n" + "="*60)
    print("ğŸ”¬ ë¬¼ë¦¬ ì œì•½ ê²€ì¦")
    print("="*60)
    
    # ìŒìˆ˜ ì˜ˆì¸¡ ì²´í¬
    negative_pred1 = np.sum(pred1 < 0)
    negative_pred2 = np.sum(pred2 < 0)
    
    # ìš©ëŸ‰ ì´ˆê³¼ ì²´í¬ (ê°€ì •: ìµœëŒ€ 200)
    over_capacity1 = np.sum(pred1 > 200)
    over_capacity2 = np.sum(pred2 > 200)
    
    print(f"ìŒìˆ˜ ì˜ˆì¸¡:")
    print(f"  - PatchTST: {negative_pred1}ê°œ")
    print(f"  - PatchTST+PINN: {negative_pred2}ê°œ")
    print(f"\nìš©ëŸ‰ ì´ˆê³¼ ì˜ˆì¸¡ (>200):")
    print(f"  - PatchTST: {over_capacity1}ê°œ")
    print(f"  - PatchTST+PINN: {over_capacity2}ê°œ")
    
    # 12. ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜
    print("\n" + "="*60)
    print("ğŸ¯ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜")
    print("="*60)
    
    # ë§ˆì§€ë§‰ 20ë¶„ ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡
    if len(X_test) > 0:
        last_20min = X_test_scaled[-1:, :, :]
        last_20min_tensor = torch.FloatTensor(last_20min).to(device)
        
        model1.eval()
        model2.eval()
        
        with torch.no_grad():
            pred_model1 = model1(last_20min_tensor).cpu().numpy()[0]
            pred_model2 = model2(last_20min_tensor).cpu().numpy()[0]
        
        # ì—­ë³€í™˜
        pred_model1_original = scaler_y.inverse_transform([[pred_model1]])[0][0]
        pred_model2_original = scaler_y.inverse_transform([[pred_model2]])[0][0]
        actual_original = scaler_y.inverse_transform([[y_test_scaled[-1]]])[0][0]
        
        print(f"í˜„ì¬ ì‹œì  HUBROOM ìƒíƒœ:")
        print(f"  - ì‹¤ì œê°’: {actual_original:.0f}")
        print(f"\n10ë¶„ í›„ ì˜ˆì¸¡:")
        print(f"  - PatchTST: {pred_model1_original:.0f}")
        print(f"  - PatchTST+PINN: {pred_model2_original:.0f}")
        print(f"  - ì°¨ì´: {abs(pred_model1_original - pred_model2_original):.0f}")
    
    print("\n" + "="*60)
    print("âœ… ì‹œë‚˜ë¦¬ì˜¤ ì™„ë£Œ!")
    print("="*60)
    
    return model1, model2, comparison_df

# ì‹¤í–‰
if __name__ == "__main__":
    model1, model2, results = main_scenario()