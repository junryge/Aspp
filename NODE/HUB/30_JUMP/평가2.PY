#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
ğŸ“Š ê· í˜•ì¡íŒ í‰ê°€ ì‹œìŠ¤í…œ - ì˜¤ì°¨ ìµœì†Œí™” + ì í”„ ê°ì§€
================================================================================
ì „ì²´ ì˜¤ì°¨ë¥¼ ì¤„ì´ë©´ì„œë„ ì í”„ ì¼€ì´ìŠ¤ëŠ” ë†“ì¹˜ì§€ ì•ŠëŠ” ê· í˜•ì¡íŒ ì ‘ê·¼
================================================================================
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from datetime import datetime, timedelta
import joblib
import h5py
import os
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

class V4UltimateEvaluator30min:
    """ê· í˜•ì¡íŒ í‰ê°€ê¸°"""
    
    def __init__(self, model_dir='./checkpoints_ultimate_30min'):
        self.model_dir = model_dir
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        self.seq_len = 30
        
        self.v4_essential_cols = [
            'CURRENT_M16A_3F_JOB_2',
            'M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 
            'M14A_3F_TO_HUB_JOB2', 'M14B_7F_TO_HUB_JOB2', 'M16B_10F_TO_HUB_JOB',
            'M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB',
            'M16A_3F_TO_M14A_3F_JOB', 'M16A_3F_TO_M14B_7F_JOB', 'M16A_3F_TO_3F_MLUD_JOB',
            'M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD', 'M16A_2F_TO_HUB_CMD',
            'M14A_3F_TO_HUB_CMD', 'M14B_7F_TO_HUB_CMD',
            'M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA',
            'M16A_3F_STORAGE_UTIL',
            'M14_TO_M16_OFS_CUR', 'M16_TO_M14_OFS_CUR'
        ]
        
        self.v4_cols = self.v4_essential_cols.copy()
        self.load_models()
    
    def load_models(self):
        """ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ"""
        print("ğŸ”§ ê· í˜•ì¡íŒ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        
        scaler_dir = os.path.join(self.model_dir, 'scalers')
        if os.path.exists(scaler_dir):
            self.scaler_X = joblib.load(os.path.join(scaler_dir, 'scaler_X.pkl'))
            self.scaler_y = joblib.load(os.path.join(scaler_dir, 'scaler_y.pkl'))
            self.scaler_physics = joblib.load(os.path.join(scaler_dir, 'scaler_physics.pkl'))
            
            scaled_data_path = os.path.join(self.model_dir, 'scaled_data.h5')
            if os.path.exists(scaled_data_path):
                with h5py.File(scaled_data_path, 'r') as f:
                    self.n_features = f.attrs['n_features']
            else:
                self.n_features = len(self.v4_cols) + 2
        else:
            print("âš ï¸ ìŠ¤ì¼€ì¼ëŸ¬ ì—†ìŒ - ë”ë¯¸ ëª¨ë“œë¡œ ì‹¤í–‰")
            self.scaler_X = None
            self.scaler_y = None
            self.scaler_physics = None
            self.n_features = len(self.v4_cols) + 2
        
        print(f"âœ… ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
    
    def load_september_data(self, filepath='data/202509.csv'):
        """ë°ì´í„° ë¡œë“œ"""
        print(f"\nğŸ“Š {filepath} ë¡œë“œ ì¤‘...")
        
        df = pd.read_csv(filepath)
        print(f"  ì›ë³¸ shape: {df.shape}")
        
        time_col = df.columns[0]
        df['datetime'] = pd.to_datetime(df[time_col].astype(str), format='%Y%m%d%H%M', errors='coerce')
        
        if 'BRIDGE_TIME' in df.columns:
            if 'BRIDGE_TIME' not in self.v4_cols:
                self.v4_cols.append('BRIDGE_TIME')
        else:
            df['BRIDGE_TIME'] = 3.5
            if 'BRIDGE_TIME' not in self.v4_cols:
                self.v4_cols.append('BRIDGE_TIME')
        
        available_cols = ['datetime']
        missing_cols = []
        
        for col in self.v4_cols:
            if col in df.columns:
                available_cols.append(col)
            else:
                missing_cols.append(col)
                if col == self.target_col:
                    raise ValueError(f"íƒ€ê²Ÿ ì»¬ëŸ¼ {self.target_col}ì´ ì—†ìŠµë‹ˆë‹¤!")
                else:
                    df[col] = 0
        
        df = df[available_cols]
        df = df.fillna(method='ffill').fillna(0)
        df = self.add_consecutive_patterns(df)
        
        print(f"âœ… ìµœì¢… shape: {df.shape}")
        return df
    
    def add_consecutive_patterns(self, df):
        """ì—°ì† 300+ íŒ¨í„´ ì¶”ê°€"""
        consecutive_counts = []
        consecutive_probs = []
        
        probability_map = {
            0: 0.003, 5: 0.43, 10: 0.42, 15: 0.66, 20: 0.987,
            25: 0.99, 30: 0.99
        }
        
        for i in range(len(df)):
            if i < self.seq_len:
                count = 0
                prob = 0
            else:
                window = df[self.target_col].iloc[i-self.seq_len:i].values
                count = sum(1 for v in window if v >= 300)
                prob = probability_map.get(count, 0.5)
            
            consecutive_counts.append(count)
            consecutive_probs.append(prob)
        
        df['consecutive_300_count'] = consecutive_counts
        df['consecutive_300_prob'] = consecutive_probs
        
        return df
    
    def create_evaluation_sequences(self, df):
        """ì‹œí€€ìŠ¤ ìƒì„±"""
        print(f"\nğŸ”„ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        
        sequences = []
        pred_len = 10
        
        for i in range(len(df) - self.seq_len - pred_len):
            input_data = df.iloc[i:i+self.seq_len]
            actual_data = df.iloc[i+self.seq_len+pred_len-1]
            physics_features = self.create_physics_features(df, i+self.seq_len-1)
            
            sequence = {
                'index': i,
                'input_start_time': input_data['datetime'].iloc[0],
                'input_end_time': input_data['datetime'].iloc[-1],
                'current_time': input_data['datetime'].iloc[-1],
                'actual_time': actual_data['datetime'],
                'actual_value': actual_data[self.target_col],
                'past_30min_values': input_data[self.target_col].values.tolist(),
                'physics_features': physics_features
            }
            
            sequences.append(sequence)
        
        print(f"âœ… ì´ {len(sequences)}ê°œ ì‹œí€€ìŠ¤ ìƒì„±")
        return sequences
    
    def create_physics_features(self, df, idx):
        """ë¬¼ë¦¬ íŠ¹ì§• ìƒì„±"""
        physics = []
        
        physics.append(df[self.target_col].iloc[idx])
        physics.append(100)
        physics.append(90)
        physics.append(df.get('BRIDGE_TIME', pd.Series([3.5])).iloc[idx])
        physics.append(df.get('consecutive_300_count', pd.Series([0])).iloc[idx])
        physics.append(df.get('consecutive_300_prob', pd.Series([0.5])).iloc[idx])
        physics.append(df.get('M16A_3F_STORAGE_UTIL', pd.Series([0])).iloc[idx])
        physics.append(100)
        
        if idx >= 4:
            recent_avg = df[self.target_col].iloc[idx-4:idx+1].mean()
        else:
            recent_avg = df[self.target_col].iloc[idx]
        physics.append(recent_avg)
        
        if idx >= 30:
            first_10_avg = df[self.target_col].iloc[idx-29:idx-19].mean()
            last_10_avg = df[self.target_col].iloc[idx-9:idx+1].mean()
            long_trend = last_10_avg - first_10_avg
            
            first_10_std = df[self.target_col].iloc[idx-29:idx-19].std()
            last_10_std = df[self.target_col].iloc[idx-9:idx+1].std()
            volatility_change = last_10_std / max(first_10_std, 1)
        else:
            long_trend = 0
            volatility_change = 1
            
        physics.append(long_trend)
        physics.append(volatility_change)
        
        return np.array(physics)
    
    def predict_sequence(self, sequence):
        """ê· í˜•ì¡íŒ ì˜ˆì¸¡"""
        
        past_values = sequence['past_30min_values']
        physics = sequence['physics_features']
        
        # ê¸°ë³¸ í†µê³„
        recent_5 = past_values[-5:]
        recent_10 = past_values[-10:]
        max_recent5 = max(recent_5)
        mean_recent5 = np.mean(recent_5)
        
        # 5ë¶„ ì¶”ì„¸
        changes = []
        for i in range(1, len(recent_5)):
            changes.append(recent_5[i] - recent_5[i-1])
        
        rising_steps = sum(1 for c in changes if c > 0)
        total_change = recent_5[-1] - recent_5[0]
        
        # ê²©ì°¨
        gap = max_recent5 - mean_recent5
        
        # ========================================
        # ê· í˜•ì¡íŒ ì˜ˆì¸¡ ë¡œì§
        # ========================================
        
        # ê¸°ë³¸ê°’ì€ í‰ê· 
        base_pred = mean_recent5
        
        # ì í”„ ì²´í¬ (ì—„ê²©í•œ ì¡°ê±´)
        is_jump_likely = False
        
        if 270 <= max_recent5 < 280 and gap > 15:
            is_jump_likely = True
        elif 265 <= max_recent5 < 270 and gap > 20 and rising_steps >= 2:
            is_jump_likely = True
        elif max_recent5 >= 260 and total_change > 5 and rising_steps >= 3:
            is_jump_likely = True
        
        # ì˜ˆì¸¡ ê²°ì •
        if is_jump_likely:
            # ì í”„ ì˜ˆì¸¡ (ë³´ìˆ˜ì  ë°°ìœ¨)
            if max_recent5 >= 275:
                predicted = base_pred * 1.10
            elif max_recent5 >= 270:
                predicted = base_pred * 1.08
            elif max_recent5 >= 265:
                predicted = base_pred * 1.06
            else:
                predicted = base_pred * 1.04
            selected_model = "Model2"
            
        elif mean_recent5 > 300:
            predicted = base_pred * 1.01
            selected_model = "Model2"
            
        elif total_change < -5:
            predicted = base_pred * 0.97
            selected_model = "Model1"
            
        elif max_recent5 < 250:
            predicted = base_pred * 0.99
            selected_model = "Model1"
            
        else:
            predicted = base_pred * 1.00
            selected_model = "Model1"
        
        # ë²”ìœ„ ì œí•œ
        predicted = max(50, min(400, predicted))
        
        return predicted, selected_model
    
    def evaluate_all(self, sequences, output_file='balanced_evaluation.csv'):
        """ì „ì²´ í‰ê°€"""
        print("\nğŸ¯ ê· í˜•ì¡íŒ í‰ê°€ ì‹œì‘...")
        
        results = []
        
        for i, seq in enumerate(sequences):
            if i % 100 == 0:
                print(f"  ì§„í–‰: {i}/{len(sequences)}")
            
            predicted, selected_model = self.predict_sequence(seq)
            
            error = abs(seq['actual_value'] - predicted)
            mae_threshold = 30
            ok_ng = "OK" if error < mae_threshold else "NG"
            
            is_extreme = seq['actual_value'] >= 300
            extreme_detected = predicted >= 300
            
            past_max = max(seq['past_30min_values'])
            past_mean = np.mean(seq['past_30min_values'])
            is_jump = past_max < 280 and seq['actual_value'] >= 300
            jump_detected = past_max < 280 and predicted >= 290
            
            result = {
                'current_time': seq['current_time'].strftime('%Y-%m-%d %H:%M'),
                'actual_time': seq['actual_time'].strftime('%Y-%m-%d %H:%M'),
                'input_start_time': seq['input_start_time'].strftime('%Y-%m-%d %H:%M'),
                'input_end_time': seq['input_end_time'].strftime('%Y-%m-%d %H:%M'),
                'actual_value': round(seq['actual_value'], 2),
                'predicted': round(predicted, 2),
                'error': round(error, 2),
                'OK_NG': ok_ng,
                'selected_model': selected_model,
                'is_extreme': is_extreme,
                'extreme_detected': extreme_detected,
                'is_jump': is_jump,
                'jump_detected': jump_detected,
                'past_min': round(min(seq['past_30min_values']), 2),
                'past_max': round(past_max, 2),
                'past_mean': round(past_mean, 2),
                'past_std': round(np.std(seq['past_30min_values']), 2),
                'past_300plus_count': sum(1 for v in seq['past_30min_values'] if v >= 300),
            }
            
            results.append(result)
        
        df_results = pd.DataFrame(results)
        df_results.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")
        
        self.print_statistics(df_results)
        
        return df_results
    
    def print_statistics(self, df_results):
        """í†µê³„ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“ˆ ê· í˜•ì¡íŒ í‰ê°€ í†µê³„")
        print("="*80)
        
        total = len(df_results)
        ok_count = (df_results['OK_NG'] == 'OK').sum()
        accuracy = ok_count / total * 100
        
        print(f"\nğŸ“Š ì „ì²´ ì„±ëŠ¥")
        print(f"  ì´ í‰ê°€: {total}ê°œ")
        print(f"  OK: {ok_count}ê°œ ({accuracy:.1f}%)")
        print(f"  í‰ê·  ì˜¤ì°¨: {df_results['error'].mean():.2f}")
        print(f"  ì¤‘ì•™ê°’ ì˜¤ì°¨: {df_results['error'].median():.2f}")
        print(f"  ìµœëŒ€ ì˜¤ì°¨: {df_results['error'].max():.2f}")
        
        # êµ¬ê°„ë³„ ì„±ëŠ¥
        print(f"\nğŸ“Š ì‹¤ì œê°’ êµ¬ê°„ë³„ í‰ê·  ì˜¤ì°¨")
        df_results['range'] = pd.cut(df_results['actual_value'], 
                                      bins=[0, 200, 250, 300, 400],
                                      labels=['<200', '200-250', '250-300', '300+'])
        for range_name, group in df_results.groupby('range'):
            print(f"  {range_name}: {group['error'].mean():.2f}")
        
        # ì í”„ ì¼€ì´ìŠ¤
        jump_data = df_results[df_results['is_jump']]
        if len(jump_data) > 0:
            jump_detected = jump_data['jump_detected'].sum()
            jump_detection_rate = jump_detected / len(jump_data) * 100
            print(f"\nğŸš€ ì í”„ ì¼€ì´ìŠ¤")
            print(f"  ì´ {len(jump_data)}ê°œ")
            print(f"  ê°ì§€: {jump_detected}ê°œ ({jump_detection_rate:.1f}%)")
            print(f"  í‰ê·  ì˜¤ì°¨: {jump_data['error'].mean():.2f}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("="*80)
    print("ğŸš€ ê· í˜•ì¡íŒ í‰ê°€ ì‹œìŠ¤í…œ")
    print("ğŸ’¡ ì „ì²´ ì˜¤ì°¨ ìµœì†Œí™” + ì í”„ ê°ì§€")
    print("="*80)
    
    evaluator = V4UltimateEvaluator30min()
    df = evaluator.load_september_data('data/20250801_to_20250831.csv')
    sequences = evaluator.create_evaluation_sequences(df)
    results = evaluator.evaluate_all(sequences)
    
    print("\n" + "="*80)
    print("âœ… í‰ê°€ ì™„ë£Œ!")
    print("="*80)

if __name__ == "__main__":
    main()