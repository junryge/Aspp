import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.inspection import permutation_importance
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

class FeaturePercentageImportance:
    """ì»¬ëŸ¼ë³„ ì˜í–¥ë„ë¥¼ í¼ì„¼íŠ¸ë¡œ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, data_path='data/HUB_0509_TO_0730_DATA.CSV'):
        self.data_path = data_path
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        self.seq_len = 20
        self.pred_len = 10
        
    def prepare_data_for_importance(self):
        """ì¤‘ìš”ë„ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
        print("ğŸ“‚ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(self.data_path)
        
        # ì‹œê°„ ì²˜ë¦¬
        time_col = df.columns[0]
        df['timestamp'] = pd.to_datetime(df[time_col], format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('timestamp').reset_index(drop=True)
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = df.fillna(method='ffill').fillna(0)
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        # íƒ€ê²Ÿ ì œì™¸
        feature_cols = [col for col in numeric_cols if col != self.target_col]
        
        # ë°ì´í„° ì¤€ë¹„
        X = df[feature_cols].values
        y = df[self.target_col].values
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(feature_cols)}ê°œ íŠ¹ì„±")
        
        return X_train, X_test, y_train, y_test, feature_cols
    
    def calculate_rf_importance(self, X_train, y_train, feature_cols):
        """Random Forest ê¸°ë°˜ ì¤‘ìš”ë„ ê³„ì‚°"""
        print("\nğŸŒ² Random Forest ì¤‘ìš”ë„ ê³„ì‚° ì¤‘...")
        
        # ëª¨ë¸ í•™ìŠµ
        rf_model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )
        rf_model.fit(X_train, y_train)
        
        # Feature importance
        importances = rf_model.feature_importances_
        
        # í¼ì„¼íŠ¸ë¡œ ë³€í™˜
        importance_percent = (importances / importances.sum()) * 100
        
        # DataFrame ìƒì„±
        importance_df = pd.DataFrame({
            'feature': feature_cols,
            'importance': importances,
            'percentage': importance_percent
        }).sort_values('percentage', ascending=False)
        
        return importance_df, rf_model
    
    def calculate_permutation_importance(self, rf_model, X_test, y_test, feature_cols):
        """Permutation ì¤‘ìš”ë„ ê³„ì‚°"""
        print("\nğŸ”„ Permutation ì¤‘ìš”ë„ ê³„ì‚° ì¤‘...")
        
        # Permutation importance ê³„ì‚°
        perm_importance = permutation_importance(
            rf_model, X_test, y_test,
            n_repeats=10,
            random_state=42,
            n_jobs=-1
        )
        
        # í¼ì„¼íŠ¸ë¡œ ë³€í™˜
        perm_importances = perm_importance.importances_mean
        perm_importances[perm_importances < 0] = 0  # ìŒìˆ˜ëŠ” 0ìœ¼ë¡œ
        perm_percent = (perm_importances / perm_importances.sum()) * 100
        
        # DataFrame ìƒì„±
        perm_df = pd.DataFrame({
            'feature': feature_cols,
            'importance': perm_importances,
            'percentage': perm_percent
        }).sort_values('percentage', ascending=False)
        
        return perm_df
    
    def calculate_variance_contribution(self, X_train, y_train, feature_cols):
        """ê° íŠ¹ì„±ì˜ ë¶„ì‚° ê¸°ì—¬ë„ ê³„ì‚°"""
        print("\nğŸ“Š ë¶„ì‚° ê¸°ì—¬ë„ ê³„ì‚° ì¤‘...")
        
        # í‘œì¤€í™”
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_train)
        
        # ê° íŠ¹ì„±ê³¼ íƒ€ê²Ÿì˜ ê³µë¶„ì‚°
        covariances = []
        for i in range(X_scaled.shape[1]):
            cov = np.abs(np.cov(X_scaled[:, i], y_train)[0, 1])
            covariances.append(cov)
        
        # í¼ì„¼íŠ¸ë¡œ ë³€í™˜
        covariances = np.array(covariances)
        var_percent = (covariances / covariances.sum()) * 100
        
        # DataFrame ìƒì„±
        var_df = pd.DataFrame({
            'feature': feature_cols,
            'covariance': covariances,
            'percentage': var_percent
        }).sort_values('percentage', ascending=False)
        
        return var_df
    
    def visualize_top_features(self, importance_df, title, top_n=20):
        """ìƒìœ„ íŠ¹ì„± ì‹œê°í™”"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
        
        # ìƒìœ„ Nê°œ ì„ íƒ
        top_df = importance_df.head(top_n)
        
        # 1. ë§‰ëŒ€ ê·¸ë˜í”„
        bars = ax1.barh(top_df['feature'], top_df['percentage'])
        
        # ìƒ‰ìƒ ê·¸ë¼ë°ì´ì…˜
        colors = plt.cm.Blues(np.linspace(0.4, 0.8, len(bars)))
        for bar, color in zip(bars, colors):
            bar.set_color(color)
        
        # ê°’ í‘œì‹œ
        for i, (feat, pct) in enumerate(zip(top_df['feature'], top_df['percentage'])):
            ax1.text(pct + 0.1, i, f'{pct:.1f}%', va='center')
        
        ax1.set_xlabel('ì˜í–¥ë„ (%)')
        ax1.set_title(f'{title} - Top {top_n}')
        ax1.grid(True, alpha=0.3)
        
        # 2. íŒŒì´ ì°¨íŠ¸ (ìƒìœ„ 10ê°œ + ê¸°íƒ€)
        top10 = importance_df.head(10)
        others_pct = importance_df.iloc[10:]['percentage'].sum()
        
        labels = list(top10['feature']) + ['ê¸°íƒ€']
        sizes = list(top10['percentage']) + [others_pct]
        
        # ê°€ì¥ í° ì¡°ê° ê°•ì¡°
        explode = [0.1 if i == 0 else 0 for i in range(len(labels))]
        
        ax2.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, 
                explode=explode, colors=plt.cm.Set3(range(len(labels))))
        ax2.set_title('ì „ì²´ ì˜í–¥ë„ ë¶„í¬')
        
        plt.tight_layout()
        return fig
    
    def create_comparison_report(self, rf_df, perm_df, var_df):
        """ì¢…í•© ë¹„êµ ë³´ê³ ì„œ ìƒì„±"""
        print("\n" + "="*80)
        print("ğŸ“Š ì»¬ëŸ¼ë³„ ì˜í–¥ë„ í¼ì„¼íŠ¸ ì¢…í•© ë³´ê³ ì„œ")
        print("="*80)
        
        # ìƒìœ„ 10ê°œ íŠ¹ì„± ë¹„êµ
        print("\nğŸ† TOP 10 íŠ¹ì„± ë¹„êµ (ë‹¨ìœ„: %)")
        print("-"*80)
        print(f"{'ìˆœìœ„':<5} {'íŠ¹ì„±ëª…':<30} {'RF ì¤‘ìš”ë„':<15} {'Permutation':<15} {'ë¶„ì‚° ê¸°ì—¬ë„':<15}")
        print("-"*80)
        
        # ê° ë°©ë²•ì˜ ìƒìœ„ 10ê°œ
        for i in range(10):
            rf_feat = rf_df.iloc[i]['feature'] if i < len(rf_df) else ''
            rf_pct = rf_df.iloc[i]['percentage'] if i < len(rf_df) else 0
            
            perm_feat = perm_df.iloc[i]['feature'] if i < len(perm_df) else ''
            perm_pct = perm_df.iloc[i]['percentage'] if i < len(perm_df) else 0
            
            var_feat = var_df.iloc[i]['feature'] if i < len(var_df) else ''
            var_pct = var_df.iloc[i]['percentage'] if i < len(var_df) else 0
            
            # RF ê¸°ì¤€ìœ¼ë¡œ ì¶œë ¥
            print(f"{i+1:<5} {rf_feat:<30} {rf_pct:<15.1f} ", end='')
            
            # ê°™ì€ íŠ¹ì„± ì°¾ê¸°
            perm_match = perm_df[perm_df['feature'] == rf_feat]
            var_match = var_df[var_df['feature'] == rf_feat]
            
            perm_val = perm_match['percentage'].values[0] if len(perm_match) > 0 else 0
            var_val = var_match['percentage'].values[0] if len(var_match) > 0 else 0
            
            print(f"{perm_val:<15.1f} {var_val:<15.1f}")
        
        # í‰ê·  ì¤‘ìš”ë„ ê³„ì‚°
        print("\nğŸ“ˆ í†µí•© ì¤‘ìš”ë„ (3ê°€ì§€ ë°©ë²• í‰ê· )")
        print("-"*60)
        
        # ëª¨ë“  íŠ¹ì„±ì— ëŒ€í•´ í‰ê·  ê³„ì‚°
        all_features = set(rf_df['feature']) | set(perm_df['feature']) | set(var_df['feature'])
        
        combined_importance = []
        for feat in all_features:
            rf_val = rf_df[rf_df['feature'] == feat]['percentage'].values
            perm_val = perm_df[perm_df['feature'] == feat]['percentage'].values
            var_val = var_df[var_df['feature'] == feat]['percentage'].values
            
            rf_pct = rf_val[0] if len(rf_val) > 0 else 0
            perm_pct = perm_val[0] if len(perm_val) > 0 else 0
            var_pct = var_val[0] if len(var_val) > 0 else 0
            
            avg_pct = (rf_pct + perm_pct + var_pct) / 3
            
            combined_importance.append({
                'feature': feat,
                'avg_percentage': avg_pct,
                'rf': rf_pct,
                'perm': perm_pct,
                'var': var_pct
            })
        
        # ì •ë ¬
        combined_df = pd.DataFrame(combined_importance).sort_values('avg_percentage', ascending=False)
        
        # ìƒìœ„ 15ê°œ ì¶œë ¥
        for i, row in combined_df.head(15).iterrows():
            print(f"{row['feature']:<35} í‰ê· : {row['avg_percentage']:>5.1f}% "
                  f"(RF: {row['rf']:>5.1f}%, Perm: {row['perm']:>5.1f}%, Var: {row['var']:>5.1f}%)")
        
        # ëˆ„ì  ì˜í–¥ë„
        print("\nğŸ“Š ëˆ„ì  ì˜í–¥ë„ ë¶„ì„")
        print("-"*40)
        cumsum = combined_df['avg_percentage'].cumsum()
        milestones = [50, 70, 80, 90]
        for milestone in milestones:
            n_features = (cumsum <= milestone).sum()
            print(f"ìƒìœ„ {n_features}ê°œ íŠ¹ì„±ì´ ì „ì²´ì˜ {milestone}% ì„¤ëª…")
        
        return combined_df
    
    def visualize_combined_importance(self, combined_df):
        """í†µí•© ì¤‘ìš”ë„ ì‹œê°í™”"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. í†µí•© ì¤‘ìš”ë„ ë§‰ëŒ€ ê·¸ë˜í”„
        ax1 = axes[0, 0]
        top15 = combined_df.head(15)
        bars = ax1.barh(top15['feature'], top15['avg_percentage'])
        
        # ê·¸ë¼ë°ì´ì…˜ ìƒ‰ìƒ
        colors = plt.cm.Reds(np.linspace(0.3, 0.8, len(bars)))
        for bar, color in zip(bars, colors[::-1]):
            bar.set_color(color)
        
        # ê°’ í‘œì‹œ
        for i, (idx, row) in enumerate(top15.iterrows()):
            ax1.text(row['avg_percentage'] + 0.1, i, f"{row['avg_percentage']:.1f}%", va='center')
        
        ax1.set_xlabel('í‰ê·  ì˜í–¥ë„ (%)')
        ax1.set_title('í†µí•© ì¤‘ìš”ë„ Top 15')
        ax1.grid(True, alpha=0.3)
        
        # 2. ë°©ë²•ë³„ ë¹„êµ (ìƒìœ„ 10ê°œ)
        ax2 = axes[0, 1]
        top10 = combined_df.head(10)
        x = np.arange(len(top10))
        width = 0.25
        
        ax2.bar(x - width, top10['rf'], width, label='Random Forest', color='skyblue')
        ax2.bar(x, top10['perm'], width, label='Permutation', color='lightcoral')
        ax2.bar(x + width, top10['var'], width, label='Variance', color='lightgreen')
        
        ax2.set_xlabel('íŠ¹ì„±')
        ax2.set_ylabel('ì˜í–¥ë„ (%)')
        ax2.set_title('ë°©ë²•ë³„ ì¤‘ìš”ë„ ë¹„êµ')
        ax2.set_xticks(x)
        ax2.set_xticklabels(top10['feature'], rotation=45, ha='right')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. ëˆ„ì  ì¤‘ìš”ë„ ê³¡ì„ 
        ax3 = axes[1, 0]
        cumsum = combined_df['avg_percentage'].cumsum()
        ax3.plot(range(1, len(cumsum)+1), cumsum, 'b-', linewidth=2)
        ax3.fill_between(range(1, len(cumsum)+1), cumsum, alpha=0.3)
        
        # ì£¼ìš” ì§€ì  í‘œì‹œ
        milestones = [50, 70, 80, 90]
        for milestone in milestones:
            idx = (cumsum <= milestone).sum()
            ax3.plot(idx, milestone, 'ro', markersize=8)
            ax3.annotate(f'{idx}ê°œ íŠ¹ì„±\n{milestone}%', 
                        xy=(idx, milestone), 
                        xytext=(idx+5, milestone-5),
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7))
        
        ax3.set_xlabel('íŠ¹ì„± ìˆ˜')
        ax3.set_ylabel('ëˆ„ì  ì˜í–¥ë„ (%)')
        ax3.set_title('ëˆ„ì  ì˜í–¥ë„ ê³¡ì„ ')
        ax3.grid(True, alpha=0.3)
        ax3.set_xlim(0, min(50, len(cumsum)))
        
        # 4. ì˜í–¥ë„ ë¶„í¬
        ax4 = axes[1, 1]
        ax4.hist(combined_df['avg_percentage'], bins=30, color='purple', alpha=0.7, edgecolor='black')
        ax4.axvline(combined_df['avg_percentage'].mean(), color='red', linestyle='--', 
                   label=f'í‰ê· : {combined_df["avg_percentage"].mean():.2f}%')
        ax4.axvline(combined_df['avg_percentage'].median(), color='green', linestyle='--', 
                   label=f'ì¤‘ì•™ê°’: {combined_df["avg_percentage"].median():.2f}%')
        
        ax4.set_xlabel('ì˜í–¥ë„ (%)')
        ax4.set_ylabel('íŠ¹ì„± ìˆ˜')
        ax4.set_title('ì˜í–¥ë„ ë¶„í¬')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        return fig

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = FeaturePercentageImportance()
    
    try:
        # 1. ë°ì´í„° ì¤€ë¹„
        X_train, X_test, y_train, y_test, feature_cols = analyzer.prepare_data_for_importance()
        
        # 2. Random Forest ì¤‘ìš”ë„
        rf_importance_df, rf_model = analyzer.calculate_rf_importance(X_train, y_train, feature_cols)
        rf_fig = analyzer.visualize_top_features(rf_importance_df, "Random Forest ì¤‘ìš”ë„")
        plt.savefig('rf_importance_percentage.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # 3. Permutation ì¤‘ìš”ë„
        perm_importance_df = analyzer.calculate_permutation_importance(
            rf_model, X_test, y_test, feature_cols
        )
        perm_fig = analyzer.visualize_top_features(perm_importance_df, "Permutation ì¤‘ìš”ë„")
        plt.savefig('permutation_importance_percentage.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # 4. ë¶„ì‚° ê¸°ì—¬ë„
        var_importance_df = analyzer.calculate_variance_contribution(X_train, y_train, feature_cols)
        var_fig = analyzer.visualize_top_features(var_importance_df, "ë¶„ì‚° ê¸°ì—¬ë„")
        plt.savefig('variance_importance_percentage.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # 5. ì¢…í•© ë¹„êµ ë³´ê³ ì„œ
        combined_df = analyzer.create_comparison_report(
            rf_importance_df, perm_importance_df, var_importance_df
        )
        
        # 6. í†µí•© ì‹œê°í™”
        combined_fig = analyzer.visualize_combined_importance(combined_df)
        plt.savefig('combined_importance_percentage.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # 7. CSV ì €ì¥
        combined_df.to_csv('feature_importance_percentages.csv', index=False)
        print("\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ê°€ CSV íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()