# -*- coding: utf-8 -*- 
# ê¸°ë³¸ ì‹¤í–‰
python MAIN_LSTM_SINGLE_20250709_CPU.py

# íŒŒë¼ë¯¸í„°ì™€ í•¨ê»˜ ì‹¤í–‰
python MAIN_LSTM_SINGLE_20250709_CPU.py 0 5

# VHL OFF ìƒí™© í…ŒìŠ¤íŠ¸
python MAIN_LSTM_SINGLE_20250709_CPU.py 1 10
#MAIN LSTM_SINGLE_20250709 - CPU ìµœì í™” ë²„ì „
import numpy as np
import pandas as pd

# TensorFlow 2.15.0 CPU í˜¸í™˜ì„± ì„¤ì •
import warnings
warnings.filterwarnings('ignore')
import os

# CPU ì „ìš© ì„¤ì •
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # GPU ì™„ì „ ë¹„í™œì„±í™”
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'false'

import tensorflow as tf

# CPUë§Œ ì‚¬ìš©í•˜ë„ë¡ ê°•ì œ ì„¤ì •
tf.config.set_visible_devices([], 'GPU')

from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import load_model
from sklearn.metrics import mean_squared_error, mean_absolute_error
import sys
from tensorflow.keras.models import Sequential,load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_squared_error, mean_absolute_error

# preproc í´ë”ì˜ ìƒëŒ€ ê²½ë¡œ ì¶”ê°€
preproc_path = os.path.join(os.path.dirname(__file__), 'preproc')
sys.path.append(preproc_path)

from datetime import datetime
from EMPTY_ROW_SPLIT import EmptyRowSplit
#from ADD_OHT_ERROR import process_data_in_chunks 
from MAKE_UTIL import process_data_in_chunks as make_util_process_data_in_chunks
from MAKE_FUTURE import process_data_in_chunks as make_future_process_data_in_chunks
import joblib
import logging

tf.get_logger().setLevel(logging.ERROR)


def parse_command_arguments():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ë¥¼ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜"""
    if len(sys.argv) > 1:
        param1 = sys.argv[1] 
        param2 = sys.argv[2]
        priority = int(param1)  # Convert to integer
        add_argument = int(param2)
        print(f"íŒŒë¼ë¯¸í„° ë°›ìŒ: priority={priority}, add_argument={add_argument}")
    else:   #argument ì „ë‹¬ ëª»ë°›ì€ ê²½ìš° ê¸°ë³¸ê°’ 0ìœ¼ë¡œ ì ìš©
        priority = 0
        add_argument = 0
        print("ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©: priority=0, add_argument=0")
    
    return priority, add_argument


def preprocess_data(input_file_path):
    """ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
    print("=== ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ===")
    
    # 1. EMPTY_ROW_SPLIT ì²˜ë¦¬
    print("1. EMPTY_ROW_SPLIT ì²˜ë¦¬ ì¤‘...")
    empty_row_split = EmptyRowSplit(input_file_path, "HUBROOM")
    datalist = empty_row_split.process_data()
    print(f"   ë°ì´í„° ì²­í¬ ê°œìˆ˜: {len(datalist)}")

    # 2. OHT ERROR ì»¬ëŸ¼ ì¶”ê°€ ì²˜ë¦¬ (í˜„ì¬ ì£¼ì„ ì²˜ë¦¬ë¨)
    #processed_data = process_data_in_chunks(datalist,'OHT_ERROR_0624_TO_0630.csv')

    # 3. ìœ í‹¸ë¦¬í‹° ì»¬ëŸ¼ ì¶”ê°€ ì²˜ë¦¬
    print("2. MAKE_UTIL ì²˜ë¦¬ ì¤‘...")
    utility_data = make_util_process_data_in_chunks(datalist)
    print("   ìœ í‹¸ë¦¬í‹° ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")

    # 4. future ì»¬ëŸ¼ ì¶”ê°€ ì²˜ë¦¬ 
    print("3. MAKE_FUTURE ì²˜ë¦¬ ì¤‘...")
    future_data = make_future_process_data_in_chunks(utility_data, 'CURRENT_M16A_3F_JOB_2', 'HUBROOM')
    print("   Future ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")

    # 5. ê²°ì¸¡ì¹˜ ì œê±° ë° ìœ íš¨ ë°ì´í„° í•„í„°ë§
    result_list = {}
    for key, data_chunk in future_data.items():
        df = data_chunk.copy()
        # future ì»¬ëŸ¼ì´ NaNì¸ í–‰ ì œê±°
        df.dropna(subset=['future'], inplace=True)
        if(df.size != 0): #ë°ì´í„°ê°€ ì—†ëŠ” chunk ì œì™¸
            result_list[key] = df
            print(f"   ìœ íš¨í•œ ì²­í¬ {key}: {len(df)}ê°œ í–‰")
    
    print(f"=== ì „ì²˜ë¦¬ ì™„ë£Œ: ì´ {len(result_list)}ê°œ ì²­í¬ ===")
    return result_list


def load_model_and_scaler():
    """ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    print("=== ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë”© ===")
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°
    current_dir = os.path.dirname(os.path.abspath(__file__))
    while not os.path.exists(os.path.join(current_dir, 'data')):
        current_dir = os.path.dirname(current_dir)

    # ëª¨ë¸ ë¡œë”© (TF 2.15.0 í˜¸í™˜ì„± ì²˜ë¦¬)
    model_name = 'LSTM_TEST_070714.keras'
    model_path = os.path.join(current_dir, "model", model_name)
    
    print(f"ëª¨ë¸ ê²½ë¡œ: {model_path}")
    print(f"ëª¨ë¸ íŒŒì¼ ì¡´ì¬: {os.path.exists(model_path)}")
    
    # ë‹¤ì¤‘ ì‹œë„ ëª¨ë¸ ë¡œë”©
    model = None
    try:
        # ë°©ë²• 1: ê¸°ë³¸ ë¡œë”©
        print("ë°©ë²• 1: ê¸°ë³¸ ë¡œë”© ì‹œë„...")
        model = load_model(model_path, compile=False)
        print("âœ… ê¸°ë³¸ ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ ë¡œë”© ì„±ê³µ!")
    except Exception as e1:
        print(f"âŒ ê¸°ë³¸ ë¡œë”© ì‹¤íŒ¨: {str(e1)[:100]}...")
        try:
            # ë°©ë²• 2: safe_mode=False ì‚¬ìš©
            print("ë°©ë²• 2: safe_mode=False ì‹œë„...")
            model = tf.keras.models.load_model(
                model_path, 
                compile=False,
                safe_mode=False
            )
            print("âœ… safe_mode=Falseë¡œ ëª¨ë¸ ë¡œë”© ì„±ê³µ!")
        except Exception as e2:
            print(f"âŒ safe_mode ë¡œë”©ë„ ì‹¤íŒ¨: {str(e2)[:100]}...")
            try:
                # ë°©ë²• 3: CPU ê°•ì œ ì‚¬ìš©
                print("ë°©ë²• 3: CPU ê°•ì œ ì‚¬ìš© ì‹œë„...")
                with tf.device('/CPU:0'):
                    model = tf.keras.models.load_model(model_path, compile=False)
                print("âœ… CPU ë””ë°”ì´ìŠ¤ë¡œ ëª¨ë¸ ë¡œë”© ì„±ê³µ!")
            except Exception as e3:
                print(f"âŒ ëª¨ë“  ë°©ë²• ì‹¤íŒ¨: {e3}")
                print("ëª¨ë¸ íŒŒì¼ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
                raise e3

    # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë”©
    scaler_name = 'LSTM_TEST_scaler_070714.save'
    scaler_path = os.path.join(current_dir, "scaler", scaler_name)
    
    print(f"ìŠ¤ì¼€ì¼ëŸ¬ ê²½ë¡œ: {scaler_path}")
    print(f"ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ì¡´ì¬: {os.path.exists(scaler_path)}")
    
    scaler = joblib.load(scaler_path)
    print("âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë”© ì™„ë£Œ")
    
    return model, scaler


def prepare_prediction_data(result_list, scaler):
    """ì˜ˆì¸¡ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜"""
    print("=== ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„ ===")
    
    # ì´ˆê¸°í™”
    X_not_scaled_all = []
    X_seq_all = []
    y_seq_all = []
    future_y_seq_all = []
    time_seq_all = []

    # ê° ë°ì´í„° ì²­í¬ì— ëŒ€í•´ ì „ì²˜ë¦¬
    for key, data_chunk in result_list.items():
        print(f"ì²­í¬ {key} ì²˜ë¦¬ ì¤‘...")
        df = data_chunk.copy()
        
        # STAT_DTë¥¼ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        df['STAT_DT'] = pd.to_datetime(df['STAT_DT'], format='%Y-%m-%d %H:%M:%S')
        
        y = df['future']  # future ê°’ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ íƒ€ê²Ÿìœ¼ë¡œ ì„¤ì •
        future_values = df['future'].values  # future ê°’ ë³„ë„ë¡œ ì¶”ì¶œ
        time_data = df['STAT_DT'].values  # ì‹œê°„ ë°ì´í„° ë³„ë„ë¡œ ì¶”ì¶œ
        
        #oht_error_data = df['M16A_3F_OHT_ERROR'].values
        X = df.drop(columns=['STAT_DT', 'future'])
        X_scaled = scaler.transform(X)  # fit_transform -> transformìœ¼ë¡œ ìˆ˜ì •

        #oht_error_data = oht_error_data.reshape(-1,1)
        #X_scaled=np.hstack((X_scaled, oht_error_data))
        #X['M16A_3F_OHT_ERROR'] = df['M16A_3F_OHT_ERROR'].values

        # ê²°ê³¼ ëˆ„ì 
        X_not_scaled_all.extend(X.values)
        X_seq_all.extend(X_scaled)
        y_seq_all.extend(y.values)
        future_y_seq_all.extend(future_values)
        time_seq_all.extend(time_data)

    # ìµœì¢… ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
    X_not_scaled_all = np.array(X_not_scaled_all)
    X_seq_all = np.array(X_seq_all)
    y_seq_all = np.array(y_seq_all)
    future_y_seq_all = np.array(future_y_seq_all)
    time_seq_all = np.array(time_seq_all)

    print(f"ìµœì¢… ë°ì´í„° í˜•íƒœ: X_seq_all.shape = {X_seq_all.shape}")
    
    return X_seq_all, y_seq_all, future_y_seq_all, time_seq_all


def make_prediction(model, X_seq_all, add_argument):
    """ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
    print("=== AI ì˜ˆì¸¡ ìˆ˜í–‰ ===")
    
    # CPUì—ì„œ ì˜ˆì¸¡ ìˆ˜í–‰
    with tf.device('/CPU:0'):
        # ì‹œí€€ìŠ¤ ë°ì´í„° reshape
        X_seq_all = np.array(X_seq_all)
        X_seq_all = X_seq_all.reshape((1, X_seq_all.shape[0], X_seq_all.shape[1]))
        
        print(f"ì˜ˆì¸¡ ì…ë ¥ ë°ì´í„° í˜•íƒœ: {X_seq_all.shape}")
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = np.round(model.predict(X_seq_all, verbose=0).flatten()).astype(int)
        classification_label = int(predictions >= 0.7) 
        predictions = round(predictions[0]) 
        predictions_new = predictions + add_argument

        print(f"ì›ë³¸ ì˜ˆì¸¡ê°’: {predictions}")
        print(f"ë³´ì • í›„ ì˜ˆì¸¡ê°’: {predictions_new}")
        print(f"ìœ„í—˜ë„ íŒë‹¨: {classification_label} ({'ìœ„í—˜' if classification_label == 1 else 'ì •ìƒ'})")

    return predictions_new, classification_label


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ HUBROOM ë°˜ì†¡ëŸ‰ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹œì‘")
    print(f"TensorFlow ë²„ì „: {tf.__version__}")
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {tf.config.list_physical_devices()}")
    
    try:
        # 1. ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±
        priority, add_argument = parse_command_arguments()
        
        # 2. ë°ì´í„° ì „ì²˜ë¦¬
        input_file_path = "HUBROOM_PIVOT_DATA.csv"
        result_list = preprocess_data(input_file_path)
        
        if not result_list:
            print("âŒ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 3. ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        model, scaler = load_model_and_scaler()
        
        # 4. ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„
        X_seq_all, y_seq_all, future_y_seq_all, time_seq_all = prepare_prediction_data(result_list, scaler)
        
        # 5. ì˜ˆì¸¡ ìˆ˜í–‰
        predictions_new, classification_label = make_prediction(model, X_seq_all, add_argument)
        
        # 6. ìµœì¢… ê²°ê³¼ ì¶œë ¥
        row = [{
            "PREDICTVAL": predictions_new,
            "JUDGEVAL": classification_label,
            "MODEL": 'LSTM_070714',
        }]
        
        print("=== ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ===")
        print(row)
        
        return row
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    main()