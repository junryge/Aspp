import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

def evaluate_and_save_csv(test_file='BBB.CSV'):
    """
    ëª¨ë¸ í‰ê°€ + ìƒì„¸ CSV ì €ì¥ (ì‹œê°„ ì»¬ëŸ¼ í¬í•¨)
    """
    # ëª¨ë¸ ë¡œë“œ
    try:
        with open('xgboost_model_30min_10min.pkl', 'rb') as f:
            model = pickle.load(f)
    except:
        print("âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ")
        return
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    df_test = pd.read_csv(test_file, on_bad_lines='skip')
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
    
    # STAT_DT ì²˜ë¦¬
    if 'STAT_DT' in df_test.columns:
        try:
            df_test['STAT_DT'] = pd.to_datetime(df_test['STAT_DT'].astype(str), format='%Y%m%d%H%M')
        except:
            base_date = datetime(2024, 1, 1)
            df_test['STAT_DT'] = [base_date + timedelta(minutes=i) for i in range(len(df_test))]
    else:
        base_date = datetime(2024, 1, 1)
        df_test['STAT_DT'] = [base_date + timedelta(minutes=i) for i in range(len(df_test))]
    
    # Feature ìƒì„± ë° ì˜ˆì¸¡
    results = []
    indices = []
    X_test = []
    y_test = []
    seq_max_list = []
    seq_min_list = []
    
    for i in range(30, len(df_test) - 10):
        seq = df_test[TARGET_COL].iloc[i-30:i].values
        
        features = {
            'target_mean': np.mean(seq),
            'target_std': np.std(seq),
            'target_last_5_mean': np.mean(seq[-5:]),
            'target_max': np.max(seq),
            'target_min': np.min(seq),
            'target_slope': np.polyfit(np.arange(30), seq, 1)[0],
            'target_last_10_mean': np.mean(seq[-10:]),
            'target_first_10_mean': np.mean(seq[:10])
        }
        
        X_test.append(features)
        y_test.append(df_test[TARGET_COL].iloc[i:i+10].max())
        seq_max_list.append(np.max(seq))
        seq_min_list.append(np.min(seq))
        indices.append(i)
    
    X_test = pd.DataFrame(X_test)
    y_test = np.array(y_test)
    
    # ì˜ˆì¸¡
    y_pred = model.predict(X_test)
    
    # í‰ê°€ ì§€í‘œ
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    
    # ê²°ê³¼ DataFrame ìƒì„± (ì‹œê°„ ì •ë³´ í¬í•¨)
    jump_count = 0
    extreme_count = 0
    extreme_detected = 0
    
    for i, idx in enumerate(indices):
        current_time = df_test['STAT_DT'].iloc[idx]
        seq_start_time = df_test['STAT_DT'].iloc[idx-30]
        prediction_time = current_time + timedelta(minutes=10)
        
        is_jump = (seq_max_list[i] < 280) and (y_test[i] >= 300)
        if is_jump:
            jump_count += 1
        
        if y_test[i] >= 300:
            extreme_count += 1
            if y_pred[i] >= 290:
                extreme_detected += 1
        
        # CSV ì €ì¥ ì»¬ëŸ¼ (ì›í•˜ëŠ” ìˆœì„œëŒ€ë¡œ)
        results.append({
            'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
            'ì˜ˆì¸¡ì‹œê°„(+10ë¶„)': prediction_time.strftime('%Y-%m-%d %H:%M'),
            'ì‹œí€€ìŠ¤ì‹œì‘': seq_start_time.strftime('%Y-%m-%d %H:%M'),
            'ì‹œí€€ìŠ¤ì™„ë£Œ': current_time.strftime('%Y-%m-%d %H:%M'),
            'ì‹¤ì œê°’': round(y_test[i], 2),
            'ì˜ˆì¸¡ê°’': round(y_pred[i], 2),
            'ì˜¤ì°¨': round(abs(y_test[i] - y_pred[i]), 2),
            'ì˜¤ì°¨ìœ¨(%)': round(abs(y_test[i] - y_pred[i]) / y_test[i] * 100, 2),
            'ì‹œí€€ìŠ¤MAX': round(seq_max_list[i], 2),
            'ì‹œí€€ìŠ¤MIN': round(seq_min_list[i], 2),
            'ì‹œí€€ìŠ¤ë²”ìœ„': round(seq_max_list[i] - seq_min_list[i], 2),
            'ì í”„ì¼€ì´ìŠ¤': 'O' if is_jump else '-',
            'ê·¹ë‹¨ê°’(300+)': 'O' if y_test[i] >= 300 else '-',
            'ê·¹ë‹¨ê°’ê°ì§€': 'O' if (y_test[i] >= 300 and y_pred[i] >= 290) else '-'
        })
    
    df_results = pd.DataFrame(results)
    
    # í‰ê°€ ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š í‰ê°€ ê²°ê³¼ ({test_file}):")
    print(f"  MAE:  {mae:.2f}")
    print(f"  RMSE: {rmse:.2f}")
    print(f"  RÂ²:   {r2:.3f}")
    print(f"\n  ì „ì²´: {len(df_results)}ê°œ")
    print(f"  ê·¹ë‹¨ê°’: {extreme_count}ê°œ ({extreme_detected}ê°œ ê°ì§€, {extreme_detected/extreme_count*100 if extreme_count > 0 else 0:.1f}%)")
    print(f"  ì í”„: {jump_count}ê°œ")
    
    # CSV ì €ì¥
    df_results.to_csv('evaluation_results.csv', index=False, encoding='utf-8-sig')
    print(f"\nâœ… ìƒì„¸ ê²°ê³¼ ì €ì¥: evaluation_results.csv")
    
    # ìš”ì•½ ì €ì¥
    summary = pd.DataFrame([{
        'í‰ê°€íŒŒì¼': test_file,
        'í‰ê°€ì‹œê°„': datetime.now().strftime('%Y-%m-%d %H:%M'),
        'MAE': round(mae, 2),
        'RMSE': round(rmse, 2),
        'R2': round(r2, 3),
        'ì „ì²´ìƒ˜í”Œ': len(df_results),
        'ê·¹ë‹¨ê°’ê°œìˆ˜': extreme_count,
        'ê·¹ë‹¨ê°’ê°ì§€': extreme_detected,
        'ê°ì§€ìœ¨(%)': round(extreme_detected/extreme_count*100 if extreme_count > 0 else 0, 1),
        'ì í”„ì¼€ì´ìŠ¤': jump_count
    }])
    
    summary.to_csv('evaluation_summary.csv', index=False, encoding='utf-8-sig')
    print("âœ… ìš”ì•½ ì €ì¥: evaluation_summary.csv")
    
    return df_results

# ì‹¤í–‰
if __name__ == '__main__':
    results = evaluate_and_save_csv('BBB.CSV')
    
    # ë‹¤ë¥¸ íŒŒì¼ë„ í‰ê°€í•˜ë ¤ë©´
    # results = evaluate_and_save_csv('ë‹¤ë¥¸íŒŒì¼.csv')