# -*- coding: utf-8 -*-
"""
Created on Thu Oct  2 07:35:29 2025

@author: X0163954
"""

import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta

def create_features(seq_data, seq_target, FEATURE_COLS, df):
    """Feature ìƒì„± í•¨ìˆ˜"""
    features = {
        'target_mean': np.mean(seq_target),
        'target_std': np.std(seq_target),
        'target_last_5_mean': np.mean(seq_target[-5:]),
        'target_max': np.max(seq_target),
        'target_min': np.min(seq_target),
        'target_slope': np.polyfit(np.arange(len(seq_target)), seq_target, 1)[0],
        'target_last_10_mean': np.mean(seq_target[-10:]),
        'target_first_10_mean': np.mean(seq_target[:10])
    }
    
    # ê° ì»¬ëŸ¼ ê·¸ë£¹ë³„ íŠ¹ì„± ì¶”ê°€
    for group_name, cols in FEATURE_COLS.items():
        for col in cols:
            if col in df.columns:
                col_seq = seq_data[col].values
                
                # ê¸°ë³¸ í†µê³„
                features[f'{col}_mean'] = np.mean(col_seq)
                features[f'{col}_std'] = np.std(col_seq)
                features[f'{col}_max'] = np.max(col_seq)
                features[f'{col}_min'] = np.min(col_seq)
                
                # ìµœê·¼ íŠ¹ì„±
                features[f'{col}_last_5_mean'] = np.mean(col_seq[-5:])
                features[f'{col}_last_10_mean'] = np.mean(col_seq[-10:])
                
                # ì¶”ì„¸
                features[f'{col}_slope'] = np.polyfit(np.arange(len(col_seq)), col_seq, 1)[0]
                
                # êµ¬ê°„ë³„ í‰ê· 
                features[f'{col}_first_10_mean'] = np.mean(col_seq[:10])
                features[f'{col}_mid_10_mean'] = np.mean(col_seq[10:20])
                features[f'{col}_last_value'] = col_seq[-1]
    
    # ìœ ì…-ìœ ì¶œ ì°¨ì´ (Net Flow)
    inflow_sum = 0
    outflow_sum = 0
    for col in FEATURE_COLS['inflow']:
        if col in df.columns:
            inflow_sum += seq_data[col].iloc[-1]
    for col in FEATURE_COLS['outflow']:
        if col in df.columns:
            outflow_sum += seq_data[col].iloc[-1]
    features['net_flow'] = inflow_sum - outflow_sum
    
    # CMD ì´í•©
    cmd_sum = 0
    for col in FEATURE_COLS['cmd']:
        if col in df.columns:
            cmd_sum += seq_data[col].iloc[-1]
    features['total_cmd'] = cmd_sum
    
    return features

def evaluate_all_predictions():
    """ì „ì²´ ë°ì´í„°ë¥¼ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ í‰ê°€ - 10ë¶„/20ë¶„/30ë¶„ ì˜ˆì¸¡"""
   
    # í•µì‹¬ 12ê°œ ì»¬ëŸ¼
    FEATURE_COLS = {
        'storage': ['M16A_3F_STORAGE_UTIL'],
        'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],
        'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],
        'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],
        'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA']
    }
    
    # ëª¨ë¸ ë¡œë“œ
    try:
        with open('xgboost_model_30min_10min_12ì»¬ëŸ¼.pkl', 'rb') as f:
            model = pickle.load(f)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {e}")
        return None
   
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv('HUB0906_0929.CSV', on_bad_lines='skip')
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")
   
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸
    print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸:")
    all_feature_cols = []
    for group_name, cols in FEATURE_COLS.items():
        available = [col for col in cols if col in df.columns]
        all_feature_cols.extend(available)
        print(f"  - {group_name}: {len(available)}/{len(cols)}ê°œ")
   
    # STAT_DT ì²˜ë¦¬
    if 'STAT_DT' in df.columns:
        try:
            df['STAT_DT'] = pd.to_datetime(df['STAT_DT'].astype(str), format='%Y%m%d%H%M')
        except:
            print("âš ï¸ STAT_DT ë³€í™˜ ì‹¤íŒ¨, ê°€ìƒ ì‹œê°„ ìƒì„±")
            base_time = datetime(2024, 1, 1, 0, 0)
            df['STAT_DT'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
   
    results = []
   
    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°: 30ê°œ ì‹œí€€ìŠ¤ â†’ 10/20/30ë¶„ í›„ ì˜ˆì¸¡
    for i in range(30, len(df) - 30):  # -30: 30ë¶„ í›„ ì‹¤ì œê°’ í™•ë³´
        # ê³¼ê±° 30ê°œ ë°ì´í„°
        seq_data_original = df.iloc[i-30:i].copy()
        seq_target_original = seq_data_original[TARGET_COL].values.copy()
       
        # í˜„ì¬ ì‹œì 
        current_time = seq_data_original['STAT_DT'].iloc[-1]
       
        # ===== 10ë¶„ í›„ ì˜ˆì¸¡ =====
        seq_data_10 = seq_data_original.copy()
        seq_target_10 = seq_target_original.copy()
        
        features_10 = create_features(seq_data_10, seq_target_10, FEATURE_COLS, df)
        X_pred_10 = pd.DataFrame([features_10])
        prediction_10min = model.predict(X_pred_10)[0]
        
        # ì‹¤ì œê°’ 10ë¶„ í›„
        actual_10min = df.iloc[i][TARGET_COL] if i < len(df) else None
        actual_time_10 = df.iloc[i]['STAT_DT'] if i < len(df) else None
        
        # ===== 20ë¶„ í›„ ì˜ˆì¸¡ (ì¬ê·€ì ) =====
        # ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸: í•œ ì¹¸ ë°€ê³  10ë¶„ ì˜ˆì¸¡ê°’ ì¶”ê°€
        seq_target_20 = np.append(seq_target_10[1:], prediction_10min)
        
        # ë‹¤ë¥¸ ì»¬ëŸ¼ë“¤ì€ ë§ˆì§€ë§‰ ê°’ ìœ ì§€ (ê°„ë‹¨í•œ ë°©ë²•)
        new_row = seq_data_10.iloc[-1:].copy()
        new_row[TARGET_COL] = prediction_10min
        seq_data_20 = pd.concat([seq_data_10.iloc[1:], new_row], ignore_index=True)
        
        features_20 = create_features(seq_data_20, seq_target_20, FEATURE_COLS, df)
        X_pred_20 = pd.DataFrame([features_20])
        prediction_20min = model.predict(X_pred_20)[0]
        
        # ì‹¤ì œê°’ 20ë¶„ í›„
        actual_20min = df.iloc[i+10][TARGET_COL] if i+10 < len(df) else None
        actual_time_20 = df.iloc[i+10]['STAT_DT'] if i+10 < len(df) else None
        
        # ===== 30ë¶„ í›„ ì˜ˆì¸¡ (ì¬ê·€ì ) =====
        seq_target_30 = np.append(seq_target_20[1:], prediction_20min)
        
        new_row_30 = seq_data_20.iloc[-1:].copy()
        new_row_30[TARGET_COL] = prediction_20min
        seq_data_30 = pd.concat([seq_data_20.iloc[1:], new_row_30], ignore_index=True)
        
        features_30 = create_features(seq_data_30, seq_target_30, FEATURE_COLS, df)
        X_pred_30 = pd.DataFrame([features_30])
        prediction_30min = model.predict(X_pred_30)[0]
        
        # ì‹¤ì œê°’ 30ë¶„ í›„
        actual_30min = df.iloc[i+20][TARGET_COL] if i+20 < len(df) else None
        actual_time_30 = df.iloc[i+20]['STAT_DT'] if i+20 < len(df) else None
        
        # 300 ì´ìƒ ì í”„ ê°ì§€
        jump_detected = np.any(seq_target_original >= 300)
        
        # ê²°ê³¼ ì €ì¥
        result = {
            'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
            
            # 10ë¶„ í›„
            'ì˜ˆì¸¡ì‹œì _10min': (current_time + timedelta(minutes=10)).strftime('%Y-%m-%d %H:%M'),
            'ì‹¤ì œì‹œì _10min': actual_time_10.strftime('%Y-%m-%d %H:%M') if actual_time_10 else '',
            'ì‹¤ì œê°’_10min': actual_10min if actual_10min else 0,
            'ì˜ˆì¸¡ê°’_10min': round(prediction_10min, 2),
            'ì˜¤ì°¨_10min': round(actual_10min - prediction_10min, 2) if actual_10min else 0,
            'ì˜¤ì°¨ìœ¨_10min(%)': round(abs(actual_10min - prediction_10min) / max(actual_10min, 1) * 100, 2) if actual_10min else 0,
            
            # 20ë¶„ í›„
            'ì˜ˆì¸¡ì‹œì _20min': (current_time + timedelta(minutes=20)).strftime('%Y-%m-%d %H:%M'),
            'ì‹¤ì œì‹œì _20min': actual_time_20.strftime('%Y-%m-%d %H:%M') if actual_time_20 else '',
            'ì‹¤ì œê°’_20min': actual_20min if actual_20min else 0,
            'ì˜ˆì¸¡ê°’_20min': round(prediction_20min, 2),
            'ì˜¤ì°¨_20min': round(actual_20min - prediction_20min, 2) if actual_20min else 0,
            'ì˜¤ì°¨ìœ¨_20min(%)': round(abs(actual_20min - prediction_20min) / max(actual_20min, 1) * 100, 2) if actual_20min else 0,
            
            # 30ë¶„ í›„
            'ì˜ˆì¸¡ì‹œì _30min': (current_time + timedelta(minutes=30)).strftime('%Y-%m-%d %H:%M'),
            'ì‹¤ì œì‹œì _30min': actual_time_30.strftime('%Y-%m-%d %H:%M') if actual_time_30 else '',
            'ì‹¤ì œê°’_30min': actual_30min if actual_30min else 0,
            'ì˜ˆì¸¡ê°’_30min': round(prediction_30min, 2),
            'ì˜¤ì°¨_30min': round(actual_30min - prediction_30min, 2) if actual_30min else 0,
            'ì˜¤ì°¨ìœ¨_30min(%)': round(abs(actual_30min - prediction_30min) / max(actual_30min, 1) * 100, 2) if actual_30min else 0,
            
            # ì‹œí€€ìŠ¤ ì •ë³´
            'ì‹œí€€ìŠ¤MAX': np.max(seq_target_original),
            'ì‹œí€€ìŠ¤MIN': np.min(seq_target_original),
            'ì‹œí€€ìŠ¤í‰ê· ': round(np.mean(seq_target_original), 2),
            '300ì´ìƒì í”„': 'ğŸ”´' if jump_detected else '',
            
            # ìƒíƒœ í”Œë˜ê·¸
            'ì‹¤ì œê°’ìƒíƒœ_10min': 'ğŸ”´ê·¹ë‹¨' if (actual_10min and actual_10min >= 300) else ('ğŸŸ¡ì£¼ì˜' if (actual_10min and actual_10min >= 280) else 'ğŸŸ¢ì •ìƒ'),
            'ì˜ˆì¸¡ê°’ìƒíƒœ_10min': 'ğŸ”´ê·¹ë‹¨' if prediction_10min >= 300 else ('ğŸŸ¡ì£¼ì˜' if prediction_10min >= 280 else 'ğŸŸ¢ì •ìƒ'),
            'ì‹¤ì œê°’ìƒíƒœ_20min': 'ğŸ”´ê·¹ë‹¨' if (actual_20min and actual_20min >= 300) else ('ğŸŸ¡ì£¼ì˜' if (actual_20min and actual_20min >= 280) else 'ğŸŸ¢ì •ìƒ'),
            'ì˜ˆì¸¡ê°’ìƒíƒœ_20min': 'ğŸ”´ê·¹ë‹¨' if prediction_20min >= 300 else ('ğŸŸ¡ì£¼ì˜' if prediction_20min >= 280 else 'ğŸŸ¢ì •ìƒ'),
            'ì‹¤ì œê°’ìƒíƒœ_30min': 'ğŸ”´ê·¹ë‹¨' if (actual_30min and actual_30min >= 300) else ('ğŸŸ¡ì£¼ì˜' if (actual_30min and actual_30min >= 280) else 'ğŸŸ¢ì •ìƒ'),
            'ì˜ˆì¸¡ê°’ìƒíƒœ_30min': 'ğŸ”´ê·¹ë‹¨' if prediction_30min >= 300 else ('ğŸŸ¡ì£¼ì˜' if prediction_30min >= 280 else 'ğŸŸ¢ì •ìƒ')
        }
        
        results.append(result)
       
        # ì§„í–‰ìƒí™© ì¶œë ¥
        if (i - 30) % 100 == 0:
            print(f"ì§„í–‰ì¤‘... {i-30}/{len(df)-60} ({(i-30)/(len(df)-60)*100:.1f}%)")
   
    # DataFrame ë³€í™˜
    results_df = pd.DataFrame(results)
   
    # CSV ì €ì¥
    output_file = 'prediction_evaluation_10_20_30min.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
   
    # í†µê³„ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ“Š í‰ê°€ í†µê³„ - 10ë¶„/20ë¶„/30ë¶„ í›„ ì˜ˆì¸¡")
    print("="*80)
    print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(results_df)}")
    
    print(f"\n[10ë¶„ í›„ ì˜ˆì¸¡]")
    print(f"  í‰ê·  ì˜¤ì°¨: {results_df['ì˜¤ì°¨_10min'].abs().mean():.2f}")
    print(f"  í‰ê·  ì˜¤ì°¨ìœ¨: {results_df['ì˜¤ì°¨ìœ¨_10min(%)'].mean():.2f}%")
    print(f"  ìµœëŒ€ ì˜¤ì°¨: {results_df['ì˜¤ì°¨_10min'].abs().max():.2f}")
    print(f"  ì‹¤ì œê°’ ê·¹ë‹¨(â‰¥300): {(results_df['ì‹¤ì œê°’_10min'] >= 300).sum()}ê°œ")
    print(f"  ì˜ˆì¸¡ê°’ ê·¹ë‹¨(â‰¥300): {(results_df['ì˜ˆì¸¡ê°’_10min'] >= 300).sum()}ê°œ")
    
    print(f"\n[20ë¶„ í›„ ì˜ˆì¸¡]")
    print(f"  í‰ê·  ì˜¤ì°¨: {results_df['ì˜¤ì°¨_20min'].abs().mean():.2f}")
    print(f"  í‰ê·  ì˜¤ì°¨ìœ¨: {results_df['ì˜¤ì°¨ìœ¨_20min(%)'].mean():.2f}%")
    print(f"  ìµœëŒ€ ì˜¤ì°¨: {results_df['ì˜¤ì°¨_20min'].abs().max():.2f}")
    print(f"  ì‹¤ì œê°’ ê·¹ë‹¨(â‰¥300): {(results_df['ì‹¤ì œê°’_20min'] >= 300).sum()}ê°œ")
    print(f"  ì˜ˆì¸¡ê°’ ê·¹ë‹¨(â‰¥300): {(results_df['ì˜ˆì¸¡ê°’_20min'] >= 300).sum()}ê°œ")
    
    print(f"\n[30ë¶„ í›„ ì˜ˆì¸¡]")
    print(f"  í‰ê·  ì˜¤ì°¨: {results_df['ì˜¤ì°¨_30min'].abs().mean():.2f}")
    print(f"  í‰ê·  ì˜¤ì°¨ìœ¨: {results_df['ì˜¤ì°¨ìœ¨_30min(%)'].mean():.2f}%")
    print(f"  ìµœëŒ€ ì˜¤ì°¨: {results_df['ì˜¤ì°¨_30min'].abs().max():.2f}")
    print(f"  ì‹¤ì œê°’ ê·¹ë‹¨(â‰¥300): {(results_df['ì‹¤ì œê°’_30min'] >= 300).sum()}ê°œ")
    print(f"  ì˜ˆì¸¡ê°’ ê·¹ë‹¨(â‰¥300): {(results_df['ì˜ˆì¸¡ê°’_30min'] >= 300).sum()}ê°œ")
    
    print(f"\n300ì´ìƒ ì í”„ êµ¬ê°„: {results_df['300ì´ìƒì í”„'].value_counts().get('ğŸ”´', 0)}ê°œ")
   
    # ìƒìœ„ ì˜¤ì°¨ êµ¬ê°„ (10ë¶„ ê¸°ì¤€)
    print("\n" + "="*80)
    print("âŒ 10ë¶„ í›„ ì˜ˆì¸¡ ì˜¤ì°¨ ìƒìœ„ 10ê°œ êµ¬ê°„")
    print("="*80)
    top_errors = results_df.nlargest(10, 'ì˜¤ì°¨ìœ¨_10min(%)')
    print(top_errors[['í˜„ì¬ì‹œê°„', 'ì‹¤ì œê°’_10min', 'ì˜ˆì¸¡ê°’_10min', 'ì˜¤ì°¨_10min', 'ì˜¤ì°¨ìœ¨_10min(%)', 'ì‹œí€€ìŠ¤MAX']].to_string(index=False))
   
    # ê·¹ë‹¨ê°’ êµ¬ê°„ (10ë¶„ í›„ ê¸°ì¤€)
    extreme_cases = results_df[results_df['ì‹¤ì œê°’_10min'] >= 300]
    if len(extreme_cases) > 0:
        print("\n" + "="*80)
        print("ğŸ”´ ì‹¤ì œ ê·¹ë‹¨ê°’(â‰¥300) êµ¬ê°„ - 10ë¶„ í›„")
        print("="*80)
        print(extreme_cases[['í˜„ì¬ì‹œê°„', 'ì‹¤ì œê°’_10min', 'ì˜ˆì¸¡ê°’_10min', 'ì˜¤ì°¨_10min', 'ì‹œí€€ìŠ¤MAX', 'ì‹œí€€ìŠ¤MIN']].head(10).to_string(index=False))
   
    return results_df

if __name__ == '__main__':
    print("ğŸš€ 10ë¶„/20ë¶„/30ë¶„ í›„ ì˜ˆì¸¡ í‰ê°€ ì‹œì‘...\n")
    results = evaluate_all_predictions()
   
    if results is not None:
        print(f"\nâœ… í‰ê°€ ì™„ë£Œ! ì´ {len(results)}ê°œ ì˜ˆì¸¡ ìƒì„±")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: prediction_evaluation_10_20_30min.csv")