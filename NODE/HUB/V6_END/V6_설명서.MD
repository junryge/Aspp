# HUBROOM ê·¹ë‹¨ê°’ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ê¸°ìˆ  ë¬¸ì„œ

## ğŸ“Œ Executive Summary

HUBROOM ê·¹ë‹¨ê°’ ì˜ˆì¸¡ ì‹œìŠ¤í…œì€ ê³¼ê±° 30ë¶„ê°„ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í–¥í›„ 10ë¶„ ë™ì•ˆ ë°œìƒí•  ìµœëŒ€ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. XGBoost ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ 98.9%ì˜ ê·¹ë‹¨ê°’ ê°ì§€ìœ¨ì„ ë‹¬ì„±í–ˆìœ¼ë©°, í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ëŠ” 15.87ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

### í•µì‹¬ ì„±ê³¼
- ì˜ˆì¸¡ ì •í™•ë„: RÂ² 0.912
- ê·¹ë‹¨ê°’(300+) ê°ì§€ìœ¨: 98.9%
- ì˜ˆì¸¡ ì†Œìš” ì‹œê°„: 0.1ì´ˆ
- 10ë¶„ ì‚¬ì „ ê²½ê³  ì œê³µ

---

## 1. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 1.1 ê¸°ìˆ  ìŠ¤íƒ
- **ì•Œê³ ë¦¬ì¦˜**: XGBoost (eXtreme Gradient Boosting)
- **í”„ë¡œê·¸ë˜ë° ì–¸ì–´**: Python 3.8+
- **ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬**: pandas, numpy, scikit-learn, xgboost
- **ë°ì´í„° í˜•ì‹**: CSV (1ë¶„ ë‹¨ìœ„ ì‹œê³„ì—´)

### 1.2 ëª¨ë¸ êµ¬ì„±
```python
XGBRegressor(
    n_estimators=100,     # 100ê°œ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬
    max_depth=5,          # íŠ¸ë¦¬ ê¹Šì´ 5
    learning_rate=0.1,    # í•™ìŠµë¥ 
    random_state=42       # ì¬í˜„ê°€ëŠ¥ì„±
)
```

### 1.3 ë°ì´í„° íŒŒì´í”„ë¼ì¸
ì›ì‹œ ë°ì´í„°(CSV) â†’ 30ë¶„ ì‹œí€€ìŠ¤ ì¶”ì¶œ â†’ Feature Engineering(8ê°œ) â†’ XGBoost ì˜ˆì¸¡ â†’ 10ë¶„ MAX ì¶œë ¥

---

## 2. ë°ì´í„° ì‚¬ì–‘

### 2.1 í•„ìˆ˜ ì»¬ëŸ¼
| ì»¬ëŸ¼ëª… | íƒ€ì… | ì„¤ëª… | ìš©ë„ |
|--------|------|------|------|
| CURRENT_M16A_3F_JOB_2 | Integer | HUBROOM í˜„ì¬ê°’ | ì˜ˆì¸¡ íƒ€ê²Ÿ |
| STAT_DT | DateTime | ì‹œê°„ ì •ë³´ (YYYYMMDDHHMM) | ì‹œê³„ì—´ ì •ë ¬ |

### 2.2 ë°ì´í„° ìš”êµ¬ì‚¬í•­
- ìµœì†Œ ë°ì´í„°: 40ê°œ ì‹œì  (30ë¶„ ì‹œí€€ìŠ¤ + 10ë¶„ ì˜ˆì¸¡)
- ê¶Œì¥ í•™ìŠµ ë°ì´í„°: 20,000ê°œ ì´ìƒ
- ì‹œê°„ ê°„ê²©: 1ë¶„ ë‹¨ìœ„
- ê²°ì¸¡ì¹˜: ì „ì²˜ë¦¬ í•„ìˆ˜

---

## 3. Feature Engineering (30ë¶„ ì‹œí€€ìŠ¤ ê¸°ë°˜)

### 3.1 8ê°œ í•µì‹¬ Feature

| # | Feature ëª…ì¹­ | ê³„ì‚°ì‹ | ì„¤ëª… | ì¤‘ìš”ë„ |
|---|-------------|--------|------|---------|
| 1 | target_last_5_mean | mean(seq[-5:]) | ìµœê·¼ 5ë¶„ í‰ê·  | â­â­â­â­â­ |
| 2 | target_max | max(seq[0:30]) | 30ë¶„ ìµœëŒ€ê°’ | â­â­â­â­ |
| 3 | target_mean | mean(seq[0:30]) | 30ë¶„ í‰ê·  | â­â­â­ |
| 4 | target_slope | polyfit(seq, 1)[0] | 30ë¶„ ì¶”ì„¸ ê¸°ìš¸ê¸° | â­â­â­ |
| 5 | target_last_10_mean | mean(seq[-10:]) | ìµœê·¼ 10ë¶„ í‰ê·  | â­â­ |
| 6 | target_std | std(seq[0:30]) | 30ë¶„ í‘œì¤€í¸ì°¨ | â­â­ |
| 7 | target_min | min(seq[0:30]) | 30ë¶„ ìµœì†Œê°’ | â­ |
| 8 | target_first_10_mean | mean(seq[0:10]) | ì´ˆê¸° 10ë¶„ í‰ê·  | â­ |

### 3.2 Feature ê³„ì‚° ì½”ë“œ
```python
def create_features(seq):  # seqëŠ” 30ê°œ ë°ì´í„°
    return {
        'target_mean': np.mean(seq),              # 30ë¶„ í‰ê· 
        'target_std': np.std(seq),                # 30ë¶„ í‘œì¤€í¸ì°¨
        'target_last_5_mean': np.mean(seq[-5:]),  # ìµœê·¼ 5ë¶„
        'target_max': np.max(seq),                # 30ë¶„ ìµœëŒ€
        'target_min': np.min(seq),                # 30ë¶„ ìµœì†Œ
        'target_slope': np.polyfit(np.arange(30), seq, 1)[0],
        'target_last_10_mean': np.mean(seq[-10:]),
        'target_first_10_mean': np.mean(seq[:10])
    }
```

---

## 4. í•™ìŠµ í”„ë¡œì„¸ìŠ¤

### 4.1 í•™ìŠµ ë°ì´í„° (aas.csv)
- **ì „ì²´ ë°ì´í„°**: 27,560ê°œ í–‰
- **í•™ìŠµ ê°€ëŠ¥ ìƒ˜í”Œ**: 27,520ê°œ (30ë¶„ ì‹œí€€ìŠ¤ + 10ë¶„ ì˜ˆì¸¡)
- **ê·¹ë‹¨ê°’(300+)**: 1,794ê°œ (6.5%)
- **ì í”„ ì¼€ì´ìŠ¤**: 186ê°œ (0.7%)
- **í•™ìŠµ ì‹œê°„**: ì•½ 3ë¶„

### 4.2 í•™ìŠµ ì½”ë“œ
```python
# ì‹œí€€ìŠ¤ ìƒì„± (i-30 ~ i-1 â†’ i ~ i+9 ì˜ˆì¸¡)
for i in range(30, len(df) - 10):
    seq = df['CURRENT_M16A_3F_JOB_2'].iloc[i-30:i].values
    features = create_features(seq)
    label = df['CURRENT_M16A_3F_JOB_2'].iloc[i:i+10].max()
    X_train.append(features)
    y_train.append(label)

# ëª¨ë¸ í•™ìŠµ
model = XGBRegressor(n_estimators=100, max_depth=5)
model.fit(X_train, y_train)
```

---

## 5. í‰ê°€ í”„ë¡œì„¸ìŠ¤

### 5.1 í…ŒìŠ¤íŠ¸ ë°ì´í„° (BBB.CSV)
- **ì „ì²´ ë°ì´í„°**: ë…ë¦½ëœ í…ŒìŠ¤íŠ¸ì…‹
- **í‰ê°€ ë°©ì‹**: 30ë¶„ ì‹œí€€ìŠ¤ë¡œ 10ë¶„ MAX ì˜ˆì¸¡
- **í‰ê°€ ì§€í‘œ**: MAE, RMSE, RÂ², ê·¹ë‹¨ê°’ ê°ì§€ìœ¨

### 5.2 í‰ê°€ ê²°ê³¼
| ì§€í‘œ | ê°’ | ì„¤ëª… |
|------|-----|------|
| MAE | 15.87 | í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ |
| RMSE | 22.45 | í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ |
| RÂ² | 0.912 | ê²°ì • ê³„ìˆ˜ |
| ê·¹ë‹¨ê°’ ê°ì§€ | 98.9% | 300+ ê°’ ê°ì§€ìœ¨ |
| ì í”„ ê°ì§€ | 19.9% | ê¸‰ê²©í•œ ë³€í™” ê°ì§€ìœ¨ |

### 5.3 í‰ê°€ ì½”ë“œ
```python
for i in range(30, len(df_test) - 10):
    seq = df_test['CURRENT_M16A_3F_JOB_2'].iloc[i-30:i].values
    features = create_features(seq)
    pred_max = model.predict([features])[0]
    actual_max = df_test['CURRENT_M16A_3F_JOB_2'].iloc[i:i+10].max()
```

---

## 6. ì‹¤ì‹œê°„ ì˜ˆì¸¡

### 6.1 ì…ë ¥ ë°ì´í„°
- **íŒŒì¼**: data/HUBROOM_PIVOT_DATA.CSV
- **ì²˜ë¦¬**: ìµœê·¼ 30ê°œ í–‰ ì¶”ì¶œ (tail(30))
- **ì‹œí€€ìŠ¤**: ì •í™•íˆ 30ë¶„ ë°ì´í„°

### 6.2 ì˜ˆì¸¡ í”„ë¡œì„¸ìŠ¤
1. CSVì—ì„œ ìµœê·¼ 30ê°œ ë°ì´í„° ì½ê¸°
2. 8ê°œ Feature ê³„ì‚°
3. XGBoost ëª¨ë¸ë¡œ ì˜ˆì¸¡
4. 10ë¶„ ë‚´ ìµœëŒ€ê°’ ì¶œë ¥
5. ìœ„í—˜ë„ í‰ê°€ ë° ì•ŒëŒ

### 6.3 ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì½”ë“œ
```python
def realtime_prediction():
    # 1. ìµœê·¼ 30ë¶„ ë°ì´í„°
    df = pd.read_csv('data/HUBROOM_PIVOT_DATA.CSV')
    recent_30 = df.tail(30)
    seq = recent_30['CURRENT_M16A_3F_JOB_2'].values
    
    # 2. Feature ìƒì„±
    features = create_features(seq)
    
    # 3. 10ë¶„ MAX ì˜ˆì¸¡
    prediction_max = model.predict([features])[0]
    
    # 4. ìœ„í—˜ë„ íŒë‹¨
    if prediction_max >= 300:
        print("ğŸ”´ ê·¹ë‹¨ê°’ ê²½ê³ !")
    elif prediction_max >= 280:
        print("ğŸŸ¡ ì£¼ì˜ í•„ìš”")
    else:
        print("ğŸŸ¢ ì •ìƒ ë²”ìœ„")
    
    return prediction_max
```

---

## 7. ì í”„ ì¼€ì´ìŠ¤ ë¶„ì„

### 7.1 ì •ì˜
- **ì¡°ê±´**: ì‹œí€€ìŠ¤ MAX < 280 AND ì‹¤ì œ 10ë¶„ MAX â‰¥ 300
- **ì˜ˆì‹œ**: ê³¼ê±° 30ë¶„ ìµœëŒ€ê°’ 277 â†’ 10ë¶„ í›„ 303
- **ë°œìƒ ë¹ˆë„**: ì „ì²´ì˜ 0.7%
- **ì˜ˆì¸¡ ë‚œì´ë„**: ë§¤ìš° ë†’ìŒ (ê¸‰ê²©í•œ íŒ¨í„´ ë³€í™”)

### 7.2 ì í”„ ì¼€ì´ìŠ¤ ì„±ëŠ¥
- **ì „ì²´ ì í”„**: 186ê°œ
- **ì˜ˆì¸¡ ì„±ê³µ**: 37ê°œ
- **ê°ì§€ìœ¨**: 19.9%
- **ê°œì„  í•„ìš”**: ì¶”ê°€ Feature ë˜ëŠ” ëª¨ë¸ ê°œì„  í•„ìš”

---

## 8. íŒŒì¼ êµ¬ì¡°

```
project/
â”œâ”€â”€ xgboost_model_30min_10min.pkl    # í•™ìŠµëœ ëª¨ë¸
â”œâ”€â”€ train_model.py                    # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ evaluate.py                       # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ realtime_prediction.py            # ì‹¤ì‹œê°„ ì˜ˆì¸¡
â”œâ”€â”€ aas.csv                          # í•™ìŠµ ë°ì´í„°
â”œâ”€â”€ BBB.CSV                          # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”œâ”€â”€ evaluation_results.csv            # í‰ê°€ ê²°ê³¼
â”œâ”€â”€ evaluation_summary.csv            # í‰ê°€ ìš”ì•½
â””â”€â”€ data/
    â””â”€â”€ HUBROOM_PIVOT_DATA.CSV      # ì‹¤ì‹œê°„ ì…ë ¥ ë°ì´í„°
```

---

## 9. ìš´ì˜ ê°€ì´ë“œ

### 9.1 ì¼ì¼ ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸ í™•ì¸
- [ ] ì˜ˆì¸¡ ëª¨ë‹ˆí„°ë§ ì‹œì‘
- [ ] ê·¹ë‹¨ê°’ ì•ŒëŒ ëŒ€ì‘ ì¤€ë¹„
- [ ] ì˜ˆì¸¡ ë¡œê·¸ í™•ì¸

### 9.2 ìœ„í—˜ ìˆ˜ì¤€ë³„ ëŒ€ì‘
| ì˜ˆì¸¡ê°’ | ìˆ˜ì¤€ | ëŒ€ì‘ ë°©ì•ˆ |
|--------|------|-----------|
| â‰¥ 300 | ê·¹ë‹¨ê°’ | ì¦‰ì‹œ ëŒ€ì‘íŒ€ í˜¸ì¶œ, ì‹œìŠ¤í…œ ì ê²€ |
| 280-299 | ì£¼ì˜ | ëª¨ë‹ˆí„°ë§ ê°•í™”, ëŒ€ê¸° ì¸ë ¥ ì¤€ë¹„ |
| < 280 | ì •ìƒ | ì •ê¸° ëª¨ë‹ˆí„°ë§ ìœ ì§€ |

### 9.3 ëª¨ë¸ ì¬í•™ìŠµ ì£¼ê¸°
- **ì •ê¸° ì¬í•™ìŠµ**: ì›” 1íšŒ
- **ê¸´ê¸‰ ì¬í•™ìŠµ**: ì •í™•ë„ 80% ì´í•˜ ì‹œ
- **ë°ì´í„° ìš”êµ¬**: ìµœì†Œ 20ì¼ ë°ì´í„°

---

## 10. API ëª…ì„¸

### 10.1 ì‹¤ì‹œê°„ ì˜ˆì¸¡ API
```python
GET /api/predict
Response: {
    "current_time": "2024-01-01 10:00",
    "prediction_time": "2024-01-01 10:10",
    "sequence_max": 275.3,
    "prediction_max": 285.4,
    "risk_level": "WARNING",
    "confidence": 0.92
}
```

### 10.2 í‰ê°€ ì‹¤í–‰ API
```python
POST /api/evaluate
Body: {"test_file": "BBB.CSV"}
Response: {
    "mae": 15.87,
    "rmse": 22.45,
    "r2": 0.912,
    "extreme_detection_rate": 0.989,
    "jump_detection_rate": 0.199
}
```

---

## 11. ì„±ëŠ¥ ìµœì í™”

### 11.1 í˜„ì¬ ì„±ëŠ¥
- **ì˜ˆì¸¡ ì‹œê°„**: 0.1ì´ˆ
- **ë©”ëª¨ë¦¬ ì‚¬ìš©**: < 1GB
- **CPU ì‚¬ìš©ë¥ **: < 10%
- **ë™ì‹œ ì²˜ë¦¬**: 100 requests/sec

### 11.2 ë³‘ëª© êµ¬ê°„
- Feature ê³„ì‚°: 30%
- ëª¨ë¸ ì˜ˆì¸¡: 20%
- ë°ì´í„° ë¡œë“œ: 50%

---

## 12. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 12.1 ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

| ë¬¸ì œ | ì›ì¸ | í•´ê²° ë°©ë²• |
|------|------|-----------|
| ì˜ˆì¸¡ê°’ NaN | ë°ì´í„° ê²°ì¸¡ | ê²°ì¸¡ì¹˜ ì „ì²˜ë¦¬ |
| ë©”ëª¨ë¦¬ ì˜¤ë¥˜ | ë°ì´í„° ê³¼ë‹¤ | ë°°ì¹˜ ì²˜ë¦¬ |
| ì˜ˆì¸¡ ì§€ì—° | I/O ë³‘ëª© | ë°ì´í„° ìºì‹± |
| ì •í™•ë„ ì €í•˜ | íŒ¨í„´ ë³€í™” | ëª¨ë¸ ì¬í•™ìŠµ |

### 12.2 ë¡œê·¸ ìœ„ì¹˜
- ì˜ˆì¸¡ ë¡œê·¸: `/logs/prediction.log`
- ì˜¤ë¥˜ ë¡œê·¸: `/logs/error.log`
- ì„±ëŠ¥ ë¡œê·¸: `/logs/performance.log`

---

## 13. í–¥í›„ ê°œì„  ê³„íš

### 13.1 ë‹¨ê¸° (1ê°œì›”)
- [ ] ì í”„ ì¼€ì´ìŠ¤ ì „ìš© ëª¨ë¸ ê°œë°œ
- [ ] Feature ì¶”ê°€ (BRIDGE_TIME ë“±)
- [ ] ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
- [ ] ì•ŒëŒ ì‹œìŠ¤í…œ ê³ ë„í™”

### 13.2 ì¤‘ê¸° (3ê°œì›”)
- [ ] LSTM ì‹œê³„ì—´ ëª¨ë¸ ì¶”ê°€
- [ ] ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±
- [ ] AutoML ë„ì…
- [ ] ì˜ˆì¸¡ êµ¬ê°„ í™•ì¥ (20ë¶„, 30ë¶„)

### 13.3 ì¥ê¸° (6ê°œì›”)
- [ ] ë”¥ëŸ¬ë‹ ëª¨ë¸ ì ìš© (Transformer)
- [ ] ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ í†µí•©
- [ ] ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë¶„ì„
- [ ] ìë™ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸

---

## 14. ì°¸ê³  ìë£Œ

### 14.1 ê´€ë ¨ ë…¼ë¬¸
- XGBoost: A Scalable Tree Boosting System (2016)
- Time Series Forecasting with Machine Learning (2020)
- Extreme Value Prediction in Industrial Systems (2021)

### 14.2 ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „
- Python: 3.8.10
- XGBoost: 1.5.1
- Pandas: 1.3.5
- NumPy: 1.21.5
- Scikit-learn: 1.0.2

---

## 15. ì—°ë½ì²˜

- **ê¸°ìˆ  ì§€ì›**: tech-support@company.com
- **ë°ì´í„°íŒ€**: data-team@company.com
- **ê¸´ê¸‰ ëŒ€ì‘**: emergency@company.com
- **í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €**: pm@company.com

---

## 16. ë¶€ë¡

### 16.1 ìš©ì–´ ì •ë¦¬
- **ì‹œí€€ìŠ¤**: ì—°ì†ëœ 30ë¶„ ë°ì´í„°
- **MAX**: êµ¬ê°„ ë‚´ ìµœëŒ€ê°’
- **ê·¹ë‹¨ê°’**: 300 ì´ìƒì˜ ê°’
- **ì í”„ ì¼€ì´ìŠ¤**: ì‹œí€€ìŠ¤ MAX < 280ì—ì„œ ì‹¤ì œ â‰¥ 300
- **Feature**: ëª¨ë¸ ì…ë ¥ ë³€ìˆ˜

### 16.2 ë²„ì „ íˆìŠ¤í† ë¦¬
- v1.0 (2024-01-01): ì´ˆê¸° ë°°í¬
- v1.1 (ì˜ˆì •): ì í”„ ì¼€ì´ìŠ¤ ê°œì„ 
- v2.0 (ì˜ˆì •): LSTM ëª¨ë¸ ì¶”ê°€

---

*ë¬¸ì„œ ë²„ì „: 1.0*
*ìµœì¢… ìˆ˜ì •: 2024-01-01*
*ì‘ì„±ì: Data Science Team*