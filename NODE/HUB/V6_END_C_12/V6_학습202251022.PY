


'''
âœ… CD_M163FSTORAGEUSE (Storage ì‚¬ìš©ëŸ‰) - ì ˆëŒ€ê°’!
âœ… CD_M163FSTORAGETOTAL (Storage ì´ëŸ‰) - ì ˆëŒ€ê°’!
âœ… CD_M163FSTORAGEUTIL (Storage í™œìš©ë¥ ) - ì •í™•í•œ ë¹„ìœ¨!


Storage ì‚¬ìš©ëŸ‰ ì¶”ì„¸ â†’ ê¸‰ì¦ì´ "ì–¼ë§ˆë‚˜ ë¹ ë¥´ê²Œ" ì¼ì–´ë‚˜ëŠ”ì§€ ì¸¡ì •
ì—¬ìœ  ê³µê°„ ê³„ì‚° â†’ Storageê°€ "ì–¸ì œ" í•œê³„ì— ë„ë‹¬í•˜ëŠ”ì§€ ì˜ˆì¸¡
í™œìš©ë¥  ì„ê³„ê°’ â†’ ìœ„í—˜ êµ¬ê°„ì„ ì •í™•íˆ íŒë‹¨

í•µì‹¬ ì¸ì‚¬ì´íŠ¸:

Storage ì—¬ìœ  ê³µê°„ < 150 â†’ ê¸‰ì¦ í™•ë¥  80% ğŸ”¥
Storage í™œìš©ë¥  â‰¥ 10% â†’ ê¸‰ì¦ í™•ë¥  75% ğŸ”¥
Storage ë¶„ë‹¹ ì¦ê°€ìœ¨ > 0.3 â†’ ê¸‰ì¦ í™•ë¥  70% ğŸ”¥


M16A_3F_CMD < 180 â†’ HIGH (70%)
M16A_3F_CMD 260~280 â†’ HIGH (67%)
M16A_3F_CMD < 220 â†’ MEDIUM (30%)
ìœ„í—˜ë„ íŒì •ì˜ í•µì‹¬!

HUBROOMTOTAL = HUBì˜ ì „ì²´ ë£¸(ê³µê°„) ì´ëŸ‰

ì‹œìŠ¤í…œ ì „ì²´ ë¶€í•˜ ì§€í‘œ

StorageëŠ” M16A 3Fë§Œ ë³´ì§€ë§Œ
HUBROOMTOTALì€ ì „ì²´ HUB ìƒíƒœë¥¼ ë‚˜íƒ€ëƒ„


ê¸‰ì¦ ì˜ˆì¸¡ì— ê²°ì •ì 

HUB ì „ì²´ê°€ ê½‰ ì°¨ë©´ â†’ M16A 3Fë„ ì˜í–¥ ë°›ìŒ
620ëŒ€ â†’ ì •ìƒ, 600ëŒ€ ì´ˆë°˜ â†’ ìœ„í—˜, 580ëŒ€ ì´í•˜ â†’ ë§¤ìš° ìœ„í—˜


ë‹¤ë¥¸ ì»¬ëŸ¼ê³¼ì˜ ìƒí˜¸ì‘ìš©

HUBROOMTOTAL ë‚®ìŒ + CMD ë†’ìŒ = ë³‘ëª© ë°œìƒ ê°€ëŠ¥
HUBROOMTOTAL ë‚®ìŒ + Storage Util ë†’ìŒ = ê·¹ë„ ìœ„í—˜

'''

import numpy as np
import pandas as pd
import xgboost as xgb
import pickle
import warnings
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

warnings.filterwarnings('ignore')
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

def train_final_optimized():
    """
    ğŸ¯ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ìµœì¢… ìµœì í™” ë²„ì „
    - 1,804ê°œ ê¸‰ì¦ ì¼€ì´ìŠ¤ í™•ì¸ (3.00%)
    - í•µì‹¬ íŒ¨í„´: HUBROOMTOTAL<610(87.5%), STORAGEâ‰¥205(82.9%), CMD<220(45.4%), FS_UTILâ‰¥7(25.3%)
    """
    print("="*80)
    print("ğŸ¯ ìµœì¢… ìµœì í™”: 1,804ê°œ ê¸‰ì¦ ì¼€ì´ìŠ¤ ê¸°ë°˜ í•™ìŠµ")
    print("="*80)
    
    FEATURE_COLS = {
        'storage': ['M16A_3F_STORAGE_UTIL'],
        'fs_storage': ['CD_M163FSTORAGEUSE', 'CD_M163FSTORAGETOTAL', 'CD_M163FSTORAGEUTIL'],
        'hub': ['HUBROOMTOTAL'],
        'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],
        'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],
        'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],
        'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA']
    }
    
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
    
    def create_features_optimized(df, start_idx=30):
        """ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ Feature ìƒì„±"""
        features_list = []
        labels = []
        seq_max_list = []
        seq_min_list = []
        indices = []
        seq_target_list = []
        
        for i in range(start_idx, len(df) - 10):
            seq_target = df[TARGET_COL].iloc[i-30:i].values
            
            # íƒ€ê²Ÿ ê¸°ë³¸ í†µê³„
            features = {
                'target_mean': np.mean(seq_target),
                'target_std': np.std(seq_target),
                'target_max': np.max(seq_target),
                'target_min': np.min(seq_target),
                'target_last_value': seq_target[-1],
                'target_last_5_mean': np.mean(seq_target[-5:]),
                'target_slope': np.polyfit(np.arange(30), seq_target, 1)[0],
            }
            
            # ê° ì»¬ëŸ¼ ê·¸ë£¹ Feature
            for group_name, cols in FEATURE_COLS.items():
                for col in cols:
                    if col not in df.columns:
                        continue
                    
                    col_seq = df[col].iloc[i-30:i].values
                    
                    if group_name == 'maxcapa':
                        features[f'{col}_last_value'] = col_seq[-1]
                    
                    elif group_name in ['cmd', 'storage', 'fs_storage', 'hub']:
                        # í•µì‹¬ Feature
                        features[f'{col}_mean'] = np.mean(col_seq)
                        features[f'{col}_std'] = np.std(col_seq)
                        features[f'{col}_max'] = np.max(col_seq)
                        features[f'{col}_min'] = np.min(col_seq)
                        features[f'{col}_last_value'] = col_seq[-1]
                        features[f'{col}_last_5_mean'] = np.mean(col_seq[-5:])
                        features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
                    
                    else:
                        # Inflow/Outflow ê°„ì†Œí™”
                        features[f'{col}_mean'] = np.mean(col_seq)
                        features[f'{col}_last_value'] = col_seq[-1]
                        features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
            
            # ğŸ¯ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ Feature
            if 'CD_M163FSTORAGEUSE' in df.columns and 'CD_M163FSTORAGETOTAL' in df.columns:
                storage_use = df['CD_M163FSTORAGEUSE'].iloc[i-30:i].values
                storage_total = df['CD_M163FSTORAGETOTAL'].iloc[i-30:i].values
                storage_util = df['CD_M163FSTORAGEUTIL'].iloc[i-30:i].values
                
                features['storage_use_rate'] = (storage_use[-1] - storage_use[0]) / 30
                features['storage_remaining'] = storage_total[-1] - storage_use[-1]
                features['storage_util_last'] = storage_util[-1]
                # ğŸ¯ ë¶„ì„ ê²°ê³¼: FS_UTIL â‰¥ 7 â†’ 25.3% ê¸‰ì¦
                features['storage_util_high'] = 1 if storage_util[-1] >= 7 else 0
                features['storage_util_critical'] = 1 if storage_util[-1] >= 10 else 0
            
            # ğŸ¯ HUBROOMTOTAL Feature (ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
            if 'HUBROOMTOTAL' in df.columns:
                hub_seq = df['HUBROOMTOTAL'].iloc[i-30:i].values
                hub_last = hub_seq[-1]
                
                # ğŸ¯ ë¶„ì„ ê²°ê³¼: HUBROOMTOTAL < 610 â†’ 87.5% ê¸‰ì¦
                features['hub_critical'] = 1 if hub_last < 590 else 0
                features['hub_high'] = 1 if hub_last < 610 else 0  # ğŸ”¥ í•µì‹¬!
                features['hub_warning'] = 1 if hub_last < 620 else 0
                
                features['hub_decrease_rate'] = (hub_seq[0] - hub_last) / 30
                
                # HUB Ã— Storage ë³µí•© ìœ„í—˜
                if 'CD_M163FSTORAGEUTIL' in df.columns:
                    storage_util_last = df['CD_M163FSTORAGEUTIL'].iloc[i-1]
                    # ğŸ¯ HUB<610 + FS_UTILâ‰¥7 = ê·¹ë„ ìœ„í—˜
                    features['hub_storage_risk'] = 1 if (hub_last < 610 and storage_util_last >= 7) else 0
            
            # ìœ ì…-ìœ ì¶œ, CMD
            inflow_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['inflow'] if col in df.columns)
            outflow_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['outflow'] if col in df.columns)
            features['net_flow'] = inflow_sum - outflow_sum
            
            cmd_sum = sum(df[col].iloc[i-1] for col in FEATURE_COLS['cmd'] if col in df.columns)
            features['total_cmd'] = cmd_sum
            # ğŸ¯ ë¶„ì„ ê²°ê³¼: CMD < 220 â†’ 45.4% ê¸‰ì¦
            features['total_cmd_low'] = 1 if cmd_sum < 220 else 0
            features['total_cmd_very_low'] = 1 if cmd_sum < 200 else 0
            
            # ğŸ¯ HUB Ã— CMD ë³µí•©
            if 'HUBROOMTOTAL' in df.columns:
                hub_last = df['HUBROOMTOTAL'].iloc[i-1]
                # HUB ë‚®ìŒ + CMD ë‚®ìŒ = ë³‘ëª© + ê¸‰ì¦ ìœ„í—˜
                features['hub_cmd_bottleneck'] = 1 if (hub_last < 610 and cmd_sum < 220) else 0
            
            # ğŸ¯ Storage Util ìœ„í—˜ (ë¶„ì„ ê²°ê³¼: STORAGEâ‰¥205 â†’ 82.9% ê¸‰ì¦)
            if 'M16A_3F_STORAGE_UTIL' in df.columns:
                storage_util = df['M16A_3F_STORAGE_UTIL'].iloc[i-1]
                features['storage_util_critical'] = 1 if storage_util >= 205 else 0
                features['storage_util_high_risk'] = 1 if storage_util >= 207 else 0
            
            features_list.append(features)
            labels.append(df[TARGET_COL].iloc[i:i+10].max())
            seq_max_list.append(np.max(seq_target))
            seq_min_list.append(np.min(seq_target))
            indices.append(i)
            seq_target_list.append(seq_target)
        
        return pd.DataFrame(features_list), np.array(labels), seq_max_list, seq_min_list, indices, seq_target_list
    
    # ===== 1. í•™ìŠµ =====
    print("\n[STEP 1] FS ë°ì´í„° í•™ìŠµ (1,804ê°œ ê¸‰ì¦ ì¼€ì´ìŠ¤ í™œìš©)")
    print("-"*40)
    
    try:
        df_train = pd.read_csv('/mnt/user-data/uploads/FS__1_', on_bad_lines='skip', encoding='utf-8', low_memory=False)
    except:
        try:
            df_train = pd.read_csv('/mnt/user-data/uploads/FS__1_', on_bad_lines='skip', encoding='cp949', low_memory=False)
        except:
            df_train = pd.read_csv('/mnt/user-data/uploads/FS__1_', on_bad_lines='skip', encoding='euc-kr', low_memory=False)
    
    # íƒ€ì… ë³€í™˜
    df_train[TARGET_COL] = pd.to_numeric(df_train[TARGET_COL], errors='coerce')
    df_train = df_train.dropna(subset=[TARGET_COL])
    
    print(f"í•™ìŠµ ë°ì´í„°: {len(df_train)}ê°œ í–‰")
    
    # ì»¬ëŸ¼ í™•ì¸
    print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼:")
    for group_name, cols in FEATURE_COLS.items():
        available = [col for col in cols if col in df_train.columns]
        marker = "ğŸ”¥" if group_name in ['hub', 'fs_storage'] else "  "
        print(f"{marker} - {group_name}: {len(available)}/{len(cols)}ê°œ")
    
    # Feature ìƒì„±
    X_train, y_train, _, _, _, _ = create_features_optimized(df_train)
    
    print(f"\nâœ… Feature ìƒì„± ì™„ë£Œ:")
    print(f"  - ì´ Feature: {len(X_train.columns)}ê°œ")
    print(f"  - í•™ìŠµ ìƒ˜í”Œ: {len(X_train)}ê°œ")
    
    # ê¸‰ì¦ ì¼€ì´ìŠ¤ ë¹„ìœ¨ í™•ì¸
    surge_in_train = sum(1 for i in range(len(y_train)) 
                         if X_train.iloc[i]['target_max'] < 300 and y_train[i] >= 300)
    print(f"  - ê¸‰ì¦ ì¼€ì´ìŠ¤: {surge_in_train}ê°œ ({surge_in_train/len(y_train)*100:.2f}%)")
    
    # í•™ìŠµ/ê²€ì¦ ë¶„í• 
    X_tr, X_val, y_tr, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42
    )
    
    # GPU/CPU ê°ì§€
    print("\nğŸ” í•™ìŠµ í™˜ê²½ ê°ì§€...")
    use_gpu = False
    
    try:
        test_model = xgb.XGBRegressor(
            n_estimators=5, max_depth=3, random_state=42,
            tree_method='gpu_hist', gpu_id=0
        )
        test_model.fit(X_tr[:100], y_tr[:100], verbose=False)
        use_gpu = True
        print("  âœ… GPU ëª¨ë“œ\n")
    except:
        print("  âš ï¸ CPU ëª¨ë“œ\n")
        use_gpu = False
    
    # ëª¨ë¸ ìƒì„± (ê¸‰ì¦ ì¼€ì´ìŠ¤ ìµœì í™”)
    if use_gpu:
        model = xgb.XGBRegressor(
            n_estimators=200,  # ê¸‰ì¦ ì¼€ì´ìŠ¤ ì¶©ë¶„í•˜ë¯€ë¡œ ì¦ê°€
            max_depth=7,       # ë³µì¡í•œ íŒ¨í„´ í¬ì°©
            learning_rate=0.04,
            subsample=0.85,
            colsample_bytree=0.85,
            min_child_weight=2,
            gamma=0.05,
            reg_alpha=0.05,
            reg_lambda=0.8,
            random_state=42,
            tree_method='gpu_hist',
            gpu_id=0,
            predictor='gpu_predictor'
        )
    else:
        model = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=7,
            learning_rate=0.04,
            subsample=0.85,
            colsample_bytree=0.85,
            min_child_weight=2,
            gamma=0.05,
            reg_alpha=0.05,
            reg_lambda=0.8,
            random_state=42,
            tree_method='hist',
            n_jobs=-1
        )
    
    print("ëª¨ë¸ í•™ìŠµ ì¤‘ (ê¸‰ì¦ ì¼€ì´ìŠ¤ ìµœì í™”)...")
    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)
    
    # í‰ê°€
    y_val_pred = model.predict(X_val)
    train_mae = mean_absolute_error(y_val, y_val_pred)
    train_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))
    train_r2 = r2_score(y_val, y_val_pred)
    
    print(f"\ní•™ìŠµ ì„±ëŠ¥:")
    print(f"  MAE:  {train_mae:.4f}")
    print(f"  RMSE: {train_rmse:.4f}")
    print(f"  RÂ²:   {train_r2:.4f}")
    
    # ëª¨ë¸ ì €ì¥
    with open('xgboost_ìµœì¢…_ê¸‰ì¦ìµœì í™”.pkl', 'wb') as f:
        pickle.dump(model, f)
    print("âœ… ëª¨ë¸ ì €ì¥: xgboost_ìµœì¢…_ê¸‰ì¦ìµœì í™”.pkl")
    
    # Feature ì¤‘ìš”ë„
    print("\nğŸ”¥ Feature ì¤‘ìš”ë„ Top 30:")
    feature_importance = pd.DataFrame({
        'feature': X_train.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False).head(30)
    
    for idx, row in feature_importance.iterrows():
        # ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ Feature ê°•ì¡°
        if any(keyword in row['feature'] for keyword in ['hub_high', 'hub_critical', 'storage_util_high', 
                                                          'total_cmd_low', 'hub_storage_risk', 'hub_cmd_bottleneck',
                                                          'storage_util_critical']):
            marker = "ğŸ¯"
        elif 'HUBROOM' in row['feature'] or 'storage_util' in row['feature'] or 'CMD' in row['feature']:
            marker = "ğŸ”¥"
        else:
            marker = "  "
        print(f"{marker} {row['feature']}: {row['importance']:.4f}")
    
    # ===== 2. í‰ê°€ =====
    print("\n[STEP 2] í‰ê°€")
    print("-"*40)
    
    split_idx = int(len(df_train) * 0.8)
    df_test = df_train.iloc[split_idx:].copy()
    
    X_test, y_test, seq_max_list, seq_min_list, indices, seq_target_list = create_features_optimized(df_test, start_idx=30)
    
    y_pred = model.predict(X_test)
    
    test_mae = mean_absolute_error(y_test, y_pred)
    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    test_r2 = r2_score(y_test, y_pred)
    
    print(f"\ní‰ê°€ ì„±ëŠ¥:")
    print(f"  MAE:  {test_mae:.4f}")
    print(f"  RMSE: {test_rmse:.4f}")
    print(f"  RÂ²:   {test_r2:.4f}")
    
    # ê¸‰ì¦ ì¼€ì´ìŠ¤ ì„±ëŠ¥
    surge_count = sum(1 for i in range(len(y_test)) 
                      if seq_target_list[i][-1] < 300 and y_test[i] >= 300)
    surge_detected = sum(1 for i in range(len(y_test)) 
                         if seq_target_list[i][-1] < 300 and y_test[i] >= 300 and y_pred[i] >= 290)
    
    print(f"\nğŸ¯ ê¸‰ì¦ ì˜ˆì¸¡ ì„±ëŠ¥:")
    print(f"  ë°œìƒ: {surge_count}ê°œ")
    print(f"  ì˜ˆì¸¡ ì„±ê³µ: {surge_detected}/{surge_count}ê°œ ({surge_detected/surge_count*100 if surge_count > 0 else 0:.1f}%)")
    
    # ê·¹ë‹¨ê°’ ì„±ëŠ¥
    extreme_mask = y_test >= 300
    extreme_count = extreme_mask.sum()
    extreme_detected = ((y_pred >= 290) & extreme_mask).sum()
    
    print(f"\nê·¹ë‹¨ê°’ (300+) ê°ì§€:")
    print(f"  ë°œìƒ: {extreme_count}ê°œ")
    print(f"  ê°ì§€: {extreme_detected}/{extreme_count}ê°œ ({extreme_detected/extreme_count*100 if extreme_count > 0 else 0:.1f}%)")
    
    # ê²°ê³¼ ì €ì¥
    results = []
    for i, idx in enumerate(indices):
        results.append({
            'ì‹¤ì œê°’': y_test[i],
            'ì˜ˆì¸¡ê°’': round(y_pred[i], 2),
            'ì˜¤ì°¨': round(abs(y_test[i] - y_pred[i]), 2),
            'ì‹œí€€ìŠ¤MAX': seq_max_list[i],
            'ê¸‰ì¦': 'O' if (seq_target_list[i][-1] < 300 and y_test[i] >= 300) else '-',
            'ê¸‰ì¦ê°ì§€': 'O' if (seq_target_list[i][-1] < 300 and y_test[i] >= 300 and y_pred[i] >= 290) else '-',
            'ê·¹ë‹¨ê°’': 'O' if y_test[i] >= 300 else '-',
            'ê°ì§€': 'O' if (y_test[i] >= 300 and y_pred[i] >= 290) else '-'
        })
    
    df_results = pd.DataFrame(results)
    df_results.to_csv('ìµœì¢…_ê¸‰ì¦ìµœì í™”_ê²°ê³¼.csv', index=False, encoding='utf-8-sig')
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: ìµœì¢…_ê¸‰ì¦ìµœì í™”_ê²°ê³¼.csv")
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "="*80)
    print("ğŸ“Š ìµœì¢… ìš”ì•½ (1,804ê°œ ê¸‰ì¦ ì¼€ì´ìŠ¤ ê¸°ë°˜)")
    print("="*80)
    
    print(f"\n1. ë°ì´í„° ë¶„ì„ ê²°ê³¼:")
    print(f"   - ê¸‰ì¦ ì¼€ì´ìŠ¤: 1,804ê°œ (3.00%)")
    print(f"   - í‰ê·  ê¸‰ì¦ëŸ‰: 22.9")
    print(f"   - ìµœëŒ€ ê¸‰ì¦ëŸ‰: 130.0")
    
    print(f"\n2. í•µì‹¬ íŒ¨í„´:")
    print(f"   ğŸ¯ HUBROOMTOTAL < 610: 87.5%")
    print(f"   ğŸ¯ STORAGE_UTIL â‰¥ 205: 82.9%")
    print(f"   ğŸ¯ CMD < 220: 45.4%")
    print(f"   ğŸ¯ FS_UTIL â‰¥ 7: 25.3%")
    
    print(f"\n3. Feature êµ¬ì„±:")
    print(f"   - íƒ€ê²Ÿ: 7ê°œ")
    print(f"   - HUBROOMTOTAL: ~13ê°œ (hub_high í•µì‹¬!)")
    print(f"   - FS Storage: ~12ê°œ (storage_util_high í•µì‹¬!)")
    print(f"   - CMD: ~20ê°œ (total_cmd_low í•µì‹¬!)")
    print(f"   - Storage: ~13ê°œ (storage_util_critical í•µì‹¬!)")
    print(f"   - ë³µí•©: hub_storage_risk, hub_cmd_bottleneck")
    print(f"   - ì´: {len(X_train.columns)}ê°œ")
    
    print(f"\n4. ëª¨ë¸ ì„±ëŠ¥:")
    print(f"   - í•™ìŠµ MAE: {train_mae:.2f}")
    print(f"   - í‰ê°€ MAE: {test_mae:.2f}")
    print(f"   - RÂ²: {test_r2:.3f}")
    
    print(f"\n5. ê¸‰ì¦ ì˜ˆì¸¡:")
    print(f"   - ë°œìƒ: {surge_count}ê°œ")
    print(f"   - ì„±ê³µë¥ : {surge_detected/surge_count*100 if surge_count > 0 else 0:.1f}%")
    
    print(f"\n6. ê·¹ë‹¨ê°’ ê°ì§€:")
    print(f"   - ë°œìƒ: {extreme_count}ê°œ")
    print(f"   - ê°ì§€ìœ¨: {extreme_detected/extreme_count*100 if extreme_count > 0 else 0:.1f}%")
    
    return model, df_results, feature_importance

if __name__ == '__main__':
    model, results, importance = train_final_optimized()