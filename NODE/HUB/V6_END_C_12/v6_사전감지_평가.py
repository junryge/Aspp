# -*- coding: utf-8 -*-
"""
V6 í‰ê°€ì½”ë“œ - ì‚¬ì „ê°ì§€ ì¡°ê±´ ë° ì˜ˆì¸¡ê°’ ë³´ì • ì ìš©
ì¡°ê±´: 30 ì‹œí€€ìŠ¤ì— 283 ì´ìƒ + ì¦ê°€ë¥  15 ì´ìƒ
ë³´ì •: ì¡°ê±´ ë§Œì¡± ì‹œ ì˜ˆì¸¡ê°’ +15
"""

import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta


def evaluate_all_predictions():
    """ì „ì²´ ë°ì´í„°ë¥¼ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ í‰ê°€ (ì‚¬ì „ê°ì§€ ë³´ì • ì ìš©)"""
   
    # V4 Ultimate í•„ìˆ˜ ì»¬ëŸ¼ ì •ì˜
    FEATURE_COLS = {
        'storage': ['M16A_3F_STORAGE_UTIL'],
        'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],
        'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],
        'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],
        'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA']
    }
     
    # ëª¨ë¸ ë¡œë“œ
    try:
        with open('xgboost_model_30min_10min_12ì»¬ëŸ¼.pkl', 'rb') as f:
            model = pickle.load(f)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {e}")
        return None
   
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv('HUB0905101512.CSV', on_bad_lines='skip')
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")
   
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸
    print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸:")
    all_feature_cols = []
    for group_name, cols in FEATURE_COLS.items():
        available = [col for col in cols if col in df.columns]
        all_feature_cols.extend(available)
        print(f"  - {group_name}: {len(available)}/{len(cols)}ê°œ")
   
    # STAT_DT ì²˜ë¦¬
    if 'STAT_DT' in df.columns:
        try:
            df['STAT_DT'] = pd.to_datetime(df['STAT_DT'].astype(str), format='%Y%m%d%H%M')
        except:
            print("âš ï¸ STAT_DT ë³€í™˜ ì‹¤íŒ¨, ê°€ìƒ ì‹œê°„ ìƒì„±")
            base_time = datetime(2024, 1, 1, 0, 0)
            df['STAT_DT'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
   
    results = []
    ì‚¬ì „ê°ì§€_count = 0
    ë³´ì •ì ìš©_count = 0
   
    print("\n" + "="*80)
    print("ğŸš¨ ì‚¬ì „ê°ì§€ ì¡°ê±´ ì ìš©")
    print("="*80)
    print("ì¡°ê±´ 1: 30 ì‹œí€€ìŠ¤ MAX < 300")
    print("ì¡°ê±´ 2: 30 ì‹œí€€ìŠ¤ì— 283 ì´ìƒ ê°’ ì¡´ì¬")
    print("ì¡°ê±´ 3: ì¦ê°€ë¥ (ë-ì²˜ìŒ) >= 15")
    print("ë³´ì •ê°’: +15")
    print("="*80 + "\n")
   
    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°: 30ê°œ ì‹œí€€ìŠ¤ â†’ 10ë¶„ í›„ ì˜ˆì¸¡
    for i in range(30, len(df)):
        # ê³¼ê±° 30ê°œ ë°ì´í„°
        seq_data = df.iloc[i-30:i].copy()
        seq_target = seq_data[TARGET_COL].values
       
        # í˜„ì¬ ì‹œì  (ì‹œí€€ìŠ¤ ë§ˆì§€ë§‰)
        current_time = seq_data['STAT_DT'].iloc[-1]
       
        # ì˜ˆì¸¡ ì‹œì  (10ë¶„ í›„)
        prediction_time = current_time + timedelta(minutes=10)
       
        # ì‹¤ì œê°’ (ië²ˆì§¸ í–‰)
        actual_value = df.iloc[i][TARGET_COL]
        actual_time = df.iloc[i]['STAT_DT']
       
        # Feature ìƒì„± (íƒ€ê²Ÿ ì»¬ëŸ¼)
        features = {
            'target_mean': np.mean(seq_target),
            'target_std': np.std(seq_target),
            'target_last_5_mean': np.mean(seq_target[-5:]),
            'target_max': np.max(seq_target),
            'target_min': np.min(seq_target),
            'target_slope': np.polyfit(np.arange(30), seq_target, 1)[0],
            'target_last_10_mean': np.mean(seq_target[-10:]),
            'target_first_10_mean': np.mean(seq_target[:10])
        }
        
        # ê° ì»¬ëŸ¼ ê·¸ë£¹ë³„ íŠ¹ì„± ì¶”ê°€
        for group_name, cols in FEATURE_COLS.items():
            for col in cols:
                if col in df.columns:
                    col_seq = seq_data[col].values
                    
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_std'] = np.std(col_seq)
                    features[f'{col}_max'] = np.max(col_seq)
                    features[f'{col}_min'] = np.min(col_seq)
                    features[f'{col}_last_5_mean'] = np.mean(col_seq[-5:])
                    features[f'{col}_last_10_mean'] = np.mean(col_seq[-10:])
                    features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
                    features[f'{col}_first_10_mean'] = np.mean(col_seq[:10])
                    features[f'{col}_mid_10_mean'] = np.mean(col_seq[10:20])
                    features[f'{col}_last_value'] = col_seq[-1]
        
        # ìœ ì…-ìœ ì¶œ ì°¨ì´
        inflow_sum = 0
        outflow_sum = 0
        for col in FEATURE_COLS['inflow']:
            if col in df.columns:
                inflow_sum += df[col].iloc[i-1]
        for col in FEATURE_COLS['outflow']:
            if col in df.columns:
                outflow_sum += df[col].iloc[i-1]
        features['net_flow'] = inflow_sum - outflow_sum
        
        # CMD ì´í•©
        cmd_sum = 0
        for col in FEATURE_COLS['cmd']:
            if col in df.columns:
                cmd_sum += df[col].iloc[i-1]
        features['total_cmd'] = cmd_sum
       
        X_pred = pd.DataFrame([features])
       
        # ê¸°ë³¸ ì˜ˆì¸¡
        prediction = model.predict(X_pred)[0]
        
        # ========================================
        # ğŸš¨ ì‚¬ì „ê°ì§€ ì¡°ê±´ ì²´í¬ ë° ë³´ì • ì ìš©
        # ========================================
        seq_max = np.max(seq_target)
        seq_min = np.min(seq_target)
        
        # ì¡°ê±´ 1: ì‹œí€€ìŠ¤ MAX < 300
        condition1 = seq_max < 300
        
        # ì¡°ê±´ 2: ì‹œí€€ìŠ¤ì— 283 ì´ìƒ ì¡´ì¬
        condition2 = np.any(seq_target >= 283)
        
        # ì¡°ê±´ 3: ì¦ê°€ë¥  >= 15
        increase_rate = seq_target[-1] - seq_target[0]
        condition3 = increase_rate >= 15
        
        # ì‚¬ì „ê°ì§€ ì¡°ê±´ ë§Œì¡± ì—¬ë¶€
        ì‚¬ì „ê°ì§€_ì¡°ê±´ = condition1 and condition2 and condition3
        
        # ì˜ˆì¸¡ê°’ ë³´ì •
        if ì‚¬ì „ê°ì§€_ì¡°ê±´:
            ì‚¬ì „ê°ì§€_count += 1
            # ì˜ˆì¸¡ê°’ì´ 300 ë¯¸ë§Œì¼ ë•Œë§Œ +15 ë³´ì •
            if prediction < 300:
                ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸° = prediction + 15  # +15 ë³´ì •
            else:
                ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸° = prediction  # ì´ë¯¸ 300 ì´ìƒì´ë©´ ë³´ì • ì•ˆ í•¨
            
            if actual_value >= 300:
                ë³´ì •ì ìš©_count += 1
        else:
            ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸° = prediction  # ë³´ì • ì—†ìŒ
        
        # 300 ì´ìƒ ì í”„ ê°ì§€
        jump_detected = np.any(seq_target >= 300)
       
        # ê²°ê³¼ ì €ì¥
        results.append({
            'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
            'ì˜ˆì¸¡ì‹œì ': prediction_time.strftime('%Y-%m-%d %H:%M'),
            'ì‹¤ì œì‹œì ': actual_time.strftime('%Y-%m-%d %H:%M'),
            'ì‹¤ì œê°’': actual_value,
            'ì˜ˆì¸¡ê°’': round(prediction, 2),
            'ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸°': round(ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸°, 2),
            'ì˜¤ì°¨': round(actual_value - ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸°, 2),
            'ì˜¤ì°¨ìœ¨(%)': round(abs(actual_value - ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸°) / max(actual_value, 1) * 100, 2),
            'ì‹œí€€ìŠ¤MAX': seq_max,
            'ì‹œí€€ìŠ¤MIN': seq_min,
            'ì‹œí€€ìŠ¤í‰ê· ': round(np.mean(seq_target), 2),
            'ì‹œí€€ìŠ¤ì¦ê°€': round(increase_rate, 2),
            'ì‚¬ì „ê°ì§€': 'ì‚¬ì „ê°ì§€' if ì‚¬ì „ê°ì§€_ì¡°ê±´ else 'ì´ìƒì—†ìŒ',
            'ë³´ì •ì ìš©': 'âœ…' if ì‚¬ì „ê°ì§€_ì¡°ê±´ else '',
            '300ì´ìƒì í”„': 'ğŸ”´' if jump_detected else '',
            'ì‹¤ì œê°’ìƒíƒœ': 'ğŸ”´ê·¹ë‹¨' if actual_value >= 300 else ('ğŸŸ¡ì£¼ì˜' if actual_value >= 280 else 'ğŸŸ¢ì •ìƒ'),
            'ì˜ˆì¸¡ê°’ìƒíƒœ': 'ğŸ”´ê·¹ë‹¨' if ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸° >= 300 else ('ğŸŸ¡ì£¼ì˜' if ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸° >= 280 else 'ğŸŸ¢ì •ìƒ')
        })
       
        # ì§„í–‰ìƒí™© ì¶œë ¥
        if (i - 30) % 100 == 0:
            print(f"ì§„í–‰ì¤‘... {i-30}/{len(df)-30} ({(i-30)/(len(df)-30)*100:.1f}%)")
   
    # DataFrame ë³€í™˜
    results_df = pd.DataFrame(results)
   
    # CSV ì €ì¥
    output_file = 'prediction_evaluation_ì‚¬ì „ê°ì§€ë³´ì •_ì ìš©.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
   
    # í†µê³„ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ“Š í‰ê°€ í†µê³„")
    print("="*80)
    print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(results_df)}")
    print(f"í‰ê·  ì˜¤ì°¨: {results_df['ì˜¤ì°¨'].abs().mean():.2f}")
    print(f"í‰ê·  ì˜¤ì°¨ìœ¨: {results_df['ì˜¤ì°¨ìœ¨(%)'].mean():.2f}%")
    print(f"ìµœëŒ€ ì˜¤ì°¨: {results_df['ì˜¤ì°¨'].abs().max():.2f}")
    
    print("\n" + "="*80)
    print("ğŸš¨ ì‚¬ì „ê°ì§€ í†µê³„")
    print("="*80)
    print(f"ì‚¬ì „ê°ì§€ ì¡°ê±´ ë§Œì¡±: {ì‚¬ì „ê°ì§€_count}ê°œ")
    print(f"ì‹¤ì œ 300+ ì í”„: {(results_df['ì‹¤ì œê°’'] >= 300).sum()}ê°œ")
    print(f"ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸° 300+: {(results_df['ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸°'] >= 300).sum()}ê°œ")
    print(f"ì‚¬ì „ê°ì§€ ì¤‘ ì‹¤ì œ 300+ ì í”„: {ë³´ì •ì ìš©_count}ê°œ")
    
    if ì‚¬ì „ê°ì§€_count > 0:
        print(f"ì‚¬ì „ê°ì§€ ì •í™•ë„: {ë³´ì •ì ìš©_count/ì‚¬ì „ê°ì§€_count*100:.1f}%")
    
    # ì‚¬ì „ê°ì§€ ì¼€ì´ìŠ¤ ìƒì„¸
    ì‚¬ì „ê°ì§€_cases = results_df[results_df['ì‚¬ì „ê°ì§€'] == 'ì‚¬ì „ê°ì§€']
    if len(ì‚¬ì „ê°ì§€_cases) > 0:
        print("\n" + "="*80)
        print(f"ğŸš¨ ì‚¬ì „ê°ì§€ ì¼€ì´ìŠ¤ ìƒì„¸ (ìƒìœ„ 20ê°œ)")
        print("="*80)
        print(ì‚¬ì „ê°ì§€_cases[['í˜„ì¬ì‹œê°„', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’', 'ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸°', 'ì˜¤ì°¨', 'ì‹¤ì œê°’ìƒíƒœ']].head(20).to_string(index=False))
    
    # ê·¹ë‹¨ê°’ êµ¬ê°„
    extreme_cases = results_df[results_df['ì‹¤ì œê°’'] >= 300]
    if len(extreme_cases) > 0:
        print("\n" + "="*80)
        print("ğŸ”´ ì‹¤ì œ ê·¹ë‹¨ê°’(â‰¥300) êµ¬ê°„")
        print("="*80)
        print(extreme_cases[['í˜„ì¬ì‹œê°„', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’ë‚´ë¦¬ê¸°', 'ì˜¤ì°¨', 'ì‹œí€€ìŠ¤MAX', 'ì‚¬ì „ê°ì§€']].to_string(index=False))
   
    return results_df

if __name__ == '__main__':
    print("ğŸš€ ì‹¤ì‹œê°„ ì˜ˆì¸¡ í‰ê°€ ì‹œì‘ (ì‚¬ì „ê°ì§€ ë³´ì • ì ìš©)...\n")
    results = evaluate_all_predictions()
   
    if results is not None:
        print(f"\nâœ… í‰ê°€ ì™„ë£Œ! ì´ {len(results)}ê°œ ì˜ˆì¸¡ ìƒì„±")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: prediction_evaluation_ì‚¬ì „ê°ì§€ë³´ì •_ì ìš©.csv")