# -*- coding: utf-8 -*-
"""
V6 í‰ê°€ ì „ìš© ì½”ë“œ + ê¸‰ì¦ ìœ„í—˜ë„ ê¸°ë°˜ ë³´ì •
ì „ì²´ ë°ì´í„°ë¥¼ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ í‰ê°€ + ì ì‘í˜• ë³´ì • ì ìš©
"""

import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta


def calculate_surge_risk(features):
    """
    ê¸‰ì¦ ìœ„í—˜ë„ ë° ì˜ˆìƒ ê¸‰ì¦ëŸ‰ ê³„ì‚°
    
    Returns:
        risk_level: ìœ„í—˜ë„ (HIGH/MEDIUM/LOW)
        surge_prob: ê¸‰ì¦ í™•ë¥  (0~1)
        expected_surge: ì˜ˆìƒ ê¸‰ì¦ëŸ‰
    """
    # ì£¼ìš” ì§€í‘œ ì¶”ì¶œ
    cmd_last = features.get('M16A_3F_CMD_last_value', 999)
    cmd_mean = features.get('M16A_3F_CMD_mean', 999)
    storage_last = features.get('M16A_3F_STORAGE_UTIL_last_value', 0)
    storage_mean = features.get('M16A_3F_STORAGE_UTIL_mean', 0)
    
    # CMD ë³€í™”ëŸ‰ ê³„ì‚°
    cmd_slope = features.get('M16A_3F_CMD_slope', 0)
    
    # ìœ„í—˜ë„ íŒì • (ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
    if cmd_last < 180:
        # CMDê°€ ë§¤ìš° ë‚®ìŒ â†’ í° ê¸‰ì¦ ê°€ëŠ¥ì„±
        risk_level = "HIGH"
        surge_prob = 0.70
        expected_surge = 60
    elif storage_last >= 30 and storage_last <= 40:
        # Storage Util ìœ„í—˜ êµ¬ê°„
        risk_level = "HIGH"
        surge_prob = 0.45
        expected_surge = 50
    elif cmd_last >= 260 and cmd_last <= 280:
        # CMD ë†’ì€ êµ¬ê°„ì—ì„œë„ ê¸‰ì¦ ê°€ëŠ¥
        risk_level = "HIGH"
        surge_prob = 0.67
        expected_surge = 60
    elif cmd_last < 220:
        # CMD ì¤‘ê°„ êµ¬ê°„
        risk_level = "MEDIUM"
        surge_prob = 0.30
        expected_surge = 35
    else:
        # ì¼ë°˜ ìƒí™©
        risk_level = "LOW"
        surge_prob = 0.05
        expected_surge = 20
    
    # ì¶”ê°€ ë³´ì • ìš”ì†Œ
    # 1. CMD ê¸‰ê° íŒ¨í„´ (slopeê°€ ìŒìˆ˜ì´ê³  í¼)
    if cmd_slope < -5:
        surge_prob *= 1.2  # 20% ì¦ê°€
        expected_surge *= 1.1
    
    # 2. Storage Utilì´ ì¦ê°€ ì¶”ì„¸
    storage_slope = features.get('M16A_3F_STORAGE_UTIL_slope', 0)
    if storage_slope > 2:
        surge_prob *= 1.1  # 10% ì¦ê°€
    
    # í™•ë¥  ìƒí•œ ì¡°ì •
    surge_prob = min(surge_prob, 0.85)
    
    return risk_level, surge_prob, expected_surge

def apply_adaptive_correction(prediction, features, seq_target):
    """
    ì ì‘í˜• ì˜ˆì¸¡ê°’ ë³´ì •
    
    Args:
        prediction: ì›ë˜ ëª¨ë¸ ì˜ˆì¸¡ê°’
        features: íŠ¹ì„± ë”•ì…”ë„ˆë¦¬
        seq_target: 30ê°œ ì‹œí€€ìŠ¤ íƒ€ê²Ÿê°’
    
    Returns:
        ë³´ì •ëœ ì˜ˆì¸¡ê°’, ìœ„í—˜ë„, ê¸‰ì¦ í™•ë¥ , ë³´ì •ëŸ‰
    """
    # ìœ„í—˜ë„ ê³„ì‚°
    risk_level, surge_prob, expected_surge = calculate_surge_risk(features)
    
    # í˜„ì¬ ê°’ (ì‹œí€€ìŠ¤ ë§ˆì§€ë§‰)
    current_value = seq_target[-1]
    
    # ì‹œí€€ìŠ¤ í†µê³„
    seq_mean = np.mean(seq_target)
    seq_std = np.std(seq_target)
    seq_max = np.max(seq_target)
    recent_mean = np.mean(seq_target[-5:])
    
    # ë³´ì • ì „ëµ
    correction = 0
    
    # 1. ê¸°ë³¸ ë³´ì •: ìœ„í—˜ë„ì— ë”°ë¥¸ ê¸‰ì¦ ë°˜ì˜
    if current_value < 300:  # í˜„ì¬ 300 ë¯¸ë§Œì¼ ë•Œë§Œ
        if risk_level == "HIGH":
            # ë†’ì€ ìœ„í—˜ë„: ê¸‰ì¦ ê°€ëŠ¥ì„± ì ê·¹ ë°˜ì˜
            if prediction < 300:
                # ì˜ˆì¸¡ê°’ì´ 300 ë¯¸ë§Œì´ë©´ ê¸‰ì¦ ê°€ëŠ¥ì„± ë°˜ì˜
                potential_value = current_value + expected_surge * surge_prob
                
                # 300 ë„ë‹¬ ê°€ëŠ¥ì„± ì²´í¬
                if potential_value >= 300:
                    # 300 ë„˜ì„ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë©´ ë³´ì •
                    correction = (potential_value - prediction) * 0.7  # 70% ë°˜ì˜
                else:
                    # 300 ë¯¸ë‹¬ì´ì–´ë„ ìƒí–¥ ë³´ì •
                    correction = expected_surge * surge_prob * 0.5
                    
        elif risk_level == "MEDIUM":
            # ì¤‘ê°„ ìœ„í—˜ë„: ë³´ìˆ˜ì  ë³´ì •
            if prediction < 300 and surge_prob > 0.25:
                correction = expected_surge * surge_prob * 0.3
                
        else:  # LOW
            # ë‚®ì€ ìœ„í—˜ë„: ìµœì†Œ ë³´ì •
            correction = expected_surge * surge_prob * 0.1
    
    # 2. ì¶”ê°€ ë³´ì •: ì‹œí€€ìŠ¤ íŒ¨í„´ ë°˜ì˜
    # ìµœê·¼ ê¸‰ì¦ ì¶”ì„¸
    recent_increase = recent_mean - seq_mean
    if recent_increase > 10:  # ìµœê·¼ ê¸‰ì¦ ì¤‘
        correction += recent_increase * 0.2
    
    # ì‹œí€€ìŠ¤ ë‚´ 300 ì´ìƒ ìˆì—ˆë˜ ê²½ìš°
    if seq_max >= 300:
        correction += 5  # ì¶”ê°€ ìƒí–¥
    
    # 3. ë³´ì •ê°’ ì œí•œ
    corrected_prediction = prediction + correction
    
    # ìƒí•œ/í•˜í•œ ì œí•œ
    corrected_prediction = max(corrected_prediction, current_value - 50)  # ê¸‰ë½ ì œí•œ
    corrected_prediction = min(corrected_prediction, current_value + 100)  # ê¸‰ë“± ì œí•œ
    
    # í˜„ì‹¤ì  ë²”ìœ„ ì œí•œ
    if current_value < 250 and corrected_prediction > 350:
        corrected_prediction = 320  # ê³¼ë„í•œ ê¸‰ì¦ ì œí•œ
    
    return corrected_prediction, risk_level, surge_prob, correction


def evaluate_all_predictions_with_correction():
    """ì „ì²´ ë°ì´í„°ë¥¼ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ í‰ê°€ + ê¸‰ì¦ ìœ„í—˜ë„ ë³´ì •"""
   
    # V4 Ultimate í•„ìˆ˜ ì»¬ëŸ¼ ì •ì˜
    # í•µì‹¬ 12ê°œ ì»¬ëŸ¼ë§Œ ì‚¬ìš© (ë¬¼ë¦¬ì ìœ¼ë¡œ ì¤‘ìš”í•œ ê²ƒë§Œ)
    FEATURE_COLS = {
        'storage': ['M16A_3F_STORAGE_UTIL'],  # ê·¹ë‹¨ê°’ í•µì‹¬ ì§€í‘œ
        'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],  # ì£¼ìš” CMD
        'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],  # ì£¼ìš” ìœ ì…
        'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],  # ì£¼ìš” ìœ ì¶œ
        'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA']  # ìš©ëŸ‰ ì œí•œ
    }
     
    # ëª¨ë¸ ë¡œë“œ
    try:
        with open('xgboost_model_30min_10min.pkl', 'rb') as f:
            model = pickle.load(f)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: xgboost_model_30min_10min.pkl")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {e}")
        return None
   
    # ë°ì´í„° ë¡œë“œ (ì¸ì½”ë”© ìë™ ê°ì§€)
    try:
        df = pd.read_csv('HUB0905101512.CSV', on_bad_lines='skip', encoding='utf-8')
    except UnicodeDecodeError:
        try:
            df = pd.read_csv('HUB0905101512.CSV', on_bad_lines='skip', encoding='cp949')
            print("âš ï¸ ì¸ì½”ë”©: CP949ë¡œ íŒŒì¼ ë¡œë“œ")
        except:
            df = pd.read_csv('HUB0905101512.CSV', on_bad_lines='skip', encoding='euc-kr')
            print("âš ï¸ ì¸ì½”ë”©: EUC-KRë¡œ íŒŒì¼ ë¡œë“œ")
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")
   
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸
    print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸:")
    all_feature_cols = []
    for group_name, cols in FEATURE_COLS.items():
        available = [col for col in cols if col in df.columns]
        all_feature_cols.extend(available)
        print(f"  - {group_name}: {len(available)}/{len(cols)}ê°œ")
   
    # STAT_DT ì²˜ë¦¬
    if 'STAT_DT' in df.columns:
        try:
            df['STAT_DT'] = pd.to_datetime(df['STAT_DT'].astype(str), format='%Y%m%d%H%M')
        except:
            print("âš ï¸ STAT_DT ë³€í™˜ ì‹¤íŒ¨, ê°€ìƒ ì‹œê°„ ìƒì„±")
            base_time = datetime(2024, 1, 1, 0, 0)
            df['STAT_DT'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
   
    results = []
   
    print("\nìŠ¬ë¼ì´ë”© ìœˆë„ìš° í‰ê°€ ì‹œì‘...")
    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°: 30ê°œ ì‹œí€€ìŠ¤ â†’ 10ë¶„ í›„ ì˜ˆì¸¡
    # i=30ë¶€í„° ì‹œì‘ (0~29ë¡œ ì²« ì˜ˆì¸¡, ì‹¤ì œê°’ì€ 30ë²ˆì§¸)
    for i in range(30, len(df)):
        # ê³¼ê±° 30ê°œ ë°ì´í„°
        seq_data = df.iloc[i-30:i].copy()
        seq_target = seq_data[TARGET_COL].values
       
        # í˜„ì¬ ì‹œì  (ì‹œí€€ìŠ¤ ë§ˆì§€ë§‰)
        current_time = seq_data['STAT_DT'].iloc[-1]
        current_value = seq_target[-1]
       
        # ì˜ˆì¸¡ ì‹œì  (10ë¶„ í›„)
        prediction_time = current_time + timedelta(minutes=10)
       
        # ì‹¤ì œê°’ (ië²ˆì§¸ í–‰)
        actual_value = df.iloc[i][TARGET_COL]
        actual_time = df.iloc[i]['STAT_DT']
       
        # Feature ìƒì„± (íƒ€ê²Ÿ ì»¬ëŸ¼)
        features = {
            'target_mean': np.mean(seq_target),
            'target_std': np.std(seq_target),
            'target_last_5_mean': np.mean(seq_target[-5:]),
            'target_max': np.max(seq_target),
            'target_min': np.min(seq_target),
            'target_slope': np.polyfit(np.arange(30), seq_target, 1)[0],
            'target_last_10_mean': np.mean(seq_target[-10:]),
            'target_first_10_mean': np.mean(seq_target[:10])
        }
        
        # ê° ì»¬ëŸ¼ ê·¸ë£¹ë³„ íŠ¹ì„± ì¶”ê°€
        for group_name, cols in FEATURE_COLS.items():
            for col in cols:
                if col in df.columns:
                    col_seq = seq_data[col].values
                    
                    # ê¸°ë³¸ í†µê³„
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_std'] = np.std(col_seq)
                    features[f'{col}_max'] = np.max(col_seq)
                    features[f'{col}_min'] = np.min(col_seq)
                    
                    # ìµœê·¼ íŠ¹ì„±
                    features[f'{col}_last_5_mean'] = np.mean(col_seq[-5:])
                    features[f'{col}_last_10_mean'] = np.mean(col_seq[-10:])
                    
                    # ì¶”ì„¸
                    features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
                    
                    # êµ¬ê°„ë³„ í‰ê· 
                    features[f'{col}_first_10_mean'] = np.mean(col_seq[:10])
                    features[f'{col}_mid_10_mean'] = np.mean(col_seq[10:20])
                    features[f'{col}_last_value'] = col_seq[-1]
        
        # ìœ ì…-ìœ ì¶œ ì°¨ì´ (Net Flow)
        inflow_sum = 0
        outflow_sum = 0
        for col in FEATURE_COLS['inflow']:
            if col in df.columns:
                inflow_sum += df[col].iloc[i-1]
        for col in FEATURE_COLS['outflow']:
            if col in df.columns:
                outflow_sum += df[col].iloc[i-1]
        features['net_flow'] = inflow_sum - outflow_sum
        
        # CMD ì´í•©
        cmd_sum = 0
        for col in FEATURE_COLS['cmd']:
            if col in df.columns:
                cmd_sum += df[col].iloc[i-1]
        features['total_cmd'] = cmd_sum
       
        X_pred = pd.DataFrame([features])
       
        # ê¸°ë³¸ ì˜ˆì¸¡
        prediction_original = model.predict(X_pred)[0]
        
        # ë³´ì •ëœ ì˜ˆì¸¡
        prediction_corrected, risk_level, surge_prob, correction_amount = \
            apply_adaptive_correction(prediction_original, features, seq_target)
       
        # 300 ì´ìƒ ì í”„ ê°ì§€ (ì‹œí€€ìŠ¤ ë‚´)
        jump_detected = np.any(seq_target >= 300)
        
        # ê¸‰ì¦ ì—¬ë¶€ íŒì •
        is_surge = (current_value < 300 and actual_value >= 300)
       
        # ê²°ê³¼ ì €ì¥
        results.append({
            'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
            'ì˜ˆì¸¡ì‹œì ': prediction_time.strftime('%Y-%m-%d %H:%M'),
            'ì‹¤ì œì‹œì ': actual_time.strftime('%Y-%m-%d %H:%M'),
            'í˜„ì¬ê°’': round(current_value, 2),
            'ì‹¤ì œê°’': round(actual_value, 2),
            'ì˜ˆì¸¡ê°’': round(prediction_original, 2),
            'ì˜ˆì¸¡ê°’_ë³´ì •í›„': round(prediction_corrected, 2),
            'ìœ„í—˜ë„': risk_level,
            'ê¸‰ì¦í™•ë¥ ': f"{surge_prob*100:.0f}%",
            'ë³´ì •ëŸ‰': round(correction_amount, 2),
            'ì˜¤ì°¨': round(actual_value - prediction_original, 2),
            'ì˜¤ì°¨_ë³´ì •í›„': round(actual_value - prediction_corrected, 2),
            'ì˜¤ì°¨ìœ¨(%)': round(abs(actual_value - prediction_original) / max(actual_value, 1) * 100, 2),
            'ì˜¤ì°¨ìœ¨_ë³´ì •í›„(%)': round(abs(actual_value - prediction_corrected) / max(actual_value, 1) * 100, 2),
            'ì‹œí€€ìŠ¤MAX': round(np.max(seq_target), 2),
            'ì‹œí€€ìŠ¤MIN': round(np.min(seq_target), 2),
            'ì‹œí€€ìŠ¤í‰ê· ': round(np.mean(seq_target), 2),
            'ì‹œí€€ìŠ¤ì¦ê°€': round(seq_target[-1] - seq_target[0], 2),
            '300ì´ìƒì í”„': 'ğŸ”´' if jump_detected else '',
            '300ê¸‰ì¦': 'âœ…' if is_surge else '',
            'ê¸‰ì¦ì˜ˆì¸¡ì„±ê³µ_ë³´ì •ì „': 'â­•' if (is_surge and prediction_original >= 300) else '',
            'ê¸‰ì¦ì˜ˆì¸¡ì„±ê³µ_ë³´ì •í›„': 'âœ…' if (is_surge and prediction_corrected >= 300) else '',
            'ì‹¤ì œê°’ìƒíƒœ': 'ğŸ”´ê·¹ë‹¨' if actual_value >= 300 else ('ğŸŸ¡ì£¼ì˜' if actual_value >= 280 else 'ğŸŸ¢ì •ìƒ'),
            'ì˜ˆì¸¡ìƒíƒœ_ë³´ì •ì „': 'ğŸ”´ê·¹ë‹¨' if prediction_original >= 300 else ('ğŸŸ¡ì£¼ì˜' if prediction_original >= 280 else 'ğŸŸ¢ì •ìƒ'),
            'ì˜ˆì¸¡ìƒíƒœ_ë³´ì •í›„': 'ğŸ”´ê·¹ë‹¨' if prediction_corrected >= 300 else ('ğŸŸ¡ì£¼ì˜' if prediction_corrected >= 280 else 'ğŸŸ¢ì •ìƒ'),
            'M16A_3F_CMD': round(features.get('M16A_3F_CMD_last_value', 0), 2),
            'M16A_3F_STORAGE_UTIL': round(features.get('M16A_3F_STORAGE_UTIL_last_value', 0), 2)
        })
       
        # ì§„í–‰ìƒí™© ì¶œë ¥
        if (i - 30) % 100 == 0:
            print(f"ì§„í–‰ì¤‘... {i-30}/{len(df)-30} ({(i-30)/(len(df)-30)*100:.1f}%)")
   
    # DataFrame ë³€í™˜
    results_df = pd.DataFrame(results)
   
    # CSV ì €ì¥
    output_file = 'prediction_evaluation_with_correction.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
   
    # ============ í‰ê°€ í†µê³„ ============
    print("\n" + "="*80)
    print("ğŸ“Š ì „ì²´ í‰ê°€ í†µê³„")
    print("="*80)
    print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(results_df)}")
    
    print(f"\n[ë³´ì • ì „]")
    print(f"  í‰ê·  ì˜¤ì°¨: {results_df['ì˜¤ì°¨'].abs().mean():.2f}")
    print(f"  í‰ê·  ì˜¤ì°¨ìœ¨: {results_df['ì˜¤ì°¨ìœ¨(%)'].mean():.2f}%")
    print(f"  ìµœëŒ€ ì˜¤ì°¨: {results_df['ì˜¤ì°¨'].abs().max():.2f}")
    
    print(f"\n[ë³´ì • í›„]")
    print(f"  í‰ê·  ì˜¤ì°¨: {results_df['ì˜¤ì°¨_ë³´ì •í›„'].abs().mean():.2f}")
    print(f"  í‰ê·  ì˜¤ì°¨ìœ¨: {results_df['ì˜¤ì°¨ìœ¨_ë³´ì •í›„(%)'].mean():.2f}%")
    print(f"  ìµœëŒ€ ì˜¤ì°¨: {results_df['ì˜¤ì°¨_ë³´ì •í›„'].abs().max():.2f}")
    print(f"  í‰ê·  ë³´ì •ëŸ‰: {results_df['ë³´ì •ëŸ‰'].abs().mean():.2f}")
    
    improvement = results_df['ì˜¤ì°¨ìœ¨(%)'].mean() - results_df['ì˜¤ì°¨ìœ¨_ë³´ì •í›„(%)'].mean()
    print(f"  ì˜¤ì°¨ìœ¨ ê°œì„ : {improvement:.2f}% í¬ì¸íŠ¸")
    
    # 300 ê¸‰ì¦ ì˜ˆì¸¡ ì„±ëŠ¥
    surge_cases = results_df[results_df['300ê¸‰ì¦'] == 'âœ…']
    if len(surge_cases) > 0:
        print("\n" + "="*80)
        print("ğŸš¨ 300 ê¸‰ì¦ ì˜ˆì¸¡ ì„±ëŠ¥ (300ë¯¸ë§Œ â†’ 300ì´ìƒ)")
        print("="*80)
        print(f"ì´ ê¸‰ì¦ ì¼€ì´ìŠ¤: {len(surge_cases)}ê°œ ({len(surge_cases)/len(results_df)*100:.1f}%)")
        
        # ë³´ì • ì „ ì„±ëŠ¥
        pred_success_before = (surge_cases['ì˜ˆì¸¡ê°’'] >= 300).sum()
        pred_280_before = (surge_cases['ì˜ˆì¸¡ê°’'] >= 280).sum()
        
        # ë³´ì • í›„ ì„±ëŠ¥
        pred_success_after = (surge_cases['ì˜ˆì¸¡ê°’_ë³´ì •í›„'] >= 300).sum()
        pred_280_after = (surge_cases['ì˜ˆì¸¡ê°’_ë³´ì •í›„'] >= 280).sum()
        
        print(f"\n[ë³´ì • ì „]")
        print(f"  300 ì´ìƒ ì˜ˆì¸¡ ì„±ê³µ: {pred_success_before}/{len(surge_cases)}ê°œ ({pred_success_before/len(surge_cases)*100:.1f}%)")
        print(f"  280 ì´ìƒ ì˜ˆì¸¡ (ì£¼ì˜): {pred_280_before}/{len(surge_cases)}ê°œ ({pred_280_before/len(surge_cases)*100:.1f}%)")
        
        print(f"\n[ë³´ì • í›„]")
        print(f"  300 ì´ìƒ ì˜ˆì¸¡ ì„±ê³µ: {pred_success_after}/{len(surge_cases)}ê°œ ({pred_success_after/len(surge_cases)*100:.1f}%)")
        print(f"  280 ì´ìƒ ì˜ˆì¸¡ (ì£¼ì˜): {pred_280_after}/{len(surge_cases)}ê°œ ({pred_280_after/len(surge_cases)*100:.1f}%)")
        print(f"  ì„±ëŠ¥ ê°œì„ : +{(pred_success_after - pred_success_before)}ê°œ ({(pred_success_after - pred_success_before)/len(surge_cases)*100:.1f}% í¬ì¸íŠ¸)")
    
    # ìœ„í—˜ë„ë³„ í†µê³„
    print("\n" + "="*80)
    print("âš ï¸ ìœ„í—˜ë„ë³„ ì˜ˆì¸¡ ì„±ëŠ¥")
    print("="*80)
    for risk in ['HIGH', 'MEDIUM', 'LOW']:
        risk_df = results_df[results_df['ìœ„í—˜ë„'] == risk]
        if len(risk_df) > 0:
            actual_surge = (risk_df['300ê¸‰ì¦'] == 'âœ…').sum()
            print(f"\n[{risk} ìœ„í—˜ë„] - {len(risk_df)}ê°œ ({len(risk_df)/len(results_df)*100:.1f}%)")
            print(f"  ì‹¤ì œ ê¸‰ì¦ ë°œìƒ: {actual_surge}ê°œ ({actual_surge/len(risk_df)*100:.1f}%)")
            print(f"  í‰ê·  ì˜¤ì°¨(ë³´ì •ì „): {risk_df['ì˜¤ì°¨'].abs().mean():.2f}")
            print(f"  í‰ê·  ì˜¤ì°¨(ë³´ì •í›„): {risk_df['ì˜¤ì°¨_ë³´ì •í›„'].abs().mean():.2f}")
    
    # 300ì´ìƒ ì í”„ êµ¬ê°„
    print(f"\n300ì´ìƒ ì í”„ êµ¬ê°„: {results_df['300ì´ìƒì í”„'].value_counts().get('ğŸ”´', 0)}ê°œ")
    
    # ê·¹ë‹¨ê°’ ë¶„ì„
    extreme_cases = results_df[results_df['ì‹¤ì œê°’'] >= 300]
    if len(extreme_cases) > 0:
        print(f"\nì‹¤ì œê°’ ê·¹ë‹¨(â‰¥300): {len(extreme_cases)}ê°œ ({len(extreme_cases)/len(results_df)*100:.1f}%)")
        pred_extreme_before = (results_df['ì˜ˆì¸¡ê°’'] >= 300).sum()
        pred_extreme_after = (results_df['ì˜ˆì¸¡ê°’_ë³´ì •í›„'] >= 300).sum()
        print(f"ì˜ˆì¸¡ê°’ ê·¹ë‹¨(â‰¥300) ë³´ì •ì „: {pred_extreme_before}ê°œ")
        print(f"ì˜ˆì¸¡ê°’ ê·¹ë‹¨(â‰¥300) ë³´ì •í›„: {pred_extreme_after}ê°œ")
   
    # ê¸‰ì¦ ì˜ˆì¸¡ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„
    if len(surge_cases) > 0:
        surge_failed = surge_cases[surge_cases['ê¸‰ì¦ì˜ˆì¸¡ì„±ê³µ_ë³´ì •í›„'] != 'âœ…']
        if len(surge_failed) > 0:
            print("\n" + "="*80)
            print("âŒ ê¸‰ì¦ ì˜ˆì¸¡ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ (ìƒìœ„ 10ê°œ)")
            print("="*80)
            failed_top = surge_failed.nsmallest(10, 'ì˜ˆì¸¡ê°’_ë³´ì •í›„')
            display_cols = ['í˜„ì¬ì‹œê°„', 'í˜„ì¬ê°’', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’_ë³´ì •í›„', 'ìœ„í—˜ë„', 'M16A_3F_CMD', 'M16A_3F_STORAGE_UTIL']
            print(failed_top[display_cols].to_string(index=False))
    
    # ê·¹ë‹¨ê°’ êµ¬ê°„ë³„ ë¶„ì„
    if len(extreme_cases) > 0:
        print("\n" + "="*80)
        print("ğŸ”´ ê·¹ë‹¨ê°’(â‰¥300) êµ¬ê°„ë³„ ì˜ˆì¸¡ ì •í™•ë„")
        print("="*80)
        
        # êµ¬ê°„ë³„ ë¶„ì„
        ranges = [(300, 320), (320, 350), (350, 400), (400, 500)]
        for low, high in ranges:
            range_df = extreme_cases[(extreme_cases['ì‹¤ì œê°’'] >= low) & (extreme_cases['ì‹¤ì œê°’'] < high)]
            if len(range_df) > 0:
                print(f"\n[{low}~{high} êµ¬ê°„] - {len(range_df)}ê°œ")
                print(f"  í‰ê·  ì˜¤ì°¨(ë³´ì •ì „): {range_df['ì˜¤ì°¨'].abs().mean():.2f}")
                print(f"  í‰ê·  ì˜¤ì°¨(ë³´ì •í›„): {range_df['ì˜¤ì°¨_ë³´ì •í›„'].abs().mean():.2f}")
                pred_success = (range_df['ì˜ˆì¸¡ê°’_ë³´ì •í›„'] >= 300).sum()
                print(f"  300ì´ìƒ ì˜ˆì¸¡ ì„±ê³µë¥ : {pred_success}/{len(range_df)}ê°œ ({pred_success/len(range_df)*100:.1f}%)")
    
    # ìƒìœ„ ì˜¤ì°¨ êµ¬ê°„
    print("\n" + "="*80)
    print("âŒ ì˜¤ì°¨ ìƒìœ„ 10ê°œ êµ¬ê°„ (ë³´ì • í›„ ê¸°ì¤€)")
    print("="*80)
    top_errors = results_df.nlargest(10, 'ì˜¤ì°¨ìœ¨_ë³´ì •í›„(%)')
    display_cols = ['í˜„ì¬ì‹œê°„', 'í˜„ì¬ê°’', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’_ë³´ì •í›„', 'ì˜¤ì°¨_ë³´ì •í›„', 'ì˜¤ì°¨ìœ¨_ë³´ì •í›„(%)', 'ìœ„í—˜ë„', '300ê¸‰ì¦']
    print(top_errors[display_cols].to_string(index=False))
   
    return results_df

if __name__ == '__main__':
    print("ğŸš€ V6 ì‹¤ì‹œê°„ ì˜ˆì¸¡ í‰ê°€ + ê¸‰ì¦ ìœ„í—˜ë„ ë³´ì • ì‹œì‘...\n")
    print("="*80)
    print("ğŸ’¡ ë³´ì • ë¡œì§:")
    print("  - M16A_3F_CMD < 180: HIGH ìœ„í—˜ë„ (70% ê¸‰ì¦ í™•ë¥ )")
    print("  - STORAGE_UTIL 30~40: HIGH ìœ„í—˜ë„ (45% ê¸‰ì¦ í™•ë¥ )")
    print("  - M16A_3F_CMD 260~280: HIGH ìœ„í—˜ë„ (67% ê¸‰ì¦ í™•ë¥ )")
    print("  - M16A_3F_CMD < 220: MEDIUM ìœ„í—˜ë„ (30% ê¸‰ì¦ í™•ë¥ )")
    print("  - ê¸°íƒ€: LOW ìœ„í—˜ë„ (5% ê¸‰ì¦ í™•ë¥ )")
    print("="*80)
    print()
    
    results = evaluate_all_predictions_with_correction()
   
    if results is not None:
        print(f"\nâœ… í‰ê°€ ì™„ë£Œ! ì´ {len(results)}ê°œ ì˜ˆì¸¡ ìƒì„±")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: prediction_evaluation_with_correction.csv")
        
        # ìµœì¢… ìš”ì•½
        print("\n" + "="*80)
        print("ğŸ’¡ ìµœì¢… ìš”ì•½")
        print("="*80)
        
        improvement = results['ì˜¤ì°¨ìœ¨(%)'].mean() - results['ì˜¤ì°¨ìœ¨_ë³´ì •í›„(%)'].mean()
        print(f"âœ… ì˜¤ì°¨ìœ¨ ê°œì„ : {improvement:.2f}% í¬ì¸íŠ¸")
        
        high_risk = results[results['ìœ„í—˜ë„'] == 'HIGH']
        if len(high_risk) > 0:
            surge_in_high = (high_risk['300ê¸‰ì¦'] == 'âœ…').sum()
            print(f"âœ… HIGH ìœ„í—˜ë„ ì ì¤‘ë¥ : {surge_in_high}/{len(high_risk)}ê°œ ({surge_in_high/len(high_risk)*100:.1f}%)")
        
        surge_all = results[results['300ê¸‰ì¦'] == 'âœ…']
        if len(surge_all) > 0:
            surge_detected = (surge_all['ê¸‰ì¦ì˜ˆì¸¡ì„±ê³µ_ë³´ì •í›„'] == 'âœ…').sum()
            print(f"âœ… 300 ê¸‰ì¦ ì˜ˆì¸¡ ì„±ê³µë¥ : {surge_detected}/{len(surge_all)}ê°œ ({surge_detected/len(surge_all)*100:.1f}%)")