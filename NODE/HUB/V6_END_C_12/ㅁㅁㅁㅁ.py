# -*- coding: utf-8 -*-
"""
V6 ëª¨ë¸ë¡œ ì˜ˆì¸¡ + ì‚¬ì „ê°ì§€ ë¶„ì„
- ëª¨ë¸(pkl) ì‚¬ìš©í•´ì„œ ì˜ˆì¸¡
- ì˜ˆì¸¡íƒ€ê²Ÿì‹œì (+10ë¶„)ì˜ ì •í™•í•œ ì‹¤ì œê°’ ì‚¬ìš©
- ì‚¬ì „ê°ì§€ ì¡°ê±´: ê³¼ê±°30ê°œ<300 AND ì˜ˆì¸¡íƒ€ê²Ÿì‹œì  ì‹¤ì œê°’â‰¥300
"""

import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta

def predict_and_detect_early():
    """
    ëª¨ë¸ë¡œ ì˜ˆì¸¡í•˜ê³  ì‚¬ì „ê°ì§€ ì¼€ì´ìŠ¤ ë¶„ì„
    """
    
    # í•µì‹¬ 12ê°œ ì»¬ëŸ¼ ì •ì˜
    FEATURE_COLS = {
        'storage': ['M16A_3F_STORAGE_UTIL'],
        'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],
        'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],
        'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],
        'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA']
    }
    
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
    
    print("="*80)
    print("ğŸ” V6 ëª¨ë¸ ì˜ˆì¸¡ + ì‚¬ì „ê°ì§€ ë¶„ì„")
    print("="*80)
    
    # 1. ëª¨ë¸ ë¡œë“œ
    print("\n[STEP 1] ëª¨ë¸ ë¡œë“œ")
    try:
        with open('xgboost_model_30min_10min_12ì»¬ëŸ¼.pkl', 'rb') as f:
            model = pickle.load(f)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: xgboost_model_30min_10min_12ì»¬ëŸ¼.pkl")
    except:
        try:
            with open('xgboost_model_30min_10min.pkl', 'rb') as f:
                model = pickle.load(f)
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: xgboost_model_30min_10min.pkl")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {e}")
            return None
    
    # 2. ì›ë³¸ ë°ì´í„° ë¡œë“œ
    print("\n[STEP 2] ì›ë³¸ ë°ì´í„° ë¡œë“œ")
    try:
        df = pd.read_csv('HUB0905101512.CSV', on_bad_lines='skip')
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")
    except FileNotFoundError:
        print("âŒ HUB0905101512.CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì»¬ëŸ¼ í™•ì¸
    print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸:")
    all_feature_cols = []
    for group_name, cols in FEATURE_COLS.items():
        available = [col for col in cols if col in df.columns]
        all_feature_cols.extend(available)
        print(f"  - {group_name}: {len(available)}/{len(cols)}ê°œ")
    
    # STAT_DT ì²˜ë¦¬
    if 'STAT_DT' in df.columns:
        try:
            df['STAT_DT'] = pd.to_datetime(df['STAT_DT'].astype(str), format='%Y%m%d%H%M')
            print(f"âœ… STAT_DT ë³€í™˜ ì™„ë£Œ")
        except:
            print("âš ï¸ STAT_DT ë³€í™˜ ì‹¤íŒ¨, ê°€ìƒ ì‹œê°„ ìƒì„±")
            base_time = datetime(2025, 9, 5, 0, 0)
            df['STAT_DT'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
    else:
        print("âš ï¸ STAT_DT ì»¬ëŸ¼ ì—†ìŒ, ê°€ìƒ ì‹œê°„ ìƒì„±")
        base_time = datetime(2025, 9, 5, 0, 0)
        df['STAT_DT'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
    
    # 3. ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì˜ˆì¸¡ + ì‚¬ì „ê°ì§€ ë¶„ì„
    print("\n[STEP 3] ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì˜ˆì¸¡ + ì‚¬ì „ê°ì§€ ë¶„ì„")
    print("ì¡°ê±´: ê³¼ê±°30ê°œ<300 AND ì˜ˆì¸¡íƒ€ê²Ÿì‹œì (+10ë¶„) ì‹¤ì œê°’â‰¥300")
    
    results = []
    early_detection_cases = []
    
    # i: í˜„ì¬ ì‹œì  ì¸ë±ìŠ¤
    # i+10: ì˜ˆì¸¡íƒ€ê²Ÿì‹œì  ì¸ë±ìŠ¤ (10ë¶„ í›„)
    for i in range(30, len(df) - 10):  # -10: 10ë¶„ í›„ ë°ì´í„° í•„ìš”
        # ê³¼ê±° 30ê°œ ë°ì´í„° (i-30 ~ i-1)
        seq_data = df.iloc[i-30:i].copy()
        seq_target = seq_data[TARGET_COL].values
        
        # í˜„ì¬ ì‹œì 
        current_time = df['STAT_DT'].iloc[i]
        
        # ì˜ˆì¸¡íƒ€ê²Ÿì‹œì  (10ë¶„ í›„)
        target_time = df['STAT_DT'].iloc[i+10]
        target_actual_value = df[TARGET_COL].iloc[i+10]
        
        # Feature ìƒì„±
        features = {
            'target_mean': np.mean(seq_target),
            'target_std': np.std(seq_target),
            'target_last_5_mean': np.mean(seq_target[-5:]),
            'target_max': np.max(seq_target),
            'target_min': np.min(seq_target),
            'target_slope': np.polyfit(np.arange(30), seq_target, 1)[0],
            'target_last_10_mean': np.mean(seq_target[-10:]),
            'target_first_10_mean': np.mean(seq_target[:10])
        }
        
        # ê° ì»¬ëŸ¼ ê·¸ë£¹ë³„ íŠ¹ì„± ì¶”ê°€
        for group_name, cols in FEATURE_COLS.items():
            for col in cols:
                if col in df.columns:
                    col_seq = seq_data[col].values
                    
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_std'] = np.std(col_seq)
                    features[f'{col}_max'] = np.max(col_seq)
                    features[f'{col}_min'] = np.min(col_seq)
                    features[f'{col}_last_5_mean'] = np.mean(col_seq[-5:])
                    features[f'{col}_last_10_mean'] = np.mean(col_seq[-10:])
                    features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
                    features[f'{col}_first_10_mean'] = np.mean(col_seq[:10])
                    features[f'{col}_mid_10_mean'] = np.mean(col_seq[10:20])
                    features[f'{col}_last_value'] = col_seq[-1]
        
        # Net Flow
        inflow_sum = 0
        outflow_sum = 0
        for col in FEATURE_COLS['inflow']:
            if col in df.columns:
                inflow_sum += df[col].iloc[i-1]
        for col in FEATURE_COLS['outflow']:
            if col in df.columns:
                outflow_sum += df[col].iloc[i-1]
        features['net_flow'] = inflow_sum - outflow_sum
        
        # CMD ì´í•©
        cmd_sum = 0
        for col in FEATURE_COLS['cmd']:
            if col in df.columns:
                cmd_sum += df[col].iloc[i-1]
        features['total_cmd'] = cmd_sum
        
        X_pred = pd.DataFrame([features])
        
        # ëª¨ë¸ ì˜ˆì¸¡
        prediction = model.predict(X_pred)[0]
        
        # ì‹œí€€ìŠ¤ í†µê³„
        seq_max = np.max(seq_target)
        seq_min = np.min(seq_target)
        seq_mean = np.mean(seq_target)
        seq_std = np.std(seq_target)
        
        # â˜…â˜…â˜… ì‚¬ì „ê°ì§€ ì¡°ê±´ ì²´í¬ â˜…â˜…â˜…
        # ê³¼ê±° 30ê°œ ëª¨ë‘ < 300 AND ì˜ˆì¸¡íƒ€ê²Ÿì‹œì  ì‹¤ì œê°’ >= 300
        is_early_detection = (seq_max < 300) and (target_actual_value >= 300)
        
        # ê²°ê³¼ ì €ì¥
        result_row = {
            'ì¸ë±ìŠ¤': i,
            'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
            'ì˜ˆì¸¡íƒ€ê²Ÿì‹œì ': target_time.strftime('%Y-%m-%d %H:%M'),
            'ì‹œí€€ìŠ¤MAX': round(seq_max, 2),
            'ì‹œí€€ìŠ¤MIN': round(seq_min, 2),
            'ì‹œí€€ìŠ¤í‰ê· ': round(seq_mean, 2),
            'ì‹œí€€ìŠ¤STD': round(seq_std, 2),
            'ì˜ˆì¸¡íƒ€ê²Ÿì‹œì _ì‹¤ì œê°’': round(target_actual_value, 2),
            'ì˜ˆì¸¡ê°’': round(prediction, 2),
            'ì˜¤ì°¨': round(target_actual_value - prediction, 2),
            'ì˜¤ì°¨ìœ¨(%)': round(abs(target_actual_value - prediction) / max(target_actual_value, 1) * 100, 2),
            'ì‚¬ì „ê°ì§€': 'âœ…' if is_early_detection else ''
        }
        
        results.append(result_row)
        
        # ì‚¬ì „ê°ì§€ ì¼€ì´ìŠ¤ ë³„ë„ ì €ì¥
        if is_early_detection:
            early_detection_cases.append({
                **result_row,
                'ì‚¬ì „ê°ì§€_ì„±ê³µì—¬ë¶€': 'âœ… ì„±ê³µ' if prediction >= 290 else 'âŒ ì‹¤íŒ¨',
                'ì‚¬ì „ê°ì§€_ì ìˆ˜(%)': round(prediction / target_actual_value * 100, 2)
            })
        
        # ì§„í–‰ìƒí™©
        if (i - 30) % 100 == 0:
            print(f"  ì§„í–‰ì¤‘... {i-30}/{len(df)-40} ({(i-30)/(len(df)-40)*100:.1f}%)")
    
    # 4. DataFrame ìƒì„±
    df_results = pd.DataFrame(results)
    
    print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(df_results)}ê°œ")
    
    # 5. ì‚¬ì „ê°ì§€ ì¼€ì´ìŠ¤ ë¶„ì„
    if len(early_detection_cases) == 0:
        print("\nâš ï¸ ì‚¬ì „ê°ì§€ ì¼€ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   (ê³¼ê±°30ê°œ<300 AND ì˜ˆì¸¡íƒ€ê²Ÿì‹œì â‰¥300 ì¡°ê±´)")
        
        # ì „ì²´ ê²°ê³¼ ì €ì¥
        output_file = 'ì „ì²´_ì˜ˆì¸¡ê²°ê³¼.csv'
        df_results.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"\nâœ… ì „ì²´ ê²°ê³¼ ì €ì¥: {output_file}")
        return df_results
    
    df_early = pd.DataFrame(early_detection_cases)
    
    # í†µê³„ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ“Š ì‚¬ì „ê°ì§€ ì¼€ì´ìŠ¤ í†µê³„")
    print("="*80)
    
    success_count = (df_early['ì˜ˆì¸¡ê°’'] >= 290).sum()
    success_rate = success_count / len(df_early) * 100
    
    print(f"ì „ì²´ ì˜ˆì¸¡: {len(df_results)}ê°œ")
    print(f"ì‚¬ì „ê°ì§€ ì¼€ì´ìŠ¤: {len(df_early)}ê°œ ({len(df_early)/len(df_results)*100:.2f}%)")
    print(f"\nì‚¬ì „ê°ì§€ ì„±ê³µ (ì˜ˆì¸¡ê°’â‰¥290): {success_count}ê°œ ({success_rate:.1f}%)")
    print(f"ì‚¬ì „ê°ì§€ ì‹¤íŒ¨ (ì˜ˆì¸¡ê°’<290): {len(df_early) - success_count}ê°œ ({100-success_rate:.1f}%)")
    print(f"\ní‰ê·  ì˜¤ì°¨: {df_early['ì˜¤ì°¨'].abs().mean():.2f}")
    print(f"í‰ê·  ì˜¤ì°¨ìœ¨: {df_early['ì˜¤ì°¨ìœ¨(%)'].mean():.2f}%")
    print(f"í‰ê·  ì‚¬ì „ê°ì§€ ì ìˆ˜: {df_early['ì‚¬ì „ê°ì§€_ì ìˆ˜(%)'].mean():.1f}%")
    
    # 6. ìƒì„¸ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ”¥ ì‚¬ì „ê°ì§€ ì¼€ì´ìŠ¤ ìƒì„¸ (ìƒìœ„ 10ê°œ)")
    print("="*80)
    display_cols = ['í˜„ì¬ì‹œê°„', 'ì˜ˆì¸¡íƒ€ê²Ÿì‹œì ', 'ì‹œí€€ìŠ¤MAX', 'ì‹œí€€ìŠ¤í‰ê· ', 
                    'ì˜ˆì¸¡íƒ€ê²Ÿì‹œì _ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’', 'ì˜¤ì°¨', 'ì‚¬ì „ê°ì§€_ì„±ê³µì—¬ë¶€']
    print(df_early[display_cols].head(10).to_string(index=False))
    
    # 7. ì„±ê³µ/ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„
    success_df = df_early[df_early['ì˜ˆì¸¡ê°’'] >= 290]
    failed_df = df_early[df_early['ì˜ˆì¸¡ê°’'] < 290]
    
    if len(success_df) > 0:
        print("\n" + "="*80)
        print("âœ… ì‚¬ì „ê°ì§€ ì„±ê³µ ì¼€ì´ìŠ¤")
        print("="*80)
        print(success_df[display_cols].head(5).to_string(index=False))
        print(f"\ní‰ê·  ì‹œí€€ìŠ¤MAX: {success_df['ì‹œí€€ìŠ¤MAX'].mean():.2f}")
        print(f"í‰ê·  ì˜ˆì¸¡ê°’: {success_df['ì˜ˆì¸¡ê°’'].mean():.2f}")
        print(f"í‰ê·  ì‹¤ì œê°’: {success_df['ì˜ˆì¸¡íƒ€ê²Ÿì‹œì _ì‹¤ì œê°’'].mean():.2f}")
    
    if len(failed_df) > 0:
        print("\n" + "="*80)
        print("âŒ ì‚¬ì „ê°ì§€ ì‹¤íŒ¨ ì¼€ì´ìŠ¤")
        print("="*80)
        print(failed_df[display_cols].head(5).to_string(index=False))
        print(f"\ní‰ê·  ì‹œí€€ìŠ¤MAX: {failed_df['ì‹œí€€ìŠ¤MAX'].mean():.2f}")
        print(f"í‰ê·  ì˜ˆì¸¡ê°’: {failed_df['ì˜ˆì¸¡ê°’'].mean():.2f}")
        print(f"í‰ê·  ì‹¤ì œê°’: {failed_df['ì˜ˆì¸¡íƒ€ê²Ÿì‹œì _ì‹¤ì œê°’'].mean():.2f}")
    
    # 8. CSV ì €ì¥
    output_file1 = 'ì‚¬ì „ê°ì§€_ë¶„ì„ê²°ê³¼.csv'
    df_early.to_csv(output_file1, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ì‚¬ì „ê°ì§€ ê²°ê³¼ ì €ì¥: {output_file1}")
    
    output_file2 = 'ì „ì²´_ì˜ˆì¸¡ê²°ê³¼.csv'
    df_results.to_csv(output_file2, index=False, encoding='utf-8-sig')
    print(f"âœ… ì „ì²´ ê²°ê³¼ ì €ì¥: {output_file2}")
    
    # 9. ìµœì¢… ìš”ì•½
    print("\n" + "="*80)
    print("ğŸ“‹ ìµœì¢… ìš”ì•½")
    print("="*80)
    print(f"1. ì‚¬ì „ê°ì§€ ì •ì˜:")
    print(f"   - ê³¼ê±° 30ê°œ ë°ì´í„° ëª¨ë‘ < 300")
    print(f"   - ì˜ˆì¸¡íƒ€ê²Ÿì‹œì (+10ë¶„) ì‹¤ì œê°’ >= 300")
    print(f"\n2. ë°œê²¬ëœ ì‚¬ì „ê°ì§€ ì¼€ì´ìŠ¤: {len(df_early)}ê°œ")
    print(f"3. ì‚¬ì „ê°ì§€ ì„±ê³µë¥ : {success_rate:.1f}% (ì˜ˆì¸¡ê°’â‰¥290 ê¸°ì¤€)")
    print(f"4. í‰ê·  ì˜¤ì°¨: {df_early['ì˜¤ì°¨'].abs().mean():.2f}")
    print(f"5. ì €ì¥ íŒŒì¼:")
    print(f"   - ì‚¬ì „ê°ì§€ë§Œ: {output_file1}")
    print(f"   - ì „ì²´ ê²°ê³¼: {output_file2}")
    
    print(f"\nğŸ’¡ ì¸ì‚¬ì´íŠ¸:")
    if success_rate >= 70:
        print(f"   âœ… ì‚¬ì „ê°ì§€ ì„±ê³µë¥  {success_rate:.1f}%ë¡œ ìš°ìˆ˜!")
    elif success_rate >= 50:
        print(f"   ğŸŸ¡ ì‚¬ì „ê°ì§€ ì„±ê³µë¥  {success_rate:.1f}%ë¡œ ì–‘í˜¸")
    else:
        print(f"   âŒ ì‚¬ì „ê°ì§€ ì„±ê³µë¥  {success_rate:.1f}%ë¡œ ê°œì„  í•„ìš”")
    
    return df_early

if __name__ == '__main__':
    print("ğŸš€ V6 ëª¨ë¸ ì˜ˆì¸¡ + ì‚¬ì „ê°ì§€ ë¶„ì„ ì‹œì‘\n")
    results = predict_and_detect_early()
    
    if results is not None:
        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ì‚¬ì „ê°ì§€ ì¼€ì´ìŠ¤ {len(results)}ê°œ ë°œê²¬")