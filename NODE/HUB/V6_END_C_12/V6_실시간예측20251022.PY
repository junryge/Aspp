# -*- coding: utf-8 -*-
"""
V6 ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì½”ë“œ + ê¸‰ì¦ ìœ„í—˜ë„ ê¸°ë°˜ ë³´ì •
- ìµœê·¼ 30ê°œ ë°ì´í„°ë¡œ 10ë¶„ í›„ ì˜ˆì¸¡
- ë³´ì • ì „/í›„ ì˜ˆì¸¡ê°’ ëª¨ë‘ ë°˜í™˜
- ìœ„í—˜ë„ í‰ê°€ í¬í•¨
"""

import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta
import os

# í˜„ ë””ë ‰í„°ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
script_dir = os.path.dirname(os.path.abspath(__file__))
model_dir = os.path.join(script_dir, 'model', 'xgboost_model_30min_10min.pkl')
data_dir = os.path.join(script_dir, 'data', 'HUBROOM_PIVOT_DATA.csv')

# V6 í•„ìˆ˜ ì»¬ëŸ¼ ì •ì˜ (12ê°œ í•µì‹¬ ì»¬ëŸ¼)
FEATURE_COLS = {
    'storage': ['M16A_3F_STORAGE_UTIL'],
    'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],
    'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],
    'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],
    'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA']
}

TARGET_COL = 'CURRENT_M16A_3F_JOB_2'


def calculate_surge_risk(features):
    """ê¸‰ì¦ ìœ„í—˜ë„ ë° ì˜ˆìƒ ê¸‰ì¦ëŸ‰ ê³„ì‚°"""
    cmd_last = features.get('M16A_3F_CMD_last_value', 999)
    storage_last = features.get('M16A_3F_STORAGE_UTIL_last_value', 0)
    cmd_slope = features.get('M16A_3F_CMD_slope', 0)
    
    # ìœ„í—˜ë„ íŒì • (ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
    if cmd_last < 180:
        risk_level = "HIGH"
        surge_prob = 0.70
        expected_surge = 60
    elif storage_last >= 30 and storage_last <= 40:
        risk_level = "HIGH"
        surge_prob = 0.45
        expected_surge = 50
    elif cmd_last >= 260 and cmd_last <= 280:
        risk_level = "HIGH"
        surge_prob = 0.67
        expected_surge = 60
    elif cmd_last < 220:
        risk_level = "MEDIUM"
        surge_prob = 0.30
        expected_surge = 35
    else:
        risk_level = "LOW"
        surge_prob = 0.05
        expected_surge = 20
    
    # ì¶”ê°€ ë³´ì • ìš”ì†Œ
    if cmd_slope < -5:
        surge_prob *= 1.2
        expected_surge *= 1.1
    
    storage_slope = features.get('M16A_3F_STORAGE_UTIL_slope', 0)
    if storage_slope > 2:
        surge_prob *= 1.1
    
    surge_prob = min(surge_prob, 0.85)
    
    return risk_level, surge_prob, expected_surge


def apply_adaptive_correction(prediction, features, seq_target):
    """ì ì‘í˜• ì˜ˆì¸¡ê°’ ë³´ì •"""
    risk_level, surge_prob, expected_surge = calculate_surge_risk(features)
    current_value = seq_target[-1]
    seq_mean = np.mean(seq_target)
    seq_max = np.max(seq_target)
    recent_mean = np.mean(seq_target[-5:])
    
    correction = 0
    
    # 1. ê¸°ë³¸ ë³´ì •: ìœ„í—˜ë„ì— ë”°ë¥¸ ê¸‰ì¦ ë°˜ì˜
    if current_value < 300:
        if risk_level == "HIGH":
            if prediction < 300:
                potential_value = current_value + expected_surge * surge_prob
                if potential_value >= 300:
                    correction = (potential_value - prediction) * 0.7
                else:
                    correction = expected_surge * surge_prob * 0.5
        elif risk_level == "MEDIUM":
            if prediction < 300 and surge_prob > 0.25:
                correction = expected_surge * surge_prob * 0.3
        else:
            correction = expected_surge * surge_prob * 0.1
    
    # 2. ì¶”ê°€ ë³´ì •: ì‹œí€€ìŠ¤ íŒ¨í„´ ë°˜ì˜
    recent_increase = recent_mean - seq_mean
    if recent_increase > 10:
        correction += recent_increase * 0.2
    
    if seq_max >= 300:
        correction += 5
    
    # 3. ë³´ì •ê°’ ì œí•œ
    corrected_prediction = prediction + correction
    corrected_prediction = max(corrected_prediction, current_value - 50)
    corrected_prediction = min(corrected_prediction, current_value + 100)
    
    if current_value < 250 and corrected_prediction > 350:
        corrected_prediction = 320
    
    return corrected_prediction, risk_level, surge_prob, correction


def realtime_prediction():
    """ì‹¤ì‹œê°„ ì˜ˆì¸¡ í•¨ìˆ˜ (ë³´ì • í¬í•¨)"""
    
    # ëª¨ë¸ ë¡œë“œ
    try:
        with open(model_dir, 'rb') as f:
            model = pickle.load(f)
    except FileNotFoundError:
        return None, "model is not found"
    except Exception as e:
        return None, f"model load error: {str(e)}"
    
    # ë°ì´í„° ë¡œë“œ
    try:
        df = pd.read_csv(data_dir, on_bad_lines='skip', encoding='utf-8')
    except UnicodeDecodeError:
        try:
            df = pd.read_csv(data_dir, on_bad_lines='skip', encoding='cp949')
        except:
            df = pd.read_csv(data_dir, on_bad_lines='skip', encoding='euc-kr')
    except FileNotFoundError:
        return None, "file is not found"
    except Exception as e:
        return None, f"file read error: {str(e)}"
    
    # ìµœê·¼ 30ê°œ ë°ì´í„° í™•ì¸
    if len(df) < 30:
        return None, "insufficient data (need at least 30 rows)"
    
    recent_30 = df.tail(30).copy()
    
    if TARGET_COL not in recent_30.columns:
        return None, "target column is not included"
    
    seq_target = recent_30[TARGET_COL].values
    
    # NaN ì²´í¬
    if np.any(np.isnan(seq_target)) or np.any(np.isinf(seq_target)):
        return None, "target column contains NaN or Inf"
    
    # STAT_DT ì²˜ë¦¬
    if 'STAT_DT' in recent_30.columns:
        try:
            recent_30['STAT_DT'] = pd.to_datetime(recent_30['STAT_DT'].astype(str), format='%Y%m%d%H%M')
        except:
            base_time = datetime.now()
            recent_30['STAT_DT'] = [base_time - timedelta(minutes=(29-i)) for i in range(30)]
    else:
        base_time = datetime.now()
        recent_30['STAT_DT'] = [base_time - timedelta(minutes=(29-i)) for i in range(30)]
    
    seq_end = recent_30['STAT_DT'].iloc[-1]
    prediction_time = seq_end + timedelta(minutes=10)
    current_value = seq_target[-1]
    
    # Feature ìƒì„± - íƒ€ê²Ÿ ì»¬ëŸ¼ ê¸°ë³¸ íŠ¹ì„±
    features = {
        'target_mean': np.mean(seq_target),
        'target_std': np.std(seq_target),
        'target_last_5_mean': np.mean(seq_target[-5:]),
        'target_max': np.max(seq_target),
        'target_min': np.min(seq_target),
        'target_slope': np.polyfit(np.arange(30), seq_target, 1)[0],
        'target_last_10_mean': np.mean(seq_target[-10:]),
        'target_first_10_mean': np.mean(seq_target[:10])
    }
    
    # ê° ì»¬ëŸ¼ ê·¸ë£¹ë³„ íŠ¹ì„± ì¶”ê°€ (12ê°œ í•µì‹¬ ì»¬ëŸ¼)
    for group_name, cols in FEATURE_COLS.items():
        for col in cols:
            if col in recent_30.columns:
                col_seq = recent_30[col].values
                
                # ê¸°ë³¸ í†µê³„
                features[f'{col}_mean'] = np.mean(col_seq)
                features[f'{col}_std'] = np.std(col_seq)
                features[f'{col}_max'] = np.max(col_seq)
                features[f'{col}_min'] = np.min(col_seq)
                
                # ìµœê·¼ íŠ¹ì„±
                features[f'{col}_last_5_mean'] = np.mean(col_seq[-5:])
                features[f'{col}_last_10_mean'] = np.mean(col_seq[-10:])
                
                # ì¶”ì„¸
                features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
                
                # êµ¬ê°„ë³„ í‰ê· 
                features[f'{col}_first_10_mean'] = np.mean(col_seq[:10])
                features[f'{col}_mid_10_mean'] = np.mean(col_seq[10:20])
                features[f'{col}_last_value'] = col_seq[-1]
    
    # ìœ ì…-ìœ ì¶œ ì°¨ì´ (Net Flow)
    inflow_sum = 0
    outflow_sum = 0
    for col in FEATURE_COLS['inflow']:
        if col in recent_30.columns:
            inflow_sum += recent_30[col].iloc[-1]
    for col in FEATURE_COLS['outflow']:
        if col in recent_30.columns:
            outflow_sum += recent_30[col].iloc[-1]
    features['net_flow'] = inflow_sum - outflow_sum
    
    # CMD ì´í•©
    cmd_sum = 0
    for col in FEATURE_COLS['cmd']:
        if col in recent_30.columns:
            cmd_sum += recent_30[col].iloc[-1]
    features['total_cmd'] = cmd_sum
    
    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    X_pred = pd.DataFrame([features])
    
    # ê¸°ë³¸ ì˜ˆì¸¡
    prediction_original = model.predict(X_pred)[0]
    
    # ë³´ì •ëœ ì˜ˆì¸¡
    prediction_corrected, risk_level, surge_prob, correction_amount = \
        apply_adaptive_correction(prediction_original, features, seq_target)
    
    # ìƒíƒœ ê²°ì • (ë³´ì • í›„ ì˜ˆì¸¡ê°’ ê¸°ì¤€)
    if prediction_corrected >= 300:
        status = "DANGEROUS"
    elif prediction_corrected >= 280:
        status = "WARNING"
    else:
        status = "NORMAL"
    
    # ê²°ê³¼ ë°˜í™˜
    result = {
        'current_time': seq_end.strftime('%Y-%m-%d %H:%M'),
        'prediction_time': prediction_time.strftime('%Y-%m-%d %H:%M'),
        'current_value': round(current_value, 2),
        'prediction_original': round(prediction_original, 2),
        'prediction_corrected': round(prediction_corrected, 2),
        'correction_amount': round(correction_amount, 2),
        'risk_level': risk_level,
        'surge_probability': f"{surge_prob*100:.0f}%",
        'status': status,
        'cmd_last': round(features.get('M16A_3F_CMD_last_value', 0), 2),
        'storage_last': round(features.get('M16A_3F_STORAGE_UTIL_last_value', 0), 2)
    }
    
    return result, None


def predict_realtime():
    """ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥"""
    result, error = realtime_prediction()
    
    if error:
        row = {"EXCEPT": error}
        print([row])
    else:
        # ìš´ì˜ í™˜ê²½ ì¶œë ¥ í˜•ì‹ (ë³´ì •ëœ ì˜ˆì¸¡ê°’ ì‚¬ìš©)
        classification_label = int(result['prediction_corrected'] >= 300)
        row = {
            "PREDICTVAL": int(result['prediction_corrected']),
            "PREDICTVAL_ORIGINAL": int(result['prediction_original']),
            "CORRECTION": int(result['correction_amount']),
            "JUDGEVAL": classification_label,
            "RISK_LEVEL": result['risk_level'],
            "SURGE_PROB": result['surge_probability'],
            "CURRENT_VALUE": int(result['current_value']),
            "MODEL": "V6_HUBROOM_MODEL_C12_WITH_CORRECTION",
            "STATUS": result['status'],
            "PREDICTION_TIME": result['prediction_time']
        }
        print([row])


def predict_realtime_detail():
    """ìƒì„¸ ì •ë³´ í¬í•¨ ì‹¤ì‹œê°„ ì˜ˆì¸¡ (ë””ë²„ê¹…/ëª¨ë‹ˆí„°ë§ìš©)"""
    result, error = realtime_prediction()
    
    if error:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {error}")
        return
    
    print("="*80)
    print("ğŸš€ V6 ì‹¤ì‹œê°„ ì˜ˆì¸¡ ê²°ê³¼ (ê¸‰ì¦ ìœ„í—˜ë„ ë³´ì • í¬í•¨)")
    print("="*80)
    print(f"\nğŸ“… í˜„ì¬ ì‹œê°„: {result['current_time']}")
    print(f"ğŸ“… ì˜ˆì¸¡ ì‹œì : {result['prediction_time']}")
    print(f"\ní˜„ì¬ê°’: {result['current_value']}")
    print(f"\n[ë³´ì • ì „] ì˜ˆì¸¡ê°’: {result['prediction_original']}")
    print(f"[ë³´ì • í›„] ì˜ˆì¸¡ê°’: {result['prediction_corrected']}")
    print(f"ë³´ì •ëŸ‰: +{result['correction_amount']}")
    print(f"\nâš ï¸ ìœ„í—˜ë„: {result['risk_level']}")
    print(f"ğŸ“Š ê¸‰ì¦ í™•ë¥ : {result['surge_probability']}")
    print(f"ğŸš¦ ìƒíƒœ: {result['status']}")
    print(f"\nì£¼ìš” ì§€í‘œ:")
    print(f"  - M16A_3F_CMD: {result['cmd_last']}")
    print(f"  - M16A_3F_STORAGE_UTIL: {result['storage_last']}")
    print("="*80)


if __name__ == '__main__':
    # ìš´ì˜ í™˜ê²½: ê°„ë‹¨í•œ ì¶œë ¥
    predict_realtime()
    
    # ë””ë²„ê¹…/ëª¨ë‹ˆí„°ë§: ìƒì„¸ ì¶œë ¥ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
    # print("\n")
    # predict_realtime_detail()