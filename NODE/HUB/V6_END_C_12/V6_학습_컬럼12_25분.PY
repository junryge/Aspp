# -*- coding: utf-8 -*-
"""
30ë¶„ ì‹œí€€ìŠ¤ â†’ 25ë¶„ í›„ ì˜ˆì¸¡ í•™ìŠµ ì½”ë“œ
12ê°œ í•µì‹¬ ì»¬ëŸ¼ ì‚¬ìš©
"""

import numpy as np
import pandas as pd
import pickle
import xgboost as xgb
from sklearn.model_selection import train_test_split
from datetime import datetime, timedelta

# V4 Ultimate í•„ìˆ˜ ì»¬ëŸ¼ ì •ì˜ (12ê°œ í•µì‹¬ ì»¬ëŸ¼)
FEATURE_COLS = {
    'storage': ['M16A_3F_STORAGE_UTIL'],
    'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],
    'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],
    'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],
    'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA']
}

TARGET_COL = 'CURRENT_M16A_3F_JOB_2'

def create_features(df, seq_len=30, pred_offset=25):
    """
    30ë¶„ ì‹œí€€ìŠ¤ â†’ 25ë¶„ í›„ ì˜ˆì¸¡
    
    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆìž„
        seq_len: ì‹œí€€ìŠ¤ ê¸¸ì´ (30ë¶„)
        pred_offset: ì˜ˆì¸¡ ì˜¤í”„ì…‹ (25ë¶„ í›„)
    
    Returns:
        X, y, timestamps, actuals, sequences
    """
    X_features = []
    y_values = []
    timestamps = []
    actual_values = []
    sequences = []
    
    print(f"\níŠ¹ì„± ìƒì„± ì¤‘... (ì‹œí€€ìŠ¤={seq_len}ë¶„, ì˜ˆì¸¡={pred_offset}ë¶„ í›„)")
    
    for i in range(seq_len, len(df) - pred_offset):
        # ê³¼ê±° 30ê°œ ë°ì´í„°
        seq_data = df.iloc[i-seq_len:i].copy()
        seq_target = seq_data[TARGET_COL].values
        
        # Feature ìƒì„± (íƒ€ê²Ÿ ì»¬ëŸ¼)
        features = {
            'target_mean': np.mean(seq_target),
            'target_std': np.std(seq_target),
            'target_last_5_mean': np.mean(seq_target[-5:]),
            'target_max': np.max(seq_target),
            'target_min': np.min(seq_target),
            'target_slope': np.polyfit(np.arange(30), seq_target, 1)[0],
            'target_last_10_mean': np.mean(seq_target[-10:]),
            'target_first_10_mean': np.mean(seq_target[:10])
        }
        
        # ê° ì»¬ëŸ¼ ê·¸ë£¹ë³„ íŠ¹ì„± ì¶”ê°€
        for group_name, cols in FEATURE_COLS.items():
            for col in cols:
                if col in df.columns:
                    col_seq = seq_data[col].values
                    
                    # ê¸°ë³¸ í†µê³„
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_std'] = np.std(col_seq)
                    features[f'{col}_max'] = np.max(col_seq)
                    features[f'{col}_min'] = np.min(col_seq)
                    
                    # ìµœê·¼ íŠ¹ì„±
                    features[f'{col}_last_5_mean'] = np.mean(col_seq[-5:])
                    features[f'{col}_last_10_mean'] = np.mean(col_seq[-10:])
                    
                    # ì¶”ì„¸
                    features[f'{col}_slope'] = np.polyfit(np.arange(30), col_seq, 1)[0]
                    
                    # êµ¬ê°„ë³„ í‰ê· 
                    features[f'{col}_first_10_mean'] = np.mean(col_seq[:10])
                    features[f'{col}_mid_10_mean'] = np.mean(col_seq[10:20])
                    features[f'{col}_last_value'] = col_seq[-1]
        
        # ìœ ìž…-ìœ ì¶œ ì°¨ì´ (Net Flow)
        inflow_sum = 0
        outflow_sum = 0
        for col in FEATURE_COLS['inflow']:
            if col in df.columns:
                inflow_sum += seq_data[col].iloc[-1]
        for col in FEATURE_COLS['outflow']:
            if col in df.columns:
                outflow_sum += seq_data[col].iloc[-1]
        features['net_flow'] = inflow_sum - outflow_sum
        
        # CMD ì´í•©
        cmd_sum = 0
        for col in FEATURE_COLS['cmd']:
            if col in df.columns:
                cmd_sum += seq_data[col].iloc[-1]
        features['total_cmd'] = cmd_sum
        
        X_features.append(features)
        
        # 25ë¶„ í›„ ì‹¤ì œê°’
        y_values.append(df.iloc[i + pred_offset][TARGET_COL])
        
        # ì‹œê°„ ì •ë³´
        if 'STAT_DT' in df.columns:
            timestamps.append(df.iloc[i]['STAT_DT'])
            actual_values.append(df.iloc[i + pred_offset][TARGET_COL])
        
        sequences.append(seq_target)
        
        if (i - seq_len) % 1000 == 0:
            print(f"  ì§„í–‰: {i-seq_len}/{len(df)-seq_len-pred_offset}")
    
    X = pd.DataFrame(X_features)
    y = np.array(y_values)
    
    return X, y, timestamps, actual_values, sequences


def main():
    print("="*80)
    print("ðŸš€ 30ë¶„â†’25ë¶„ í›„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ")
    print("="*80)
    
    # ===== 1. í•™ìŠµ ë‹¨ê³„ =====
    print("\n[STEP 1] í•™ìŠµ ë°ì´í„° ë¡œë“œ")
    print("-"*40)
    
    df_train = pd.read_csv('HUB_0509_TO_09_DATA.csv', on_bad_lines='skip')
    
    print(f"í•™ìŠµ ë°ì´í„°: {len(df_train)}ê°œ í–‰")
    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ í™•ì¸:")
    
    all_feature_cols = []
    for group_name, cols in FEATURE_COLS.items():
        available = [col for col in cols if col in df_train.columns]
        all_feature_cols.extend(available)
        print(f"  - {group_name}: {len(available)}/{len(cols)}ê°œ")
    
    # STAT_DT ì²˜ë¦¬
    if 'STAT_DT' in df_train.columns:
        try:
            df_train['STAT_DT'] = pd.to_datetime(df_train['STAT_DT'].astype(str), format='%Y%m%d%H%M')
        except:
            print("âš ï¸ STAT_DT ë³€í™˜ ì‹¤íŒ¨, ê°€ìƒ ì‹œê°„ ìƒì„±")
            base_time = datetime(2024, 1, 1, 0, 0)
            df_train['STAT_DT'] = [base_time + timedelta(minutes=i) for i in range(len(df_train))]
    
    # í•™ìŠµ ë°ì´í„° ìƒì„±
    X_train, y_train, _, _, _ = create_features(df_train, seq_len=30, pred_offset=25)
    
    print(f"\nìƒì„±ëœ Feature ìˆ˜: {len(X_train.columns)}ê°œ")
    print(f"í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {len(X_train)}ê°œ")
    
    # í•™ìŠµ/ê²€ì¦ ë¶„í• 
    X_tr, X_val, y_tr, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42
    )
    
    # GPU/CPU ìžë™ ì„ íƒ
    print("\nðŸ” í•™ìŠµ í™˜ê²½ ê°ì§€ ì¤‘...")
    use_gpu = False
    
    try:
        print("  â†’ GPU ëª¨ë“œ ì‹œë„ ì¤‘...")
        test_model = xgb.XGBRegressor(
            n_estimators=5,
            max_depth=3,
            random_state=42,
            tree_method='gpu_hist',
            gpu_id=0
        )
        test_model.fit(X_tr[:100], y_tr[:100], verbose=False)
        use_gpu = True
        print("  âœ… GPU ì‚¬ìš© ê°€ëŠ¥! GPU ëª¨ë“œë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n")
    except Exception as e:
        print(f"  âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€: {str(e)[:100]}")
        print("  â†’ CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.\n")
        use_gpu = False
    
    # ì‹¤ì œ ëª¨ë¸ ìƒì„± (25ë¶„ ì˜ˆì¸¡ - n_estimators=100)
    if use_gpu:
        model = xgb.XGBRegressor(
            n_estimators=100,
            max_depth=3,
            learning_rate=0.15,
            subsample=0.5,
            colsample_bytree=0.5,
            min_child_weight=10,
            gamma=0.7,
            reg_alpha=0.8,
            reg_lambda=3.0,
            random_state=42,
            tree_method='gpu_hist',
            gpu_id=0,
            predictor='gpu_predictor'
        )
    else:
        model = xgb.XGBRegressor(
            n_estimators=100,
            max_depth=3,
            learning_rate=0.15,
            subsample=0.5,
            colsample_bytree=0.5,
            min_child_weight=10,
            gamma=0.7,
            reg_alpha=0.8,
            reg_lambda=3.0,
            random_state=42,
            tree_method='hist',
            n_jobs=-1
        )
    
    print("ëª¨ë¸ í•™ìŠµ ì¤‘ (30ë¶„â†’25ë¶„ í›„ ì˜ˆì¸¡)...")
    model.fit(
        X_tr, y_tr,
        eval_set=[(X_val, y_val)],
        verbose=False
    )
    
    # ëª¨ë¸ ì €ìž¥
    model_filename = 'xgboost_model_30min_25min_12ì»¬ëŸ¼.pkl'
    with open(model_filename, 'wb') as f:
        pickle.dump(model, f)
    
    print(f"\nâœ… ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: {model_filename}")
    
    # ê²€ì¦ ì„±ëŠ¥
    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
    
    y_pred = model.predict(X_val)
    mae = mean_absolute_error(y_val, y_pred)
    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
    r2 = r2_score(y_val, y_pred)
    
    print("\n" + "="*80)
    print("ðŸ“Š ê²€ì¦ ì„¸íŠ¸ ì„±ëŠ¥")
    print("="*80)
    print(f"MAE:  {mae:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"RÂ²:   {r2:.4f}")
    
    # ê·¹ë‹¨ê°’ ì„±ëŠ¥
    extreme_mask = y_val >= 300
    if extreme_mask.sum() > 0:
        extreme_mae = mean_absolute_error(y_val[extreme_mask], y_pred[extreme_mask])
        print(f"\nê·¹ë‹¨ê°’(â‰¥300) MAE: {extreme_mae:.2f}")
        print(f"ê·¹ë‹¨ê°’ ìƒ˜í”Œ ìˆ˜: {extreme_mask.sum()}ê°œ")
    
    print("\nâœ… í•™ìŠµ ì™„ë£Œ!")


if __name__ == '__main__':
    main()