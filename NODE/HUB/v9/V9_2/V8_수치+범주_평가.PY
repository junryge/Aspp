import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta
from sklearn.metrics import accuracy_score

# ========== ì„ê³„ê°’ ì„¤ì • (ì—¬ê¸°ì„œ ì¡°ì •!) ==========
SUDDEN_THRESHOLD = 30  # ê¸‰ë³€ í™•ë¥  ì„ê³„ê°’ (%) - 30, 40, 50 ë“± í…ŒìŠ¤íŠ¸
# ================================================

def evaluate_v8_2stage_v2():
    """
    ğŸ¯ V8 2ë‹¨ê³„ ë¶„ë¦¬ ëª¨ë¸ í‰ê°€ (V2 - ì„ê³„ê°’ ì¡°ì • ê°€ëŠ¥)
    
    ì„ê³„ê°’: SUDDEN_THRESHOLD (í˜„ì¬ {SUDDEN_THRESHOLD}%)
    â†’ ê¸‰ë³€ í™•ë¥ ì´ ì´ ê°’ ì´ìƒì´ë©´ ê¸‰ë³€ìœ¼ë¡œ íŒì •
    """
    print("="*80)
    print(f"ğŸ¯ V8 2ë‹¨ê³„ ë¶„ë¦¬ ëª¨ë¸ í‰ê°€ (ì„ê³„ê°’: {SUDDEN_THRESHOLD}%)")
    print("="*80)
    
    FEATURE_COLS_V8 = {
        'storage': ['M16A_3F_STORAGE_UTIL'],
        'fs_storage': ['CD_M163FSTORAGEUSE', 'CD_M163FSTORAGETOTAL', 'CD_M163FSTORAGEUTIL'],
        'hub': ['HUBROOMTOTAL'],
        'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],
        'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],
        'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],
        'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA'],
    }
    
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
    
    normal_class_names = {0: 'ì†Œí­í•˜ë½', 1: 'ì •ì²´', 2: 'ì†Œí­ìƒìŠ¹'}
    
    def get_actual_class(change):
        if change <= -50: return 'ê¸‰ë½'
        elif change <= -20: return 'ì†Œí­í•˜ë½'
        elif change <= 20: return 'ì •ì²´'
        elif change <= 50: return 'ì†Œí­ìƒìŠ¹'
        else: return 'ê¸‰ë“±'
    
    # ëª¨ë¸ ë¡œë“œ
    try:
        with open('xgboost_2stage_V8_v2.pkl', 'rb') as f:
            model_dict = pickle.load(f)
        sudden_detector = model_dict['sudden_detector']
        surge_model = model_dict['surge_model']
        drop_model = model_dict['drop_model']
        normal_clf = model_dict['normal_classifier']
        normal_regressors = model_dict['normal_regressors']
        print("âœ… ëª¨ë¸ ë¡œë“œ: xgboost_2stage_V8_v2.pkl")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì—†ìŒ: {e}")
        return None
    
    # ë°ì´í„° ë¡œë“œ
    try:
        df = pd.read_csv('test_data.csv', on_bad_lines='skip', encoding='utf-8', low_memory=False)
    except:
        try:
            df = pd.read_csv('test_data.csv', on_bad_lines='skip', encoding='cp949', low_memory=False)
        except:
            df = pd.read_csv('test_data.csv', on_bad_lines='skip', encoding='euc-kr', low_memory=False)
    
    df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')
    df = df.dropna(subset=[TARGET_COL])
    print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(df)}ê°œ í–‰")
    
    available_cols = set(df.columns)
    
    if 'STAT_DT' in df.columns:
        try:
            df['STAT_DT'] = pd.to_datetime(df['STAT_DT'].astype(str), format='%Y%m%d%H%M')
        except:
            df['STAT_DT'] = [datetime(2024,1,1) + timedelta(minutes=i) for i in range(len(df))]
    
    results = []
    x_range = np.arange(30)
    
    sudden_true_list = []
    sudden_pred_list = []
    
    print(f"\nâš™ï¸ ê¸‰ë³€ ì„ê³„ê°’: {SUDDEN_THRESHOLD}%")
    print("\ní‰ê°€ ì‹œì‘...")
    total = len(df) - 40
    
    for idx, i in enumerate(range(30, len(df) - 10)):
        if idx % 500 == 0:
            print(f"  ì§„í–‰: {idx}/{total} ({idx/total*100:.1f}%)")
        
        seq_data = df.iloc[i-30:i]
        seq_target = seq_data[TARGET_COL].values
        
        current_time = seq_data['STAT_DT'].iloc[-1]
        current_value = seq_target[-1]
        actual_value = df[TARGET_COL].iloc[i+9]
        actual_change = actual_value - current_value
        actual_class = get_actual_class(actual_change)
        actual_is_sudden = 1 if abs(actual_change) >= 50 else 0
        
        slope = np.polyfit(x_range, seq_target, 1)[0]
        
        # Feature ìƒì„±
        features = {
            'target_mean': np.mean(seq_target),
            'target_std': np.std(seq_target),
            'target_max': np.max(seq_target),
            'target_min': np.min(seq_target),
            'target_last_value': seq_target[-1],
            'target_slope': slope,
            'target_range': np.max(seq_target) - np.min(seq_target),
            'target_momentum': seq_target[-1] - seq_target[-5] if len(seq_target) >= 5 else 0,
            'target_accel': (seq_target[-1] - seq_target[-5]) - (seq_target[-5] - seq_target[-10]) if len(seq_target) >= 10 else 0,
            'target_volatility': np.std(np.diff(seq_target)),
        }
        
        for group_name, cols in FEATURE_COLS_V8.items():
            for col in cols:
                if col not in available_cols: continue
                col_seq = seq_data[col].values
                if group_name == 'maxcapa':
                    features[f'{col}_last_value'] = col_seq[-1]
                elif group_name in ['cmd', 'storage', 'fs_storage', 'hub']:
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_std'] = np.std(col_seq)
                    features[f'{col}_max'] = np.max(col_seq)
                    features[f'{col}_min'] = np.min(col_seq)
                    features[f'{col}_last_value'] = col_seq[-1]
                    features[f'{col}_slope'] = np.polyfit(x_range, col_seq, 1)[0]
                else:
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_last_value'] = col_seq[-1]
                    features[f'{col}_slope'] = np.polyfit(x_range, col_seq, 1)[0]
        
        if 'CD_M163FSTORAGEUTIL' in available_cols:
            util_last = seq_data['CD_M163FSTORAGEUTIL'].iloc[-1]
            features['storage_util_high'] = 1 if util_last >= 7 else 0
            features['storage_util_critical'] = 1 if util_last >= 10 else 0
        
        if 'HUBROOMTOTAL' in available_cols:
            hub_last = seq_data['HUBROOMTOTAL'].iloc[-1]
            features['hub_critical'] = 1 if hub_last < 590 else 0
            features['hub_high'] = 1 if hub_last < 610 else 0
        
        inflow = sum(seq_data[c].iloc[-1] for c in FEATURE_COLS_V8['inflow'] if c in available_cols)
        outflow = sum(seq_data[c].iloc[-1] for c in FEATURE_COLS_V8['outflow'] if c in available_cols)
        features['net_flow'] = inflow - outflow
        
        X_pred = pd.DataFrame([features])
        
        # ========== [1ë‹¨ê³„] ê¸‰ë³€ íƒì§€ (ì„ê³„ê°’ ì ìš©) ==========
        pred_sudden_proba = sudden_detector.predict_proba(X_pred)[0]
        sudden_prob = pred_sudden_proba[1] * 100
        
        # ì„ê³„ê°’ìœ¼ë¡œ íŒì • (í•µì‹¬!)
        pred_sudden = 1 if sudden_prob >= SUDDEN_THRESHOLD else 0
        
        sudden_true_list.append(actual_is_sudden)
        sudden_pred_list.append(pred_sudden)
        
        # ========== [2ë‹¨ê³„] ë¶„ê¸° ==========
        if pred_sudden == 1:
            if slope >= 0:
                if surge_model is not None:
                    final_change = surge_model.predict(X_pred)[0]
                else:
                    final_change = 60
                used_model = "ê¸‰ë“±ëª¨ë¸"
                pred_class = "ê¸‰ë“±"
            else:
                if drop_model is not None:
                    final_change = drop_model.predict(X_pred)[0]
                else:
                    final_change = -60
                used_model = "ê¸‰ë½ëª¨ë¸"
                pred_class = "ê¸‰ë½"
        else:
            normal_pred = normal_clf.predict(X_pred)[0]
            normal_proba = normal_clf.predict_proba(X_pred)[0]
            
            pred_class = normal_class_names[normal_pred]
            
            if normal_regressors[normal_pred] is not None:
                final_change = normal_regressors[normal_pred].predict(X_pred)[0]
            else:
                default = {0: -35, 1: 0, 2: 35}
                final_change = default[normal_pred]
            
            used_model = f"{pred_class}ëª¨ë¸"
        
        final_pred = current_value + final_change
        final_error = abs(actual_value - final_pred)
        
        class_correct = (pred_class == actual_class)
        
        hub_value = seq_data['HUBROOMTOTAL'].iloc[-1] if 'HUBROOMTOTAL' in available_cols else 0
        
        results.append({
            'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
            'ì˜ˆì¸¡ì‹œì ': (current_time + timedelta(minutes=10)).strftime('%Y-%m-%d %H:%M'),
            'í˜„ì¬ê°’': round(current_value, 2),
            'ì‹¤ì œê°’': round(actual_value, 2),
            'ì‹¤ì œ_ë³€í™”ëŸ‰': round(actual_change, 2),
            'ì‹¤ì œ_í´ë˜ìŠ¤': actual_class,
            'ì‹¤ì œ_ê¸‰ë³€': 'ê¸‰ë³€' if actual_is_sudden else 'ì¼ë°˜',
            'ê¸‰ë³€íƒì§€': 'ê¸‰ë³€' if pred_sudden else 'ì¼ë°˜',
            'ê¸‰ë³€í™•ë¥ ': round(sudden_prob, 1),
            'ê¸‰ë³€íƒì§€ì •í™•': 'âœ…' if pred_sudden == actual_is_sudden else 'âŒ',
            'ì˜ˆì¸¡_í´ë˜ìŠ¤': pred_class,
            'ë¶„ë¥˜ì •í™•': 'âœ…' if class_correct else 'âŒ',
            'ì‚¬ìš©ëª¨ë¸': used_model,
            'ìµœì¢…_ë³€í™”ëŸ‰': round(final_change, 2),
            'ìµœì¢…_ì˜ˆì¸¡': round(final_pred, 2),
            'ìµœì¢…_ì˜¤ì°¨': round(final_error, 2),
            'ì˜¤ì°¨â‰¤10': 'âœ…' if final_error <= 10 else '',
            'ì˜¤ì°¨â‰¤20': 'âœ…' if final_error <= 20 else '',
            'ì˜¤ì°¨â‰¤30': 'âœ…' if final_error <= 30 else '',
            'slope': round(slope, 4),
            'HUBROOMTOTAL': round(hub_value, 0),
        })
    
    results_df = pd.DataFrame(results)
    output_file = f'2ë‹¨ê³„_V8_v2_ì„ê³„ê°’{SUDDEN_THRESHOLD}_í‰ê°€ê²°ê³¼.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ì €ì¥: {output_file}")
    
    # ========== í†µê³„ ==========
    print("\n" + "="*80)
    print(f"ğŸ“Š í‰ê°€ í†µê³„ (V8 2ë‹¨ê³„ V2, ì„ê³„ê°’ {SUDDEN_THRESHOLD}%)")
    print("="*80)
    
    print(f"ì´ ì˜ˆì¸¡: {len(results_df)}ê°œ")
    
    # 1ë‹¨ê³„
    print(f"\nğŸ” [1ë‹¨ê³„] ê¸‰ë³€ íƒì§€ ì„±ëŠ¥:")
    sudden_true = np.array(sudden_true_list)
    sudden_pred = np.array(sudden_pred_list)
    
    sudden_acc = accuracy_score(sudden_true, sudden_pred)
    print(f"  ì „ì²´ ì •í™•ë„: {sudden_acc:.1%}")
    
    actual_sudden_mask = sudden_true == 1
    if actual_sudden_mask.sum() > 0:
        recall = (sudden_pred[actual_sudden_mask] == 1).mean()
        print(f"  ê¸‰ë³€ Recall: {recall:.1%} ({(sudden_pred[actual_sudden_mask] == 1).sum()}/{actual_sudden_mask.sum()}ê°œ)")
    
    pred_sudden_mask = sudden_pred == 1
    if pred_sudden_mask.sum() > 0:
        precision = (sudden_true[pred_sudden_mask] == 1).mean()
        print(f"  ê¸‰ë³€ Precision: {precision:.1%} ({(sudden_true[pred_sudden_mask] == 1).sum()}/{pred_sudden_mask.sum()}ê°œ)")
    
    normal_mask = sudden_true == 0
    if normal_mask.sum() > 0:
        false_alarm = (sudden_pred[normal_mask] == 1).sum()
        print(f"  ì˜¤íƒ (ì¼ë°˜â†’ê¸‰ë³€): {false_alarm}ê°œ ({false_alarm/normal_mask.sum()*100:.2f}%)")
    
    # 2ë‹¨ê³„
    print(f"\nğŸ¯ [2ë‹¨ê³„] ìµœì¢… ì˜ˆì¸¡ ì •í™•ë„:")
    
    acc_10 = (results_df['ì˜¤ì°¨â‰¤10'] == 'âœ…').sum() / len(results_df) * 100
    acc_20 = (results_df['ì˜¤ì°¨â‰¤20'] == 'âœ…').sum() / len(results_df) * 100
    acc_30 = (results_df['ì˜¤ì°¨â‰¤30'] == 'âœ…').sum() / len(results_df) * 100
    avg_err = results_df['ìµœì¢…_ì˜¤ì°¨'].mean()
    
    print(f"  ì˜¤ì°¨ â‰¤ 10: {acc_10:.1f}%")
    print(f"  ì˜¤ì°¨ â‰¤ 20: {acc_20:.1f}%")
    print(f"  ì˜¤ì°¨ â‰¤ 30: {acc_30:.1f}%")
    print(f"  í‰ê·  ì˜¤ì°¨: {avg_err:.2f}")
    
    # í´ë˜ìŠ¤ë³„
    print(f"\nğŸ“Š ì‹¤ì œ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
    for cls in ['ê¸‰ë½', 'ì†Œí­í•˜ë½', 'ì •ì²´', 'ì†Œí­ìƒìŠ¹', 'ê¸‰ë“±']:
        subset = results_df[results_df['ì‹¤ì œ_í´ë˜ìŠ¤'] == cls]
        if len(subset) > 0:
            avg_err = subset['ìµœì¢…_ì˜¤ì°¨'].mean()
            correct = (subset['ë¶„ë¥˜ì •í™•'] == 'âœ…').sum()
            print(f"  {cls}: í‰ê· ì˜¤ì°¨ {avg_err:.1f}, ë¶„ë¥˜ì •í™• {correct}/{len(subset)}ê°œ ({correct/len(subset)*100:.1f}%)")
    
    # í•µì‹¬!
    print(f"\nğŸ”¥ ê¸‰ë“±/ê¸‰ë½ ê°ì§€ ì„±ëŠ¥ (í•µì‹¬!):")
    
    surge_df = results_df[results_df['ì‹¤ì œ_í´ë˜ìŠ¤'] == 'ê¸‰ë“±']
    if len(surge_df) > 0:
        detected = (surge_df['ì˜ˆì¸¡_í´ë˜ìŠ¤'] == 'ê¸‰ë“±').sum()
        print(f"  ê¸‰ë“± ê°ì§€: {detected}/{len(surge_df)}ê°œ ({detected/len(surge_df)*100:.1f}%)")
    
    drop_df = results_df[results_df['ì‹¤ì œ_í´ë˜ìŠ¤'] == 'ê¸‰ë½']
    if len(drop_df) > 0:
        detected = (drop_df['ì˜ˆì¸¡_í´ë˜ìŠ¤'] == 'ê¸‰ë½').sum()
        print(f"  ê¸‰ë½ ê°ì§€: {detected}/{len(drop_df)}ê°œ ({detected/len(drop_df)*100:.1f}%)")
    
    # ëª¨ë¸ ì‚¬ìš© ë¶„í¬
    print(f"\nğŸ“Š ëª¨ë¸ ì‚¬ìš© ë¶„í¬:")
    for model in results_df['ì‚¬ìš©ëª¨ë¸'].value_counts().items():
        print(f"  {model[0]}: {model[1]}ê°œ ({model[1]/len(results_df)*100:.1f}%)")
    
    return results_df

if __name__ == '__main__':
    print("ğŸš€ V8 2ë‹¨ê³„ ë¶„ë¦¬ ëª¨ë¸ (V2) í‰ê°€ ì‹œì‘...\n")
    evaluate_v8_2stage_v2()