import numpy as np
import pandas as pd
import pickle
from datetime import datetime, timedelta
from sklearn.metrics import accuracy_score, confusion_matrix

def evaluate_v8_3stage():
    """
    ğŸ¯ V8 3ë‹¨ê³„ í‰ê°€ (14ê°œ ì»¬ëŸ¼ë§Œ ì‚¬ìš©)
    
    1ë‹¨ê³„: ë¶„ë¥˜ ëª¨ë¸ë¡œ ê¸‰ë“±/ê¸‰ë½/ìœ ì§€ íŒë‹¨
    2ë‹¨ê³„: 3ê°œ ì „ìš© ëª¨ë¸ë¡œ ê°ê° ì˜ˆì¸¡ (ì „ë¶€ í‘œì‹œ!)
    3ë‹¨ê³„: ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ìµœì¢… ì˜ˆì¸¡ ì„ íƒ
    """
    print("="*80)
    print("ğŸ¯ V8 3ë‹¨ê³„ í‰ê°€: ë¶„ë¥˜ â†’ ì „ìš© ìˆ˜ì¹˜ëª¨ë¸ (14ê°œ ì»¬ëŸ¼)")
    print("="*80)
    
    # ========== V8 ê¸°ì¡´ 14ê°œë§Œ ì‚¬ìš© ==========
    FEATURE_COLS_V8 = {
        'storage': ['M16A_3F_STORAGE_UTIL'],
        'fs_storage': ['CD_M163FSTORAGEUSE', 'CD_M163FSTORAGETOTAL', 'CD_M163FSTORAGEUTIL'],
        'hub': ['HUBROOMTOTAL'],
        'cmd': ['M16A_3F_CMD', 'M16A_6F_TO_HUB_CMD'],
        'inflow': ['M16A_6F_TO_HUB_JOB', 'M16A_2F_TO_HUB_JOB2', 'M14A_3F_TO_HUB_JOB2'],
        'outflow': ['M16A_3F_TO_M16A_6F_JOB', 'M16A_3F_TO_M16A_2F_JOB', 'M16A_3F_TO_M14A_3F_JOB'],
        'maxcapa': ['M16A_6F_LFT_MAXCAPA', 'M16A_2F_LFT_MAXCAPA'],
    }
    
    TARGET_COL = 'CURRENT_M16A_3F_JOB_2'
    
    def create_class_label(change):
        if change >= 50:
            return 2  # ê¸‰ë“±
        elif change <= -50:
            return 0  # ê¸‰ë½
        else:
            return 1  # ìœ ì§€
    
    class_names = {0: 'ê¸‰ë½', 1: 'ìœ ì§€', 2: 'ê¸‰ë“±'}
    
    # ========== ëª¨ë¸ ë¡œë“œ ==========
    try:
        with open('xgboost_3stage_V8.pkl', 'rb') as f:
            model_dict = pickle.load(f)
        
        clf_model = model_dict['classifier']
        reg_surge = model_dict['regressor_surge']
        reg_drop = model_dict['regressor_drop']
        reg_hold = model_dict['regressor_hold']
        
        print("âœ… ëª¨ë¸ ë¡œë“œ: xgboost_3stage_V8.pkl")
        print(f"  - ë¶„ë¥˜ ëª¨ë¸: âœ…")
        print(f"  - ê¸‰ë“± ëª¨ë¸: {'âœ…' if reg_surge else 'âŒ'}")
        print(f"  - ê¸‰ë½ ëª¨ë¸: {'âœ…' if reg_drop else 'âŒ'}")
        print(f"  - ìœ ì§€ ëª¨ë¸: {'âœ…' if reg_hold else 'âŒ'}")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì—†ìŒ: {e}")
        return None
    
    # ========== ë°ì´í„° ë¡œë“œ ==========
    try:
        df = pd.read_csv('test_data.csv', on_bad_lines='skip', encoding='utf-8', low_memory=False)
    except:
        try:
            df = pd.read_csv('test_data.csv', on_bad_lines='skip', encoding='cp949', low_memory=False)
        except:
            df = pd.read_csv('test_data.csv', on_bad_lines='skip', encoding='euc-kr', low_memory=False)
    
    df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')
    df = df.dropna(subset=[TARGET_COL])
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(df)}ê°œ í–‰")
    
    available_cols = set(df.columns)
    
    # ì‹œê°„ ì²˜ë¦¬
    if 'STAT_DT' in df.columns:
        try:
            df['STAT_DT'] = pd.to_datetime(df['STAT_DT'].astype(str), format='%Y%m%d%H%M')
        except:
            base_time = datetime(2024, 1, 1, 0, 0)
            df['STAT_DT'] = [base_time + timedelta(minutes=i) for i in range(len(df))]
    
    results = []
    all_true_class = []
    all_pred_class = []
    
    print("\ní‰ê°€ ì‹œì‘...")
    
    total_samples = len(df) - 40
    x_range = np.arange(30)
    
    for idx, i in enumerate(range(30, len(df) - 10)):
        if idx % 500 == 0:
            print(f"  ì§„í–‰: {idx}/{total_samples} ({idx/total_samples*100:.1f}%)")
        
        seq_data = df.iloc[i-30:i].copy()
        seq_target = seq_data[TARGET_COL].values
        
        current_time = seq_data['STAT_DT'].iloc[-1]
        current_value = seq_target[-1]
        prediction_time = current_time + timedelta(minutes=10)
        
        # ì‹¤ì œ 10ë¶„ í›„
        actual_value = df[TARGET_COL].iloc[i+9]
        actual_change = actual_value - current_value
        actual_class = create_class_label(actual_change)
        
        # ì¶”ì„¸
        target_slope = np.polyfit(x_range, seq_target, 1)[0]
        
        # ========== Feature ìƒì„± ==========
        features = {
            'target_mean': np.mean(seq_target),
            'target_std': np.std(seq_target),
            'target_max': np.max(seq_target),
            'target_min': np.min(seq_target),
            'target_last_value': seq_target[-1],
            'target_slope': target_slope,
        }
        
        # V8 ê¸°ì¡´ ì»¬ëŸ¼
        for group_name, cols in FEATURE_COLS_V8.items():
            for col in cols:
                if col not in available_cols:
                    continue
                col_seq = seq_data[col].values
                if group_name == 'maxcapa':
                    features[f'{col}_last_value'] = col_seq[-1]
                elif group_name in ['cmd', 'storage', 'fs_storage', 'hub']:
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_std'] = np.std(col_seq)
                    features[f'{col}_max'] = np.max(col_seq)
                    features[f'{col}_min'] = np.min(col_seq)
                    features[f'{col}_last_value'] = col_seq[-1]
                    features[f'{col}_slope'] = np.polyfit(x_range, col_seq, 1)[0]
                else:
                    features[f'{col}_mean'] = np.mean(col_seq)
                    features[f'{col}_last_value'] = col_seq[-1]
                    features[f'{col}_slope'] = np.polyfit(x_range, col_seq, 1)[0]
        
        # íŠ¹ìˆ˜ Feature
        if all(col in available_cols for col in ['CD_M163FSTORAGEUSE', 'CD_M163FSTORAGETOTAL', 'CD_M163FSTORAGEUTIL']):
            use_seq = seq_data['CD_M163FSTORAGEUSE'].values
            total_seq = seq_data['CD_M163FSTORAGETOTAL'].values
            util_seq = seq_data['CD_M163FSTORAGEUTIL'].values
            features['storage_util_high'] = 1 if util_seq[-1] >= 7 else 0
            features['storage_util_critical'] = 1 if util_seq[-1] >= 10 else 0
            features['storage_util_last'] = util_seq[-1]
            features['storage_use_rate'] = (use_seq[-1] - use_seq[0]) / 30
            features['storage_remaining'] = total_seq[-1] - use_seq[-1]
        
        if 'HUBROOMTOTAL' in available_cols:
            hub_seq = seq_data['HUBROOMTOTAL'].values
            hub_last = hub_seq[-1]
            features['hub_critical'] = 1 if hub_last < 590 else 0
            features['hub_high'] = 1 if hub_last < 610 else 0
            features['hub_warning'] = 1 if hub_last < 620 else 0
            features['hub_decrease_rate'] = (hub_seq[0] - hub_last) / 30
        
        # ë³µí•© Feature
        inflow_sum = sum(seq_data[col].iloc[-1] for col in FEATURE_COLS_V8['inflow'] if col in available_cols)
        outflow_sum = sum(seq_data[col].iloc[-1] for col in FEATURE_COLS_V8['outflow'] if col in available_cols)
        features['net_flow'] = inflow_sum - outflow_sum
        
        cmd_sum = sum(seq_data[col].iloc[-1] for col in FEATURE_COLS_V8['cmd'] if col in available_cols)
        features['total_cmd'] = cmd_sum
        features['total_cmd_low'] = 1 if cmd_sum < 220 else 0
        features['total_cmd_very_low'] = 1 if cmd_sum < 200 else 0
        
        features['surge_risk_score'] = (
            features.get('hub_high', 0) * 3 +
            features.get('storage_util_critical', 0) * 2 +
            features.get('total_cmd_low', 0) * 1 +
            features.get('storage_util_high', 0) * 1
        )
        
        X_pred = pd.DataFrame([features])
        
        # ========== 1ë‹¨ê³„: ë¶„ë¥˜ ==========
        pred_class = clf_model.predict(X_pred)[0]
        pred_proba = clf_model.predict_proba(X_pred)[0]
        
        all_true_class.append(actual_class)
        all_pred_class.append(pred_class)
        
        # ========== 2ë‹¨ê³„: 3ê°œ ëª¨ë¸ ì „ë¶€ ì˜ˆì¸¡ ==========
        if reg_surge is not None:
            surge_change = reg_surge.predict(X_pred)[0]
        else:
            surge_change = 50
        
        if reg_drop is not None:
            drop_change = reg_drop.predict(X_pred)[0]
        else:
            drop_change = -50
        
        if reg_hold is not None:
            hold_change = reg_hold.predict(X_pred)[0]
        else:
            hold_change = 0
        
        surge_pred = current_value + surge_change
        drop_pred = current_value + drop_change
        hold_pred = current_value + hold_change
        
        # ========== 3ë‹¨ê³„: ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ìµœì¢… ì„ íƒ ==========
        if pred_class == 2:
            final_change = surge_change
            final_pred = surge_pred
            used_model = "ê¸‰ë“±ëª¨ë¸"
        elif pred_class == 0:
            final_change = drop_change
            final_pred = drop_pred
            used_model = "ê¸‰ë½ëª¨ë¸"
        else:
            final_change = hold_change
            final_pred = hold_pred
            used_model = "ìœ ì§€ëª¨ë¸"
        
        final_error = abs(actual_value - final_pred)
        class_correct = (pred_class == actual_class)
        
        is_surge = actual_change >= 50
        is_drop = actual_change <= -50
        
        hub_value = 0
        if 'HUBROOMTOTAL' in available_cols:
            hub_value = seq_data['HUBROOMTOTAL'].iloc[-1]
        
        results.append({
            'í˜„ì¬ì‹œê°„': current_time.strftime('%Y-%m-%d %H:%M'),
            'ì˜ˆì¸¡ì‹œì ': prediction_time.strftime('%Y-%m-%d %H:%M'),
            'í˜„ì¬ê°’': round(current_value, 2),
            'ì‹¤ì œê°’': round(actual_value, 2),
            'ì‹¤ì œ_ë³€í™”ëŸ‰': round(actual_change, 2),
            'ì‹¤ì œ_í´ë˜ìŠ¤': class_names[actual_class],
            'ì˜ˆì¸¡_í´ë˜ìŠ¤': class_names[pred_class],
            'ë¶„ë¥˜ì •í™•': 'âœ…' if class_correct else 'âŒ',
            'ê¸‰ë“±ì˜ˆì¸¡': round(surge_pred, 2),
            'ê¸‰ë½ì˜ˆì¸¡': round(drop_pred, 2),
            'ìœ ì§€ì˜ˆì¸¡': round(hold_pred, 2),
            'ê¸‰ë“±ë³€í™”ëŸ‰': round(surge_change, 2),
            'ê¸‰ë½ë³€í™”ëŸ‰': round(drop_change, 2),
            'ìœ ì§€ë³€í™”ëŸ‰': round(hold_change, 2),
            'ìµœì¢…_ì˜ˆì¸¡': round(final_pred, 2),
            'ìµœì¢…_ë³€í™”ëŸ‰': round(final_change, 2),
            'ì‚¬ìš©ëª¨ë¸': used_model,
            'ìµœì¢…_ì˜¤ì°¨': round(final_error, 2),
            'ì˜¤ì°¨â‰¤10': 'âœ…' if final_error <= 10 else '',
            'ì˜¤ì°¨â‰¤20': 'âœ…' if final_error <= 20 else '',
            'ì˜¤ì°¨â‰¤30': 'âœ…' if final_error <= 30 else '',
            'ê¸‰ë“±ì—¬ë¶€': 'ğŸ“ˆ' if is_surge else '',
            'ê¸‰ë½ì—¬ë¶€': 'ğŸ“‰' if is_drop else '',
            'ê¸‰ë½í™•ë¥ ': round(pred_proba[0] * 100, 1),
            'ìœ ì§€í™•ë¥ ': round(pred_proba[1] * 100, 1),
            'ê¸‰ë“±í™•ë¥ ': round(pred_proba[2] * 100, 1),
            'ì¶”ì„¸': round(target_slope, 4),
            'HUBROOMTOTAL': round(hub_value, 0),
        })
    
    results_df = pd.DataFrame(results)
    
    output_file = '3ë‹¨ê³„_V8_í‰ê°€ê²°ê³¼.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")
    
    # ========== í†µê³„ ==========
    print("\n" + "="*80)
    print("ğŸ“Š í‰ê°€ í†µê³„ (V8 3ë‹¨ê³„)")
    print("="*80)
    
    print(f"ì´ ì˜ˆì¸¡: {len(results_df)}ê°œ")
    
    clf_accuracy = accuracy_score(all_true_class, all_pred_class)
    print(f"\nğŸ¯ ë¶„ë¥˜ ì •í™•ë„: {clf_accuracy:.4f} ({clf_accuracy*100:.1f}%)")
    
    print(f"\nğŸ“Š í´ë˜ìŠ¤ë³„ ë¶„ë¥˜:")
    for cls in [0, 1, 2]:
        mask = np.array(all_true_class) == cls
        if mask.sum() > 0:
            acc = (np.array(all_pred_class)[mask] == cls).mean()
            print(f"  {class_names[cls]}: {acc:.1%} ({mask.sum()}ê°œ)")
    
    acc_10 = (results_df['ì˜¤ì°¨â‰¤10'] == 'âœ…').sum()
    acc_20 = (results_df['ì˜¤ì°¨â‰¤20'] == 'âœ…').sum()
    acc_30 = (results_df['ì˜¤ì°¨â‰¤30'] == 'âœ…').sum()
    avg_error = results_df['ìµœì¢…_ì˜¤ì°¨'].mean()
    
    print(f"\nğŸ¯ ìµœì¢…_ì˜ˆì¸¡ ì •í™•ë„:")
    print(f"  ì˜¤ì°¨ â‰¤ 10: {acc_10}/{len(results_df)}ê°œ ({acc_10/len(results_df)*100:.1f}%)")
    print(f"  ì˜¤ì°¨ â‰¤ 20: {acc_20}/{len(results_df)}ê°œ ({acc_20/len(results_df)*100:.1f}%)")
    print(f"  ì˜¤ì°¨ â‰¤ 30: {acc_30}/{len(results_df)}ê°œ ({acc_30/len(results_df)*100:.1f}%)")
    print(f"  í‰ê·  ì˜¤ì°¨: {avg_error:.2f}")
    
    print(f"\nğŸ“Š ëª¨ë¸ë³„ ì˜¤ì°¨:")
    for model in ['ê¸‰ë“±ëª¨ë¸', 'ê¸‰ë½ëª¨ë¸', 'ìœ ì§€ëª¨ë¸']:
        subset = results_df[results_df['ì‚¬ìš©ëª¨ë¸'] == model]
        if len(subset) > 0:
            avg_err = subset['ìµœì¢…_ì˜¤ì°¨'].mean()
            print(f"  {model}: í‰ê· ì˜¤ì°¨ {avg_err:.1f} ({len(subset)}ê°œ)")
    
    print(f"\nğŸ“ˆğŸ“‰ ê¸‰ë“±/ê¸‰ë½ ì„±ëŠ¥:")
    
    surge_df = results_df[results_df['ê¸‰ë“±ì—¬ë¶€'] == 'ğŸ“ˆ']
    drop_df = results_df[results_df['ê¸‰ë½ì—¬ë¶€'] == 'ğŸ“‰']
    
    if len(surge_df) > 0:
        surge_error = surge_df['ìµœì¢…_ì˜¤ì°¨'].mean()
        surge_detected = (surge_df['ì˜ˆì¸¡_í´ë˜ìŠ¤'] == 'ê¸‰ë“±').sum()
        print(f"  ğŸ“ˆ ê¸‰ë“± ({len(surge_df)}ê°œ):")
        print(f"     í‰ê· ì˜¤ì°¨: {surge_error:.1f}")
        print(f"     ê°ì§€ ì„±ê³µ: {surge_detected}/{len(surge_df)}ê°œ ({surge_detected/len(surge_df)*100:.1f}%)")
    
    if len(drop_df) > 0:
        drop_error = drop_df['ìµœì¢…_ì˜¤ì°¨'].mean()
        drop_detected = (drop_df['ì˜ˆì¸¡_í´ë˜ìŠ¤'] == 'ê¸‰ë½').sum()
        print(f"  ğŸ“‰ ê¸‰ë½ ({len(drop_df)}ê°œ):")
        print(f"     í‰ê· ì˜¤ì°¨: {drop_error:.1f}")
        print(f"     ê°ì§€ ì„±ê³µ: {drop_detected}/{len(drop_df)}ê°œ ({drop_detected/len(drop_df)*100:.1f}%)")
    
    print(f"\nğŸ“ 400ëŒ€ ì¼€ì´ìŠ¤ ë¶„ì„:")
    high_value = results_df[(results_df['í˜„ì¬ê°’'] >= 400) & (results_df['í˜„ì¬ê°’'] <= 500)]
    if len(high_value) > 0:
        print(f"  ì¼€ì´ìŠ¤: {len(high_value)}ê°œ")
        print(f"  í‰ê·  ì˜¤ì°¨: {high_value['ìµœì¢…_ì˜¤ì°¨'].mean():.1f}")
    else:
        print(f"  ì¼€ì´ìŠ¤ ì—†ìŒ")
    
    return results_df

if __name__ == '__main__':
    print("ğŸš€ V8 3ë‹¨ê³„ í‰ê°€ ì‹œì‘...\n")
    results = evaluate_v8_3stage()
    
    if results is not None:
        print(f"\nâœ… í‰ê°€ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼: 3ë‹¨ê³„_V8_í‰ê°€ê²°ê³¼.csv")