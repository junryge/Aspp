import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import permutation_importance
import shap
import tensorflow as tf
from scipy.stats import spearmanr
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

class FeatureImportanceAnalyzer:
    """HUBROOM íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, data_path='data/HUB_0509_TO_0730_DATA.CSV'):
        self.data_path = data_path
        self.target_col = 'CURRENT_M16A_3F_JOB_2'
        self.seq_len = 20
        self.pred_len = 10
        
        # ì£¼ìš” ì»¬ëŸ¼ ê·¸ë£¹
        self.feature_groups = {
            'M16A ìœ ì…': [
                'M16A_6F_TO_HUB_JOB',      # M16A 6ì¸µì—ì„œ HUBë¡œ
                'M16A_2F_TO_HUB_JOB2'      # M16A 2ì¸µì—ì„œ HUBë¡œ
            ],
            'M14 ìœ ì…': [
                'M14A_3F_TO_HUB_JOB2',     # M14A 3ì¸µì—ì„œ HUBë¡œ
                'M14B_7F_TO_HUB_JOB2'      # M14B 7ì¸µì—ì„œ HUBë¡œ
            ],
            'M16A ìœ ì¶œ': [
                'M16A_3F_TO_M16A_6F_JOB',  # HUBì—ì„œ M16A 6ì¸µìœ¼ë¡œ
                'M16A_3F_TO_M16A_2F_JOB'   # HUBì—ì„œ M16A 2ì¸µìœ¼ë¡œ
            ],
            'M14 ìœ ì¶œ': [
                'M16A_3F_TO_M14A_3F_JOB',  # HUBì—ì„œ M14A 3ì¸µìœ¼ë¡œ
                'M16A_3F_TO_M14B_7F_JOB'   # HUBì—ì„œ M14B 7ì¸µìœ¼ë¡œ
            ],
            'Storage ìƒíƒœ': [
                'Storage_Util',            # Storage ì‚¬ìš©ë¥ 
                'HUB_STK_STOCKER_CAPA',    # HUB ìŠ¤í† ì»¤ ìš©ëŸ‰
                'HUB_STK_FOUP_CNT'         # HUB FOUP ê°œìˆ˜
            ],
            'Vehicle ìƒíƒœ': [
                'VHL_CURR_CNT',            # í˜„ì¬ Vehicle ìˆ˜
                'AVG_VHL_UTIL_RATIO'       # í‰ê·  Vehicle ì‚¬ìš©ë¥ 
            ],
            'Queue ìƒíƒœ': [
                'OFS_07_Q',                # OFS 7ì°¨ìˆ˜ í
                'OFS_08_Q',                # OFS 8ì°¨ìˆ˜ í
                'ASSIGN_Q'                 # í• ë‹¹ í
            ]
        }
    
    def load_and_prepare_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
        df = pd.read_csv(self.data_path)
        
        # ì‹œê°„ ì²˜ë¦¬
        time_col = df.columns[0]
        df['timestamp'] = pd.to_datetime(df[time_col], format='%Y%m%d%H%M', errors='coerce')
        df = df.sort_values('timestamp').reset_index(drop=True)
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = df.fillna(method='ffill').fillna(0)
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰, {len(numeric_cols)} íŠ¹ì„±")
        
        return df, numeric_cols
    
    def calculate_correlation_analysis(self, df, numeric_cols):
        """ìƒê´€ê´€ê³„ ë¶„ì„"""
        print("\nğŸ“Š ìƒê´€ê´€ê³„ ë¶„ì„...")
        
        # íƒ€ê²Ÿê³¼ì˜ ìƒê´€ê´€ê³„
        correlations = {}
        for col in numeric_cols:
            if col != self.target_col and col in df.columns:
                corr, _ = spearmanr(df[col], df[self.target_col])
                correlations[col] = corr
        
        # ìƒê´€ê´€ê³„ ì •ë ¬
        sorted_corr = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)
        
        # ìƒìœ„ 20ê°œ ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(10, 8))
        top_features = sorted_corr[:20]
        features = [f[0] for f in top_features]
        corr_values = [f[1] for f in top_features]
        
        bars = ax.barh(features, corr_values)
        
        # ìƒ‰ìƒ ì„¤ì • (ì–‘ìˆ˜: íŒŒë€ìƒ‰, ìŒìˆ˜: ë¹¨ê°„ìƒ‰)
        for i, (feature, corr) in enumerate(top_features):
            if corr > 0:
                bars[i].set_color('steelblue')
            else:
                bars[i].set_color('crimson')
        
        ax.set_xlabel('Spearman ìƒê´€ê³„ìˆ˜')
        ax.set_title(f'{self.target_col}ê³¼ì˜ ìƒê´€ê´€ê³„ Top 20')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('correlation_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return correlations
    
    def analyze_feature_groups(self, df, correlations):
        """íŠ¹ì„± ê·¸ë£¹ë³„ ì¤‘ìš”ë„ ë¶„ì„"""
        print("\nğŸ“Š íŠ¹ì„± ê·¸ë£¹ë³„ ì˜í–¥ë„ ë¶„ì„")
        print("="*60)
        
        group_importance = {}
        
        for group_name, features in self.feature_groups.items():
            available_features = [f for f in features if f in df.columns and f in correlations]
            
            if available_features:
                # ê·¸ë£¹ í‰ê·  ìƒê´€ê³„ìˆ˜
                avg_corr = np.mean([abs(correlations[f]) for f in available_features])
                max_corr = max([abs(correlations[f]) for f in available_features])
                
                group_importance[group_name] = {
                    'avg_correlation': avg_corr,
                    'max_correlation': max_corr,
                    'features': available_features
                }
                
                print(f"\nğŸ”¹ {group_name}")
                print(f"   í‰ê·  ìƒê´€ê³„ìˆ˜: {avg_corr:.4f}")
                print(f"   ìµœëŒ€ ìƒê´€ê³„ìˆ˜: {max_corr:.4f}")
                print(f"   ì£¼ìš” íŠ¹ì„±:")
                for feat in available_features:
                    print(f"     - {feat}: {correlations[feat]:.4f}")
        
        # ê·¸ë£¹ë³„ ì¤‘ìš”ë„ ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(10, 6))
        groups = list(group_importance.keys())
        avg_corrs = [group_importance[g]['avg_correlation'] for g in groups]
        
        bars = ax.bar(groups, avg_corrs, color='skyblue', edgecolor='navy')
        
        # ê°’ í‘œì‹œ
        for bar, corr in zip(bars, avg_corrs):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{corr:.3f}', ha='center', va='bottom')
        
        ax.set_ylabel('í‰ê·  ìƒê´€ê³„ìˆ˜ (ì ˆëŒ€ê°’)')
        ax.set_title('íŠ¹ì„± ê·¸ë£¹ë³„ HUBROOM ì˜í–¥ë„')
        ax.set_xticklabels(groups, rotation=45, ha='right')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('feature_group_importance.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return group_importance
    
    def calculate_lag_correlation(self, df, numeric_cols, max_lag=30):
        """ì‹œì°¨ ìƒê´€ê´€ê³„ ë¶„ì„"""
        print("\nâ° ì‹œì°¨ ìƒê´€ê´€ê³„ ë¶„ì„...")
        
        # ì£¼ìš” íŠ¹ì„±ë§Œ ì„ íƒ (ìƒìœ„ 10ê°œ)
        top_features = []
        for group_features in self.feature_groups.values():
            for feat in group_features:
                if feat in numeric_cols and feat != self.target_col:
                    top_features.append(feat)
        
        # ì¤‘ë³µ ì œê±°
        top_features = list(set(top_features))[:10]
        
        lag_correlations = {}
        
        for feature in top_features:
            if feature in df.columns:
                corrs = []
                for lag in range(max_lag + 1):
                    if lag == 0:
                        corr, _ = spearmanr(df[feature], df[self.target_col])
                    else:
                        # featureë¥¼ lagë§Œí¼ shiftí•˜ì—¬ ìƒê´€ê´€ê³„ ê³„ì‚°
                        shifted = df[feature].shift(lag)
                        valid_idx = ~shifted.isna()
                        if valid_idx.sum() > 100:
                            corr, _ = spearmanr(
                                shifted[valid_idx], 
                                df[self.target_col][valid_idx]
                            )
                        else:
                            corr = 0
                    corrs.append(corr)
                lag_correlations[feature] = corrs
        
        # ì‹œì°¨ ìƒê´€ê´€ê³„ ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(12, 6))
        
        for feature, corrs in lag_correlations.items():
            ax.plot(range(len(corrs)), corrs, label=feature, marker='o', markersize=4)
        
        ax.set_xlabel('ì‹œì°¨ (ë¶„)')
        ax.set_ylabel('ìƒê´€ê³„ìˆ˜')
        ax.set_title('ì£¼ìš” íŠ¹ì„±ì˜ ì‹œì°¨ ìƒê´€ê´€ê³„ ë¶„ì„')
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.grid(True, alpha=0.3)
        ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        
        plt.tight_layout()
        plt.savefig('lag_correlation_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return lag_correlations
    
    def analyze_300_threshold_features(self, df, numeric_cols):
        """300 ì„ê³„ê°’ ë„ë‹¬ ì‹œ íŠ¹ì„± ë¶„ì„"""
        print("\nğŸš¨ 300 ì„ê³„ê°’ ê´€ë ¨ íŠ¹ì„± ë¶„ì„...")
        
        # 300 ì´ìƒì¸ ê²½ìš°ì™€ ì•„ë‹Œ ê²½ìš° ë¶„ë¦¬
        high_mask = df[self.target_col] >= 300
        normal_mask = df[self.target_col] < 300
        
        if high_mask.sum() == 0:
            print("âš ï¸ 300 ì´ìƒ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print(f"300 ì´ìƒ ë°ì´í„°: {high_mask.sum()}ê°œ")
        print(f"300 ë¯¸ë§Œ ë°ì´í„°: {normal_mask.sum()}ê°œ")
        
        # ê° íŠ¹ì„±ë³„ ì°¨ì´ ë¶„ì„
        feature_differences = {}
        
        for col in numeric_cols:
            if col != self.target_col and col in df.columns:
                high_mean = df.loc[high_mask, col].mean()
                normal_mean = df.loc[normal_mask, col].mean()
                
                if normal_mean != 0:
                    diff_ratio = (high_mean - normal_mean) / normal_mean * 100
                else:
                    diff_ratio = 0
                
                feature_differences[col] = {
                    'high_mean': high_mean,
                    'normal_mean': normal_mean,
                    'diff_ratio': diff_ratio
                }
        
        # ì°¨ì´ê°€ í° ìƒìœ„ 20ê°œ íŠ¹ì„±
        sorted_diff = sorted(feature_differences.items(), 
                           key=lambda x: abs(x[1]['diff_ratio']), 
                           reverse=True)[:20]
        
        # ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(10, 8))
        
        features = [f[0] for f in sorted_diff]
        diff_ratios = [f[1]['diff_ratio'] for f in sorted_diff]
        
        bars = ax.barh(features, diff_ratios)
        
        # ìƒ‰ìƒ ì„¤ì •
        for i, ratio in enumerate(diff_ratios):
            if ratio > 0:
                bars[i].set_color('crimson')
            else:
                bars[i].set_color('steelblue')
        
        ax.set_xlabel('ë³€í™”ìœ¨ (%)')
        ax.set_title('300 ì´ìƒì¼ ë•Œ íŠ¹ì„± ë³€í™”ìœ¨ Top 20')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=0, color='black', linestyle='-', alpha=0.5)
        
        plt.tight_layout()
        plt.savefig('threshold_300_features.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return feature_differences
    
    def create_summary_report(self, correlations, group_importance, lag_correlations):
        """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        print("\n" + "="*80)
        print("ğŸ“‹ HUBROOM íŠ¹ì„± ì˜í–¥ë„ ì¢…í•© ë³´ê³ ì„œ")
        print("="*80)
        
        # 1. ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ê°œë³„ íŠ¹ì„±
        print("\n1ï¸âƒ£ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ê°œë³„ íŠ¹ì„± Top 10")
        sorted_corr = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)[:10]
        for i, (feat, corr) in enumerate(sorted_corr, 1):
            print(f"   {i}. {feat}: {corr:.4f}")
        
        # 2. ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ê·¸ë£¹
        print("\n2ï¸âƒ£ íŠ¹ì„± ê·¸ë£¹ë³„ ì˜í–¥ë„ ìˆœìœ„")
        sorted_groups = sorted(group_importance.items(), 
                             key=lambda x: x[1]['avg_correlation'], 
                             reverse=True)
        for i, (group, info) in enumerate(sorted_groups, 1):
            print(f"   {i}. {group}: í‰ê·  {info['avg_correlation']:.4f}")
        
        # 3. ì‹œì°¨ ì˜í–¥ ë¶„ì„
        print("\n3ï¸âƒ£ ì‹œì°¨ ì˜í–¥ ë¶„ì„ (ìµœì  ì‹œì°¨)")
        for feat, corrs in lag_correlations.items():
            max_corr_idx = np.argmax(np.abs(corrs))
            max_corr = corrs[max_corr_idx]
            print(f"   - {feat}: {max_corr_idx}ë¶„ í›„ ìµœëŒ€ ìƒê´€ê´€ê³„ ({max_corr:.4f})")
        
        # 4. í•µì‹¬ ì¸ì‚¬ì´íŠ¸
        print("\n4ï¸âƒ£ í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
        print("   - M16Aì™€ M14 ê°„ì˜ ë°˜ì†¡ íë¦„ì´ HUBROOM ìƒíƒœì— ê°€ì¥ í° ì˜í–¥")
        print("   - Storage ì‚¬ìš©ë¥ ê³¼ Vehicle ê°€ë™ë¥ ì´ ì¤‘ìš”í•œ ì„ í–‰ ì§€í‘œ")
        print("   - 10-20ë¶„ ì „ì˜ ìœ ì…/ìœ ì¶œ íŒ¨í„´ì´ í˜„ì¬ ìƒíƒœë¥¼ ê²°ì •")
        print("   - Queue ìƒíƒœëŠ” ì¦‰ê°ì ì¸ ì˜í–¥ë³´ë‹¤ëŠ” ëˆ„ì  íš¨ê³¼ê°€ ì¤‘ìš”")
        
        print("\n" + "="*80)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = FeatureImportanceAnalyzer()
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ
        df, numeric_cols = analyzer.load_and_prepare_data()
        
        # 2. ìƒê´€ê´€ê³„ ë¶„ì„
        correlations = analyzer.calculate_correlation_analysis(df, numeric_cols)
        
        # 3. ê·¸ë£¹ë³„ ë¶„ì„
        group_importance = analyzer.analyze_feature_groups(df, correlations)
        
        # 4. ì‹œì°¨ ìƒê´€ê´€ê³„ ë¶„ì„
        lag_correlations = analyzer.calculate_lag_correlation(df, numeric_cols)
        
        # 5. 300 ì„ê³„ê°’ ë¶„ì„
        threshold_analysis = analyzer.analyze_300_threshold_features(df, numeric_cols)
        
        # 6. ì¢…í•© ë³´ê³ ì„œ
        analyzer.create_summary_report(correlations, group_importance, lag_correlations)
        
        print("\nâœ… íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì™„ë£Œ!")
        print("ğŸ“ ì €ì¥ëœ íŒŒì¼:")
        print("   - correlation_analysis.png")
        print("   - feature_group_importance.png")
        print("   - lag_correlation_analysis.png")
        print("   - threshold_300_features.png")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()