"""
================================================================================
M14 ë°˜ì†¡ í ëª¨ë‹ˆí„°ë§ ì„œë²„
- Flask ì›¹ ì„œë²„
- m14_data.py: ë¡œê·¸í”„ë ˆì†Œì—ì„œ 280ë¶„ ë°ì´í„° ì¡°íšŒ
- predictor_10min.py: 10ë¶„ ì˜ˆì¸¡
- predictor_30min.py: 30ë¶„ ì˜ˆì¸¡
- evaluator.py: ì˜ˆì¸¡ í‰ê°€ (ë‚´ë¶€/ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ ì§€ì›)
- logpresso_alarm.py: ë¡œê·¸í”„ë ˆì†Œ ì•ŒëŒ ì¡°íšŒ
================================================================================
"""

from flask import Flask, jsonify, send_file, request
import pandas as pd
from datetime import datetime

# ëª¨ë“ˆ import
import m14_data
import predictor_10min
import predictor_30min
import evaluator
import logpresso_alarm

app = Flask(__name__)

# ë°ì´í„° ë§¤ë‹ˆì € (280ë¶„ ìœˆë„ìš°, data í´ë”ì— ì €ì¥)
data_manager = m14_data.M14DataManager(window_minutes=280, data_dir='data')

# ì˜ˆì¸¡ ëª¨ë“ˆ ì—°ê²°
data_manager.set_predictors(predictor_10min, predictor_30min)


@app.route('/')
def index():
    return send_file('index.html')


@app.route('/mini')
def mini():
    return send_file('mini.html')


@app.route('/api/data')
def get_data():
    """
    ì‹¤ì‹œê°„ ë°ì´í„° + ì˜ˆì¸¡ê°’ API
    - ë°ì´í„° ë§¤ë‹ˆì €ì—ì„œ ì €ì¥ëœ ë°ì´í„°/ì˜ˆì¸¡ê°’ ë°˜í™˜
    """
    
    # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
    if data_manager.data is None or len(data_manager.data) == 0:
        if not data_manager.initialize():
            return jsonify({'error': 'Data load failed'}), 500
    
    df = data_manager.get_data()
    predict_10_all, predict_30_all = data_manager.get_predictions()
    
    if df is None or len(df) == 0:
        return jsonify({'error': 'No data'}), 500
    
    # ì°¨íŠ¸ìš© ë°ì´í„° (ìµœê·¼ 60ë¶„ë§Œ)
    chart_len = min(60, len(df))
    df_chart = df.tail(chart_len).reset_index(drop=True)
    predict_10_list = predict_10_all[-chart_len:]
    predict_30_list = predict_30_all[-chart_len:]
    
    # ì‹œê°„ í¬ë§· ë³€í™˜
    times = []
    times_full = []
    for t in df_chart['CURRTIME'].values:
        t_str = str(t)
        if len(t_str) >= 12:
            times.append(f"{t_str[8:10]}:{t_str[10:12]}")
            times_full.append(f"{t_str[0:4]}-{t_str[4:6]}-{t_str[6:8]} {t_str[8:10]}:{t_str[10:12]}")
        else:
            times.append(t_str)
            times_full.append(t_str)
    
    # í˜„ì¬ ì‹œê°„ í¬ë§·
    last_t = str(df['CURRTIME'].iloc[-1])
    if len(last_t) >= 12:
        full_time = f"{last_t[0:4]}-{last_t[4:6]}-{last_t[6:8]} {last_t[8:10]}:{last_t[10:12]}"
    else:
        full_time = last_t
    
    current_val = int(df['TOTALCNT'].iloc[-1]) if pd.notna(df['TOTALCNT'].iloc[-1]) else 0
    
    # ì•ŒëŒ ê¸°ë¡ + ìƒíƒœ
    alert_10, alert_30 = data_manager.get_alerts()
    alarm_state = data_manager.get_alarm_state()
    
    # ê¸‰ì¦ ì»¬ëŸ¼ ê³„ì‚° (ìµœê·¼ 10ë¶„ ëŒ€ë¹„)
    spike_columns = []
    SPIKE_THRESHOLD = 50  # 50 ì´ìƒ ì¦ê°€ ì‹œ ê¸‰ì¦ìœ¼ë¡œ íŒë‹¨
    ANALYSIS_COLS = ['M14AM10A', 'M10AM14A', 'M14AM10ASUM', 
                     'M14AM14B', 'M14BM14A', 'M14AM14BSUM',
                     'M14AM16', 'M16M14A', 'M14AM16SUM']
    
    if len(df) >= 11:  # ìµœì†Œ 11ê°œ ë°ì´í„° í•„ìš” (í˜„ì¬ + 10ë¶„ì „)
        current_row = df.iloc[-1]
        prev_row = df.iloc[-11]  # 10ë¶„ ì „
        
        for col in ANALYSIS_COLS:
            if col in df.columns:
                curr_val = current_row.get(col, 0)
                prev_val = prev_row.get(col, 0)
                
                if pd.notna(curr_val) and pd.notna(prev_val):
                    change = float(curr_val) - float(prev_val)
                    if change >= SPIKE_THRESHOLD:
                        spike_columns.append({
                            'column': col,
                            'change': int(change),
                            'current': int(curr_val),
                            'previous': int(prev_val)
                        })
        
        # ë³€í™”ëŸ‰ ê¸°ì¤€ ì •ë ¬
        spike_columns.sort(key=lambda x: x['change'], reverse=True)
    
    return jsonify({
        'x': times,
        'x_full': times_full,
        'y': df_chart['TOTALCNT'].fillna(0).astype(int).tolist(),
        'predict_10_list': predict_10_list,
        'predict_30_list': predict_30_list,
        'current': current_val,
        'predict_10': predict_10_list[-1] if predict_10_list else 0,
        'predict_30': predict_30_list[-1] if predict_30_list else 0,
        'currtime': full_time,
        'idx': len(df),
        'total': len(df),
        'alert_10': alert_10,
        'alert_30': alert_30,
        'alarm_state': alarm_state,
        'spike_columns': spike_columns
    })


@app.route('/api/next')
def next_step():
    """ë‹¤ìŒ ìŠ¤í… - ìƒˆ ë°ì´í„° ì¶”ê°€ í›„ ì¡°íšŒ"""
    data_manager.update()
    return get_data()


@app.route('/api/reset')
def reset():
    """ë¦¬ì…‹ - ì „ì²´ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"""
    data_manager.refresh()
    return jsonify({'status': 'ok'})


@app.route('/api/status')
def status():
    """ì„œë²„ ìƒíƒœ"""
    return jsonify({
        'status': 'running',
        'data_count': len(data_manager.data) if data_manager.data is not None else 0,
        'last_update': str(data_manager.last_update) if data_manager.last_update else None,
        'sequence_length': 280,
    })


@app.route('/history')
def history():
    """ê³¼ê±° ë°ì´í„° ì¡°íšŒ í˜ì´ì§€"""
    return send_file('history.html')


@app.route('/api/history')
def get_history():
    """
    ê³¼ê±° ë°ì´í„° ì¡°íšŒ API
    
    Parameters:
        date: YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œ
    
    Returns:
        data: í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„° + ì˜ˆì¸¡ê°’
        alerts_10: 10ë¶„ ì˜ˆì¸¡ ì•ŒëŒ ê¸°ë¡
        alerts_30: 30ë¶„ ì˜ˆì¸¡ ì•ŒëŒ ê¸°ë¡
    """
    import os
    
    date_str = request.args.get('date', '')
    
    if not date_str or len(date_str) != 8:
        return jsonify({'error': 'ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤ (YYYYMMDD)'}), 400
    
    data_dir = data_manager.data_dir
    data_file = os.path.join(data_dir, f'm14_data_{date_str}.csv')
    pred_file = os.path.join(data_dir, f'm14_pred_{date_str}.csv')
    alert_file = os.path.join(data_dir, f'm14_alert_{date_str}.csv')
    
    # ë°ì´í„° íŒŒì¼ í™•ì¸
    if not os.path.exists(data_file):
        return jsonify({'error': f'{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'})
    
    try:
        # ì˜ˆì¸¡ íŒŒì¼ ë¨¼ì € í™•ì¸ (TOTALCNT í¬í•¨ëœ ê²½ìš°)
        if os.path.exists(pred_file):
            df_pred = pd.read_csv(pred_file)
            
            # pred íŒŒì¼ì— TOTALCNT ìˆìœ¼ë©´ ë°”ë¡œ ì‚¬ìš©
            if 'TOTALCNT' in df_pred.columns and 'CURRTIME' in df_pred.columns:
                df_merged = df_pred
            else:
                # ì—†ìœ¼ë©´ data íŒŒì¼ê³¼ merge
                df_data = pd.read_csv(data_file)
                if 'CURRTIME' in df_pred.columns:
                    df_merged = pd.merge(df_data, df_pred, on='CURRTIME', how='left')
                else:
                    for col in ['PREDICT_10', 'PREDICT_30', 'PRED_TIME_10', 'PRED_TIME_30']:
                        if col in df_pred.columns:
                            df_data[col] = df_pred[col].values[:len(df_data)]
                    df_merged = df_data
        else:
            # pred íŒŒì¼ ì—†ìœ¼ë©´ dataë§Œ
            df_merged = pd.read_csv(data_file)
        
        # NaN ì²˜ë¦¬
        df_merged = df_merged.fillna(0)
        
        # ì•ŒëŒ ê¸°ë¡ ë¡œë“œ
        alerts_10 = []
        alerts_30 = []
        
        if os.path.exists(alert_file):
            df_alert = pd.read_csv(alert_file)
            # TYPEì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (CSVì—ì„œ ì •ìˆ˜ë¡œ ì½í ìˆ˜ ìˆìŒ)
            df_alert['TYPE'] = df_alert['TYPE'].astype(str)
            for _, row in df_alert.iterrows():
                alert_item = {
                    'CURRTIME': row.get('CURRTIME', ''),
                    'VALUE': int(row.get('VALUE', 0)),
                    'ALARM_NO': int(row.get('ALARM_NO', 0)),
                    'IS_ALARM': bool(row.get('IS_ALARM', False)),
                    'COOLDOWN_MINS': int(row.get('COOLDOWN_MINS', 0)) if pd.notna(row.get('COOLDOWN_MINS')) else 0
                }
                # TYPEì´ '10' ë˜ëŠ” '30'ìœ¼ë¡œ ì €ì¥ë¨
                if row.get('TYPE') == '10':
                    alerts_10.append(alert_item)
                elif row.get('TYPE') == '30':
                    alerts_30.append(alert_item)
        
        # 10ë¶„ ëŒ€ë¹„ ê¸‰ì¦ ì»¬ëŸ¼ ê³„ì‚° (+50 ì´ìƒ)
        SPIKE_THRESHOLD = 50
        ANALYSIS_COLS = ['M14AM10A', 'M10AM14A', 'M14AM10ASUM', 
                         'M14AM14B', 'M14BM14A', 'M14AM14BSUM',
                         'M14AM16', 'M16M14A', 'M14AM16SUM']
        
        spike_info_list = []
        for idx in range(len(df_merged)):
            spike_cols = []
            if idx >= 10:  # 10ë¶„ ì „ ë°ì´í„°ê°€ ìˆì–´ì•¼ ë¹„êµ ê°€ëŠ¥
                current_row = df_merged.iloc[idx]
                prev_row = df_merged.iloc[idx - 10]
                
                for col in ANALYSIS_COLS:
                    if col in df_merged.columns:
                        curr_val = current_row.get(col, 0)
                        prev_val = prev_row.get(col, 0)
                        
                        if pd.notna(curr_val) and pd.notna(prev_val):
                            change = float(curr_val) - float(prev_val)
                            if change >= SPIKE_THRESHOLD:
                                spike_cols.append(f"{col} +{int(change)}")
            
            spike_info_list.append(', '.join(spike_cols) if spike_cols else '')
        
        df_merged['SPIKE_INFO'] = spike_info_list
        
        # ê²°ê³¼ ë°˜í™˜
        return jsonify({
            'date': date_str,
            'data': df_merged.to_dict('records'),
            'alerts_10': alerts_10,
            'alerts_30': alerts_30
        })
        
    except Exception as e:
        return jsonify({'error': f'ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}'}), 500


# ============================================================================
# ë¡œê·¸í”„ë ˆì†Œ ì•ŒëŒ API
# ============================================================================

@app.route('/api/logpresso_alarm')
def get_logpresso_alarm():
    """
    ë¡œê·¸í”„ë ˆì†Œ ì•ŒëŒ ì¡°íšŒ API
    
    Parameters:
        from: ì‹œì‘ ì‹œê°„ (YYYYMMDDHHMM00)
        to: ì¢…ë£Œ ì‹œê°„ (YYYYMMDDHHMM00)
    
    Returns:
        data: ì•ŒëŒ ë¦¬ìŠ¤íŠ¸ [{MEAS_TM, LSTM_FCAST_TM, ALARM_DESC, ALARM_YN}, ...]
    """
    from_time = request.args.get('from', '')
    to_time = request.args.get('to', '')
    
    if not from_time or not to_time:
        return jsonify({'error': 'from, to íŒŒë¼ë¯¸í„° í•„ìš”'}), 400
    
    try:
        alarms = logpresso_alarm.get_alarm_data(from_time, to_time)
        return jsonify({
            'from': from_time,
            'to': to_time,
            'count': len(alarms),
            'data': alarms
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ============================================================================
# í‰ê°€ ê´€ë ¨ ë¼ìš°íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)
# ============================================================================

@app.route('/evaluate')
def evaluate_page():
    """ì˜ˆì¸¡ í‰ê°€ í˜ì´ì§€"""
    return send_file('evaluate.html')


@app.route('/api/evaluate/start', methods=['POST', 'GET'])
def start_evaluate():
    """
    ë°±ê·¸ë¼ìš´ë“œ í‰ê°€ ì‹œì‘ API
    
    Parameters:
        date_start: ì‹œì‘ ë‚ ì§œ (YYYYMMDD)
        date_end: ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD)
        time_start: ì‹œì‘ ì‹œê°„ (HHMM)
        time_end: ì¢…ë£Œ ì‹œê°„ (HHMM)
        pred_type: '10' ë˜ëŠ” '30'
        data_source: 'internal' (íŒŒì¼) ë˜ëŠ” 'external' (ë¡œê·¸í”„ë ˆì†Œ)
    """
    date_start = request.args.get('date_start', '')
    date_end = request.args.get('date_end', '')
    time_start = request.args.get('time_start', '0000')
    time_end = request.args.get('time_end', '2359')
    pred_type = request.args.get('pred_type', '10')
    data_source = request.args.get('data_source', 'internal')  # ê¸°ë³¸ê°’: ë‚´ë¶€(íŒŒì¼)
    
    if not date_start or not date_end:
        return jsonify({'error': 'ì‹œì‘/ì¢…ë£Œ ë‚ ì§œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”'}), 400
    
    if len(date_start) != 8 or len(date_end) != 8:
        return jsonify({'error': 'ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤ (YYYYMMDD)'}), 400
    
    if pred_type not in ['10', '30']:
        return jsonify({'error': 'pred_typeì€ 10 ë˜ëŠ” 30ì´ì–´ì•¼ í•©ë‹ˆë‹¤'}), 400
    
    if data_source not in ['internal', 'external']:
        return jsonify({'error': 'data_sourceëŠ” internal ë˜ëŠ” externalì´ì–´ì•¼ í•©ë‹ˆë‹¤'}), 400
    
    success, msg = evaluator.eval_manager.start(
        data_dir=data_manager.data_dir,
        date_start=date_start,
        date_end=date_end,
        time_start=time_start,
        time_end=time_end,
        pred_type=pred_type,
        data_source=data_source
    )
    
    if success:
        return jsonify({'status': 'started', 'message': msg, 'data_source': data_source})
    else:
        return jsonify({'error': msg}), 400


@app.route('/api/evaluate/status')
def get_evaluate_status():
    """í‰ê°€ ì§„í–‰ ìƒíƒœ ì¡°íšŒ"""
    return jsonify(evaluator.eval_manager.get_status())


@app.route('/api/evaluate/result')
def get_evaluate_result():
    """í‰ê°€ ê²°ê³¼ ì¡°íšŒ"""
    result = evaluator.eval_manager.get_result()
    if result:
        return jsonify(result)
    else:
        return jsonify({'error': 'ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤ (í‰ê°€ ì§„í–‰ ì¤‘ì´ê±°ë‚˜ ì‹œì‘ë˜ì§€ ì•ŠìŒ)'}), 400


@app.route('/api/evaluate/reset')
def reset_evaluate():
    """í‰ê°€ ìƒíƒœ ì´ˆê¸°í™”"""
    evaluator.eval_manager.reset()
    return jsonify({'status': 'reset'})


@app.route('/api/evaluate/dates')
def get_available_dates():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ëª©ë¡ ë°˜í™˜ (ë‚´ë¶€ íŒŒì¼ìš©)"""
    dates = evaluator.get_available_dates(data_manager.data_dir)
    return jsonify({'dates': dates})


@app.route('/api/detail')
def get_detail():
    """
    ìƒì„¸ ë¶„ì„ API - íŠ¹ì • ì‹œì ì˜ ì»¬ëŸ¼ë³„ ë³€í™”ëŸ‰ ë¶„ì„
    
    Parameters:
        date: YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œ
        time: HHMM í˜•ì‹ì˜ ì‹œê°„
        range: ë¶„ì„ ë²”ìœ„ (ë¶„ ë‹¨ìœ„, ê¸°ë³¸ê°’ 10)
    
    Returns:
        current: í˜„ì¬ ì‹œì  ë°ì´í„°
        previous: ì´ì „ ì‹œì  ë°ì´í„° (rangeë¶„ ì „)
        changes: ì»¬ëŸ¼ë³„ ë³€í™”ëŸ‰/ë³€í™”ìœ¨
    
    ë¶„ì„ ëŒ€ìƒ ì»¬ëŸ¼:
        - M14AM10A, M10AM14A, M14AM10ASUM
        - M14AM14B, M14BM14A, M14AM14BSUM
        - M14AM16, M16M14A, M14AM16SUM
        - M14.QUE.ALL.CURRENTQCREATED (ë¯¸ìˆ˜ì§‘ ê°€ëŠ¥)
        - M14.QUE.ALL.CURRENTQCOMPLETED (ë¯¸ìˆ˜ì§‘ ê°€ëŠ¥)
        - M14.QUE.OHT.OHTUTIL (ë¯¸ìˆ˜ì§‘ ê°€ëŠ¥)
        - M14.QUE.ALL.TRANSPORT4MINOVERCNT (ë¯¸ìˆ˜ì§‘ ê°€ëŠ¥)
        - M14B.QUE.SENDFAB.VERTICALQUEUECOUNT (ë¯¸ìˆ˜ì§‘ ê°€ëŠ¥)
    """
    import os
    
    date_str = request.args.get('date', '')
    time_str = request.args.get('time', '')
    range_min = int(request.args.get('range', '10'))
    
    if not date_str or len(date_str) != 8:
        return jsonify({'error': 'ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤ (YYYYMMDD)'}), 400
    
    if not time_str or len(time_str) != 4:
        return jsonify({'error': 'ì‹œê°„ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤ (HHMM)'}), 400
    
    # ë¶„ì„ ëŒ€ìƒ ì»¬ëŸ¼
    ANALYSIS_COLUMNS = [
        'M14AM10A', 'M10AM14A', 'M14AM10ASUM',
        'M14AM14B', 'M14BM14A', 'M14AM14BSUM',
        'M14AM16', 'M16M14A', 'M14AM16SUM',
        'M14.QUE.ALL.CURRENTQCREATED',
        'M14.QUE.ALL.CURRENTQCOMPLETED',
        'M14.QUE.OHT.OHTUTIL',
        'M14.QUE.ALL.TRANSPORT4MINOVERCNT',
        'M14B.QUE.SENDFAB.VERTICALQUEUECOUNT'
    ]
    
    # ë¯¸ìˆ˜ì§‘ ê°€ëŠ¥ ì»¬ëŸ¼ (star_transport_viewì—ì„œ ì˜¤ëŠ” ì»¬ëŸ¼)
    UNCOLLECTED_COLUMNS = [
        'M14.QUE.ALL.CURRENTQCREATED',
        'M14.QUE.ALL.CURRENTQCOMPLETED',
        'M14.QUE.OHT.OHTUTIL',
        'M14.QUE.ALL.TRANSPORT4MINOVERCNT',
        'M14B.QUE.SENDFAB.VERTICALQUEUECOUNT'
    ]
    
    data_dir = data_manager.data_dir
    
    # í˜„ì¬ ì‹œê°„ê³¼ ì´ì „ ì‹œê°„ ê³„ì‚°
    current_time = date_str + time_str
    
    # ì´ì „ ì‹œê°„ ê³„ì‚° (rangeë¶„ ì „)
    try:
        from datetime import datetime, timedelta
        dt = datetime.strptime(current_time, "%Y%m%d%H%M")
        dt_prev = dt - timedelta(minutes=range_min)
        prev_date_str = dt_prev.strftime("%Y%m%d")
        prev_time_str = dt_prev.strftime("%H%M")
        prev_time_full = dt_prev.strftime("%Y%m%d%H%M")
    except Exception as e:
        return jsonify({'error': f'ì‹œê°„ ê³„ì‚° ì‹¤íŒ¨: {str(e)}'}), 400
    
    # ë°ì´í„° íŒŒì¼ë“¤ ë¡œë“œ (í˜„ì¬ ë‚ ì§œ + ì´ì „ ë‚ ì§œê°€ ë‹¤ë¥´ë©´ ë‘˜ ë‹¤)
    all_data = []
    dates_to_load = list(set([date_str, prev_date_str]))
    
    for d in dates_to_load:
        data_file = os.path.join(data_dir, f'm14_data_{d}.csv')
        if os.path.exists(data_file):
            try:
                df = pd.read_csv(data_file)
                df['CURRTIME'] = df['CURRTIME'].astype(str)
                all_data.append(df)
            except Exception as e:
                print(f"[detail] íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {d}: {e}")
    
    if not all_data:
        return jsonify({'error': 'ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}), 404
    
    # ë°ì´í„° ë³‘í•©
    df_all = pd.concat(all_data, ignore_index=True)
    df_all = df_all.drop_duplicates(subset=['CURRTIME'], keep='last')
    df_all = df_all.sort_values('CURRTIME').reset_index(drop=True)
    
    # í˜„ì¬ ì‹œì  ë°ì´í„° ì°¾ê¸°
    current_row = df_all[df_all['CURRTIME'] == current_time]
    if len(current_row) == 0:
        return jsonify({'error': f'{date_str} {time_str[:2]}:{time_str[2:]} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}), 404
    
    current_row = current_row.iloc[0]
    
    # ì´ì „ ì‹œì  ë°ì´í„° ì°¾ê¸°
    prev_row = df_all[df_all['CURRTIME'] == prev_time_full]
    if len(prev_row) == 0:
        # ì •í™•í•œ ì‹œê°„ì´ ì—†ìœ¼ë©´ ê°€ì¥ ê°€ê¹Œìš´ ì´ì „ ì‹œê°„ ì°¾ê¸°
        prev_candidates = df_all[df_all['CURRTIME'] < current_time]
        if len(prev_candidates) > 0:
            prev_row = prev_candidates.iloc[-1]
            prev_time_full = prev_row['CURRTIME']
        else:
            return jsonify({'error': f'{range_min}ë¶„ ì „ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}), 404
    else:
        prev_row = prev_row.iloc[0]
    
    # ë³€í™”ëŸ‰ ê³„ì‚°
    changes = []
    for col in ANALYSIS_COLUMNS:
        current_val = current_row.get(col, 0) if col in current_row.index else 0
        prev_val = prev_row.get(col, 0) if col in prev_row.index else 0
        
        # NaN ì²˜ë¦¬
        if pd.isna(current_val):
            current_val = 0
        if pd.isna(prev_val):
            prev_val = 0
        
        current_val = float(current_val)
        prev_val = float(prev_val)
        
        change = current_val - prev_val
        change_rate = (change / prev_val * 100) if prev_val != 0 else 0
        
        # ë¯¸ìˆ˜ì§‘ ì—¬ë¶€ íŒë‹¨ (ê°’ì´ ëª¨ë‘ 0ì´ë©´ ë¯¸ìˆ˜ì§‘ ê°€ëŠ¥ì„±)
        is_uncollected = col in UNCOLLECTED_COLUMNS and current_val == 0 and prev_val == 0
        
        changes.append({
            'column': col,
            'current': current_val,
            'previous': prev_val,
            'change': change,
            'change_rate': round(change_rate, 1),
            'is_uncollected': is_uncollected
        })
    
    # ë³€í™”ëŸ‰ ì ˆëŒ€ê°’ ê¸°ì¤€ ì •ë ¬
    changes.sort(key=lambda x: abs(x['change']), reverse=True)
    
    return jsonify({
        'current_time': current_time,
        'previous_time': prev_time_full,
        'range': range_min,
        'current': {
            'CURRTIME': str(current_row.get('CURRTIME', '')),
            'TOTALCNT': int(current_row.get('TOTALCNT', 0)) if pd.notna(current_row.get('TOTALCNT')) else 0
        },
        'previous': {
            'CURRTIME': str(prev_row.get('CURRTIME', '')),
            'TOTALCNT': int(prev_row.get('TOTALCNT', 0)) if pd.notna(prev_row.get('TOTALCNT')) else 0
        },
        'changes': changes
    })


# ============================================================================
# LLM ë¶„ì„ ì„œë²„ í”„ë¡ì‹œ (llm_analysis_server.py:8002ë¡œ ì „ë‹¬)
# ============================================================================
LLM_SERVER_URL = "http://127.0.0.1:8002"

@app.route('/api/llm_mode', methods=['POST'])
def proxy_llm_mode():
    """LLM ëª¨ë“œ ì„¤ì • í”„ë¡ì‹œ"""
    import requests as req
    try:
        resp = req.post(f"{LLM_SERVER_URL}/api/llm_mode", json=request.get_json(), timeout=30)
        return jsonify(resp.json()), resp.status_code
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/llm_history_analyze', methods=['POST'])
def proxy_llm_history_analyze():
    """LLM íˆìŠ¤í† ë¦¬ ë¶„ì„ í”„ë¡ì‹œ (ìŠ¤íŠ¸ë¦¬ë°)"""
    import requests as req
    try:
        resp = req.post(
            f"{LLM_SERVER_URL}/api/llm_history_analyze",
            json=request.get_json(),
            stream=True,
            timeout=300
        )
        
        def generate():
            for chunk in resp.iter_content(chunk_size=1024):
                if chunk:
                    yield chunk
        
        return app.response_class(generate(), mimetype='text/event-stream')
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/prompts', methods=['GET', 'POST'])
def proxy_prompts():
    """í”„ë¡¬í”„íŠ¸ ì„¤ì • í”„ë¡ì‹œ"""
    import requests as req
    try:
        if request.method == 'GET':
            resp = req.get(f"{LLM_SERVER_URL}/api/prompts", timeout=30)
        else:
            resp = req.post(f"{LLM_SERVER_URL}/api/prompts", json=request.get_json(), timeout=30)
        return jsonify(resp.json()), resp.status_code
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/llm_status', methods=['GET'])
def proxy_llm_status():
    """LLM ìƒíƒœ ì¡°íšŒ í”„ë¡ì‹œ"""
    import requests as req
    try:
        resp = req.get(f"{LLM_SERVER_URL}/api/status", timeout=30)
        return jsonify(resp.json()), resp.status_code
    except Exception as e:
        return jsonify({'error': str(e), 'status': 'offline'}), 500


@app.route('/api/realtime_detail')
def get_realtime_detail():
    """
    ì‹¤ì‹œê°„ ìƒì„¸ ë¶„ì„ API - ë©”ëª¨ë¦¬ ë°ì´í„°ì—ì„œ ì»¬ëŸ¼ë³„ ë³€í™”ëŸ‰ ë¶„ì„
    
    Parameters:
        time: YYYYMMDDHHMM í˜•ì‹ì˜ ì‹œê°„
        range: ë¶„ì„ ë²”ìœ„ (ë¶„ ë‹¨ìœ„, ê¸°ë³¸ê°’ 10)
    
    Returns:
        current: í˜„ì¬ ì‹œì  ë°ì´í„°
        previous: ì´ì „ ì‹œì  ë°ì´í„° (rangeë¶„ ì „)
        changes: ì»¬ëŸ¼ë³„ ë³€í™”ëŸ‰/ë³€í™”ìœ¨
    """
    time_str = request.args.get('time', '')
    range_min = int(request.args.get('range', '10'))
    
    if not time_str or len(time_str) != 12:
        return jsonify({'error': 'ì‹œê°„ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤ (YYYYMMDDHHMM)'}), 400
    
    # ë¶„ì„ ëŒ€ìƒ ì»¬ëŸ¼
    ANALYSIS_COLUMNS = [
        'M14AM10A', 'M10AM14A', 'M14AM10ASUM',
        'M14AM14B', 'M14BM14A', 'M14AM14BSUM',
        'M14AM16', 'M16M14A', 'M14AM16SUM',
        'M14.QUE.ALL.CURRENTQCREATED',
        'M14.QUE.ALL.CURRENTQCOMPLETED',
        'M14.QUE.OHT.OHTUTIL',
        'M14.QUE.ALL.TRANSPORT4MINOVERCNT',
        'M14B.QUE.SENDFAB.VERTICALQUEUECOUNT'
    ]
    
    # ë¯¸ìˆ˜ì§‘ ê°€ëŠ¥ ì»¬ëŸ¼
    UNCOLLECTED_COLUMNS = [
        'M14.QUE.ALL.CURRENTQCREATED',
        'M14.QUE.ALL.CURRENTQCOMPLETED',
        'M14.QUE.OHT.OHTUTIL',
        'M14.QUE.ALL.TRANSPORT4MINOVERCNT',
        'M14B.QUE.SENDFAB.VERTICALQUEUECOUNT'
    ]
    
    # ë©”ëª¨ë¦¬ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    df = data_manager.get_data()
    
    if df is None or len(df) == 0:
        return jsonify({'error': 'ì‹¤ì‹œê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}), 404
    
    df['CURRTIME'] = df['CURRTIME'].astype(str)
    
    # í˜„ì¬ ì‹œì  ë°ì´í„° ì°¾ê¸°
    current_row = df[df['CURRTIME'] == time_str]
    if len(current_row) == 0:
        return jsonify({'error': f'{time_str} ì‹œì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}), 404
    
    current_idx = current_row.index[0]
    current_row = current_row.iloc[0]
    
    # ì´ì „ ì‹œì  ì°¾ê¸° (range_min ì „)
    prev_idx = max(0, current_idx - range_min)
    prev_row = df.iloc[prev_idx]
    prev_time_full = str(prev_row['CURRTIME'])
    
    # ë³€í™”ëŸ‰ ê³„ì‚°
    changes = []
    for col in ANALYSIS_COLUMNS:
        current_val = current_row.get(col, 0) if col in current_row.index else 0
        prev_val = prev_row.get(col, 0) if col in prev_row.index else 0
        
        # NaN ì²˜ë¦¬
        if pd.isna(current_val):
            current_val = 0
        if pd.isna(prev_val):
            prev_val = 0
        
        current_val = float(current_val)
        prev_val = float(prev_val)
        
        change = current_val - prev_val
        change_rate = (change / prev_val * 100) if prev_val != 0 else 0
        
        # ë¯¸ìˆ˜ì§‘ ì—¬ë¶€ íŒë‹¨
        is_uncollected = col in UNCOLLECTED_COLUMNS and current_val == 0 and prev_val == 0
        
        changes.append({
            'column': col,
            'current': current_val,
            'previous': prev_val,
            'change': change,
            'change_rate': round(change_rate, 1),
            'is_uncollected': is_uncollected
        })
    
    # ë³€í™”ëŸ‰ ì ˆëŒ€ê°’ ê¸°ì¤€ ì •ë ¬
    changes.sort(key=lambda x: abs(x['change']), reverse=True)
    
    return jsonify({
        'current_time': time_str,
        'previous_time': prev_time_full,
        'range': range_min,
        'current': {
            'CURRTIME': str(current_row.get('CURRTIME', '')),
            'TOTALCNT': int(current_row.get('TOTALCNT', 0)) if pd.notna(current_row.get('TOTALCNT')) else 0
        },
        'previous': {
            'CURRTIME': str(prev_row.get('CURRTIME', '')),
            'TOTALCNT': int(prev_row.get('TOTALCNT', 0)) if pd.notna(prev_row.get('TOTALCNT')) else 0
        },
        'changes': changes
    })


if __name__ == '__main__':
    print('=' * 60)
    print('M14 ë°˜ì†¡ í ëª¨ë‹ˆí„°ë§ ì„œë²„')
    print('=' * 60)
    print('ğŸ“¦ ëª¨ë“ˆ:')
    print('  - m14_data.py: ë¡œê·¸í”„ë ˆì†Œ 280ë¶„ ë°ì´í„° ì¡°íšŒ')
    print('  - predictor_10min.py: V10_4 10ë¶„ ì˜ˆì¸¡')
    print('  - predictor_30min.py: V10_4 30ë¶„ ì˜ˆì¸¡')
    print('  - evaluator.py: ì˜ˆì¸¡ í‰ê°€ (ë‚´ë¶€/ì™¸ë¶€ ì§€ì›)')
    print('  - logpresso_alarm.py: ë¡œê·¸í”„ë ˆì†Œ ì•ŒëŒ ì¡°íšŒ')
    print('=' * 60)
    print('ğŸŒ http://localhost:5000')
    print('   /evaluate - ì˜ˆì¸¡ í‰ê°€ í˜ì´ì§€')
    print('     ğŸ“ ë‚´ë¶€: data í´ë” CSV íŒŒì¼ ì‚¬ìš©')
    print('     ğŸŒ ì™¸ë¶€: ë¡œê·¸í”„ë ˆì†Œ API ì§ì ‘ ì¡°íšŒ')
    print('   /api/logpresso_alarm - ë¡œê·¸í”„ë ˆì†Œ ì•ŒëŒ ì¡°íšŒ')
    print('=' * 60)
    
    # ì´ˆê¸° ë°ì´í„° ë¡œë“œ
    print('\n[ì´ˆê¸°í™”] 280ë¶„ ë°ì´í„° ë¡œë“œ ì¤‘...')
    data_manager.initialize()
    
    # ì„œë²„ ì‹œì‘
    app.run(debug=False, port=5000)#, host='0.0.0.0')