"""
âš¡ ë§ˆê¸°(main1_First) ì½”ë”© ì—ì´ì „íŠ¸ - nanobot-ai ì§ì ‘ import í†µí•©
pip install nanobot-ai í›„ ì‚¬ìš©
"""
import asyncio, json, os, re, time, traceback
from pathlib import Path
from typing import Any, Optional
from datetime import datetime

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from loguru import logger

# nanobot ë‚´ë¶€ ëª¨ë“ˆ ì§ì ‘ import
from nanobot.agent.loop import AgentLoop
from nanobot.agent.context import ContextBuilder
from nanobot.agent.memory import MemoryStore
from nanobot.agent.tools.registry import ToolRegistry
from nanobot.agent.tools.base import Tool
from nanobot.agent.tools.filesystem import ReadFileTool, WriteFileTool, EditFileTool, ListDirTool
from nanobot.agent.tools.shell import ExecTool
from nanobot.bus.queue import MessageBus
from nanobot.bus.events import InboundMessage, OutboundMessage
from nanobot.providers.base import LLMProvider, LLMResponse, ToolCallRequest
from nanobot.session.manager import SessionManager

# ì„¤ì •
WORKSPACE = Path("nanobot_workspace")
WORKSPACE.mkdir(exist_ok=True)
(WORKSPACE / "output").mkdir(exist_ok=True)
(WORKSPACE / "memory").mkdir(exist_ok=True)
KNOWLEDGE_DIR = Path(__file__).parent / "knowledge"  # ì§€ì‹ë² ì´ìŠ¤ í´ë” (MD)
DOMAIN_KNOWLEDGE_FILE = Path(__file__).parent / "domain_knowledge.txt"  # ë„ë©”ì¸ ì§€ì‹ (TXT)
RALPH_MAX_RETRY = 3
MAX_ITERATIONS = 15


class SKHynixProvider(LLMProvider):
    """SK Hynix LLM API - nanobot LLMProvider ìƒì†"""
    def __init__(self):
        super().__init__()
        self._token = self._url = self._model = None
        self._sync()

    def _sync(self):
        try:
            import pc_assistant as pa
            self._token = getattr(pa, 'API_TOKEN', None)
            self._url = getattr(pa, 'API_URL', None)
            self._model = getattr(pa, 'API_MODEL', None)
        except ImportError:
            tp = Path("token.txt")
            if tp.exists(): self._token = tp.read_text().strip()
            self._url = "http://dev.assistant.llm.skhynix.com/v1/chat/completions"
            self._model = "Qwen3-Coder-30B-A3B-Instruct"

    def _get_local_llm(self):
        """pc_assistantì—ì„œ ë¡œë“œëœ GGUF ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            import pc_assistant as pa
            return getattr(pa, 'LOCAL_LLM', None)
        except:
            return None

    def _call_gguf(self, messages, max_tokens=1024, temperature=0.7):
        """GGUF ë¡œì»¬ ëª¨ë¸ë¡œ ëŒ€í™” (tool_calls ë¯¸ì§€ì›, í…ìŠ¤íŠ¸ ì‘ë‹µë§Œ)"""
        local_llm = self._get_local_llm()
        if not local_llm:
            return None

        # í˜„ì¬ ëª¨ë¸ í™•ì¸
        is_gemma = False
        try:
            import pc_assistant as pa
            is_gemma = getattr(pa, 'CURRENT_LOCAL_MODEL', '') == 'gemma3-12b'
        except:
            pass

        # messages â†’ í”„ë¡¬í”„íŠ¸ ë³€í™˜ (ëª¨ë¸ë³„)
        prompt_parts = []
        if is_gemma:
            # Gemma 3: systemì„ userì— í•©ì¹¨
            sys_content = ""
            for msg in messages:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                if role == "system":
                    sys_content = content + "\n\n"
                elif role == "user":
                    prompt_parts.append(f"<start_of_turn>user\n{sys_content}{content}<end_of_turn>")
                    sys_content = ""
                elif role == "assistant":
                    prompt_parts.append(f"<start_of_turn>model\n{content}<end_of_turn>")
            prompt_parts.append("<start_of_turn>model\n")
            stop_tokens = ["<end_of_turn>", "<start_of_turn>"]
        else:
            # Qwen3 (ê¸°ë³¸): ChatML
            for msg in messages:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                prompt_parts.append(f"<|im_start|>{role}\n{content}<|im_end|>")
            prompt_parts.append("<|im_start|>assistant\n/no_think\n")
            stop_tokens = ["<|im_end|>", "<|im_start|>"]
        full_prompt = "\n".join(prompt_parts)

        try:
            output = local_llm(
                full_prompt,
                max_tokens=max_tokens,
                temperature=temperature,
                repeat_penalty=1.1,
                stop=stop_tokens,
                echo=False
            )
            content = output["choices"][0]["text"].strip()
            # think ë¸”ë¡ í˜¹ì‹œ ë‚¨ì•„ìˆìœ¼ë©´ ì œê±°
            content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL).strip()
            return LLMResponse(content=content, tool_calls=[], finish_reason="stop", usage={})
        except Exception as e:
            logger.error(f"GGUF ì˜¤ë¥˜: {e}")
            return None

    async def chat(self, messages, tools=None, model=None, max_tokens=4096, temperature=0.3):
        self._sync()

        # API í† í° ì—†ìœ¼ë©´ GGUF í´ë°±
        if not self._token:
            gguf_resp = self._call_gguf(messages, max_tokens, temperature)
            if gguf_resp:
                return gguf_resp
            return LLMResponse(content="âŒ API í† í°ë„ ì—†ê³  GGUF ëª¨ë¸ë„ ì—†ìŒ", finish_reason="error")

        import httpx
        headers = {"Authorization": f"Bearer {self._token}", "Content-Type": "application/json"}
        payload = {"model": model or self._model, "messages": messages,
                   "max_tokens": max_tokens, "temperature": temperature}
        if tools:
            payload["tools"] = tools
            payload["tool_choice"] = "auto"

        try:
            async with httpx.AsyncClient(timeout=300) as c:
                resp = await c.post(self._url, headers=headers, json=payload)
            if resp.status_code != 200:
                return LLMResponse(content=f"âŒ API {resp.status_code}", finish_reason="error")

            result = resp.json()
            ch = result["choices"][0]
            msg = ch["message"]
            content = re.sub(r'<think>.*?</think>', '', msg.get("content","") or "", flags=re.DOTALL).strip()

            tc_list = []
            for tc in (msg.get("tool_calls") or []):
                args = tc["function"]["arguments"]
                if isinstance(args, str):
                    try: args = json.loads(args)
                    except: args = {"raw": args}
                tc_list.append(ToolCallRequest(id=tc["id"], name=tc["function"]["name"], arguments=args))

            usage = {}
            if result.get("usage"):
                usage = {k: result["usage"].get(k,0) for k in ("prompt_tokens","completion_tokens","total_tokens")}
                try:
                    import pc_assistant as pa
                    tu = getattr(pa, 'TOKEN_USAGE', None)
                    if tu:
                        for k in usage: tu[k] += usage[k]
                        tu["call_count"] += 1
                except: pass

            return LLMResponse(content=content, tool_calls=tc_list,
                             finish_reason=ch.get("finish_reason","stop"), usage=usage)
        except Exception as e:
            logger.error(f"LLM ì˜¤ë¥˜: {e}")
            return LLMResponse(content=f"âŒ {e}", finish_reason="error")

    def get_default_model(self):
        self._sync()
        if self._token:
            return self._model or "Qwen3-Coder-30B-A3B-Instruct"
        # GGUF ëª¨ë“œì¼ ë•Œ ì‹¤ì œ ëª¨ë¸ëª… ë°˜í™˜
        try:
            import pc_assistant as pa
            model_key = getattr(pa, 'CURRENT_LOCAL_MODEL', '?')
            models = getattr(pa, 'AVAILABLE_MODELS', {})
            return models.get(model_key, {}).get("name", model_key)
        except:
            return "GGUF-Local"


class ValidateCodeTool(Tool):
    @property
    def name(self): return "validate_code"
    @property
    def description(self): return "ì½”ë“œ êµ¬ë¬¸ ê²€ì¦ (Python/JS/HTML)"
    @property
    def parameters(self):
        return {"type":"object","properties":{
            "code":{"type":"string","description":"ê²€ì¦í•  ì½”ë“œ"},
            "language":{"type":"string","description":"ì–¸ì–´"}}, "required":["code","language"]}

    async def execute(self, code="", language="python", **kw):
        errors, lang = [], language.lower()
        if len(code.strip()) < 5:
            return json.dumps({"valid":False,"errors":["ì½”ë“œê°€ ë„ˆë¬´ ì§§ìŒ"]})
        if lang == "python":
            try: compile(code, "<agent>", "exec")
            except SyntaxError as e: errors.append(f"Line {e.lineno}: {e.msg}")
        elif lang in ("javascript","typescript"):
            stack, pairs = [], {'{':'}','(':')','[':']'}
            for i,ch in enumerate(code):
                if ch in pairs: stack.append((ch,i))
                elif ch in pairs.values():
                    if not stack: errors.append(f"Pos {i}: '{ch}' ëŒ€ì‘ì—†ìŒ")
                    else:
                        o,_ = stack.pop()
                        if pairs[o]!=ch: errors.append(f"Pos {i}: '{pairs[o]}' ì˜ˆìƒ")
            for o,p in stack: errors.append(f"Pos {p}: '{o}' ë¯¸ë‹«í˜")
        elif lang == "html":
            void = {'br','hr','img','input','meta','link','area','base','col','embed','source','track','wbr'}
            opens = [t.lower() for t in re.findall(r'<([a-zA-Z]\w*)[^>]*(?<!/)>',code) if t.lower() not in void]
            closes = [t.lower() for t in re.findall(r'</([a-zA-Z]\w*)>',code)]
            if len(opens)!=len(closes): errors.append(f"íƒœê·¸ ë¶ˆì¼ì¹˜: ì—´ê¸°{len(opens)} ë‹«ê¸°{len(closes)}")
        return json.dumps({"valid":not errors,"errors":errors,"language":lang}, ensure_ascii=False)


class SaveCodeTool(Tool):
    @property
    def name(self): return "save_code"
    @property
    def description(self): return "ì½”ë“œë¥¼ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ì €ì¥"
    @property
    def parameters(self):
        return {"type":"object","properties":{
            "filename":{"type":"string","description":"íŒŒì¼ëª…"},
            "code":{"type":"string","description":"ì½”ë“œ"},
            "language":{"type":"string","description":"ì–¸ì–´"}}, "required":["filename","code"]}

    async def execute(self, filename="", code="", language="", **kw):
        out = WORKSPACE / "output"; out.mkdir(exist_ok=True)
        safe = "".join(c for c in filename if c.isalnum() or c in '.-_').strip()
        if not safe:
            ext = {"python":".py","javascript":".js","typescript":".ts","java":".java",
                   "html":".html","css":".css","sql":".sql","bash":".sh"}.get(language.lower(),".txt")
            safe = f"code_{int(time.time())}{ext}"
        fp = out / safe; fp.write_text(code, encoding="utf-8")
        return json.dumps({"saved":True,"path":str(fp),"filename":safe,"lines":len(code.split('\n'))}, ensure_ascii=False)


class NanobotManager:
    """nanobot ëª¨ë“ˆ ë˜í•‘ - FastAPI í†µí•©"""
    def __init__(self):
        self.provider = None
        self.sessions = None
        self.memory = None
        self.tools = None
        self._init = False

    def initialize(self):
        if self._init: return
        logger.info("âš¡ ë§ˆê¸°(main1_First) ì´ˆê¸°í™”...")
        self.provider = SKHynixProvider()
        self.sessions = SessionManager(WORKSPACE)
        self.memory = MemoryStore(WORKSPACE)
        self.tools = ToolRegistry()
        for t in [ReadFileTool(), WriteFileTool(), EditFileTool(), ListDirTool()]:
            self.tools.register(t)
        self.tools.register(ExecTool(working_dir=str(WORKSPACE), timeout=30, restrict_to_workspace=False))
        self.tools.register(ValidateCodeTool())
        self.tools.register(SaveCodeTool())
        self._init = True
        logger.info(f"âš¡ ë§ˆê¸°(main1_First) ì¤€ë¹„ - ë„êµ¬ {len(self.tools)}ê°œ")

    def _sys_prompt(self):
        now = datetime.now().strftime("%Y-%m-%d %H:%M (%A)")
        ws = str(WORKSPACE.resolve())
        kb = str(KNOWLEDGE_DIR.resolve())
        # ì§€ì‹ë² ì´ìŠ¤ íŒŒì¼ ëª©ë¡ (MD + TXT)
        kb_files = ""
        if KNOWLEDGE_DIR.exists():
            files = [f.name for f in KNOWLEDGE_DIR.iterdir() if f.is_file() and f.suffix.lower() in ('.md', '.txt')]
            if files:
                kb_files = "\n".join(f"  - {kb}/{f}" for f in files)
        # ë„ë©”ì¸ ì§€ì‹ TXT ë¡œë“œ
        domain_knowledge = ""
        if DOMAIN_KNOWLEDGE_FILE.exists():
            try:
                raw = DOMAIN_KNOWLEDGE_FILE.read_text(encoding="utf-8")
                # ì£¼ì„(#ìœ¼ë¡œ ì‹œì‘) ì œê±°í•œ ì‹¤ì œ ë‚´ìš©ë§Œ
                lines = [l for l in raw.strip().split("\n") if l.strip() and not l.strip().startswith("#")]
                if lines:
                    domain_knowledge = "\n".join(lines)
            except:
                pass
        p = f"""# âš¡ ë§ˆê¸°(main1_First) ì½”ë”© ì—ì´ì „íŠ¸
ë‹¹ì‹ ì€ 'ë§ˆê¸°(main1_First)' ì½”ë”© ì „ë¬¸ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
## í˜„ì¬: {now}  |  ì›Œí¬ìŠ¤í˜ì´ìŠ¤: {ws}
## ì§€ì‹ë² ì´ìŠ¤: {kb}
{f'ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ:{chr(10)}{kb_files}' if kb_files else 'ë¬¸ì„œ ì—†ìŒ'}
- ë„ë©”ì¸ ì§€ì‹ íŒŒì¼: {DOMAIN_KNOWLEDGE_FILE.resolve()}
{f'## ë„ë©”ì¸ ì§€ì‹ (ì•½ì–´/ìš©ì–´ ì°¸ê³ ìš©){chr(10)}{domain_knowledge}' if domain_knowledge else ''}
## ê·œì¹™
1. ì½”ë“œ ìƒì„± â†’ validate_code ê²€ì¦ â†’ save_code ì €ì¥
2. ê²€ì¦ ì‹¤íŒ¨ â†’ ìˆ˜ì • í›„ ì¬ê²€ì¦ (ìµœëŒ€ {RALPH_MAX_RETRY}íšŒ)
3. íŒŒì¼ ì‘ì—…ì€ ë„êµ¬ ì‚¬ìš© (read_file, write_file, list_dir, exec)
4. ì§€ì‹/ë„ë©”ì¸ ì§ˆë¬¸ â†’ **ë°˜ë“œì‹œ** ë¨¼ì € ì§€ì‹ë² ì´ìŠ¤ ë¬¸ì„œë¥¼ read_fileë¡œ ì½ê³ , ë¬¸ì„œ ë‚´ìš©ë§Œìœ¼ë¡œ ë‹µë³€. ë„ë©”ì¸ ì§€ì‹ë§Œìœ¼ë¡œ ìƒì„¸ ë‹µë³€ ê¸ˆì§€.
5. í•œêµ­ì–´ ì‘ë‹µ
6. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”. ì—†ìœ¼ë©´ "ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
## Ralph Loop: validate_code â†’ (ì‹¤íŒ¨ì‹œ ìˆ˜ì •) â†’ save_code"""
        mem = self.memory.get_memory_context() if self.memory else ""
        if mem: p += f"\n## ë©”ëª¨ë¦¬\n{mem}"
        return p

    def _is_gguf_mode(self):
        """í˜„ì¬ GGUF ë¡œì»¬ ëª¨ë“œì¸ì§€ í™•ì¸"""
        self.provider._sync()
        return not self.provider._token

    def _search_knowledge(self, query, max_chars=1500):
        """ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ â†’ ì§€ì‹ë² ì´ìŠ¤ íŒŒì¼ì—ì„œ ê´€ë ¨ ë‚´ìš© ê²€ìƒ‰"""
        if not KNOWLEDGE_DIR.exists():
            return ""
        # í‚¤ì›Œë“œ ì¶”ì¶œ (í•œê¸€/ì˜ë¬¸ ë‹¨ì–´, 2ê¸€ì ì´ìƒ)
        keywords = [w for w in re.findall(r'[ê°€-í£a-zA-Z0-9_]{2,}', query.lower())]
        stop_words = {'ì–´ë–»ê²Œ','ë¬´ì—‡','ì•Œë ¤ì¤˜','ì„¤ëª…','í•´ì¤˜','ë­ì•¼','ìˆë‚˜ìš”','ëŒ€í•´','ê´€ë ¨','ë§ˆê¸°(main1_First)','ì½”ë”©','ì—ì´ì „íŠ¸','ë¶€íƒ'}
        keywords = [k for k in keywords if k not in stop_words]
        if not keywords:
            return ""

        results = []
        for fp in KNOWLEDGE_DIR.iterdir():
            if not fp.is_file() or fp.suffix.lower() not in ('.md', '.txt'):
                continue
            try:
                text = fp.read_text(encoding="utf-8")
            except:
                continue
            # íŒŒì¼ëª…ë„ ë§¤ì¹­ ëŒ€ìƒ
            fname_lower = fp.stem.lower()
            score = sum(1 for k in keywords if k in fname_lower) * 3  # íŒŒì¼ëª… ë§¤ì¹­ ê°€ì¤‘ì¹˜
            score += sum(1 for k in keywords if k in text.lower())
            if score > 0:
                results.append((score, fp.name, text))

        if not results:
            return ""

        # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
        results.sort(key=lambda x: x[0], reverse=True)

        # ìƒìœ„ íŒŒì¼ì—ì„œ ê´€ë ¨ ì¤„ ì¶”ì¶œ (max_chars ì œí•œ)
        output = []
        total = 0
        for score, fname, text in results[:2]:  # ìµœëŒ€ 2ê°œ íŒŒì¼
            lines = text.split("\n")
            matched = []
            for i, line in enumerate(lines):
                if any(k in line.lower() for k in keywords):
                    # ë§¤ì¹­ëœ ì¤„ Â± 2ì¤„ ì»¨í…ìŠ¤íŠ¸
                    start = max(0, i - 2)
                    end = min(len(lines), i + 3)
                    for j in range(start, end):
                        if lines[j] not in matched:
                            matched.append(lines[j])
            if not matched:
                # í‚¤ì›Œë“œê°€ íŒŒì¼ëª…ì—ë§Œ ë§¤ì¹­ â†’ ì•ë¶€ë¶„ ê°€ì ¸ì˜¤ê¸°
                matched = lines[:15]
            chunk = "\n".join(matched)
            if total + len(chunk) > max_chars:
                chunk = chunk[:max_chars - total]
            if chunk:
                output.append(f"[{fname}]\n{chunk}")
                total += len(chunk)
            if total >= max_chars:
                break

        return "\n\n".join(output)

    def _sys_prompt_light(self, query=""):
        """GGUF ëª¨ë“œìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥)"""
        now = datetime.now().strftime("%Y-%m-%d %H:%M")
        kb_dir = str(KNOWLEDGE_DIR.resolve()) if KNOWLEDGE_DIR.exists() else ""
        # ë„ë©”ì¸ ì§€ì‹ ë¡œë“œ
        domain = ""
        if DOMAIN_KNOWLEDGE_FILE.exists():
            try:
                raw = DOMAIN_KNOWLEDGE_FILE.read_text(encoding="utf-8")
                lines = [l for l in raw.strip().split("\n") if l.strip() and not l.strip().startswith("#")]
                if lines:
                    domain = "\n".join(lines[:60])
            except:
                pass
        # ì§ˆë¬¸ ê´€ë ¨ ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰
        kb_context = self._search_knowledge(query) if query else ""

        return f"""ë‹¹ì‹ ì€ 'ë§ˆê¸°(main1_First)' ì§€ì‹ê¸°ë°˜ AI ë¹„ì„œì…ë‹ˆë‹¤. í˜„ì¬: {now}.
ì§€ì‹ë² ì´ìŠ¤ ê²½ë¡œ: {kb_dir}
{f'## ë„ë©”ì¸ ì§€ì‹{chr(10)}{domain}' if domain else ''}
{f'## ì°¸ê³  ì§€ì‹{chr(10)}{kb_context}' if kb_context else ''}
## ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬
ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{"tool":"ë„êµ¬ëª…","args":{{"íŒŒë¼ë¯¸í„°":"ê°’"}}}}

- list_dir: í´ë” ë‚´ íŒŒì¼ ëª©ë¡. args: {{"path":"ê²½ë¡œ"}}
- read_file: íŒŒì¼ ì½ê¸°. args: {{"path":"íŒŒì¼ê²½ë¡œ"}}

## ê·œì¹™
- ë„êµ¬ê°€ í•„ìš”í•˜ë©´ JSONë§Œ ì¶œë ¥ (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ê¸ˆì§€)
- ë„êµ¬ê°€ í•„ìš”ì—†ìœ¼ë©´ ë°”ë¡œ í…ìŠ¤íŠ¸ë¡œ ë‹µë³€
- ì½”ë“œë¥¼ ì ˆëŒ€ ì‘ì„±í•˜ì§€ ë§ˆë¼
- ì°¸ê³  ì§€ì‹ì„ ì •ë¦¬í•´ì„œ í…ìŠ¤íŠ¸ë¡œë§Œ ë‹µë³€
- "ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”" ê°™ì€ ë– ë„˜ê¸°ê¸° ê¸ˆì§€. ì§ì ‘ ë‹µë³€
- í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€
- ë‹µë³€ ë§ˆì§€ë§‰ì— ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ í‘œì‹œ:
  ë„ë©”ì¸ ì§€ì‹ì—ì„œ ë‹µë³€í–ˆìœ¼ë©´ â†’ ğŸ“Œ ì¶œì²˜: domain_knowledge.txt
  ì§€ì‹ë² ì´ìŠ¤ MDì—ì„œ ë‹µë³€í–ˆìœ¼ë©´ â†’ ğŸ“Œ ì¶œì²˜: [íŒŒì¼ëª….md]
  ë„êµ¬ë¡œ íŒŒì¼ì„ ì½ì—ˆìœ¼ë©´ â†’ ğŸ“Œ ì¶œì²˜: [ì½ì€ íŒŒì¼ëª…]
  ë³¸ì¸ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í–ˆìœ¼ë©´ â†’ ğŸ“Œ ì¶œì²˜: AI ì¼ë°˜ ì§€ì‹"""

    def _parse_tool_call(self, text):
        """GGUF ì‘ë‹µì—ì„œ ë„êµ¬ í˜¸ì¶œ JSON íŒŒì‹±"""
        if not text:
            return None
        text = text.strip()
        # "tool" í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ë„êµ¬ í˜¸ì¶œ ì•„ë‹˜
        if '"tool"' not in text and "'tool'" not in text:
            return None
        try:
            # ```json ... ``` ë¸”ë¡
            m = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
            if m:
                return json.loads(m.group(1))
            # í…ìŠ¤íŠ¸ì—ì„œ ì²« ë²ˆì§¸ { ... } ì¶”ì¶œ
            start = text.find('{')
            if start >= 0:
                brace = 0
                for i in range(start, len(text)):
                    if text[i] == '{': brace += 1
                    elif text[i] == '}': brace -= 1
                    if brace == 0:
                        parsed = json.loads(text[start:i+1])
                        if "tool" in parsed:
                            return parsed
                        break
        except Exception as e:
            logger.warning(f"ë„êµ¬ íŒŒì‹± ì‹¤íŒ¨: {e}, ì›ë¬¸: {text[:200]}")
        return None

    async def process(self, content, session_id="web:default"):
        if not self._init: self.initialize()
        t0 = time.time()
        steps, usage = [], {"prompt_tokens":0,"completion_tokens":0,"total_tokens":0}

        gguf_mode = self._is_gguf_mode()

        session = self.sessions.get_or_create(session_id)

        if gguf_mode:
            # GGUF: ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥ (ìµœëŒ€ 3íšŒ ë°˜ë³µ)
            msgs = [{"role":"system","content":self._sys_prompt_light(query=content)}]
            msgs.extend(session.get_history(max_messages=4))
            msgs.append({"role":"user","content":content})
            steps.append({"type":"context","icon":"ğŸ“‹","detail":"GGUF ëª¨ë“œ","duration":round(time.time()-t0,2)})

            final = None
            for gguf_it in range(3):  # ìµœëŒ€ 3íšŒ ë„êµ¬ í˜¸ì¶œ
                ts = time.time()
                resp = await self.provider.chat(messages=msgs, tools=None, max_tokens=512)
                dur = round(time.time()-ts,2)
                raw = resp.content or ""
                steps.append({"type":"llm","icon":"ğŸ§ ","detail":f"GGUF #{gguf_it+1} {dur}ì´ˆ","duration":dur})

                # ë„êµ¬ í˜¸ì¶œ ê°ì§€
                logger.info(f"ğŸ” GGUF ì›ë¬¸: [{raw[:300]}]")
                tool_call = self._parse_tool_call(raw)
                logger.info(f"ğŸ” íŒŒì‹± ê²°ê³¼: {tool_call}")
                if tool_call and "tool" in tool_call:
                    tool_name = tool_call["tool"]
                    tool_args = tool_call.get("args", {})
                    logger.info(f"ğŸ”§ GGUF ë„êµ¬ í˜¸ì¶œ: {tool_name}({tool_args})")
                    try:
                        result = await self.tools.execute(tool_name, tool_args)
                        # ê²°ê³¼ê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
                        if len(result) > 2000:
                            result = result[:2000] + "\n... (ì´í•˜ ìƒëµ)"
                        steps.append({"type":"tool","icon":"ğŸ”§","detail":f"{tool_name}: {result[:100]}","duration":round(time.time()-ts,2)})
                        # ë„êµ¬ ê²°ê³¼ë¥¼ ëŒ€í™”ì— ì¶”ê°€í•˜ê³  ë‹¤ì‹œ LLM í˜¸ì¶œ
                        msgs.append({"role":"assistant","content":raw})
                        msgs.append({"role":"user","content":f"[ë„êµ¬ ê²°ê³¼: {tool_name}]\n{result}\n\nìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”."})
                    except Exception as e:
                        logger.error(f"ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                        final = f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}"
                        break
                else:
                    # ë„êµ¬ í˜¸ì¶œ ì•„ë‹˜ â†’ ìµœì¢… ë‹µë³€
                    final = raw
                    break

            if not final:
                final = "ì²˜ë¦¬ ì™„ë£Œ."
            # ë„êµ¬ JSONì€ íˆìŠ¤í† ë¦¬ì— ì €ì¥í•˜ì§€ ì•ŠìŒ
            if not self._parse_tool_call(final):
                session.add_message("user", content)
                session.add_message("assistant", final)
            self.sessions.save(session)
            tt = round(time.time()-t0,2)
            steps.append({"type":"complete","icon":"ğŸ","detail":f"GGUF {tt}ì´ˆ","duration":tt})
            return {"success":True,"response":final,"steps":steps,"session_id":session_id,"usage":usage,"iterations":1,"total_time":tt}

        # API ëª¨ë“œ: ê¸°ì¡´ ë¡œì§ (ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥)
        msgs = [{"role":"system","content":self._sys_prompt()}]
        msgs.extend(session.get_history(max_messages=20))
        msgs.append({"role":"user","content":content})

        steps.append({"type":"context","icon":"ğŸ“‹","detail":f"íˆìŠ¤í† ë¦¬ {len(session.get_history())}ê°œ","duration":round(time.time()-t0,2)})

        it, final = 0, None
        while it < MAX_ITERATIONS:
            it += 1; ts = time.time()
            resp = await self.provider.chat(messages=msgs, tools=self.tools.get_definitions())
            if resp.usage:
                for k in usage: usage[k] += resp.usage.get(k,0)

            if resp.has_tool_calls:
                tc_dicts = [{"id":tc.id,"type":"function",
                    "function":{"name":tc.name,"arguments":json.dumps(tc.arguments,ensure_ascii=False)}}
                    for tc in resp.tool_calls]
                msgs.append({"role":"assistant","content":resp.content or "","tool_calls":tc_dicts})

                for tc in resp.tool_calls:
                    tt = time.time()
                    result = await self.tools.execute(tc.name, tc.arguments)
                    msgs.append({"role":"tool","tool_call_id":tc.id,"name":tc.name,"content":result})
                    icons = {"validate_code":"âœ…","save_code":"ğŸ’¾","exec":"âš¡","read_file":"ğŸ“–",
                             "write_file":"âœï¸","edit_file":"âœï¸","list_dir":"ğŸ“"}
                    steps.append({"type":"tool","icon":icons.get(tc.name,"ğŸ”§"),
                                  "detail":f"{tc.name}: {result[:120]}","duration":round(time.time()-tt,2)})
                steps.append({"type":"llm","icon":"ğŸ§ ","detail":f"#{it} ë„êµ¬ {len(resp.tool_calls)}ê°œ",
                              "duration":round(time.time()-ts,2)})
            else:
                final = resp.content
                steps.append({"type":"llm","icon":"ğŸ§ ","detail":f"#{it} ìµœì¢…","duration":round(time.time()-ts,2)})
                break

        if not final: final = "ì²˜ë¦¬ ì™„ë£Œ."
        session.add_message("user", content)
        session.add_message("assistant", final)
        self.sessions.save(session)

        tt = round(time.time()-t0,2)
        steps.append({"type":"complete","icon":"ğŸ","detail":f"{it}íšŒ {tt}ì´ˆ","duration":tt})
        return {"success":True,"response":final,"steps":steps,"session_id":session_id,"usage":usage,"iterations":it,"total_time":tt}


# ì‹±ê¸€í†¤
nanobot_manager = NanobotManager()

# FastAPI ë¼ìš°í„°
agent_router = APIRouter(prefix="/assistant", tags=["nanobot"])

class ChatReq(BaseModel):
    message: str
    session_id: str = "web:default"

@agent_router.post("/api/agent/chat")
async def agent_chat(req: ChatReq):
    try: return await nanobot_manager.process(req.message, req.session_id)
    except Exception as e:
        logger.error(traceback.format_exc()); raise HTTPException(500, str(e))

@agent_router.get("/api/agent/status")
async def agent_status():
    try:
        m = nanobot_manager
        if not m._init:
            m.initialize()
        # ì‹¤ì œ ì„œë²„ ëª¨ë“œ/ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        provider_name = "?"
        current_model = m.provider.get_default_model() if m.provider else None
        try:
            import pc_assistant as pa
            llm_mode = getattr(pa, 'LLM_MODE', '?')
            if llm_mode == "local":
                model_key = getattr(pa, 'CURRENT_LOCAL_MODEL', '?')
                models = getattr(pa, 'AVAILABLE_MODELS', {})
                model_info = models.get(model_key, {})
                current_model = model_info.get("name", model_key)
                provider_name = f"LOCAL({current_model})"
            else:
                env = getattr(pa, 'CURRENT_ENV', '?')
                provider_name = getattr(pa, 'ENV_CONFIG', {}).get(env, {}).get("name", env)
        except: pass
        return {
            "success": True,
            "initialized": m._init,
            "tools": m.tools.tool_names if m.tools else [],
            "model": current_model,
            "provider": provider_name,
            "llm_mode": llm_mode if 'llm_mode' in dir() else "?",
            "max_iterations": MAX_ITERATIONS,
            "nanobot_version": _ver(),
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "initialized": False,
        }

@agent_router.get("/api/agent/history")
async def agent_history(session_id: str = "web:default"):
    """ë§ˆê¸°(main1_First) ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
    try:
        m = nanobot_manager
        if not m._init:
            m.initialize()
        session = m.sessions.get_or_create(session_id)
        history = session.get_history(max_messages=50)
        return {"success": True, "history": history}
    except Exception as e:
        return {"success": True, "history": []}

@agent_router.get("/api/agent/files")
async def agent_files():
    d = WORKSPACE/"output"
    if not d.exists(): return {"files":[]}
    return {"files":[{"name":f.name,"size":f.stat().st_size,
            "modified":datetime.fromtimestamp(f.stat().st_mtime).isoformat(),"ext":f.suffix}
            for f in sorted(d.iterdir(),key=lambda x:x.stat().st_mtime,reverse=True) if f.is_file()]}

@agent_router.get("/api/agent/files/{fn}")
async def agent_read(fn:str):
    fp = WORKSPACE/"output"/fn
    if not fp.exists(): raise HTTPException(404)
    return {"filename":fn,"content":fp.read_text(encoding="utf-8"),"size":fp.stat().st_size}

@agent_router.delete("/api/agent/files/{fn}")
async def agent_del(fn:str):
    fp = WORKSPACE/"output"/fn
    if fp.exists(): fp.unlink(); return {"deleted":True}
    raise HTTPException(404)

@agent_router.get("/api/agent/sessions")
async def agent_sessions():
    if not nanobot_manager._init: nanobot_manager.initialize()
    return {"sessions":nanobot_manager.sessions.list_sessions()}

@agent_router.delete("/api/agent/sessions/{sid}")
async def agent_del_session(sid:str):
    if not nanobot_manager._init: nanobot_manager.initialize()
    return {"deleted":nanobot_manager.sessions.delete(sid)}

@agent_router.get("/api/agent/memory")
async def agent_mem():
    if not nanobot_manager._init: nanobot_manager.initialize()
    m = nanobot_manager.memory
    return {"long_term":m.read_long_term(),"today":m.read_today(),
            "files":[f.name for f in m.list_memory_files()[:10]]}
#ã…
def _ver():
    try:
        import importlib.metadata; return importlib.metadata.version("nanobot-ai")
    except: return "?"

def get_agent_router(): return agent_router

logger.info("âš¡ coding_agent.py ë¡œë“œ (nanobot-ai ì§ì ‘ import)")