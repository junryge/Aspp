#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
pc_assistant.py
PC ê°œì¸ë¹„ì„œ AI (Moltbot ìŠ¤íƒ€ì¼ Tool Calling) v0.2
- ìŠ¤í¬ë¦°ìƒ·: ì „ìš© í´ë” ì €ì¥ + ì›¹ ì¸ë¼ì¸ í‘œì‹œ
- íŒŒì¼ íƒìƒ‰ê¸°/ë©”ëª¨ì¥ ì‹¤í–‰ ì œê±°
"""

import os
import re
import json
import subprocess
import platform
import psutil
import tempfile
import datetime
import webbrowser
import fnmatch
import requests
import pandas as pd
from typing import Optional, List
from fastapi import FastAPI, APIRouter, UploadFile, File
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("PCAssistant")

router = APIRouter(prefix="/assistant", tags=["assistant"])
app = FastAPI(title="ì§í‰ ëª°íŠ¸ë´‡ ê°ë§ˆë²„ì „ VER 0.2")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========================================
# Global Configuration
# ========================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
GGUF_MODEL_PATH = os.path.join(BASE_DIR, "Qwen3-14B-Q4_K_M.gguf")
LOCAL_LLM = None
CHAT_HISTORY = []
HISTORY_FILE = os.path.join(BASE_DIR, "chat_history.json")

# â˜… í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
TOKEN_USAGE = {
    "prompt_tokens": 0,
    "completion_tokens": 0,
    "total_tokens": 0,
    "call_count": 0
}

# â˜… ìŠ¤í¬ë¦°ìƒ· ì „ìš© í´ë”
SCREENSHOT_DIR = os.path.join(BASE_DIR, "screenshots")
os.makedirs(SCREENSHOT_DIR, exist_ok=True)

# â˜… ì§€ì‹ë² ì´ìŠ¤(MD ë¬¸ì„œ) í´ë”
KNOWLEDGE_DIR = os.path.join(BASE_DIR, "knowledge")
os.makedirs(KNOWLEDGE_DIR, exist_ok=True)

# â˜… ê³¼ê±°ì§€ì‹ ë³´ê´€ í´ë”
KNOWLEDGE_ARCHIVE_DIR = os.path.join(BASE_DIR, "knowledge_archive")
os.makedirs(KNOWLEDGE_ARCHIVE_DIR, exist_ok=True)

LLM_MODE = "local"
API_TOKEN = None

ENV_CONFIG = {
    "dev": {
        "url": "http://dev.assistant.llm.skhynix.com/v1/chat/completions",
        "model": "Qwen3-Coder-30B-A3B-Instruct",
        "name": "DEV(30B)"
    },
    "prod": {
        "url": "http://summary.llm.skhynix.com/v1/chat/completions",
        "model": "Qwen3-Next-80B-A3B-Instruct",
        "name": "PROD(80B)"
    },
    "common": {
        "url": "http://common.llm.skhynix.com/v1/chat/completions",
        "model": "gpt-oss-20b",
        "name": "COMMON(20B)"
    }
}
CURRENT_ENV = "common"
API_URL = ENV_CONFIG["common"]["url"]
API_MODEL = ENV_CONFIG["common"]["model"]

# ========================================
# System Prompt
# ========================================
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ 'ì§í‰ ëª°íŠ¸ë´‡ ê°ë§ˆë²„ì „ VER 0.2'ì´ë¼ëŠ” PC ê°œì¸ë¹„ì„œ AIì…ë‹ˆë‹¤.

[ì¤‘ìš” ê·œì¹™]
1. PC ì‘ì—…ì´ í•„ìš”í•˜ë©´ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.
2. ë„êµ¬ë¥¼ í˜¸ì¶œí•  ë•ŒëŠ” JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ JSON ì•ë’¤ì— ë¶™ì´ì§€ ë§ˆì„¸ìš”.
3. keywordì—ëŠ” í™•ì¥ìë‚˜ ì™€ì¼ë“œì¹´ë“œ ì—†ì´ ìˆœìˆ˜ í‚¤ì›Œë“œë§Œ ë„£ìœ¼ì„¸ìš”.
4. ```json ì½”ë“œë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì§€ ë§ˆì„¸ìš”. ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.

[ë„êµ¬ ëª©ë¡]
- íŒŒì¼ê²€ìƒ‰: {"tool": "search_files", "keyword": "ë¬¸ì„œ", "path": "C:/"}
- ë‚´ìš©ê²€ìƒ‰: {"tool": "search_content", "keyword": "hello", "path": "C:/"}
- ì‹œìŠ¤í…œì •ë³´: {"tool": "get_system_info"}
- í´ë”ë³´ê¸°: {"tool": "list_directory", "path": "C:/Users"}
- íŒŒì¼ì½ê¸°: {"tool": "read_file", "path": "C:/test.txt"}
- í”„ë¡œê·¸ë¨ì‹¤í–‰: {"tool": "run_program", "program": "notepad"}
- í”„ë¡œê·¸ë¨ì¢…ë£Œ: {"tool": "kill_program", "name": "notepad"}
- ì›¹ì—´ê¸°: {"tool": "open_web", "url": "https://google.com"}
- êµ¬ê¸€ê²€ìƒ‰: {"tool": "google_search", "query": "ê²€ìƒ‰ì–´"}
- í˜„ì¬ì‹œê°„: {"tool": "get_time"}
- ìŠ¤í¬ë¦°ìƒ·: {"tool": "screenshot"}
- ìµœì‹ ë‰´ìŠ¤: {"tool": "latest_news"}
- ë°ì´í„°ë¶„ì„: {"tool": "analyze_data", "path": "C:/data.csv"}
- í”„ë¡œì„¸ìŠ¤ëª©ë¡: {"tool": "list_processes", "sort_by": "memory"}
- ì§€ì‹ê²€ìƒ‰: {"tool": "search_knowledge", "keyword": "HID_INOUT"}
- ì§€ì‹ëª©ë¡: {"tool": "list_knowledge"}
- ì§€ì‹ì½ê¸°: {"tool": "read_knowledge", "filename": "HID_INOUT_Java_ë³€ê²½ì‚¬í•­.md"}

[ì§€ì‹ë² ì´ìŠ¤ ê´€ë ¨]
- ì‚¬ìš©ìê°€ í”„ë¡œì íŠ¸, ì½”ë“œ ë³€ê²½ì‚¬í•­, ê¸°ìˆ  ë¬¸ì„œì— ëŒ€í•´ ë¬¼ì–´ë³´ë©´ ë¨¼ì € search_knowledgeë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.
- HID, INOUT, ì—£ì§€, í…Œì´ë¸”, OhtMsgWorker ë“± ê¸°ìˆ  í‚¤ì›Œë“œê°€ ë‚˜ì˜¤ë©´ ì§€ì‹ë² ì´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.
- ë¬¸ì„œë¥¼ ì°¾ìœ¼ë©´ read_knowledgeë¡œ ë‚´ìš©ì„ ì½ê³  ê·¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

[ìµœì‹ ë‰´ìŠ¤ ê´€ë ¨]
- ë‰´ìŠ¤, ìµœì‹ ë‰´ìŠ¤, ë‰´ìŠ¤ ë³´ì—¬ì¤˜ ë“±ì˜ ìš”ì²­ì—ëŠ” ë°˜ë“œì‹œ latest_news ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- êµ¬ê¸€ê²€ìƒ‰ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ì§€ ë§ˆì„¸ìš”.

ì¼ë°˜ ëŒ€í™”ëŠ” í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”."""


# ========================================
# LLM Functions
# ========================================
def load_local_model():
    global LOCAL_LLM
    try:
        from llama_cpp import Llama
        if not os.path.exists(GGUF_MODEL_PATH):
            logger.error(f"GGUF íŒŒì¼ ì—†ìŒ: {GGUF_MODEL_PATH}")
            return None
        logger.info("GGUF ëª¨ë¸ ë¡œë”© ì¤‘...")
        llm = Llama(
            model_path=GGUF_MODEL_PATH,
            n_ctx=8192,
            n_threads=8,
            n_gpu_layers=50,
            n_batch=512,
            verbose=False
        )
        logger.info("GGUF ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        return llm
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def load_api_token():
    global API_TOKEN
    paths = [
        os.path.join(BASE_DIR, "token.txt"),
        os.path.join(BASE_DIR, "api_token.txt"),
        "token.txt",
        "../token.txt",
        os.path.expanduser("~/token.txt")
    ]
    for p in paths:
        if os.path.exists(p):
            try:
                with open(p, 'r', encoding='utf-8') as f:
                    API_TOKEN = f.read().strip()
                if API_TOKEN and "REPLACE" not in API_TOKEN:
                    logger.info(f"âœ… API í† í° ë¡œë“œ: {p}")
                    return True
            except Exception as e:
                logger.error(f"âŒ í† í° ë¡œë“œ ì‹¤íŒ¨: {e}")
    logger.warning("âš ï¸ API í† í° íŒŒì¼ ì—†ìŒ")
    return False


def call_local_llm(prompt: str, system_prompt: str = "", max_tokens: int = 4096) -> dict:
    global LOCAL_LLM
    if LOCAL_LLM is None:
        return {"success": False, "error": "ë¡œì»¬ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}

    full_prompt = f"""<|im_start|>system
{system_prompt}<|im_end|>
<|im_start|>user
{prompt}<|im_end|>
<|im_start|>assistant
"""
    try:
        output = LOCAL_LLM(
            full_prompt,
            max_tokens=max_tokens,
            temperature=0.3,
            stop=["<|im_end|>", "<|im_start|>"],
            echo=False
        )
        content = output["choices"][0]["text"].strip()
        content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL).strip()
        return {"success": True, "content": content}
    except Exception as e:
        return {"success": False, "error": str(e)}


def call_api_llm(prompt: str, system_prompt: str = "", max_tokens: int = 4096) -> dict:
    global API_TOKEN
    if not API_TOKEN:
        return {"success": False, "error": "API í† í° ì—†ìŒ"}

    headers = {
        "Authorization": f"Bearer {API_TOKEN}",
        "Content-Type": "application/json"
    }
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})

    data = {
        "model": API_MODEL,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": 0.3
    }
    try:
        response = requests.post(API_URL, headers=headers, json=data, timeout=300)
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL).strip()
            
            # â˜… í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì 
            usage = result.get("usage", {})
            if usage:
                TOKEN_USAGE["prompt_tokens"] += usage.get("prompt_tokens", 0)
                TOKEN_USAGE["completion_tokens"] += usage.get("completion_tokens", 0)
                TOKEN_USAGE["total_tokens"] += usage.get("total_tokens", 0)
                TOKEN_USAGE["call_count"] += 1
                logger.info(f"ğŸ“Š í† í°: +{usage.get('total_tokens', 0)} (ëˆ„ì : {TOKEN_USAGE['total_tokens']})")
            
            return {"success": True, "content": content}
        else:
            return {"success": False, "error": f"API ì˜¤ë¥˜: {response.status_code}"}
    except Exception as e:
        return {"success": False, "error": str(e)}


def call_llm(prompt: str, system_prompt: str = "", max_tokens: int = 4096) -> dict:
    if LLM_MODE == "local":
        return call_local_llm(prompt, system_prompt, max_tokens)
    else:
        return call_api_llm(prompt, system_prompt, max_tokens)


# ========================================
# Tool Functions
# ========================================
def search_files(keyword: str, path: str = "C:/", limit: int = 50) -> List[dict]:
    results = []
    logger.info(f"íŒŒì¼ ê²€ìƒ‰: '{keyword}' in '{path}'")
    try:
        for root, dirs, files in os.walk(path):
            for name in files + dirs:
                if keyword.lower() in name.lower():
                    full_path = os.path.join(root, name)
                    is_dir = os.path.isdir(full_path)
                    try:
                        size = os.path.getsize(full_path) if not is_dir else 0
                        size_str = f"{size / (1024**3):.2f}GB" if size > 1024**3 else f"{size / (1024**2):.1f}MB" if size > 1024**2 else f"{size}B"
                    except:
                        size_str = "?"
                    results.append({
                        "name": name, "path": full_path,
                        "type": "í´ë”" if is_dir else "íŒŒì¼", "size": size_str
                    })
                    if len(results) >= limit:
                        return results
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
    return results


def search_content(keyword: str, path: str = "C:/", limit: int = 30) -> List[dict]:
    results = []
    extensions = ['.txt', '.py', '.md', '.json', '.html', '.css', '.js', '.csv', '.log']
    try:
        for root, dirs, files in os.walk(path):
            for name in files:
                ext = os.path.splitext(name)[1].lower()
                if ext in extensions:
                    full_path = os.path.join(root, name)
                    try:
                        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read(50000)
                            if keyword.lower() in content.lower():
                                idx = content.lower().find(keyword.lower())
                                snippet = content[max(0, idx-30):min(len(content), idx+70)].replace('\n', ' ')
                                results.append({"name": name, "path": full_path, "snippet": f"...{snippet}..."})
                                if len(results) >= limit:
                                    return results
                    except:
                        continue
    except Exception as e:
        logger.error(f"ë‚´ìš© ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
    return results


def get_system_info() -> dict:
    drives = []
    for p in psutil.disk_partitions():
        try:
            usage = psutil.disk_usage(p.mountpoint)
            drives.append({"drive": p.device, "total": f"{usage.total / (1024**3):.1f}GB", "used": f"{usage.percent}%"})
        except:
            pass
    return {
        "os": f"{platform.system()} {platform.release()}",
        "cpu": f"{psutil.cpu_count()}ì½”ì–´, {psutil.cpu_percent()}%",
        "memory": f"{psutil.virtual_memory().total // (1024**3)}GB, {psutil.virtual_memory().percent}%",
        "drives": drives
    }


def list_directory(path: str) -> List[dict]:
    items = []
    try:
        for name in os.listdir(path)[:50]:
            full_path = os.path.join(path, name)
            is_dir = os.path.isdir(full_path)
            try:
                size = os.path.getsize(full_path) if not is_dir else 0
                modified = datetime.datetime.fromtimestamp(os.path.getmtime(full_path)).strftime("%Y-%m-%d %H:%M")
            except:
                size = 0
                modified = "?"
            items.append({"name": name, "type": "í´ë”" if is_dir else "íŒŒì¼", "size": f"{size:,}" if not is_dir else "-", "modified": modified})
    except Exception as e:
        return [{"error": str(e)}]
    return items


def read_file(path: str, max_chars: int = 5000) -> str:
    try:
        with open(path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read(max_chars)
            if len(content) == max_chars:
                content += "\n... (íŒŒì¼ì´ ë„ˆë¬´ ì»¤ì„œ ì¼ë¶€ë§Œ í‘œì‹œ)"
            return content
    except Exception as e:
        return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}"


def run_program(program: str) -> str:
    try:
        subprocess.Popen(program, shell=True)
        return f"'{program}' ì‹¤í–‰ë¨"
    except Exception as e:
        return f"ì‹¤í–‰ ì˜¤ë¥˜: {e}"


def kill_program(name: str) -> str:
    try:
        killed = 0
        for proc in psutil.process_iter(['name']):
            if name.lower() in proc.info['name'].lower():
                proc.kill()
                killed += 1
        return f"{killed}ê°œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë¨"
    except Exception as e:
        return f"ì¢…ë£Œ ì˜¤ë¥˜: {e}"


def open_web(url: str) -> str:
    if not url.startswith('http'):
        url = 'https://' + url
    webbrowser.open(url)
    return f"'{url}' ì—´ë¦¼"


def google_search(query: str) -> str:
    url = f"https://www.google.com/search?q={query}"
    webbrowser.open(url)
    return f"'{query}' ê²€ìƒ‰ ì¤‘..."


def get_time() -> str:
    now = datetime.datetime.now()
    return f"{now.strftime('%Yë…„ %mì›” %dì¼ %A %Hì‹œ %Më¶„ %Sì´ˆ')}"


# â˜… ìŠ¤í¬ë¦°ìƒ·: ì „ìš© í´ë” ì €ì¥ + URL ë°˜í™˜
def take_screenshot() -> dict:
    """ìŠ¤í¬ë¦°ìƒ· ì°ê³  ì „ìš© í´ë”ì— ì €ì¥, ì›¹ í‘œì‹œìš© URL ë°˜í™˜"""
    try:
        from PIL import ImageGrab
        filename = f"screenshot_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        filepath = os.path.join(SCREENSHOT_DIR, filename)
        img = ImageGrab.grab()
        img.save(filepath)
        logger.info(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filepath}")
        # ì›¹ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ URL ë°˜í™˜
        return {
            "success": True,
            "filename": filename,
            "path": filepath,
            "url": f"/assistant/screenshots/{filename}"
        }
    except ImportError:
        return {"success": False, "error": "PIL(Pillow) ë¯¸ì„¤ì¹˜. pip install Pillow"}
    except Exception as e:
        return {"success": False, "error": str(e)}


# â˜… ìµœì‹ ë‰´ìŠ¤: ë…ë¦½ ë¸Œë¼ìš°ì € ì°½ ì—´ê¸° â†’ ìŠ¤í¬ë¦°ìƒ· â†’ ê·¸ ì°½ë§Œ ë‹«ê¸°
def latest_news() -> dict:
    """êµ¬ê¸€ë‰´ìŠ¤ë¥¼ ë…ë¦½ ë¸Œë¼ìš°ì €ë¡œ ì—´ê³ , ìŠ¤í¬ë¦°ìƒ· ì°ê³ , ê·¸ ì°½ë§Œ ë‹«ê¸°"""
    import time
    import shutil
    
    news_proc = None
    temp_profile = None
    
    try:
        news_url = "https://news.google.com/home?hl=ko&gl=KR&ceid=KR:ko"
        
        # ì„ì‹œ í”„ë¡œí•„ í´ë” (ë…ë¦½ Chrome ì¸ìŠ¤í„´ìŠ¤ìš©)
        temp_profile = os.path.join(tempfile.gettempdir(), "chrome_news_temp")
        
        # 1. Chrome ì°¾ê¸°
        chrome_paths = [
            r"C:\Program Files\Google\Chrome\Application\chrome.exe",
            r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe",
            os.path.expanduser(r"~\AppData\Local\Google\Chrome\Application\chrome.exe"),
        ]
        
        chrome_exe = None
        for p in chrome_paths:
            if os.path.exists(p):
                chrome_exe = p
                break
        
        if chrome_exe:
            # ë…ë¦½ Chrome ì¸ìŠ¤í„´ìŠ¤ (ê¸°ì¡´ Chromeê³¼ ë³„ê°œ, ì „ì²´í™”ë©´)
            news_proc = subprocess.Popen([
                chrome_exe,
                f"--user-data-dir={temp_profile}",
                "--no-first-run",
                "--no-default-browser-check",
                "--start-maximized",
                "--disable-extensions",
                "--disable-sync",
                "--disable-translate",
                news_url
            ])
            logger.info(f"ğŸ“° êµ¬ê¸€ë‰´ìŠ¤ ë…ë¦½ ì°½ ì—´ê¸° (PID: {news_proc.pid})")
        else:
            webbrowser.open(news_url)
            logger.info("ğŸ“° êµ¬ê¸€ë‰´ìŠ¤ ì—´ê¸° (ê¸°ë³¸ ë¸Œë¼ìš°ì €)")
        
        # 2. ì´ˆê¸° ë¡œë”© ëŒ€ê¸° (ì„ì‹œ í”„ë¡œí•„ ì²« ì‹¤í–‰ì€ ëŠë¦¼)
        time.sleep(3)
        
        # 2.5. ê°•ì œ ì „ì²´í™”ë©´ (ì„ì‹œ í”„ë¡œí•„ì€ ìµœëŒ€í™” ë¬´ì‹œí•  ìˆ˜ ìˆìŒ)
        try:
            import ctypes
            import ctypes.wintypes
            
            # ê°€ì¥ ì•ì— ìˆëŠ” Chrome ì°½ ì°¾ì•„ì„œ ìµœëŒ€í™”
            user32 = ctypes.windll.user32
            hwnd = user32.GetForegroundWindow()
            if hwnd:
                SW_MAXIMIZE = 3
                user32.ShowWindow(hwnd, SW_MAXIMIZE)
                logger.info(f"ğŸ”² ë‰´ìŠ¤ ì°½ ìµœëŒ€í™” ì™„ë£Œ (hwnd: {hwnd})")
        except Exception as e:
            logger.warning(f"âš ï¸ ìµœëŒ€í™” ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
        
        # 3. ë‰´ìŠ¤ í˜ì´ì§€ ì™„ì „íˆ ë¡œë”©ë  ë•Œê¹Œì§€ ì¶©ë¶„íˆ ëŒ€ê¸°
        logger.info("â³ ë‰´ìŠ¤ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘... (8ì´ˆ)")
        time.sleep(8)
        
        # 3. ìŠ¤í¬ë¦°ìƒ· ì°ê¸°
        from PIL import ImageGrab
        filename = f"news_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        filepath = os.path.join(SCREENSHOT_DIR, filename)
        img = ImageGrab.grab()
        img.save(filepath)
        logger.info(f"ğŸ“¸ ë‰´ìŠ¤ ìŠ¤í¬ë¦°ìƒ·: {filepath}")
        
        # 4. ë…ë¦½ Chromeë§Œ ì¢…ë£Œ
        time.sleep(0.5)
        if news_proc and news_proc.poll() is None:
            # ìì‹ í”„ë¡œì„¸ìŠ¤ í¬í•¨ ì „ì²´ ì¢…ë£Œ
            try:
                parent = psutil.Process(news_proc.pid)
                for child in parent.children(recursive=True):
                    child.terminate()
                parent.terminate()
                logger.info(f"ğŸ”’ ë‰´ìŠ¤ ì°½ ë‹«ê¸° ì™„ë£Œ (PID: {news_proc.pid})")
            except psutil.NoSuchProcess:
                pass
        
        # 5. ì„ì‹œ í”„ë¡œí•„ ì •ë¦¬ (ë°±ê·¸ë¼ìš´ë“œ)
        try:
            if temp_profile and os.path.exists(temp_profile):
                shutil.rmtree(temp_profile, ignore_errors=True)
        except:
            pass
        
        return {
            "success": True,
            "filename": filename,
            "path": filepath,
            "url": f"/assistant/screenshots/{filename}"
        }
    except Exception as e:
        # ì—ëŸ¬ ì‹œì—ë„ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
        if news_proc and news_proc.poll() is None:
            try:
                news_proc.terminate()
            except:
                pass
        return {"success": False, "error": str(e)}


# â˜… í”„ë¡œì„¸ìŠ¤ ëª©ë¡ ì¡°íšŒ
def list_processes(sort_by: str = "memory", limit: int = 30) -> List[dict]:
    """ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ëª©ë¡ ë°˜í™˜"""
    processes = []
    try:
        for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_info', 'status']):
            try:
                info = proc.info
                mem = info.get('memory_info')
                mem_mb = mem.rss / (1024 * 1024) if mem else 0
                processes.append({
                    "pid": info['pid'],
                    "name": info['name'],
                    "cpu": proc.cpu_percent(interval=0),
                    "memory_mb": round(mem_mb, 1),
                    "status": info.get('status', '?')
                })
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue

        # ì •ë ¬
        if sort_by == "cpu":
            processes.sort(key=lambda x: x['cpu'], reverse=True)
        else:
            processes.sort(key=lambda x: x['memory_mb'], reverse=True)

        return processes[:limit]
    except Exception as e:
        logger.error(f"í”„ë¡œì„¸ìŠ¤ ëª©ë¡ ì˜¤ë¥˜: {e}")
        return [{"error": str(e)}]


# â˜… ì§€ì‹ë² ì´ìŠ¤ í•¨ìˆ˜ë“¤
def list_knowledge() -> List[dict]:
    """ì§€ì‹ë² ì´ìŠ¤ íŒŒì¼ ëª©ë¡"""
    files = []
    try:
        for f in sorted(os.listdir(KNOWLEDGE_DIR)):
            if f.endswith(('.md', '.txt')):
                filepath = os.path.join(KNOWLEDGE_DIR, f)
                size = os.path.getsize(filepath)
                modified = datetime.datetime.fromtimestamp(os.path.getmtime(filepath)).strftime("%Y-%m-%d %H:%M")
                files.append({"filename": f, "size": f"{size:,}B", "modified": modified})
    except Exception as e:
        logger.error(f"ì§€ì‹ ëª©ë¡ ì˜¤ë¥˜: {e}")
    return files


def search_knowledge(keyword: str) -> List[dict]:
    """ì§€ì‹ë² ì´ìŠ¤ì—ì„œ í‚¤ì›Œë“œë¡œ íŒŒì¼ ê²€ìƒ‰"""
    results = []
    try:
        for f in os.listdir(KNOWLEDGE_DIR):
            if not f.endswith(('.md', '.txt')):
                continue
            filepath = os.path.join(KNOWLEDGE_DIR, f)
            matched = False
            snippet = ""

            if keyword.lower() in f.lower():
                matched = True

            try:
                with open(filepath, 'r', encoding='utf-8', errors='ignore') as fh:
                    content = fh.read()
                    if keyword.lower() in content.lower():
                        matched = True
                        idx = content.lower().find(keyword.lower())
                        snippet = content[max(0, idx-50):min(len(content), idx+100)].replace('\n', ' ').strip()
            except:
                pass

            if matched:
                results.append({"filename": f, "snippet": f"...{snippet}..." if snippet else "(íŒŒì¼ëª… ë§¤ì¹­)"})
    except Exception as e:
        logger.error(f"ì§€ì‹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
    return results


def read_knowledge(filename: str) -> str:
    """ì§€ì‹ë² ì´ìŠ¤ MD íŒŒì¼ ì½ê¸°"""
    filepath = os.path.join(KNOWLEDGE_DIR, filename)
    if not os.path.exists(filepath):
        for f in os.listdir(KNOWLEDGE_DIR):
            if filename.lower() in f.lower():
                filepath = os.path.join(KNOWLEDGE_DIR, f)
                break
        else:
            return f"âŒ '{filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    try:
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read(30000)
            if len(content) == 30000:
                content += "\n\n... (ë¬¸ì„œê°€ ê¸¸ì–´ì„œ ì¼ë¶€ë§Œ í‘œì‹œ)"
            return content
    except Exception as e:
        return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}"

    try:
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read(30000)
            if len(content) == 30000:
                content += "\n\n... (ë¬¸ì„œê°€ ê¸¸ì–´ì„œ ì¼ë¶€ë§Œ í‘œì‹œ)"
            return content
    except Exception as e:
        return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}"


def analyze_data(path: str) -> str:
    try:
        ext = os.path.splitext(path)[1].lower()
        if ext == '.csv':
            df = pd.read_csv(path, encoding='utf-8', errors='ignore')
        elif ext in ['.xlsx', '.xls']:
            df = pd.read_excel(path)
        else:
            return f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {ext}"
        result = []
        result.append(f"íŒŒì¼: {os.path.basename(path)}")
        result.append(f"í¬ê¸°: {len(df):,}í–‰ x {len(df.columns)}ì—´")
        result.append(f"ì»¬ëŸ¼: {', '.join(df.columns.tolist()[:20])}")
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            stats = df[numeric_cols].describe().to_string()
            result.append(f"í†µê³„:\n{stats}")
        result.append(f"ìƒ˜í”Œ:\n{df.head(5).to_string()}")
        return "\n".join(result)
    except Exception as e:
        return f"ë¶„ì„ ì˜¤ë¥˜: {e}"


# ========================================
# Tool ì‹¤í–‰ê¸°
# ========================================
def execute_tool(tool_data: dict) -> str:
    tool_name = tool_data.get("tool")

    if tool_name == "search_files":
        results = search_files(tool_data.get("keyword", ""), tool_data.get("path", "C:/"))
        return json.dumps(results[:20], ensure_ascii=False, indent=2)

    elif tool_name == "search_content":
        results = search_content(tool_data.get("keyword", ""), tool_data.get("path", "C:/"))
        return json.dumps(results[:10], ensure_ascii=False, indent=2)

    elif tool_name == "get_system_info":
        return json.dumps(get_system_info(), ensure_ascii=False, indent=2)

    elif tool_name == "list_directory":
        results = list_directory(tool_data.get("path", "C:/"))
        return json.dumps(results, ensure_ascii=False, indent=2)

    elif tool_name == "read_file":
        return read_file(tool_data.get("path", ""))

    elif tool_name == "run_program":
        return run_program(tool_data.get("program", ""))

    elif tool_name == "kill_program":
        return kill_program(tool_data.get("name", ""))

    elif tool_name == "open_web":
        return open_web(tool_data.get("url", ""))

    elif tool_name == "google_search":
        return google_search(tool_data.get("query", ""))

    elif tool_name == "get_time":
        return get_time()

    # â˜… ìŠ¤í¬ë¦°ìƒ· - JSON ë°˜í™˜
    elif tool_name == "screenshot":
        result = take_screenshot()
        return json.dumps(result, ensure_ascii=False)

    # â˜… ìµœì‹ ë‰´ìŠ¤ - êµ¬ê¸€ë‰´ìŠ¤ ì—´ê³  ìŠ¤í¬ë¦°ìƒ· ì°ê³  ë‹«ê¸°
    elif tool_name == "latest_news":
        result = latest_news()
        return json.dumps(result, ensure_ascii=False)

    elif tool_name == "analyze_data":
        return analyze_data(tool_data.get("path", ""))

    # â˜… ì§€ì‹ë² ì´ìŠ¤ ë„êµ¬ë“¤
    elif tool_name == "list_knowledge":
        results = list_knowledge()
        return json.dumps(results, ensure_ascii=False, indent=2)

    elif tool_name == "search_knowledge":
        results = search_knowledge(tool_data.get("keyword", ""))
        return json.dumps(results, ensure_ascii=False, indent=2)

    elif tool_name == "read_knowledge":
        return read_knowledge(tool_data.get("filename", ""))

    # â˜… í”„ë¡œì„¸ìŠ¤ ëª©ë¡
    elif tool_name == "list_processes":
        results = list_processes(tool_data.get("sort_by", "memory"), tool_data.get("limit", 30))
        return json.dumps(results, ensure_ascii=False, indent=2)

    return "ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬"


# ========================================
# JSON ê°ì§€
# ========================================
def extract_tool_json(text: str) -> Optional[dict]:
    # íŒ¨í„´ 1: ```json ì½”ë“œë¸”ë¡
    match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
    if match:
        try:
            data = json.loads(match.group(1))
            if "tool" in data:
                return data
        except json.JSONDecodeError:
            pass

    # íŒ¨í„´ 2: ì¸ë¼ì¸ {"tool": "..."}
    match = re.search(r'(\{[^{}]*"tool"\s*:\s*"[^"]+?"[^{}]*\})', text, re.DOTALL)
    if match:
        try:
            data = json.loads(match.group(1))
            if "tool" in data:
                return data
        except json.JSONDecodeError:
            pass

    # íŒ¨í„´ 3: ì „ì²´ê°€ JSON
    stripped = text.strip()
    if stripped.startswith('{') and stripped.endswith('}'):
        try:
            data = json.loads(stripped)
            if "tool" in data:
                return data
        except json.JSONDecodeError:
            pass

    # íŒ¨í„´ 4: ë©€í‹°ë¼ì¸ JSON
    match = re.search(r'\{\s*"tool"\s*:.*?\}', text, re.DOTALL)
    if match:
        try:
            json_str = re.sub(r'[\n\r\t]', ' ', match.group(0))
            json_str = re.sub(r'\s+', ' ', json_str)
            data = json.loads(json_str)
            if "tool" in data:
                return data
        except json.JSONDecodeError:
            pass

    return None


# ========================================
# ========================================
# Chat Processing
# ========================================
def process_chat(user_message: str) -> str:
    global LOCAL_LLM, LLM_MODE

    if LLM_MODE == "local" and LOCAL_LLM is None:
        return "âŒ ë¡œì»¬ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    if LLM_MODE != "local" and not API_TOKEN:
        return "âŒ API í† í°ì´ ì—†ìŠµë‹ˆë‹¤."

    try:
        result = call_llm(user_message, SYSTEM_PROMPT)
        if not result["success"]:
            return f"âŒ LLM ì˜¤ë¥˜: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"

        text = result["content"]
        logger.info(f"ğŸ“ LLM ì‘ë‹µ: {text[:200]}")

        tool_data = extract_tool_json(text)

        if tool_data:
            try:
                if "keyword" in tool_data:
                    kw = tool_data["keyword"].replace("*", "").replace(".", "").strip()
                    if not kw:
                        return "âŒ ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                    tool_data["keyword"] = kw

                logger.info(f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: {tool_data}")
                tool_result = execute_tool(tool_data)
                logger.info(f"ğŸ“Š ë„êµ¬ ê²°ê³¼: {tool_result[:300]}")

                tool_name = tool_data.get("tool")

                # â˜… ìŠ¤í¬ë¦°ìƒ·: ì§ì ‘ í¬ë§·íŒ… (LLM 2ì°¨ í˜¸ì¶œ ë¶ˆí•„ìš”)
                if tool_name == "screenshot":
                    try:
                        sc_data = json.loads(tool_result)
                        if sc_data.get("success"):
                            return f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ·ì„ ì°ì—ˆìŠµë‹ˆë‹¤!\n\n![ìŠ¤í¬ë¦°ìƒ·]({sc_data['url']})\n\nì €ì¥ ìœ„ì¹˜: `{sc_data['path']}`"
                        else:
                            return f"âŒ ìŠ¤í¬ë¦°ìƒ· ì‹¤íŒ¨: {sc_data.get('error', '?')}"
                    except:
                        return f"âŒ ìŠ¤í¬ë¦°ìƒ· ì²˜ë¦¬ ì˜¤ë¥˜"

                # â˜… ìµœì‹ ë‰´ìŠ¤: ì§ì ‘ í¬ë§·íŒ…
                if tool_name == "latest_news":
                    try:
                        news_data = json.loads(tool_result)
                        if news_data.get("success"):
                            return f"ğŸ“° **ìµœì‹  ë‰´ìŠ¤** (êµ¬ê¸€ë‰´ìŠ¤)\n\n![ë‰´ìŠ¤]({news_data['url']})\n\në¸Œë¼ìš°ì €ë¥¼ ë‹«ì•˜ìŠµë‹ˆë‹¤."
                        else:
                            return f"âŒ ë‰´ìŠ¤ í™•ì¸ ì‹¤íŒ¨: {news_data.get('error', '?')}"
                    except:
                        return f"âŒ ë‰´ìŠ¤ ì²˜ë¦¬ ì˜¤ë¥˜"

                # ========================================
                # â˜… ì§€ì‹ë² ì´ìŠ¤ í•¸ë“¤ëŸ¬ (3ê°€ì§€ êµ¬ì¡°)
                # ========================================

                # 1) read_knowledge â†’ "ì´ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•´ë¼" + ê¸°ìˆ  ë¬¸ì„œ ì „ë¬¸ê°€
                if tool_name == "read_knowledge":
                    if tool_result.startswith("âŒ"):
                        return tool_result
                    
                    # ë¬¸ì„œê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ ìë¥´ê¸°
                    doc_content = tool_result if len(tool_result) <= 12000 else tool_result[:12000] + "\n\n... (ì´í•˜ ìƒëµ)"
                    
                    follow_up_prompt = f"""[ì‚¬ìš©ì ì§ˆë¬¸]
{user_message}

[ì°¸ê³  ë¬¸ì„œ]
{doc_content}

ìœ„ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”.
ë¬¸ì„œì— ìˆëŠ” ë‚´ìš©ë§Œ ê·¼ê±°ë¡œ ë‹µë³€í•˜ê³ , ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”."""

                    follow_up_system = """ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ì´ì ê¸°ìˆ  ë¬¸ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ë‹µë³€ í˜•ì‹ - ë°˜ë“œì‹œ ì´ êµ¬ì¡°ë¡œ]
## ğŸ“‹ í•µì‹¬ ìš”ì•½
- ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ 3ì¤„ ì´ë‚´ë¡œ ìš”ì•½

## ğŸ“ ìƒì„¸ ë‚´ìš©
- êµ¬ì²´ì ì¸ ë‚´ìš© ì •ë¦¬

[ë‹µë³€ ê·œì¹™]
1. ë¬¸ì„œ ë‚´ìš©ì„ ê·¼ê±°ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
2. ì†ŒìŠ¤ì½”ë“œ ì›ë³¸ì€ ì ˆëŒ€ ë³´ì—¬ì£¼ì§€ ë§ˆì„¸ìš”. ì½”ë“œê°€ ìˆìœ¼ë©´ ê¸°ëŠ¥/ì—­í• /ë™ì‘ì„ ì„¤ëª…í•˜ì„¸ìš”.
3. í…Œì´ë¸”/ìŠ¤í‚¤ë§ˆê°€ ìˆìœ¼ë©´ ë§ˆí¬ë‹¤ìš´ í‘œë¡œ ë³´ì—¬ì£¼ì„¸ìš”.
4. í•µì‹¬ ìš”ì•½ì„ ë°˜ë“œì‹œ ë¨¼ì € ì“°ì„¸ìš”.
5. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
6. ì ˆëŒ€ JSONì„ ì¶œë ¥í•˜ê±°ë‚˜ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”."""

                    result2 = call_llm(follow_up_prompt, follow_up_system, max_tokens=6000)
                    if result2["success"] and not extract_tool_json(result2["content"]):
                        return result2["content"]
                    return f"ğŸ“„ **ë¬¸ì„œ ë‚´ìš©:**\n\n{doc_content[:5000]}"

                # 2) search_knowledge â†’ ì²« ë²ˆì§¸ íŒŒì¼ ìë™ìœ¼ë¡œ ì½ì–´ì„œ ë°”ë¡œ ë‹µë³€ (2ë‹¨ê³„â†’1ë‹¨ê³„)
                if tool_name == "search_knowledge":
                    try:
                        search_results = json.loads(tool_result)
                        if not search_results:
                            return "ğŸ” ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§€ì‹ë² ì´ìŠ¤ì— ë¬¸ì„œë¥¼ ë¨¼ì € ë“±ë¡í•´ì£¼ì„¸ìš”."
                        
                        # ì²« ë²ˆì§¸ íŒŒì¼ì„ ë°”ë¡œ ì½ê¸°
                        best_file = search_results[0]["filename"]
                        doc_content = read_knowledge(best_file)
                        
                        if doc_content.startswith("âŒ"):
                            return doc_content
                        
                        # ë¬¸ì„œê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
                        if len(doc_content) > 12000:
                            doc_content = doc_content[:12000] + "\n\n... (ì´í•˜ ìƒëµ)"
                        
                        follow_up_prompt = f"""[ì‚¬ìš©ì ì§ˆë¬¸]
{user_message}

[ì°¸ê³  ë¬¸ì„œ: {best_file}]
{doc_content}

ìœ„ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”.
ë¬¸ì„œì— ìˆëŠ” ë‚´ìš©ë§Œ ê·¼ê±°ë¡œ ë‹µë³€í•˜ê³ , ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”."""

                        follow_up_system = """ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ì´ì ê¸°ìˆ  ë¬¸ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ë‹µë³€ í˜•ì‹ - ë°˜ë“œì‹œ ì´ êµ¬ì¡°ë¡œ]
## ğŸ“‹ í•µì‹¬ ìš”ì•½
- ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ 3ì¤„ ì´ë‚´ë¡œ ìš”ì•½

## ğŸ“ ìƒì„¸ ë‚´ìš©
- êµ¬ì²´ì ì¸ ë‚´ìš© ì •ë¦¬

[ë‹µë³€ ê·œì¹™]
1. ë¬¸ì„œ ë‚´ìš©ì„ ê·¼ê±°ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
2. ì†ŒìŠ¤ì½”ë“œ ì›ë³¸ì€ ì ˆëŒ€ ë³´ì—¬ì£¼ì§€ ë§ˆì„¸ìš”. ì½”ë“œê°€ ìˆìœ¼ë©´ ê¸°ëŠ¥/ì—­í• /ë™ì‘ì„ ì„¤ëª…í•˜ì„¸ìš”.
3. í…Œì´ë¸”/ìŠ¤í‚¤ë§ˆê°€ ìˆìœ¼ë©´ ë§ˆí¬ë‹¤ìš´ í‘œë¡œ ë³´ì—¬ì£¼ì„¸ìš”.
4. í•µì‹¬ ìš”ì•½ì„ ë°˜ë“œì‹œ ë¨¼ì € ì“°ì„¸ìš”.
5. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
6. ì ˆëŒ€ JSONì„ ì¶œë ¥í•˜ê±°ë‚˜ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”."""

                        result2 = call_llm(follow_up_prompt, follow_up_system, max_tokens=6000)
                        if result2["success"] and not extract_tool_json(result2["content"]):
                            return result2["content"]
                        return f"ğŸ“„ **{best_file}:**\n\n{doc_content[:5000]}"
                    except Exception as e:
                        logger.error(f"ì§€ì‹ê²€ìƒ‰ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        pass

                # 3) list_knowledge â†’ LLM í˜¸ì¶œ ì—†ì´ ì§ì ‘ í¬ë§·íŒ… (API ë‚­ë¹„ ë°©ì§€)
                if tool_name == "list_knowledge":
                    try:
                        files = json.loads(tool_result)
                        if not files:
                            return "ğŸ“­ ì§€ì‹ë² ì´ìŠ¤ì— ë“±ë¡ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ“š ì§€ì‹ë² ì´ìŠ¤ ë²„íŠ¼ìœ¼ë¡œ MD/TXT íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
                        lines = [f"## ğŸ“š ì§€ì‹ë² ì´ìŠ¤ ë¬¸ì„œ ({len(files)}ê°œ)\n"]
                        for f in files:
                            lines.append(f"- ğŸ“„ **{f['filename']}** ({f['size']}, {f['modified']})")
                        lines.append(f"\nğŸ’¡ ë¬¸ì„œ ë‚´ìš©ì´ ê¶ê¸ˆí•˜ë©´ íŒŒì¼ëª…ìœ¼ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”. (ì˜ˆ: \"HID_INOUT ì•Œë ¤ì¤˜\")")
                        return "\n".join(lines)
                    except:
                        pass

                # ê¸°íƒ€ ë„êµ¬: 2ì°¨ LLMìœ¼ë¡œ í•´ì„
                follow_up_prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: {user_message}

ë„êµ¬ ì‹¤í–‰ ê²°ê³¼:
{tool_result}

ìœ„ ê²°ê³¼ë¥¼ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ í•œêµ­ì–´ë¡œ ì •ë¦¬í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.
- JSON ì›ë³¸ì„ ë³´ì—¬ì£¼ì§€ ë§ê³  í•µì‹¬ë§Œ ì •ë¦¬
- ë„êµ¬ë¥¼ ë‹¤ì‹œ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš” (JSON ì¶œë ¥ ê¸ˆì§€)
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ"""

                follow_up_system = """ë‹¹ì‹ ì€ PC ê°œì¸ë¹„ì„œì…ë‹ˆë‹¤.
ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.
ì ˆëŒ€ JSONì„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”. ìì—°ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."""

                result2 = call_llm(follow_up_prompt, follow_up_system)
                if result2["success"]:
                    response = result2["content"]
                    if extract_tool_json(response):
                        return format_tool_result_fallback(tool_data, tool_result)
                    return response
                else:
                    return format_tool_result_fallback(tool_data, tool_result)

            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                return "âŒ ëª…ë ¹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        return text

    except Exception as e:
        logger.error(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return f"âŒ ì˜¤ë¥˜: {e}"


# Fallback í¬ë§·í„°
def format_tool_result_fallback(tool_data: dict, tool_result: str) -> str:
    tool_name = tool_data.get("tool", "")
    try:
        if tool_name == "get_system_info":
            info = json.loads(tool_result)
            lines = ["## ğŸ’» ì‹œìŠ¤í…œ ì •ë³´", f"- **OS**: {info.get('os', '?')}", f"- **CPU**: {info.get('cpu', '?')}", f"- **ë©”ëª¨ë¦¬**: {info.get('memory', '?')}"]
            for d in info.get('drives', []):
                lines.append(f"- **{d['drive']}**: {d['total']} (ì‚¬ìš©ë¥  {d['used']})")
            return "\n".join(lines)

        elif tool_name == "get_time":
            return f"ğŸ• í˜„ì¬ ì‹œê°„: {tool_result}"

        elif tool_name in ["search_files", "search_content"]:
            results = json.loads(tool_result)
            if not results:
                return f"ğŸ” '{tool_data.get('keyword', '')}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            lines = [f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: **{len(results)}ê°œ** ë°œê²¬\n"]
            for r in results[:10]:
                if "snippet" in r:
                    lines.append(f"- ğŸ“„ `{r['name']}` â†’ {r['snippet']}")
                else:
                    lines.append(f"- {'ğŸ“' if r.get('type') == 'í´ë”' else 'ğŸ“„'} `{r['name']}` ({r.get('size', '?')})")
            return "\n".join(lines)

        elif tool_name == "list_directory":
            items = json.loads(tool_result)
            lines = [f"ğŸ“‚ `{tool_data.get('path', '')}` ë‚´ìš©:\n"]
            for item in items[:20]:
                icon = "ğŸ“" if item.get("type") == "í´ë”" else "ğŸ“„"
                lines.append(f"- {icon} `{item['name']}` ({item.get('size', '-')})")
            return "\n".join(lines)

        elif tool_name == "read_file":
            return f"ğŸ“„ **íŒŒì¼ ë‚´ìš©:**\n```\n{tool_result}\n```"

        elif tool_name in ["run_program", "kill_program", "open_web", "google_search"]:
            return f"âœ… {tool_result}"

        elif tool_name == "list_processes":
            procs = json.loads(tool_result)
            if not procs or "error" in procs[0]:
                return "âŒ í”„ë¡œì„¸ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            lines = [f"## ğŸ“‹ ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ (ìƒìœ„ {len(procs)}ê°œ)\n"]
            lines.append("| ì´ë¦„ | PID | ë©”ëª¨ë¦¬(MB) | CPU% | ìƒíƒœ |")
            lines.append("|------|-----|-----------|------|------|")
            for p in procs:
                lines.append(f"| {p['name']} | {p['pid']} | {p['memory_mb']} | {p['cpu']}% | {p['status']} |")
            return "\n".join(lines)

        elif tool_name == "analyze_data":
            return f"ğŸ“Š **ë°ì´í„° ë¶„ì„:**\n```\n{tool_result}\n```"

    except Exception as e:
        logger.error(f"í¬ë§·íŒ… ì˜¤ë¥˜: {e}")

    return f"ğŸ“‹ **ê²°ê³¼:**\n```\n{tool_result}\n```"


# ========================================
# ëŒ€í™” ê¸°ë¡
# ========================================
def save_history():
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(CHAT_HISTORY[-100:], f, ensure_ascii=False, indent=2)
    except:
        pass

def load_history():
    global CHAT_HISTORY
    try:
        if os.path.exists(HISTORY_FILE):
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                CHAT_HISTORY = json.load(f)
    except:
        CHAT_HISTORY = []


# ========================================
# API Models
# ========================================
class ChatRequest(BaseModel):
    message: str

class SearchRequest(BaseModel):
    keyword: str
    path: str = "C:/"
    file_content: bool = False

class EnvRequest(BaseModel):
    env: str


# ========================================
# Endpoints
# ========================================
def init_assistant():
    global LOCAL_LLM, LLM_MODE
    load_history()
    if load_api_token():
        LLM_MODE = "api"
        logger.info("âœ… ë¹„ì„œ: API ëª¨ë“œ")
    else:
        LOCAL_LLM = load_local_model()
        if LOCAL_LLM:
            LLM_MODE = "local"
            logger.info("âœ… ë¹„ì„œ: LOCAL ëª¨ë“œ")


@router.get("/")
async def assistant_home():
    return FileResponse(os.path.join(BASE_DIR, "assistant_ui.html"))


# â˜… ìŠ¤í¬ë¦°ìƒ· ì´ë¯¸ì§€ ì„œë¹™
@router.get("/screenshots/{filename}")
async def serve_screenshot(filename: str):
    filepath = os.path.join(SCREENSHOT_DIR, filename)
    if os.path.exists(filepath):
        return FileResponse(filepath, media_type="image/png")
    return {"error": "íŒŒì¼ ì—†ìŒ"}


# â˜… ìŠ¤í¬ë¦°ìƒ· ëª©ë¡
@router.get("/api/screenshots")
async def list_screenshots():
    files = []
    if os.path.exists(SCREENSHOT_DIR):
        for f in sorted(os.listdir(SCREENSHOT_DIR), reverse=True)[:20]:
            if f.endswith('.png'):
                filepath = os.path.join(SCREENSHOT_DIR, f)
                size = os.path.getsize(filepath)
                files.append({
                    "filename": f,
                    "url": f"/assistant/screenshots/{f}",
                    "size": f"{size / 1024:.0f}KB",
                    "time": datetime.datetime.fromtimestamp(os.path.getmtime(filepath)).strftime("%Y-%m-%d %H:%M:%S")
                })
    return {"screenshots": files}


@router.get("/api/status")
async def assistant_status():
    return {
        "mode": LLM_MODE,
        "env": CURRENT_ENV if LLM_MODE != "local" else "local",
        "model_loaded": LOCAL_LLM is not None if LLM_MODE == "local" else API_TOKEN is not None,
        "model_name": ENV_CONFIG.get(CURRENT_ENV, {}).get("name", "LOCAL") if LLM_MODE != "local" else "Qwen3-14B-GGUF",
        "system": get_system_info(),
        "history_count": len(CHAT_HISTORY),
        "token_usage": TOKEN_USAGE
    }


# â˜… í† í° ì‚¬ìš©ëŸ‰ API
@router.get("/api/tokens")
async def assistant_tokens():
    return {
        "success": True,
        "prompt_tokens": TOKEN_USAGE["prompt_tokens"],
        "completion_tokens": TOKEN_USAGE["completion_tokens"],
        "total_tokens": TOKEN_USAGE["total_tokens"],
        "call_count": TOKEN_USAGE["call_count"]
    }


@router.post("/api/tokens/reset")
async def assistant_reset_tokens():
    TOKEN_USAGE["prompt_tokens"] = 0
    TOKEN_USAGE["completion_tokens"] = 0
    TOKEN_USAGE["total_tokens"] = 0
    TOKEN_USAGE["call_count"] = 0
    return {"success": True, "message": "í† í° ì¹´ìš´í„° ì´ˆê¸°í™”ë¨"}


@router.post("/api/set_env")
async def assistant_set_env(request: EnvRequest):
    global LLM_MODE, LOCAL_LLM, CURRENT_ENV, API_URL, API_MODEL
    env = request.env.lower()

    if env == "local":
        if LOCAL_LLM is None:
            LOCAL_LLM = load_local_model()
        if LOCAL_LLM:
            LLM_MODE = "local"
            return {"success": True, "env": "local", "name": "LOCAL(14B-GGUF)"}
        return {"success": False, "error": "ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"}

    elif env in ENV_CONFIG:
        if not API_TOKEN and not load_api_token():
            return {"success": False, "error": "API í† í° ì—†ìŒ"}
        LLM_MODE = "api"
        CURRENT_ENV = env
        API_URL = ENV_CONFIG[env]["url"]
        API_MODEL = ENV_CONFIG[env]["model"]
        return {"success": True, "env": env, "name": ENV_CONFIG[env]["name"]}

    return {"success": False, "error": f"ì•Œ ìˆ˜ ì—†ëŠ” í™˜ê²½: {env}"}


@router.post("/api/chat")
async def assistant_chat(request: ChatRequest):
    user_msg = request.message.strip()
    CHAT_HISTORY.append({"role": "user", "content": user_msg, "time": datetime.datetime.now().isoformat()})
    response = process_chat(user_msg)
    CHAT_HISTORY.append({"role": "assistant", "content": response, "time": datetime.datetime.now().isoformat()})
    save_history()
    return {"success": True, "response": response}


@router.post("/api/search")
async def assistant_search(request: SearchRequest):
    if request.file_content:
        results = search_content(request.keyword, request.path)
    else:
        results = search_files(request.keyword, request.path)
    return {"success": True, "results": results, "count": len(results)}


@router.get("/api/drives")
async def assistant_drives():
    drives = []
    for p in psutil.disk_partitions():
        drives.append({"device": p.device, "mountpoint": p.mountpoint})
    return {"success": True, "drives": drives}


@router.get("/api/history")
async def assistant_get_history():
    return {"history": CHAT_HISTORY[-50:]}


@router.delete("/api/history")
async def assistant_clear_history():
    global CHAT_HISTORY
    CHAT_HISTORY = []
    save_history()
    return {"success": True}


# â˜… ì§€ì‹ë² ì´ìŠ¤ API
@router.get("/api/knowledge")
async def api_list_knowledge():
    """ì§€ì‹ë² ì´ìŠ¤ ë¬¸ì„œ ëª©ë¡"""
    files = list_knowledge()
    return {"success": True, "files": files, "count": len(files)}


@router.post("/api/knowledge/upload")
async def api_upload_knowledge(file: UploadFile = File(...)):
    """MD/TXT íŒŒì¼ ì—…ë¡œë“œ"""
    if not file.filename.lower().endswith(('.md', '.txt')):
        return {"success": False, "error": "md ë˜ëŠ” txt íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."}
    try:
        filepath = os.path.join(KNOWLEDGE_DIR, file.filename)
        content = await file.read()
        with open(filepath, 'wb') as f:
            f.write(content)
        return {"success": True, "filename": file.filename, "size": len(content)}
    except Exception as e:
        return {"success": False, "error": str(e)}


@router.delete("/api/knowledge/{filename}")
async def api_delete_knowledge(filename: str):
    """ì§€ì‹ë² ì´ìŠ¤ ë¬¸ì„œ ì‚­ì œ"""
    filepath = os.path.join(KNOWLEDGE_DIR, filename)
    if os.path.exists(filepath):
        os.remove(filepath)
        return {"success": True, "message": f"'{filename}' ì‚­ì œë¨"}
    return {"success": False, "error": "íŒŒì¼ ì—†ìŒ"}


@router.get("/api/knowledge/download/{filename}")
async def api_download_knowledge(filename: str):
    """ì§€ì‹ë² ì´ìŠ¤ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ"""
    filepath = os.path.join(KNOWLEDGE_DIR, filename)
    if os.path.exists(filepath):
        return FileResponse(filepath, filename=filename, media_type="application/octet-stream")
    return JSONResponse(status_code=404, content={"error": "íŒŒì¼ ì—†ìŒ"})


# ========================================
# ê³¼ê±°ì§€ì‹ ë³´ê´€ì†Œ API
# ========================================
@router.get("/api/knowledge/archive")
async def api_list_archive():
    """ê³¼ê±°ì§€ì‹ ë¬¸ì„œ ëª©ë¡"""
    files = []
    try:
        for f in sorted(os.listdir(KNOWLEDGE_ARCHIVE_DIR)):
            if f.lower().endswith(('.md', '.txt')):
                filepath = os.path.join(KNOWLEDGE_ARCHIVE_DIR, f)
                size = os.path.getsize(filepath)
                modified = datetime.datetime.fromtimestamp(os.path.getmtime(filepath)).strftime("%Y-%m-%d %H:%M")
                size_str = f"{size / 1024:.1f}KB" if size > 1024 else f"{size}B"
                files.append({"filename": f, "size": size_str, "modified": modified})
    except Exception as e:
        logger.error(f"ê³¼ê±°ì§€ì‹ ëª©ë¡ ì˜¤ë¥˜: {e}")
    return {"success": True, "files": files, "count": len(files)}


@router.post("/api/knowledge/archive/{filename}")
async def api_archive_knowledge(filename: str):
    """ì§€ì‹ë² ì´ìŠ¤ â†’ ê³¼ê±°ì§€ì‹ìœ¼ë¡œ ì´ë™"""
    import shutil
    src = os.path.join(KNOWLEDGE_DIR, filename)
    dst = os.path.join(KNOWLEDGE_ARCHIVE_DIR, filename)
    if not os.path.exists(src):
        return {"success": False, "error": f"'{filename}' íŒŒì¼ ì—†ìŒ"}
    try:
        shutil.move(src, dst)
        return {"success": True, "message": f"'{filename}' â†’ ê³¼ê±°ì§€ì‹ìœ¼ë¡œ ì´ë™ë¨"}
    except Exception as e:
        return {"success": False, "error": str(e)}


@router.post("/api/knowledge/restore/{filename}")
async def api_restore_knowledge(filename: str):
    """ê³¼ê±°ì§€ì‹ â†’ ì§€ì‹ë² ì´ìŠ¤ë¡œ ë³µì›"""
    import shutil
    src = os.path.join(KNOWLEDGE_ARCHIVE_DIR, filename)
    dst = os.path.join(KNOWLEDGE_DIR, filename)
    if not os.path.exists(src):
        return {"success": False, "error": f"'{filename}' íŒŒì¼ ì—†ìŒ"}
    try:
        shutil.move(src, dst)
        return {"success": True, "message": f"'{filename}' â†’ ì§€ì‹ë² ì´ìŠ¤ë¡œ ë³µì›ë¨"}
    except Exception as e:
        return {"success": False, "error": str(e)}


@router.delete("/api/knowledge/archive/{filename}")
async def api_delete_archive(filename: str):
    """ê³¼ê±°ì§€ì‹ ë¬¸ì„œ ì™„ì „ ì‚­ì œ"""
    filepath = os.path.join(KNOWLEDGE_ARCHIVE_DIR, filename)
    if os.path.exists(filepath):
        os.remove(filepath)
        return {"success": True, "message": f"'{filename}' ì™„ì „ ì‚­ì œë¨"}
    return {"success": False, "error": "íŒŒì¼ ì—†ìŒ"}


if __name__ == "__main__":
    import uvicorn
    app.include_router(router)

    @app.on_event("startup")
    async def standalone_startup():
        init_assistant()

    uvicorn.run(app, host="0.0.0.0", port=10002)