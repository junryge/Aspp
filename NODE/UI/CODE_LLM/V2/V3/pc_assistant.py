#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PC ê°œì¸ë¹„ì„œ AI (Moltbot ìŠ¤íƒ€ì¼ Tool Calling)
- LLMì´ JSONìœ¼ë¡œ ë„êµ¬ í˜¸ì¶œ
- íŒŒì¼ ê²€ìƒ‰, ë‚´ìš© ê²€ìƒ‰
- ì‹œìŠ¤í…œ ì •ë³´
- í”„ë¡œê·¸ë¨ ì‹¤í–‰
- API ë° GGUF ëª¨ë‘ ì§€ì›
- â˜… ìŠ¤í¬ë¦°ìƒ· ì›¹ í‘œì‹œ ì§€ì›
"""

import os
import re
import json
import subprocess
import platform
import psutil
import datetime
import webbrowser
import fnmatch
import requests
import pandas as pd
from typing import Optional, List
from fastapi import FastAPI, APIRouter
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("PCAssistant")

# APIRouterë¡œ ë³€ê²½ (ë©”ì¸ ì„œë²„ì—ì„œ include ê°€ëŠ¥)
router = APIRouter(prefix="/assistant", tags=["assistant"])

# ë‹¨ë… ì‹¤í–‰ìš© ì•± (í…ŒìŠ¤íŠ¸ìš©)
app = FastAPI(title="ì§í‰ ëª°íŠ¸ë´‡ ê°ë§ˆë²„ì „ VER 0.1")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========================================
# Global Configuration
# ========================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
GGUF_MODEL_PATH = os.path.join(BASE_DIR, "Qwen3-14B-Q4_K_M.gguf")
LOCAL_LLM = None
CHAT_HISTORY = []
HISTORY_FILE = os.path.join(BASE_DIR, "chat_history.json")

# â˜… ìŠ¤í¬ë¦°ìƒ· ì €ì¥ í´ë”
SCREENSHOT_DIR = os.path.join(BASE_DIR, "screenshots")
os.makedirs(SCREENSHOT_DIR, exist_ok=True)

# LLM ëª¨ë“œ ì„¤ì • (api ë˜ëŠ” local)
LLM_MODE = "local"  # ê¸°ë³¸ê°’: local
API_TOKEN = None

# API ì„¤ì •
ENV_CONFIG = {
    "dev": {
        "url": "http://dev.assistant.llm.skhynix.com/v1/chat/completions",
        "model": "Qwen3-Coder-30B-A3B-Instruct",
        "name": "DEV(30B)"
    },
    "prod": {
        "url": "http://summary.llm.skhynix.com/v1/chat/completions",
        "model": "Qwen3-Next-80B-A3B-Instruct",
        "name": "PROD(80B)"
    },
    "common": {
        "url": "http://common.llm.skhynix.com/v1/chat/completions",
        "model": "gpt-oss-20b",
        "name": "COMMON(20B)"
    }
}
CURRENT_ENV = "common"
API_URL = ENV_CONFIG["common"]["url"]
API_MODEL = ENV_CONFIG["common"]["model"]

# ========================================
# System Prompt (Tool Calling ë°©ì‹)
# ========================================
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ 'ì§í‰ ëª°íŠ¸ë´‡ ê°ë§ˆë²„ì „ VER 0.1'ì´ë¼ëŠ” PC ê°œì¸ë¹„ì„œ AIì…ë‹ˆë‹¤.

[ì¤‘ìš” ê·œì¹™]
1. PC ì‘ì—…(íŒŒì¼ê²€ìƒ‰, ì‹œìŠ¤í…œì •ë³´ ë“±)ì´ í•„ìš”í•˜ë©´ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.
2. JSONë§Œ ì¶œë ¥í•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ ë¶™ì´ì§€ ë§ˆì„¸ìš”.
3. keywordì—ëŠ” í™•ì¥ì(.gguf)ë‚˜ ì™€ì¼ë“œì¹´ë“œ(*) ì—†ì´ ìˆœìˆ˜ í‚¤ì›Œë“œë§Œ ë„£ìœ¼ì„¸ìš”. ì˜ˆ: "gguf", "txt", "python"

[ë„êµ¬ ëª©ë¡]
- íŒŒì¼ê²€ìƒ‰: {"tool": "search_files", "keyword": "gguf", "path": "F:/"}
- ë‚´ìš©ê²€ìƒ‰: {"tool": "search_content", "keyword": "hello", "path": "C:/"}
- ì‹œìŠ¤í…œì •ë³´: {"tool": "get_system_info"}
- í´ë”ë³´ê¸°: {"tool": "list_directory", "path": "C:/Users"}
- íŒŒì¼ì½ê¸°: {"tool": "read_file", "path": "C:/test.txt"}
- í”„ë¡œê·¸ë¨ì‹¤í–‰: {"tool": "run_program", "program": "notepad"}
- í”„ë¡œê·¸ë¨ì¢…ë£Œ: {"tool": "kill_program", "name": "notepad"}
- ì›¹ì—´ê¸°: {"tool": "open_web", "url": "https://google.com"}
- êµ¬ê¸€ê²€ìƒ‰: {"tool": "google_search", "query": "ë‚ ì”¨"}
- í˜„ì¬ì‹œê°„: {"tool": "get_time"}
- ìŠ¤í¬ë¦°ìƒ·: {"tool": "screenshot"}
- ë°ì´í„°ë¶„ì„: {"tool": "analyze_data", "path": "C:/data.csv"}

ì¼ë°˜ ëŒ€í™”ëŠ” í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”."""


# ========================================
# Tool Functions
# ========================================
def load_local_model():
    global LOCAL_LLM
    try:
        from llama_cpp import Llama

        if not os.path.exists(GGUF_MODEL_PATH):
            logger.error(f"GGUF íŒŒì¼ ì—†ìŒ: {GGUF_MODEL_PATH}")
            return None

        logger.info("GGUF ëª¨ë¸ ë¡œë”© ì¤‘...")
        llm = Llama(
            model_path=GGUF_MODEL_PATH,
            n_ctx=8192,
            n_threads=8,
            n_gpu_layers=50,
            n_batch=512,
            verbose=False
        )
        logger.info("GGUF ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        return llm
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def load_api_token():
    """API í† í° ë¡œë“œ"""
    global API_TOKEN
    token_file = os.path.join(BASE_DIR, "api_token.txt")
    if os.path.exists(token_file):
        with open(token_file, 'r') as f:
            API_TOKEN = f.read().strip()
            logger.info("API í† í° ë¡œë“œë¨")
            return True

    # ìƒìœ„ ë””ë ‰í† ë¦¬ë„ í™•ì¸
    paths = ["token.txt", "../token.txt", os.path.expanduser("~/token.txt")]
    for p in paths:
        if os.path.exists(p):
            try:
                with open(p, "r", encoding='utf-8') as f:
                    API_TOKEN = f.read().strip()
                if API_TOKEN and "REPLACE" not in API_TOKEN:
                    logger.info(f"API í† í° ë¡œë“œ: {p}")
                    return True
            except:
                pass

    logger.warning("API í† í° íŒŒì¼ ì—†ìŒ")
    return False


def call_local_llm(prompt: str, system_prompt: str = "") -> dict:
    """ë¡œì»¬ GGUF ëª¨ë¸ í˜¸ì¶œ"""
    global LOCAL_LLM

    if LOCAL_LLM is None:
        return {"success": False, "error": "ë¡œì»¬ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}

    full_prompt = f"""<|im_start|>system
{system_prompt}<|im_end|>
<|im_start|>user
{prompt}<|im_end|>
<|im_start|>assistant
"""

    try:
        output = LOCAL_LLM(
            full_prompt,
            max_tokens=4096,
            temperature=0.3,
            stop=["<|im_end|>", "<|im_start|>"],
            echo=False
        )
        content = output["choices"][0]["text"].strip()
        content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL).strip()
        return {"success": True, "content": content}
    except Exception as e:
        return {"success": False, "error": str(e)}


def call_api_llm(prompt: str, system_prompt: str = "") -> dict:
    """API LLM í˜¸ì¶œ"""
    global API_TOKEN

    if not API_TOKEN:
        return {"success": False, "error": "API í† í° ì—†ìŒ"}

    headers = {
        "Authorization": f"Bearer {API_TOKEN}",
        "Content-Type": "application/json"
    }

    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})

    data = {
        "model": API_MODEL,
        "messages": messages,
        "max_tokens": 4096,
        "temperature": 0.3
    }

    try:
        response = requests.post(API_URL, headers=headers, json=data, timeout=300)

        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL).strip()
            return {"success": True, "content": content}
        else:
            return {"success": False, "error": f"API ì˜¤ë¥˜: {response.status_code}"}
    except Exception as e:
        return {"success": False, "error": str(e)}


def call_llm(prompt: str, system_prompt: str = "") -> dict:
    """LLM_MODEì— ë”°ë¼ API ë˜ëŠ” ë¡œì»¬ ëª¨ë¸ í˜¸ì¶œ"""
    if LLM_MODE == "local":
        return call_local_llm(prompt, system_prompt)
    else:
        return call_api_llm(prompt, system_prompt)


def search_files(keyword: str, path: str = "C:/", limit: int = 50) -> List[dict]:
    """íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰"""
    results = []
    logger.info(f"íŒŒì¼ ê²€ìƒ‰: '{keyword}' in '{path}'")

    try:
        for root, dirs, files in os.walk(path):
            for name in files + dirs:
                if keyword.lower() in name.lower():
                    full_path = os.path.join(root, name)
                    is_dir = os.path.isdir(full_path)
                    try:
                        size = os.path.getsize(full_path) if not is_dir else 0
                        size_str = f"{size / (1024**3):.2f}GB" if size > 1024**3 else f"{size / (1024**2):.1f}MB" if size > 1024**2 else f"{size}B"
                    except:
                        size_str = "?"

                    results.append({
                        "name": name,
                        "path": full_path,
                        "type": "í´ë”" if is_dir else "íŒŒì¼",
                        "size": size_str
                    })

                    if len(results) >= limit:
                        return results
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

    return results


def search_content(keyword: str, path: str = "C:/", limit: int = 30) -> List[dict]:
    """íŒŒì¼ ë‚´ìš©ìœ¼ë¡œ ê²€ìƒ‰"""
    results = []
    extensions = ['.txt', '.py', '.md', '.json', '.html', '.css', '.js', '.csv', '.log']

    logger.info(f"ë‚´ìš© ê²€ìƒ‰: '{keyword}' in '{path}'")

    try:
        for root, dirs, files in os.walk(path):
            for name in files:
                ext = os.path.splitext(name)[1].lower()
                if ext in extensions:
                    full_path = os.path.join(root, name)
                    try:
                        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read(50000)  # 50KBê¹Œì§€ë§Œ
                            if keyword.lower() in content.lower():
                                idx = content.lower().find(keyword.lower())
                                snippet = content[max(0, idx-30):min(len(content), idx+70)].replace('\n', ' ')

                                results.append({
                                    "name": name,
                                    "path": full_path,
                                    "snippet": f"...{snippet}..."
                                })

                                if len(results) >= limit:
                                    return results
                    except:
                        continue
    except Exception as e:
        logger.error(f"ë‚´ìš© ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

    return results


def get_system_info() -> dict:
    """ì‹œìŠ¤í…œ ì •ë³´"""
    drives = []
    for p in psutil.disk_partitions():
        try:
            usage = psutil.disk_usage(p.mountpoint)
            drives.append({
                "drive": p.device,
                "total": f"{usage.total / (1024**3):.1f}GB",
                "used": f"{usage.percent}%"
            })
        except:
            pass

    return {
        "os": f"{platform.system()} {platform.release()}",
        "cpu": f"{psutil.cpu_count()}ì½”ì–´, {psutil.cpu_percent()}%",
        "memory": f"{psutil.virtual_memory().total // (1024**3)}GB, {psutil.virtual_memory().percent}%",
        "drives": drives
    }


def list_directory(path: str) -> List[dict]:
    """í´ë” ë‚´ìš©"""
    items = []
    try:
        for name in os.listdir(path)[:50]:
            full_path = os.path.join(path, name)
            is_dir = os.path.isdir(full_path)
            try:
                size = os.path.getsize(full_path) if not is_dir else 0
                modified = datetime.datetime.fromtimestamp(os.path.getmtime(full_path)).strftime("%Y-%m-%d %H:%M")
            except:
                size = 0
                modified = "?"

            items.append({
                "name": name,
                "type": "í´ë”" if is_dir else "íŒŒì¼",
                "size": f"{size:,}" if not is_dir else "-",
                "modified": modified
            })
    except Exception as e:
        return [{"error": str(e)}]

    return items


def read_file(path: str, max_chars: int = 5000) -> str:
    """íŒŒì¼ ì½ê¸°"""
    try:
        with open(path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read(max_chars)
            if len(content) == max_chars:
                content += "\n... (íŒŒì¼ì´ ë„ˆë¬´ ì»¤ì„œ ì¼ë¶€ë§Œ í‘œì‹œ)"
            return content
    except Exception as e:
        return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}"


def run_program(program: str) -> str:
    """í”„ë¡œê·¸ë¨ ì‹¤í–‰"""
    try:
        subprocess.Popen(program, shell=True)
        return f"'{program}' ì‹¤í–‰ë¨"
    except Exception as e:
        return f"ì‹¤í–‰ ì˜¤ë¥˜: {e}"


def kill_program(name: str) -> str:
    """í”„ë¡œê·¸ë¨ ì¢…ë£Œ"""
    try:
        killed = 0
        for proc in psutil.process_iter(['name']):
            if name.lower() in proc.info['name'].lower():
                proc.kill()
                killed += 1
        return f"{killed}ê°œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë¨"
    except Exception as e:
        return f"ì¢…ë£Œ ì˜¤ë¥˜: {e}"


def open_web(url: str) -> str:
    """ì›¹ ì—´ê¸°"""
    if not url.startswith('http'):
        url = 'https://' + url
    webbrowser.open(url)
    return f"'{url}' ì—´ë¦¼"


def google_search(query: str) -> str:
    """êµ¬ê¸€ ê²€ìƒ‰"""
    url = f"https://www.google.com/search?q={query}"
    webbrowser.open(url)
    return f"'{query}' ê²€ìƒ‰ ì¤‘..."


def get_time() -> str:
    """í˜„ì¬ ì‹œê°„"""
    now = datetime.datetime.now()
    return f"{now.strftime('%Yë…„ %mì›” %dì¼ %A %Hì‹œ %Më¶„ %Sì´ˆ')}"


def take_screenshot() -> dict:
    """â˜… ìŠ¤í¬ë¦°ìƒ· ì°ê³  ì›¹ URL ë°˜í™˜"""
    try:
        from PIL import ImageGrab

        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"screenshot_{timestamp}.png"
        filepath = os.path.join(SCREENSHOT_DIR, filename)

        img = ImageGrab.grab()
        img.save(filepath)

        # ì›¹ì—ì„œ ì ‘ê·¼í•  URL ë°˜í™˜
        web_url = f"/assistant/api/screenshot/{filename}"
        logger.info(f"ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filepath} â†’ URL: {web_url}")

        return {
            "success": True,
            "path": filepath,
            "filename": filename,
            "url": web_url,
            "timestamp": timestamp
        }
    except ImportError:
        return {"success": False, "error": "PIL(Pillow) ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install Pillow"}
    except Exception as e:
        return {"success": False, "error": str(e)}


def analyze_data(path: str) -> str:
    """ë°ì´í„° ë¶„ì„"""
    try:
        ext = os.path.splitext(path)[1].lower()

        if ext == '.csv':
            df = pd.read_csv(path, encoding='utf-8', errors='ignore')
        elif ext in ['.xlsx', '.xls']:
            df = pd.read_excel(path)
        else:
            return f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {ext}"

        result = []
        result.append(f"íŒŒì¼: {os.path.basename(path)}")
        result.append(f"í¬ê¸°: {len(df):,}í–‰ x {len(df.columns)}ì—´")
        result.append(f"ì»¬ëŸ¼: {', '.join(df.columns.tolist()[:20])}")

        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            stats = df[numeric_cols].describe().to_string()
            result.append(f"í†µê³„:\n{stats}")

        result.append(f"ìƒ˜í”Œ:\n{df.head(5).to_string()}")

        return "\n".join(result)
    except Exception as e:
        return f"ë¶„ì„ ì˜¤ë¥˜: {e}"


# Tool ì‹¤í–‰ê¸°
def execute_tool(tool_data: dict) -> str:
    """ë„êµ¬ ì‹¤í–‰"""
    tool_name = tool_data.get("tool")

    if tool_name == "search_files":
        results = search_files(tool_data.get("keyword", ""), tool_data.get("path", "C:/"))
        return json.dumps(results[:20], ensure_ascii=False, indent=2)

    elif tool_name == "search_content":
        results = search_content(tool_data.get("keyword", ""), tool_data.get("path", "C:/"))
        return json.dumps(results[:10], ensure_ascii=False, indent=2)

    elif tool_name == "get_system_info":
        return json.dumps(get_system_info(), ensure_ascii=False, indent=2)

    elif tool_name == "list_directory":
        results = list_directory(tool_data.get("path", "C:/"))
        return json.dumps(results, ensure_ascii=False, indent=2)

    elif tool_name == "read_file":
        return read_file(tool_data.get("path", ""))

    elif tool_name == "run_program":
        return run_program(tool_data.get("program", ""))

    elif tool_name == "kill_program":
        return kill_program(tool_data.get("name", ""))

    elif tool_name == "open_web":
        return open_web(tool_data.get("url", ""))

    elif tool_name == "google_search":
        return google_search(tool_data.get("query", ""))

    elif tool_name == "get_time":
        return get_time()

    elif tool_name == "screenshot":
        # â˜… ìŠ¤í¬ë¦°ìƒ·ì€ íŠ¹ë³„ ì²˜ë¦¬ - dict ë°˜í™˜
        result = take_screenshot()
        return json.dumps(result, ensure_ascii=False)

    elif tool_name == "analyze_data":
        return analyze_data(tool_data.get("path", ""))

    return "ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬"


# ========================================
# Chat Processing
# ========================================
def process_chat(user_message: str) -> dict:
    """â˜… ì±„íŒ… ì²˜ë¦¬ - dict ë°˜í™˜ìœ¼ë¡œ ë³€ê²½ (ì´ë¯¸ì§€ URL í¬í•¨ ê°€ëŠ¥)"""
    global LOCAL_LLM, LLM_MODE

    # ëª¨ë¸ ì²´í¬
    if LLM_MODE == "local" and LOCAL_LLM is None:
        return {"text": "ë¡œì»¬ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "image": None}
    if LLM_MODE != "local" and not API_TOKEN:
        return {"text": "API í† í°ì´ ì—†ìŠµë‹ˆë‹¤.", "image": None}

    # 1ì°¨: LLM í˜¸ì¶œ (ë„êµ¬ í˜¸ì¶œ ì—¬ë¶€ íŒë‹¨)
    try:
        result = call_llm(user_message, SYSTEM_PROMPT)
        if not result["success"]:
            return {"text": f"LLM ì˜¤ë¥˜: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}", "image": None}

        text = result["content"]

        # JSON ë„êµ¬ í˜¸ì¶œ ê°ì§€
        tool_match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
        if not tool_match:
            tool_match = re.search(r'(\{[^{}]*"tool"\s*:\s*"[^"]+?"[^{}]*\})', text, re.DOTALL)

        if tool_match:
            try:
                raw_json = tool_match.group(1)
                logger.info(f"ë„êµ¬ í˜¸ì¶œ ê°ì§€: {raw_json}")
                tool_data = json.loads(raw_json)

                # keywordì—ì„œ ì™€ì¼ë“œì¹´ë“œ ì œê±°
                if "keyword" in tool_data:
                    tool_data["keyword"] = tool_data["keyword"].replace("*", "").replace(".", "").strip()

                logger.info(f"ë„êµ¬ ì‹¤í–‰: {tool_data}")
                tool_result = execute_tool(tool_data)
                logger.info(f"ë„êµ¬ ê²°ê³¼: {tool_result[:200]}...")

                # â˜… ìŠ¤í¬ë¦°ìƒ·ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
                if tool_data.get("tool") == "screenshot":
                    try:
                        sc_data = json.loads(tool_result)
                        if sc_data.get("success"):
                            return {
                                "text": f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ·ì„ ì°ì—ˆìŠµë‹ˆë‹¤!\n\nì´¬ì˜ ì‹œê°„: {sc_data['timestamp']}\nì €ì¥ ìœ„ì¹˜: {sc_data['path']}",
                                "image": sc_data["url"]
                            }
                        else:
                            return {
                                "text": f"âŒ ìŠ¤í¬ë¦°ìƒ· ì‹¤íŒ¨: {sc_data.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}",
                                "image": None
                            }
                    except:
                        pass

                # 2ì°¨: ê²°ê³¼ í•´ì„ (ìŠ¤í¬ë¦°ìƒ· ì™¸ ì¼ë°˜ ë„êµ¬)
                follow_up_system = f"""{SYSTEM_PROMPT}

[ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]
{tool_result}

ìœ„ ê²°ê³¼ë¥¼ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
JSONì´ë‚˜ ì›ë³¸ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ë³´ì—¬ì£¼ì§€ ë§ê³ , í•µì‹¬ ë‚´ìš©ë§Œ ì •ë¦¬í•´ì„œ ë‹µë³€í•˜ì„¸ìš”."""

                result2 = call_llm(user_message, follow_up_system)
                if result2["success"]:
                    return {"text": result2["content"], "image": None}
                else:
                    return {"text": f"ê²°ê³¼ í•´ì„ ì˜¤ë¥˜: {result2.get('error', '')}", "image": None}

            except json.JSONDecodeError as e:
                logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                return {"text": "ëª…ë ¹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "image": None}

        # ë„êµ¬ í˜¸ì¶œ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì‘ë‹µ
        return {"text": text, "image": None}

    except Exception as e:
        logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {"text": f"ì˜¤ë¥˜: {e}", "image": None}


# ========================================
# ëŒ€í™” ê¸°ë¡
# ========================================
def save_history():
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(CHAT_HISTORY[-100:], f, ensure_ascii=False, indent=2)
    except:
        pass

def load_history():
    global CHAT_HISTORY
    try:
        if os.path.exists(HISTORY_FILE):
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                CHAT_HISTORY = json.load(f)
    except:
        CHAT_HISTORY = []


# ========================================
# API Models
# ========================================
class ChatRequest(BaseModel):
    message: str

class SearchRequest(BaseModel):
    keyword: str
    path: str = "C:/"
    file_content: bool = False

class EnvRequest(BaseModel):
    env: str  # "local", "dev", "prod", "common"


# ========================================
# API Endpoints
# ========================================
# ì´ˆê¸°í™” í•¨ìˆ˜ (ë©”ì¸ ì„œë²„ì—ì„œ í˜¸ì¶œ)
def init_assistant():
    global LOCAL_LLM, LLM_MODE
    load_history()
    if load_api_token():
        LLM_MODE = "api"
        logger.info("ë¹„ì„œ: API ëª¨ë“œ")
    else:
        LOCAL_LLM = load_local_model()
        if LOCAL_LLM:
            LLM_MODE = "local"
            logger.info("ë¹„ì„œ: LOCAL ëª¨ë“œ")


# Router ì—”ë“œí¬ì¸íŠ¸ë“¤ (ë©”ì¸ ì„œë²„ì— í†µí•©ë¨)
@router.get("/")
async def assistant_home():
    return FileResponse(os.path.join(BASE_DIR, "assistant_ui.html"))


@router.get("/api/status")
async def assistant_status():
    return {
        "mode": LLM_MODE,
        "env": CURRENT_ENV if LLM_MODE != "local" else "local",
        "model_loaded": LOCAL_LLM is not None if LLM_MODE == "local" else API_TOKEN is not None,
        "model_name": ENV_CONFIG.get(CURRENT_ENV, {}).get("name", "LOCAL") if LLM_MODE != "local" else "Qwen3-14B-GGUF",
        "system": get_system_info(),
        "history_count": len(CHAT_HISTORY)
    }


@router.post("/api/set_env")
async def assistant_set_env(request: EnvRequest):
    global LLM_MODE, LOCAL_LLM, CURRENT_ENV, API_URL, API_MODEL

    env = request.env.lower()

    if env == "local":
        if LOCAL_LLM is None:
            LOCAL_LLM = load_local_model()
        if LOCAL_LLM:
            LLM_MODE = "local"
            return {"success": True, "env": "local", "name": "LOCAL(14B-GGUF)"}
        else:
            return {"success": False, "error": "ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"}

    elif env in ENV_CONFIG:
        if not API_TOKEN:
            if not load_api_token():
                return {"success": False, "error": "API í† í° ì—†ìŒ"}

        LLM_MODE = "api"
        CURRENT_ENV = env
        API_URL = ENV_CONFIG[env]["url"]
        API_MODEL = ENV_CONFIG[env]["model"]
        return {"success": True, "env": env, "name": ENV_CONFIG[env]["name"]}

    return {"success": False, "error": f"ì•Œ ìˆ˜ ì—†ëŠ” í™˜ê²½: {env}"}


@router.post("/api/chat")
async def assistant_chat(request: ChatRequest):
    """â˜… ì´ë¯¸ì§€ URLë„ í•¨ê»˜ ë°˜í™˜"""
    user_msg = request.message.strip()

    CHAT_HISTORY.append({"role": "user", "content": user_msg, "time": datetime.datetime.now().isoformat()})

    response = process_chat(user_msg)

    # responseëŠ” ì´ì œ dict: {"text": ..., "image": ...}
    response_text = response["text"]
    response_image = response.get("image")

    CHAT_HISTORY.append({
        "role": "assistant",
        "content": response_text,
        "image": response_image,
        "time": datetime.datetime.now().isoformat()
    })
    save_history()

    return {
        "success": True,
        "response": response_text,
        "image": response_image  # â˜… ì´ë¯¸ì§€ URL (ì—†ìœ¼ë©´ None)
    }


# â˜… ìŠ¤í¬ë¦°ìƒ· ì´ë¯¸ì§€ ì„œë¹™ ì—”ë“œí¬ì¸íŠ¸
@router.get("/api/screenshot/{filename}")
async def serve_screenshot(filename: str):
    """ìŠ¤í¬ë¦°ìƒ· ì´ë¯¸ì§€ íŒŒì¼ ì„œë¹™"""
    # ë³´ì•ˆ: íŒŒì¼ëª…ì— ê²½ë¡œ ì¡°ì‘ ë°©ì§€
    safe_filename = os.path.basename(filename)
    filepath = os.path.join(SCREENSHOT_DIR, safe_filename)

    if not os.path.exists(filepath):
        return {"error": "ìŠ¤í¬ë¦°ìƒ· íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

    return FileResponse(filepath, media_type="image/png")


# â˜… ìµœê·¼ ìŠ¤í¬ë¦°ìƒ· ëª©ë¡
@router.get("/api/screenshots")
async def list_screenshots():
    """ìµœê·¼ ìŠ¤í¬ë¦°ìƒ· ëª©ë¡"""
    screenshots = []
    if os.path.exists(SCREENSHOT_DIR):
        for f in sorted(os.listdir(SCREENSHOT_DIR), reverse=True)[:20]:
            if f.endswith('.png'):
                filepath = os.path.join(SCREENSHOT_DIR, f)
                screenshots.append({
                    "filename": f,
                    "url": f"/assistant/api/screenshot/{f}",
                    "size": f"{os.path.getsize(filepath) / 1024:.1f}KB",
                    "time": datetime.datetime.fromtimestamp(
                        os.path.getmtime(filepath)
                    ).strftime("%Y-%m-%d %H:%M:%S")
                })
    return {"screenshots": screenshots}


@router.post("/api/search")
async def assistant_search(request: SearchRequest):
    if request.file_content:
        results = search_content(request.keyword, request.path)
    else:
        results = search_files(request.keyword, request.path)

    return {"success": True, "results": results, "count": len(results)}


@router.get("/api/drives")
async def assistant_drives():
    drives = []
    for p in psutil.disk_partitions():
        drives.append({"device": p.device, "mountpoint": p.mountpoint})
    return {"success": True, "drives": drives}


@router.get("/api/history")
async def assistant_get_history():
    return {"history": CHAT_HISTORY[-50:]}


@router.delete("/api/history")
async def assistant_clear_history():
    global CHAT_HISTORY
    CHAT_HISTORY = []
    save_history()
    return {"success": True}


# ë‹¨ë… ì‹¤í–‰ìš© (í…ŒìŠ¤íŠ¸)
if __name__ == "__main__":
    import uvicorn
    app.include_router(router)

    @app.on_event("startup")
    async def standalone_startup():
        init_assistant()

    uvicorn.run(app, host="0.0.0.0", port=8002)