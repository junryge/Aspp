#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PC ê°œì¸ë¹„ì„œ AI (Moltbot ìŠ¤íƒ€ì¼ Tool Calling)
- LLMì´ JSONìœ¼ë¡œ ë„êµ¬ í˜¸ì¶œ
- íŒŒì¼ ê²€ìƒ‰, ë‚´ìš© ê²€ìƒ‰
- ì‹œìŠ¤í…œ ì •ë³´
- í”„ë¡œê·¸ë¨ ì‹¤í–‰
- API ë° GGUF ëª¨ë‘ ì§€ì›
"""

import os
import re
import json
import subprocess
import platform
import psutil
import datetime
import webbrowser
import fnmatch
import requests
import pandas as pd
from typing import Optional, List
from fastapi import FastAPI, APIRouter
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("PCAssistant")

# APIRouterë¡œ ë³€ê²½ (ë©”ì¸ ì„œë²„ì—ì„œ include ê°€ëŠ¥)
router = APIRouter(prefix="/assistant", tags=["assistant"])

# ë‹¨ë… ì‹¤í–‰ìš© ì•± (í…ŒìŠ¤íŠ¸ìš©)
app = FastAPI(title="ì§í‰ ëª°íŠ¸ë´‡ ê°ë§ˆë²„ì „ VER 0.1")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========================================
# Global Configuration
# ========================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
GGUF_MODEL_PATH = os.path.join(BASE_DIR, "Qwen3-14B-Q4_K_M.gguf")
LOCAL_LLM = None
CHAT_HISTORY = []
HISTORY_FILE = os.path.join(BASE_DIR, "chat_history.json")

# LLM ëª¨ë“œ ì„¤ì • (api ë˜ëŠ” local)
LLM_MODE = "local"  # ê¸°ë³¸ê°’: local
API_TOKEN = None

# API ì„¤ì •
ENV_CONFIG = {
    "dev": {
        "url": "http://dev.assistant.llm.skhynix.com/v1/chat/completions",
        "model": "Qwen3-Coder-30B-A3B-Instruct",
        "name": "DEV(30B)"
    },
    "prod": {
        "url": "http://summary.llm.skhynix.com/v1/chat/completions",
        "model": "Qwen3-Next-80B-A3B-Instruct",
        "name": "PROD(80B)"
    },
    "common": {
        "url": "http://common.llm.skhynix.com/v1/chat/completions",
        "model": "gpt-oss-20b",
        "name": "COMMON(20B)"
    }
}
CURRENT_ENV = "common"
API_URL = ENV_CONFIG["common"]["url"]
API_MODEL = ENV_CONFIG["common"]["model"]

# ========================================
# System Prompt (Tool Calling ë°©ì‹)
# ========================================
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ 'ì§í‰ ëª°íŠ¸ë´‡ ê°ë§ˆë²„ì „ VER 0.1'ì´ë¼ëŠ” PC ê°œì¸ë¹„ì„œ AIì…ë‹ˆë‹¤.

[ì¤‘ìš” ê·œì¹™]
1. PC ì‘ì—…(íŒŒì¼ê²€ìƒ‰, ì‹œìŠ¤í…œì •ë³´ ë“±)ì´ í•„ìš”í•˜ë©´ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.
2. ë„êµ¬ë¥¼ í˜¸ì¶œí•  ë•ŒëŠ” JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ JSON ì•ë’¤ì— ë¶™ì´ì§€ ë§ˆì„¸ìš”.
3. keywordì—ëŠ” í™•ì¥ì(.gguf)ë‚˜ ì™€ì¼ë“œì¹´ë“œ(*) ì—†ì´ ìˆœìˆ˜ í‚¤ì›Œë“œë§Œ ë„£ìœ¼ì„¸ìš”. ì˜ˆ: "gguf", "txt", "python"
4. ë°˜ë“œì‹œ ìˆœìˆ˜ JSON ê°ì²´ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ```json ì½”ë“œë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì§€ ë§ˆì„¸ìš”.

[ë„êµ¬ ëª©ë¡]
- íŒŒì¼ê²€ìƒ‰: {"tool": "search_files", "keyword": "gguf", "path": "F:/"}
- ë‚´ìš©ê²€ìƒ‰: {"tool": "search_content", "keyword": "hello", "path": "C:/"}
- ì‹œìŠ¤í…œì •ë³´: {"tool": "get_system_info"}
- í´ë”ë³´ê¸°: {"tool": "list_directory", "path": "C:/Users"}
- íŒŒì¼ì½ê¸°: {"tool": "read_file", "path": "C:/test.txt"}
- í”„ë¡œê·¸ë¨ì‹¤í–‰: {"tool": "run_program", "program": "notepad"}
- í”„ë¡œê·¸ë¨ì¢…ë£Œ: {"tool": "kill_program", "name": "notepad"}
- ì›¹ì—´ê¸°: {"tool": "open_web", "url": "https://google.com"}
- êµ¬ê¸€ê²€ìƒ‰: {"tool": "google_search", "query": "ë‚ ì”¨"}
- í˜„ì¬ì‹œê°„: {"tool": "get_time"}
- ìŠ¤í¬ë¦°ìƒ·: {"tool": "screenshot"}
- ë°ì´í„°ë¶„ì„: {"tool": "analyze_data", "path": "C:/data.csv"}

ì¼ë°˜ ëŒ€í™”(ì¸ì‚¬, ì¡ë‹´, ì½”ë”© ì§ˆë¬¸ ë“±)ëŠ” ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì§€ ë§ê³  í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”."""


# ========================================
# Tool Functions
# ========================================
def load_local_model():
    global LOCAL_LLM
    try:
        from llama_cpp import Llama

        if not os.path.exists(GGUF_MODEL_PATH):
            logger.error(f"GGUF íŒŒì¼ ì—†ìŒ: {GGUF_MODEL_PATH}")
            return None

        logger.info("GGUF ëª¨ë¸ ë¡œë”© ì¤‘...")
        llm = Llama(
            model_path=GGUF_MODEL_PATH,
            n_ctx=8192,
            n_threads=8,
            n_gpu_layers=50,
            n_batch=512,
            verbose=False
        )
        logger.info("GGUF ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        return llm
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


# â˜… ìˆ˜ì • 1: í† í° ë¡œë“œ ê²½ë¡œ í†µì¼ (token.txt í¬í•¨)
def load_api_token():
    """API í† í° ë¡œë“œ - ë©”ì¸ ì„œë²„ì™€ ë™ì¼í•œ ê²½ë¡œ ê²€ìƒ‰"""
    global API_TOKEN
    paths = [
        os.path.join(BASE_DIR, "token.txt"),       # â˜… ë©”ì¸ ì„œë²„ì™€ ë™ì¼
        os.path.join(BASE_DIR, "api_token.txt"),    # ê¸°ì¡´ í˜¸í™˜
        "token.txt",
        "../token.txt",
        os.path.expanduser("~/token.txt")
    ]
    for p in paths:
        if os.path.exists(p):
            try:
                with open(p, 'r', encoding='utf-8') as f:
                    API_TOKEN = f.read().strip()
                if API_TOKEN and "REPLACE" not in API_TOKEN:
                    logger.info(f"âœ… API í† í° ë¡œë“œ: {p}")
                    return True
            except Exception as e:
                logger.error(f"âŒ í† í° ë¡œë“œ ì‹¤íŒ¨: {e}")
    logger.warning("âš ï¸ API í† í° íŒŒì¼ ì—†ìŒ")
    return False


def call_local_llm(prompt: str, system_prompt: str = "") -> dict:
    """ë¡œì»¬ GGUF ëª¨ë¸ í˜¸ì¶œ"""
    global LOCAL_LLM

    if LOCAL_LLM is None:
        return {"success": False, "error": "ë¡œì»¬ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}

    full_prompt = f"""<|im_start|>system
{system_prompt}<|im_end|>
<|im_start|>user
{prompt}<|im_end|>
<|im_start|>assistant
"""

    try:
        output = LOCAL_LLM(
            full_prompt,
            max_tokens=4096,
            temperature=0.3,
            stop=["<|im_end|>", "<|im_start|>"],
            echo=False
        )
        content = output["choices"][0]["text"].strip()
        content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL).strip()
        return {"success": True, "content": content}
    except Exception as e:
        return {"success": False, "error": str(e)}


def call_api_llm(prompt: str, system_prompt: str = "") -> dict:
    """API LLM í˜¸ì¶œ"""
    global API_TOKEN

    if not API_TOKEN:
        return {"success": False, "error": "API í† í° ì—†ìŒ"}

    headers = {
        "Authorization": f"Bearer {API_TOKEN}",
        "Content-Type": "application/json"
    }

    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})

    data = {
        "model": API_MODEL,
        "messages": messages,
        "max_tokens": 4096,
        "temperature": 0.3
    }

    try:
        response = requests.post(API_URL, headers=headers, json=data, timeout=300)

        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL).strip()
            return {"success": True, "content": content}
        else:
            return {"success": False, "error": f"API ì˜¤ë¥˜: {response.status_code} - {response.text[:200]}"}
    except Exception as e:
        return {"success": False, "error": str(e)}


def call_llm(prompt: str, system_prompt: str = "") -> dict:
    """LLM_MODEì— ë”°ë¼ API ë˜ëŠ” ë¡œì»¬ ëª¨ë¸ í˜¸ì¶œ"""
    if LLM_MODE == "local":
        return call_local_llm(prompt, system_prompt)
    else:
        return call_api_llm(prompt, system_prompt)


def search_files(keyword: str, path: str = "C:/", limit: int = 50) -> List[dict]:
    """íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰"""
    results = []
    logger.info(f"íŒŒì¼ ê²€ìƒ‰: '{keyword}' in '{path}'")

    try:
        for root, dirs, files in os.walk(path):
            for name in files + dirs:
                if keyword.lower() in name.lower():
                    full_path = os.path.join(root, name)
                    is_dir = os.path.isdir(full_path)
                    try:
                        size = os.path.getsize(full_path) if not is_dir else 0
                        size_str = f"{size / (1024**3):.2f}GB" if size > 1024**3 else f"{size / (1024**2):.1f}MB" if size > 1024**2 else f"{size}B"
                    except:
                        size_str = "?"

                    results.append({
                        "name": name,
                        "path": full_path,
                        "type": "í´ë”" if is_dir else "íŒŒì¼",
                        "size": size_str
                    })

                    if len(results) >= limit:
                        return results
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

    return results


def search_content(keyword: str, path: str = "C:/", limit: int = 30) -> List[dict]:
    """íŒŒì¼ ë‚´ìš©ìœ¼ë¡œ ê²€ìƒ‰"""
    results = []
    extensions = ['.txt', '.py', '.md', '.json', '.html', '.css', '.js', '.csv', '.log']

    logger.info(f"ë‚´ìš© ê²€ìƒ‰: '{keyword}' in '{path}'")

    try:
        for root, dirs, files in os.walk(path):
            for name in files:
                ext = os.path.splitext(name)[1].lower()
                if ext in extensions:
                    full_path = os.path.join(root, name)
                    try:
                        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read(50000)  # 50KBê¹Œì§€ë§Œ
                            if keyword.lower() in content.lower():
                                idx = content.lower().find(keyword.lower())
                                snippet = content[max(0, idx-30):min(len(content), idx+70)].replace('\n', ' ')

                                results.append({
                                    "name": name,
                                    "path": full_path,
                                    "snippet": f"...{snippet}..."
                                })

                                if len(results) >= limit:
                                    return results
                    except:
                        continue
    except Exception as e:
        logger.error(f"ë‚´ìš© ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

    return results


def get_system_info() -> dict:
    """ì‹œìŠ¤í…œ ì •ë³´"""
    drives = []
    for p in psutil.disk_partitions():
        try:
            usage = psutil.disk_usage(p.mountpoint)
            drives.append({
                "drive": p.device,
                "total": f"{usage.total / (1024**3):.1f}GB",
                "used": f"{usage.percent}%"
            })
        except:
            pass

    return {
        "os": f"{platform.system()} {platform.release()}",
        "cpu": f"{psutil.cpu_count()}ì½”ì–´, {psutil.cpu_percent()}%",
        "memory": f"{psutil.virtual_memory().total // (1024**3)}GB, {psutil.virtual_memory().percent}%",
        "drives": drives
    }


def list_directory(path: str) -> List[dict]:
    """í´ë” ë‚´ìš©"""
    items = []
    try:
        for name in os.listdir(path)[:50]:
            full_path = os.path.join(path, name)
            is_dir = os.path.isdir(full_path)
            try:
                size = os.path.getsize(full_path) if not is_dir else 0
                modified = datetime.datetime.fromtimestamp(os.path.getmtime(full_path)).strftime("%Y-%m-%d %H:%M")
            except:
                size = 0
                modified = "?"

            items.append({
                "name": name,
                "type": "í´ë”" if is_dir else "íŒŒì¼",
                "size": f"{size:,}" if not is_dir else "-",
                "modified": modified
            })
    except Exception as e:
        return [{"error": str(e)}]

    return items


def read_file(path: str, max_chars: int = 5000) -> str:
    """íŒŒì¼ ì½ê¸°"""
    try:
        with open(path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read(max_chars)
            if len(content) == max_chars:
                content += "\n... (íŒŒì¼ì´ ë„ˆë¬´ ì»¤ì„œ ì¼ë¶€ë§Œ í‘œì‹œ)"
            return content
    except Exception as e:
        return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}"


def run_program(program: str) -> str:
    """í”„ë¡œê·¸ë¨ ì‹¤í–‰"""
    try:
        subprocess.Popen(program, shell=True)
        return f"'{program}' ì‹¤í–‰ë¨"
    except Exception as e:
        return f"ì‹¤í–‰ ì˜¤ë¥˜: {e}"


def kill_program(name: str) -> str:
    """í”„ë¡œê·¸ë¨ ì¢…ë£Œ"""
    try:
        killed = 0
        for proc in psutil.process_iter(['name']):
            if name.lower() in proc.info['name'].lower():
                proc.kill()
                killed += 1
        return f"{killed}ê°œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë¨"
    except Exception as e:
        return f"ì¢…ë£Œ ì˜¤ë¥˜: {e}"


def open_web(url: str) -> str:
    """ì›¹ ì—´ê¸°"""
    if not url.startswith('http'):
        url = 'https://' + url
    webbrowser.open(url)
    return f"'{url}' ì—´ë¦¼"


def google_search(query: str) -> str:
    """êµ¬ê¸€ ê²€ìƒ‰"""
    url = f"https://www.google.com/search?q={query}"
    webbrowser.open(url)
    return f"'{query}' ê²€ìƒ‰ ì¤‘..."


def get_time() -> str:
    """í˜„ì¬ ì‹œê°„"""
    now = datetime.datetime.now()
    return f"{now.strftime('%Yë…„ %mì›” %dì¼ %A %Hì‹œ %Më¶„ %Sì´ˆ')}"


def take_screenshot() -> str:
    """ìŠ¤í¬ë¦°ìƒ·"""
    try:
        from PIL import ImageGrab
        path = os.path.join(BASE_DIR, f"screenshot_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
        img = ImageGrab.grab()
        img.save(path)
        return f"ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {path}"
    except Exception as e:
        return f"ìŠ¤í¬ë¦°ìƒ· ì˜¤ë¥˜: {e}"


def analyze_data(path: str) -> str:
    """ë°ì´í„° ë¶„ì„"""
    try:
        ext = os.path.splitext(path)[1].lower()

        if ext == '.csv':
            df = pd.read_csv(path, encoding='utf-8', errors='ignore')
        elif ext in ['.xlsx', '.xls']:
            df = pd.read_excel(path)
        else:
            return f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {ext}"

        result = []
        result.append(f"íŒŒì¼: {os.path.basename(path)}")
        result.append(f"í¬ê¸°: {len(df):,}í–‰ x {len(df.columns)}ì—´")
        result.append(f"ì»¬ëŸ¼: {', '.join(df.columns.tolist()[:20])}")

        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            stats = df[numeric_cols].describe().to_string()
            result.append(f"í†µê³„:\n{stats}")

        result.append(f"ìƒ˜í”Œ:\n{df.head(5).to_string()}")

        return "\n".join(result)
    except Exception as e:
        return f"ë¶„ì„ ì˜¤ë¥˜: {e}"


# Tool ì‹¤í–‰ê¸°
def execute_tool(tool_data: dict) -> str:
    """ë„êµ¬ ì‹¤í–‰"""
    tool_name = tool_data.get("tool")

    if tool_name == "search_files":
        results = search_files(tool_data.get("keyword", ""), tool_data.get("path", "C:/"))
        return json.dumps(results[:20], ensure_ascii=False, indent=2)

    elif tool_name == "search_content":
        results = search_content(tool_data.get("keyword", ""), tool_data.get("path", "C:/"))
        return json.dumps(results[:10], ensure_ascii=False, indent=2)

    elif tool_name == "get_system_info":
        return json.dumps(get_system_info(), ensure_ascii=False, indent=2)

    elif tool_name == "list_directory":
        results = list_directory(tool_data.get("path", "C:/"))
        return json.dumps(results, ensure_ascii=False, indent=2)

    elif tool_name == "read_file":
        return read_file(tool_data.get("path", ""))

    elif tool_name == "run_program":
        return run_program(tool_data.get("program", ""))

    elif tool_name == "kill_program":
        return kill_program(tool_data.get("name", ""))

    elif tool_name == "open_web":
        return open_web(tool_data.get("url", ""))

    elif tool_name == "google_search":
        return google_search(tool_data.get("query", ""))

    elif tool_name == "get_time":
        return get_time()

    elif tool_name == "screenshot":
        return take_screenshot()

    elif tool_name == "analyze_data":
        return analyze_data(tool_data.get("path", ""))

    return "ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬"


# ========================================
# â˜… ìˆ˜ì • 2: JSON ê°ì§€ ê°•í™”
# ========================================
def extract_tool_json(text: str) -> Optional[dict]:
    """LLM ì‘ë‹µì—ì„œ ë„êµ¬ í˜¸ì¶œ JSON ì¶”ì¶œ - ë‹¤ì–‘í•œ í˜•ì‹ ëŒ€ì‘"""
    
    # íŒ¨í„´ 1: ```json ì½”ë“œë¸”ë¡
    match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
    if match:
        try:
            data = json.loads(match.group(1))
            if "tool" in data:
                logger.info(f"âœ… JSON ê°ì§€ (ì½”ë“œë¸”ë¡): {data.get('tool')}")
                return data
        except json.JSONDecodeError:
            pass
    
    # íŒ¨í„´ 2: "tool" í‚¤ê°€ í¬í•¨ëœ JSON ê°ì²´ (ì¤‘ì²© ì—†ëŠ” ë‹¨ìˆœ ê°ì²´)
    match = re.search(r'(\{[^{}]*"tool"\s*:\s*"[^"]+?"[^{}]*\})', text, re.DOTALL)
    if match:
        try:
            data = json.loads(match.group(1))
            if "tool" in data:
                logger.info(f"âœ… JSON ê°ì§€ (ì¸ë¼ì¸): {data.get('tool')}")
                return data
        except json.JSONDecodeError:
            pass
    
    # íŒ¨í„´ 3: í…ìŠ¤íŠ¸ ì „ì²´ê°€ JSONì¸ ê²½ìš° (ì•ë’¤ ê³µë°±/ì¤„ë°”ê¿ˆë§Œ ìˆëŠ” ê²½ìš°)
    stripped = text.strip()
    if stripped.startswith('{') and stripped.endswith('}'):
        try:
            data = json.loads(stripped)
            if "tool" in data:
                logger.info(f"âœ… JSON ê°ì§€ (ì „ì²´): {data.get('tool')}")
                return data
        except json.JSONDecodeError:
            pass
    
    # íŒ¨í„´ 4: í…ìŠ¤íŠ¸ ì•ˆì— ì¤„ë°”ê¿ˆì´ í¬í•¨ëœ JSON (ë©€í‹°ë¼ì¸)
    match = re.search(r'\{\s*"tool"\s*:.*?\}', text, re.DOTALL)
    if match:
        try:
            # ì¤„ë°”ê¿ˆ, íƒ­ ì •ë¦¬
            json_str = match.group(0)
            json_str = re.sub(r'[\n\r\t]', ' ', json_str)
            json_str = re.sub(r'\s+', ' ', json_str)
            data = json.loads(json_str)
            if "tool" in data:
                logger.info(f"âœ… JSON ê°ì§€ (ë©€í‹°ë¼ì¸): {data.get('tool')}")
                return data
        except json.JSONDecodeError:
            pass
    
    return None


# ========================================
# Chat Processing (â˜… ìˆ˜ì •ëœ ë²„ì „)
# ========================================
def process_chat(user_message: str) -> str:
    """ì±„íŒ… ì²˜ë¦¬ (Tool Calling ë°©ì‹)"""
    global LOCAL_LLM, LLM_MODE

    # ëª¨ë¸ ì²´í¬
    if LLM_MODE == "local" and LOCAL_LLM is None:
        return "âŒ ë¡œì»¬ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API ëª¨ë“œë¡œ ì „í™˜í•´ì£¼ì„¸ìš”."
    if LLM_MODE != "local" and not API_TOKEN:
        return "âŒ API í† í°ì´ ì—†ìŠµë‹ˆë‹¤. token.txt íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

    # 1ì°¨: LLM í˜¸ì¶œ (ë„êµ¬ í˜¸ì¶œ ì—¬ë¶€ íŒë‹¨)
    try:
        result = call_llm(user_message, SYSTEM_PROMPT)
        if not result["success"]:
            return f"âŒ LLM ì˜¤ë¥˜: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"

        text = result["content"]
        logger.info(f"ğŸ“ LLM ì‘ë‹µ (ì²« 200ì): {text[:200]}")

        # â˜… ê°•í™”ëœ JSON ë„êµ¬ í˜¸ì¶œ ê°ì§€
        tool_data = extract_tool_json(text)

        if tool_data:
            try:
                # keywordì—ì„œ ì™€ì¼ë“œì¹´ë“œ/í™•ì¥ì ì œê±°
                if "keyword" in tool_data:
                    kw = tool_data["keyword"]
                    kw = kw.replace("*", "").replace(".", "").strip()
                    # ë¹ˆ í‚¤ì›Œë“œ ë°©ì§€
                    if not kw:
                        return "âŒ ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”."
                    tool_data["keyword"] = kw

                logger.info(f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: {tool_data}")
                tool_result = execute_tool(tool_data)
                logger.info(f"ğŸ“Š ë„êµ¬ ê²°ê³¼ (ì²« 300ì): {tool_result[:300]}")

                # 2ì°¨: ê²°ê³¼ í•´ì„ - ìì—°ì–´ë¡œ ë³€í™˜
                follow_up_prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: {user_message}

ë„êµ¬ ì‹¤í–‰ ê²°ê³¼:
{tool_result}

ìœ„ ê²°ê³¼ë¥¼ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.
- JSONì´ë‚˜ ì›ë³¸ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ë³´ì—¬ì£¼ì§€ ë§ê³  í•µì‹¬ë§Œ ì •ë¦¬
- ë„êµ¬ë¥¼ ë‹¤ì‹œ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš” (JSON ì¶œë ¥ ê¸ˆì§€)
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬"""

                follow_up_system = """ë‹¹ì‹ ì€ PC ê°œì¸ë¹„ì„œì…ë‹ˆë‹¤. 
ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°›ì•„ì„œ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ í•œêµ­ì–´ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
ì ˆëŒ€ JSONì„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”. ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”.
ìì—°ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."""

                result2 = call_llm(follow_up_prompt, follow_up_system)
                if result2["success"]:
                    response = result2["content"]
                    # 2ì°¨ ì‘ë‹µì—ì„œë„ í˜¹ì‹œ JSONì´ ë‚˜ì˜¤ë©´ í•„í„°ë§
                    if extract_tool_json(response):
                        logger.warning("âš ï¸ 2ì°¨ ì‘ë‹µì—ì„œë„ JSON ê°ì§€ - ë„êµ¬ ê²°ê³¼ ì§ì ‘ í¬ë§·íŒ…")
                        return format_tool_result_fallback(tool_data, tool_result)
                    return response
                else:
                    # 2ì°¨ í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì§ì ‘ í¬ë§·íŒ…
                    logger.warning(f"âš ï¸ 2ì°¨ LLM ì‹¤íŒ¨: {result2.get('error')}")
                    return format_tool_result_fallback(tool_data, tool_result)

            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                return "âŒ ëª…ë ¹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

        # ë„êµ¬ í˜¸ì¶œ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì‘ë‹µ (ì¼ë°˜ ëŒ€í™”)
        return text

    except Exception as e:
        logger.error(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return f"âŒ ì˜¤ë¥˜: {e}"


def format_tool_result_fallback(tool_data: dict, tool_result: str) -> str:
    """2ì°¨ LLM ì‹¤íŒ¨ ì‹œ ë„êµ¬ ê²°ê³¼ë¥¼ ì§ì ‘ í¬ë§·íŒ…"""
    tool_name = tool_data.get("tool", "")
    
    try:
        if tool_name == "get_system_info":
            info = json.loads(tool_result)
            lines = [
                "## ğŸ’» ì‹œìŠ¤í…œ ì •ë³´",
                f"- **OS**: {info.get('os', '?')}",
                f"- **CPU**: {info.get('cpu', '?')}",
                f"- **ë©”ëª¨ë¦¬**: {info.get('memory', '?')}",
            ]
            for d in info.get('drives', []):
                lines.append(f"- **{d['drive']}**: {d['total']} (ì‚¬ìš©ë¥  {d['used']})")
            return "\n".join(lines)
        
        elif tool_name == "get_time":
            return f"ğŸ• í˜„ì¬ ì‹œê°„: {tool_result}"
        
        elif tool_name in ["search_files", "search_content"]:
            results = json.loads(tool_result)
            if not results:
                return f"ğŸ” '{tool_data.get('keyword', '')}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            lines = [f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: **{len(results)}ê°œ** ë°œê²¬\n"]
            for r in results[:10]:
                if "snippet" in r:
                    lines.append(f"- ğŸ“„ `{r['name']}` â†’ {r['snippet']}")
                else:
                    lines.append(f"- {'ğŸ“' if r.get('type') == 'í´ë”' else 'ğŸ“„'} `{r['name']}` ({r.get('size', '?')}) â†’ `{r['path']}`")
            if len(results) > 10:
                lines.append(f"\n... ì™¸ {len(results) - 10}ê°œ ë” ìˆìŒ")
            return "\n".join(lines)
        
        elif tool_name == "list_directory":
            items = json.loads(tool_result)
            if not items or (len(items) == 1 and "error" in items[0]):
                return f"âŒ í´ë”ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {items[0].get('error', '?') if items else '?'}"
            lines = [f"ğŸ“‚ `{tool_data.get('path', '')}` ë‚´ìš©: **{len(items)}ê°œ**\n"]
            for item in items[:20]:
                icon = "ğŸ“" if item.get("type") == "í´ë”" else "ğŸ“„"
                lines.append(f"- {icon} `{item['name']}` ({item.get('size', '-')}) - {item.get('modified', '?')}")
            return "\n".join(lines)
        
        elif tool_name == "read_file":
            return f"ğŸ“„ **íŒŒì¼ ë‚´ìš©:**\n```\n{tool_result}\n```"
        
        elif tool_name in ["run_program", "kill_program", "open_web", "google_search", "screenshot"]:
            return f"âœ… {tool_result}"
        
        elif tool_name == "analyze_data":
            return f"ğŸ“Š **ë°ì´í„° ë¶„ì„ ê²°ê³¼:**\n```\n{tool_result}\n```"
        
    except Exception as e:
        logger.error(f"í¬ë§·íŒ… ì˜¤ë¥˜: {e}")
    
    # ìµœí›„ì˜ ìˆ˜ë‹¨: ê²°ê³¼ë¥¼ ì½”ë“œë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì„œ ë°˜í™˜
    return f"ğŸ“‹ **ê²°ê³¼:**\n```\n{tool_result}\n```"


# ========================================
# ëŒ€í™” ê¸°ë¡
# ========================================
def save_history():
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(CHAT_HISTORY[-100:], f, ensure_ascii=False, indent=2)
    except:
        pass

def load_history():
    global CHAT_HISTORY
    try:
        if os.path.exists(HISTORY_FILE):
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                CHAT_HISTORY = json.load(f)
    except:
        CHAT_HISTORY = []


# ========================================
# API Models
# ========================================
class ChatRequest(BaseModel):
    message: str

class SearchRequest(BaseModel):
    keyword: str
    path: str = "C:/"
    file_content: bool = False

class EnvRequest(BaseModel):
    env: str  # "local", "dev", "prod", "common"


# ========================================
# API Endpoints
# ========================================
# ì´ˆê¸°í™” í•¨ìˆ˜ (ë©”ì¸ ì„œë²„ì—ì„œ í˜¸ì¶œ)
def init_assistant():
    global LOCAL_LLM, LLM_MODE
    load_history()
    # â˜… í† í° ë¨¼ì € ì‹œë„ â†’ API ëª¨ë“œ ìš°ì„ 
    if load_api_token():
        LLM_MODE = "api"
        logger.info("âœ… ë¹„ì„œ: API ëª¨ë“œë¡œ ì‹œì‘")
    else:
        LOCAL_LLM = load_local_model()
        if LOCAL_LLM:
            LLM_MODE = "local"
            logger.info("âœ… ë¹„ì„œ: LOCAL ëª¨ë“œë¡œ ì‹œì‘")
        else:
            logger.warning("âš ï¸ ë¹„ì„œ: ëª¨ë¸ ì—†ìŒ (API í† í°ë„ ì—†ê³  ë¡œì»¬ ëª¨ë¸ë„ ì—†ìŒ)")

# Router ì—”ë“œí¬ì¸íŠ¸ë“¤ (ë©”ì¸ ì„œë²„ì— í†µí•©ë¨)
@router.get("/")
async def assistant_home():
    return FileResponse(os.path.join(BASE_DIR, "assistant_ui.html"))

@router.get("/api/status")
async def assistant_status():
    return {
        "mode": LLM_MODE,
        "env": CURRENT_ENV if LLM_MODE != "local" else "local",
        "model_loaded": LOCAL_LLM is not None if LLM_MODE == "local" else API_TOKEN is not None,
        "model_name": ENV_CONFIG.get(CURRENT_ENV, {}).get("name", "LOCAL") if LLM_MODE != "local" else "Qwen3-14B-GGUF",
        "system": get_system_info(),
        "history_count": len(CHAT_HISTORY)
    }

@router.post("/api/set_env")
async def assistant_set_env(request: EnvRequest):
    global LLM_MODE, LOCAL_LLM, CURRENT_ENV, API_URL, API_MODEL

    env = request.env.lower()

    if env == "local":
        # ë¡œì»¬ ëª¨ë“œë¡œ ì „í™˜
        if LOCAL_LLM is None:
            LOCAL_LLM = load_local_model()
        if LOCAL_LLM:
            LLM_MODE = "local"
            return {"success": True, "env": "local", "name": "LOCAL(14B-GGUF)"}
        else:
            return {"success": False, "error": "ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"}

    elif env in ENV_CONFIG:
        # API ëª¨ë“œë¡œ ì „í™˜
        if not API_TOKEN:
            if not load_api_token():
                return {"success": False, "error": "API í† í° ì—†ìŒ. token.txtë¥¼ í™•ì¸í•˜ì„¸ìš”."}

        LLM_MODE = "api"
        CURRENT_ENV = env
        API_URL = ENV_CONFIG[env]["url"]
        API_MODEL = ENV_CONFIG[env]["model"]
        return {"success": True, "env": env, "name": ENV_CONFIG[env]["name"]}

    return {"success": False, "error": f"ì•Œ ìˆ˜ ì—†ëŠ” í™˜ê²½: {env}"}

@router.post("/api/chat")
async def assistant_chat(request: ChatRequest):
    user_msg = request.message.strip()

    CHAT_HISTORY.append({"role": "user", "content": user_msg, "time": datetime.datetime.now().isoformat()})

    response = process_chat(user_msg)

    CHAT_HISTORY.append({"role": "assistant", "content": response, "time": datetime.datetime.now().isoformat()})
    save_history()

    return {"success": True, "response": response}

@router.post("/api/search")
async def assistant_search(request: SearchRequest):
    if request.file_content:
        results = search_content(request.keyword, request.path)
    else:
        results = search_files(request.keyword, request.path)

    return {"success": True, "results": results, "count": len(results)}

@router.get("/api/drives")
async def assistant_drives():
    drives = []
    for p in psutil.disk_partitions():
        drives.append({"device": p.device, "mountpoint": p.mountpoint})
    return {"success": True, "drives": drives}

@router.get("/api/history")
async def assistant_get_history():
    return {"history": CHAT_HISTORY[-50:]}

@router.delete("/api/history")
async def assistant_clear_history():
    global CHAT_HISTORY
    CHAT_HISTORY = []
    save_history()
    return {"success": True}


# ë‹¨ë… ì‹¤í–‰ìš© (í…ŒìŠ¤íŠ¸)
if __name__ == "__main__":
    import uvicorn
    # ë‹¨ë… ì‹¤í–‰ ì‹œ routerë¥¼ appì— í¬í•¨
    app.include_router(router)

    @app.on_event("startup")
    async def standalone_startup():
        init_assistant()

    uvicorn.run(app, host="0.0.0.0", port=8002)