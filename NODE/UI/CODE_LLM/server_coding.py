#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì½”ë”© ì „ìš© LLM ì„œë²„ (v1.0)
- ì½”ë“œ ìƒì„±, ë¦¬ë·°, ë²„ê·¸ ìˆ˜ì •, ì„¤ëª…, ë¦¬íŒ©í† ë§
- SK Hynix ë‚´ë¶€ API ì—°ë™
"""

import os
import re
import requests
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import Optional
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Coding LLM Tool")

# ========================================
# Global Variables
# ========================================
API_TOKEN = None

# ê°œë°œ/ìš´ì˜ í™˜ê²½ ì„¤ì •
ENV_MODE = "dev"

ENV_CONFIG = {
    "dev": {
        "url": "http://dev.assistant.llm.skhynix.com/v1/chat/completions",
        "model": "Qwen3-Coder-30B-A3B-Instruct",
        "name": "ê°œë°œ(30B)"
    },
    "prod": {
        "url": "http://summary.llm.skhynix.com/v1/chat/completions",
        "model": "Qwen3-Next-80B-A3B-Instruct",
        "name": "ìš´ì˜(80B)"
    }
}

API_URL = ENV_CONFIG["dev"]["url"]
API_MODEL = ENV_CONFIG["dev"]["model"]

# ========================================
# ëª¨ë“œë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# ========================================
SYSTEM_PROMPTS = {
    "generate": """ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œìì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ê³ í’ˆì§ˆ ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ê·œì¹™:
1. ê¹”ë”í•˜ê³  ì½ê¸° ì‰¬ìš´ ì½”ë“œ ì‘ì„±
2. ì ì ˆí•œ ì£¼ì„ í¬í•¨
3. ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨
4. ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ì¤€ìˆ˜
5. ì½”ë“œ ë¸”ë¡ì€ ```ì–¸ì–´ëª… ìœ¼ë¡œ ê°ì‹¸ê¸°

í•œêµ­ì–´ë¡œ ì„¤ëª…í•˜ê³ , ì½”ë“œëŠ” ìš”ì²­ëœ ì–¸ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.""",

    "review": """ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì½”ë“œ ë¦¬ë·°ì–´ì…ë‹ˆë‹¤.
ì œì¶œëœ ì½”ë“œë¥¼ ì² ì €íˆ ê²€í† í•˜ê³  ê°œì„ ì ì„ ì œì•ˆí•©ë‹ˆë‹¤.

ê²€í†  í•­ëª©:
1. ì½”ë“œ í’ˆì§ˆ ë° ê°€ë…ì„±
2. ë²„ê·¸ ë˜ëŠ” ì ì¬ì  ë¬¸ì œ
3. ì„±ëŠ¥ ìµœì í™” ê°€ëŠ¥ì„±
4. ë³´ì•ˆ ì·¨ì•½ì 
5. ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ì¤€ìˆ˜ ì—¬ë¶€
6. í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±

í•œêµ­ì–´ë¡œ ìƒì„¸íˆ í”¼ë“œë°±í•˜ì„¸ìš”. ì ìˆ˜(1-10)ë„ ë§¤ê²¨ì£¼ì„¸ìš”.""",

    "debug": """ë‹¹ì‹ ì€ ë””ë²„ê¹… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë²„ê·¸ë¥¼ ì°¾ì•„ ìˆ˜ì •í•˜ê³  ì›ì¸ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

ì ‘ê·¼ ë°©ì‹:
1. ì—ëŸ¬ ë©”ì‹œì§€ ë¶„ì„
2. ë²„ê·¸ ì›ì¸ íŒŒì•…
3. ìˆ˜ì •ëœ ì½”ë“œ ì œê³µ
4. ì™œ ë²„ê·¸ê°€ ë°œìƒí–ˆëŠ”ì§€ ì„¤ëª…
5. í–¥í›„ ì˜ˆë°©ë²• ì œì•ˆ

í•œêµ­ì–´ë¡œ ì„¤ëª…í•˜ê³ , ìˆ˜ì •ëœ ì½”ë“œë¥¼ ì œê³µí•˜ì„¸ìš”.""",

    "explain": """ë‹¹ì‹ ì€ í”„ë¡œê·¸ë˜ë° êµì‚¬ì…ë‹ˆë‹¤.
ì½”ë“œë¥¼ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…í•©ë‹ˆë‹¤.

ì„¤ëª… í¬í•¨ ì‚¬í•­:
1. ì „ì²´ ì½”ë“œ ëª©ì 
2. ê° ë¶€ë¶„ë³„ ë™ì‘ ì„¤ëª…
3. ì‚¬ìš©ëœ ì•Œê³ ë¦¬ì¦˜/íŒ¨í„´
4. í•µì‹¬ ê°œë… ì„¤ëª…
5. ì‹¤í–‰ íë¦„

ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆê²Œ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.""",

    "refactor": """ë‹¹ì‹ ì€ ë¦¬íŒ©í† ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê¸°ì¡´ ì½”ë“œë¥¼ ë” ì¢‹ì€ ì½”ë“œë¡œ ê°œì„ í•©ë‹ˆë‹¤.

ë¦¬íŒ©í† ë§ ì›ì¹™:
1. ê°€ë…ì„± í–¥ìƒ
2. ì¤‘ë³µ ì œê±° (DRY)
3. ë‹¨ì¼ ì±…ì„ ì›ì¹™
4. ì ì ˆí•œ í•¨ìˆ˜/í´ë˜ìŠ¤ ë¶„ë¦¬
5. ë„¤ì´ë° ê°œì„ 
6. ì„±ëŠ¥ ìµœì í™”

ì›ë³¸ ì½”ë“œì˜ ê¸°ëŠ¥ì€ ìœ ì§€í•˜ë©´ì„œ ê°œì„ ëœ ì½”ë“œë¥¼ ì œê³µí•˜ì„¸ìš”.""",

    "convert": """ë‹¹ì‹ ì€ ë‹¤êµ­ì–´ í”„ë¡œê·¸ë˜ë¨¸ì…ë‹ˆë‹¤.
ì½”ë“œë¥¼ ë‹¤ë¥¸ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ë³€í™˜ ì›ì¹™:
1. ì›ë³¸ ë¡œì§ ì™„ë²½ ìœ ì§€
2. ëŒ€ìƒ ì–¸ì–´ì˜ ê´€ìš©ì  í‘œí˜„ ì‚¬ìš©
3. ëŒ€ìƒ ì–¸ì–´ì˜ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ì¤€ìˆ˜
4. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª…ì‹œ
5. ì–¸ì–´ë³„ ì°¨ì´ì  ì„¤ëª…

í•œêµ­ì–´ë¡œ ì„¤ëª…í•˜ê³ , ë³€í™˜ëœ ì½”ë“œë¥¼ ì œê³µí•˜ì„¸ìš”.""",

    "test": """ë‹¹ì‹ ì€ í…ŒìŠ¤íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì½”ë“œì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ ì‘ì„± ì›ì¹™:
1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
2. ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸
3. ì˜ˆì™¸ ìƒí™© í…ŒìŠ¤íŠ¸
4. ëª¨í‚¹ì´ í•„ìš”í•œ ê²½ìš° ëª…ì‹œ
5. í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê³ ë ¤

ì ì ˆí•œ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.""",

    "general": """ë‹¹ì‹ ì€ ì¹œì ˆí•œ í”„ë¡œê·¸ë˜ë° ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì½”ë”© ê´€ë ¨ ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.

ë‹µë³€ ì›ì¹™:
1. ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
2. ì˜ˆì œ ì½”ë“œ í¬í•¨
3. ê´€ë ¨ ì°¸ê³  ìë£Œ ì–¸ê¸‰
4. ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…

í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""
}

# ========================================
# API Token ê´€ë¦¬
# ========================================
def load_api_token():
    """API í† í° ë¡œë“œ"""
    global API_TOKEN
    
    # ì—¬ëŸ¬ ê²½ë¡œì—ì„œ í† í° íŒŒì¼ ì°¾ê¸°
    token_paths = [
        "token.txt",
        "../token.txt",
        os.path.expanduser("~/token.txt")
    ]
    
    for token_path in token_paths:
        if os.path.exists(token_path):
            try:
                with open(token_path, "r", encoding='utf-8') as f:
                    API_TOKEN = f.read().strip()
                if API_TOKEN and "REPLACE" not in API_TOKEN:
                    logger.info(f"âœ… API í† í° ë¡œë“œ ì™„ë£Œ: {token_path}")
                    return True
                else:
                    logger.warning(f"âš ï¸ í† í° íŒŒì¼ì´ ê¸°ë³¸ê°’: {token_path}")
            except Exception as e:
                logger.error(f"âŒ í† í° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    logger.warning("âš ï¸ í† í° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    return False


# ========================================
# LLM API í˜¸ì¶œ
# ========================================
def call_llm_api(prompt: str, system_prompt: str = "", max_tokens: int = 4000) -> dict:
    """LLM API í˜¸ì¶œ"""
    global API_TOKEN
    
    if not API_TOKEN:
        return {"success": False, "error": "API í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. token.txtë¥¼ í™•ì¸í•˜ì„¸ìš”."}
    
    headers = {
        "Authorization": f"Bearer {API_TOKEN}",
        "Content-Type": "application/json"
    }
    
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})
    
    data = {
        "model": API_MODEL,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": 0.3
    }
    
    for attempt in range(2):
        try:
            logger.info(f"ğŸš€ API í˜¸ì¶œ ì¤‘... (ì‹œë„ {attempt + 1}/2)")
            response = requests.post(API_URL, headers=headers, json=data, timeout=300)
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                # <think> íƒœê·¸ ì œê±° (Qwen3 íŠ¹ì„±)
                content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL)
                content = content.strip()
                
                return {"success": True, "content": content}
            else:
                logger.error(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
                return {"success": False, "error": f"API ì˜¤ë¥˜: {response.status_code}\n{response.text}"}
                
        except requests.exceptions.Timeout:
            logger.warning(f"â±ï¸ API íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1}/2)")
            if attempt == 1:
                return {"success": False, "error": "API ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (5ë¶„). ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”."}
        except Exception as e:
            logger.error(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": f"API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"}
    
    return {"success": False, "error": "API í˜¸ì¶œ ì‹¤íŒ¨"}


# ========================================
# Pydantic Models
# ========================================
class CodingQuery(BaseModel):
    question: str
    mode: str = "general"
    language: str = "python"
    code: Optional[str] = ""


class ConvertRequest(BaseModel):
    code: str
    from_lang: str
    to_lang: str


# ========================================
# FastAPI Startup
# ========================================
@app.on_event("startup")
async def startup():
    """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    load_api_token()
    logger.info(f"ğŸš€ ì½”ë”© LLM ì„œë²„ ì‹œì‘! í™˜ê²½: {ENV_MODE}")


# ========================================
# API Endpoints
# ========================================
@app.get("/")
async def home():
    """ë©”ì¸ í˜ì´ì§€"""
    return FileResponse("index_coding.html")


@app.get("/api/status")
async def api_status():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "api_available": API_TOKEN is not None,
        "env": ENV_MODE,
        "model": API_MODEL,
        "env_name": ENV_CONFIG[ENV_MODE]["name"]
    }


@app.post("/api/reload_token")
async def reload_token():
    """í† í° ë¦¬ë¡œë“œ"""
    success = load_api_token()
    return {
        "success": success,
        "message": "í† í° ë¦¬ë¡œë“œ ì™„ë£Œ" if success else "í† í° ë¦¬ë¡œë“œ ì‹¤íŒ¨"
    }


@app.post("/api/set_env")
async def set_env(data: dict):
    """í™˜ê²½ ì „í™˜"""
    global ENV_MODE, API_URL, API_MODEL
    
    new_env = data.get("env", "dev")
    if new_env not in ENV_CONFIG:
        return {"success": False, "message": "ì˜ëª»ëœ í™˜ê²½ì…ë‹ˆë‹¤."}
    
    ENV_MODE = new_env
    API_URL = ENV_CONFIG[new_env]["url"]
    API_MODEL = ENV_CONFIG[new_env]["model"]
    
    logger.info(f"ğŸ”„ í™˜ê²½ ì „í™˜: {new_env} ({API_MODEL})")
    return {
        "success": True,
        "env": ENV_MODE,
        "model": API_MODEL,
        "name": ENV_CONFIG[new_env]["name"]
    }


@app.post("/api/ask")
async def ask(query: CodingQuery):
    """ë©”ì¸ ì§ˆë¬¸ ì²˜ë¦¬"""
    mode = query.mode
    question = query.question.strip()
    code = query.code.strip() if query.code else ""
    language = query.language
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
    system_prompt = SYSTEM_PROMPTS.get(mode, SYSTEM_PROMPTS["general"])
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    if mode == "generate":
        prompt = f"ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” {language} ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:\n\n{question}"
    elif mode in ["review", "debug", "explain", "refactor"]:
        if not code:
            return {"success": False, "answer": "âŒ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!"}
        prompt = f"ë‹¤ìŒ {language} ì½”ë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n```{language}\n{code}\n```\n\n{question if question else ''}"
    elif mode == "test":
        if not code:
            return {"success": False, "answer": "âŒ í…ŒìŠ¤íŠ¸í•  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!"}
        prompt = f"ë‹¤ìŒ {language} ì½”ë“œì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:\n\n```{language}\n{code}\n```\n\n{question if question else ''}"
    else:
        prompt = question
        if code:
            prompt += f"\n\n```{language}\n{code}\n```"
    
    # LLM í˜¸ì¶œ
    result = call_llm_api(prompt, system_prompt)
    
    if result["success"]:
        return {"success": True, "answer": result["content"]}
    else:
        return {"success": False, "answer": f"âŒ {result['error']}"}


@app.post("/api/convert")
async def convert_code(request: ConvertRequest):
    """ì½”ë“œ ì–¸ì–´ ë³€í™˜"""
    system_prompt = SYSTEM_PROMPTS["convert"]
    prompt = f"""ë‹¤ìŒ {request.from_lang} ì½”ë“œë¥¼ {request.to_lang}ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”:

```{request.from_lang}
{request.code}
```

ë³€í™˜ ì‹œ {request.to_lang}ì˜ ê´€ìš©ì ì¸ í‘œí˜„ê³¼ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ë¥¼ ë”°ë¼ì£¼ì„¸ìš”."""
    
    result = call_llm_api(prompt, system_prompt)
    
    if result["success"]:
        return {"success": True, "answer": result["content"]}
    else:
        return {"success": False, "answer": f"âŒ {result['error']}"}


@app.post("/api/quick")
async def quick_action(data: dict):
    """ë¹ ë¥¸ ì‘ì—… (ì£¼ì„ ì¶”ê°€, ë³€ìˆ˜ëª… ê°œì„  ë“±)"""
    action = data.get("action", "")
    code = data.get("code", "")
    language = data.get("language", "python")
    
    if not code:
        return {"success": False, "answer": "âŒ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!"}
    
    action_prompts = {
        "add_comments": "ì´ ì½”ë“œì— í•œêµ­ì–´ ì£¼ì„ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”. ê° í•¨ìˆ˜ì™€ ì¤‘ìš”í•œ ë¡œì§ì— ì„¤ëª…ì„ ë‹¬ì•„ì£¼ì„¸ìš”.",
        "improve_names": "ì´ ì½”ë“œì˜ ë³€ìˆ˜ëª…ê³¼ í•¨ìˆ˜ëª…ì„ ë” ëª…í™•í•˜ê³  ì˜ë¯¸ìˆê²Œ ê°œì„ í•´ì£¼ì„¸ìš”.",
        "optimize": "ì´ ì½”ë“œì˜ ì„±ëŠ¥ì„ ìµœì í™”í•´ì£¼ì„¸ìš”. ë¶ˆí•„ìš”í•œ ì—°ì‚°ì„ ì¤„ì´ê³  íš¨ìœ¨ì ì¸ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.",
        "simplify": "ì´ ì½”ë“œë¥¼ ë” ê°„ê²°í•˜ê³  ì½ê¸° ì‰½ê²Œ ë‹¨ìˆœí™”í•´ì£¼ì„¸ìš”.",
        "type_hints": "ì´ Python ì½”ë“œì— íƒ€ì… íŒíŠ¸ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.",
        "docstring": "ì´ ì½”ë“œì˜ ëª¨ë“  í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ì— docstringì„ ì¶”ê°€í•´ì£¼ì„¸ìš”."
    }
    
    if action not in action_prompts:
        return {"success": False, "answer": "âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—…ì…ë‹ˆë‹¤."}
    
    prompt = f"""{action_prompts[action]}

```{language}
{code}
```"""
    
    result = call_llm_api(prompt, SYSTEM_PROMPTS["refactor"])
    
    if result["success"]:
        return {"success": True, "answer": result["content"]}
    else:
        return {"success": False, "answer": f"âŒ {result['error']}"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8001)