#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LIFTER ë¡œê·¸ ì „ì²˜ë¦¬ ëª¨ë“ˆ V3.0 (R3 ìŠ¤íƒ€ì¼)
- STORAGE-* ë©”ì‹œì§€ ê¸°ë°˜ ë¶„ì„
- ì¸µê°„ ì´ë™ êµ¬ê°„ë³„ ì†Œìš”ì‹œê°„ ì •í™•íˆ ê³„ì‚°
- CARRIERLOC íŒŒì‹±ìœ¼ë¡œ ì •í™•í•œ ì¸µ ì¶”ì¶œ (AI311â†’3F, AI623â†’6F)
- CARRIERLOCATIONCHANGED ì´ë²¤íŠ¸ë¡œ ì¤‘ê°„ ì¸µê¹Œì§€ ì¶”ì 
- RM(ë‚´ë¶€ ì´ë™/í¬ë ˆì¸) ê°ì§€
- HCACK ì½”ë“œ ë¶„ì„
- ë‹¤ì¤‘ ìºë¦¬ì–´ ì§€ì›
- STB ìš©ì–´ í†µì¼
"""

import pandas as pd
import re
from datetime import datetime
from typing import Dict, List, Optional
import logging

logger = logging.getLogger(__name__)

HCACK_MEANINGS = {
    '0': ('ì„±ê³µ', 'ëª…ë ¹ ìˆ˜ë½'),
    '2': ('ê±°ë¶€', 'ë¦¬í”„í„° ë°˜ì†¡ ê±°ì ˆ'),
    '4': ('ì‹œì‘', 'ì‹¤í–‰ ì¤‘'),
    '6': ('ì‹¤íŒ¨', 'ì´ì†¡ ë¶ˆê°€'),
}

THRESHOLDS = {
    'entry_wait': (10, 30, 60),      # ì…êµ¬ ëŒ€ê¸°
    'crane': (15, 30, 60),           # í¬ë ˆì¸ ë™ì‘
    'floor_move': (60, 120, 240),    # ì¸µê°„ ì´ë™: 1ë¶„/2ë¶„/4ë¶„
    'exit_wait': (10, 30, 60),       # ì¶œêµ¬ ëŒ€ê¸°
    'total': (120, 240, 420),        # ì „ì²´: 2ë¶„/4ë¶„/7ë¶„
}


def parse_time_ex(time_str: str) -> Optional[datetime]:
    if pd.isna(time_str):
        return None
    match = re.search(r'\[(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d{3})\]', str(time_str))
    if match:
        try:
            return datetime.strptime(match.group(1), '%Y-%m-%d %H:%M:%S.%f')
        except:
            pass
    return None


def extract_xml_value(text: str, tag: str) -> Optional[str]:
    if pd.isna(text):
        return None
    pattern = rf'<\s*{tag}\s*>\s*([^<]*?)\s*<\s*/\s*{tag}\s*>'
    match = re.search(pattern, str(text), re.IGNORECASE)
    return match.group(1).strip() if match else None


def format_duration(seconds: float) -> str:
    if seconds < 0:
        return "N/A"
    if seconds < 60:
        return f"{seconds:.1f}ì´ˆ"
    mins = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{mins}ë¶„ {secs}ì´ˆ"


def get_status(seconds: float, seg_type: str) -> tuple:
    normal, caution, critical = THRESHOLDS.get(seg_type, (60, 120, 300))
    if seconds <= normal:
        return ("ì •ìƒ", "âœ…")
    elif seconds <= caution:
        return ("ì£¼ì˜", "ğŸŸ¡")
    elif seconds <= critical:
        return ("ê²½ê³ ", "âš ï¸")
    return ("ì§€ì—°", "ğŸ”´")


def get_floor_from_unit(unit_name: str) -> str:
    """ìœ ë‹›ëª…ì—ì„œ ì¸µ ì¶”ì¶œ: _AI323 â†’ 3F, _AO621 â†’ 6F"""
    if not unit_name:
        return ''
    match = re.search(r'_A[IO](\d)', unit_name)
    return f"{match.group(1)}F" if match else ''


def get_floor_from_carrierloc(carrierloc: str) -> str:
    """CARRIERLOCì—ì„œ ì¸µ ì¶”ì¶œ
    ì˜ˆ: 6ABL6022_AI311 â†’ 3F, 6ABL6022_OP623 â†’ 6F, 6ABL6022_AI623_B1 â†’ 6F
    íŒ¨í„´: _AI[ì¸µ][í¬íŠ¸][ë²ˆí˜¸], _AO[ì¸µ][ë²ˆí˜¸], _OP[ì¸µ][ë²ˆí˜¸]
    """
    if not carrierloc:
        return ''
    # RMì€ í¬ë ˆì¸ ë‚´ë¶€ â†’ ì¸µ ëª¨ë¦„
    if carrierloc.endswith('RM'):
        return 'RM'
    # _AI311, _AO623, _OP311 ë“±ì—ì„œ ì²« ìˆ«ìê°€ ì¸µ
    match = re.search(r'_(?:AI|AO|OP)(\d)', carrierloc)
    if match:
        return f"{match.group(1)}F"
    # _AOG6 íŒ¨í„´ (G=Ground? ëª©ì ì§€)
    match = re.search(r'_AOG(\d)', carrierloc)
    if match:
        return f"{match.group(1)}F"
    return ''


def get_location_type(carrierloc: str) -> str:
    """CARRIERLOCì—ì„œ ìœ„ì¹˜ íƒ€ì… íŒë³„"""
    if not carrierloc:
        return ''
    if carrierloc.endswith('RM'):
        return 'í¬ë ˆì¸(RM)'
    if '_AI' in carrierloc:
        if '_B' in carrierloc:
            return 'ì…êµ¬ ë²„í¼'
        return 'ì…êµ¬(AI)'
    if '_AO' in carrierloc:
        return 'ì¶œêµ¬(AO)'
    if '_OP' in carrierloc:
        return 'ì¡°ì‘ìœ„ì¹˜(OP)'
    return ''


def get_fab_info(machine_name: str) -> str:
    if not machine_name:
        return ''
    return 'M14A' if machine_name[0] == '4' else ('M16A' if machine_name[0] == '6' else '')


def analyze_lifter(df: pd.DataFrame) -> Dict:
    result = {
        'carrier_id': None, 'machine_name': None, 'fab': '',
        'source_floor': None, 'dest_floor': None,
        'source_unit': None, 'dest_unit': None,
        'carrier_locations': [],
        'location_changes': [],
        'hcack_events': [],
        'segments': [], 'delays': [],
        'total_duration_sec': 0, 'final_status': 'UNKNOWN',
        'start_time': None, 'end_time': None,
        'direction': '', 'has_rm': False,
        'preprocessed_text': ''
    }

    df = df.copy()
    df['parsed_time'] = df['TIME_EX'].apply(parse_time_ex)
    df = df.dropna(subset=['parsed_time']).sort_values('parsed_time').reset_index(drop=True)

    if df.empty:
        result['preprocessed_text'] = "âŒ ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨"
        return result

    # í•µì‹¬ ì´ë²¤íŠ¸ ì‹œê°„
    times = {
        'entry': None, 'crane_start': None, 'crane_end': None,
        'transfer_start': None, 'transfer_end': None, 'exit': None
    }
    floors = []
    carrier_locs = []
    location_changes = []

    for _, row in df.iterrows():
        msg = str(row.get('MESSAGENAME', ''))
        text = str(row.get('TEXT', ''))
        t = row['parsed_time']

        if not result['carrier_id']:
            c = row.get('CARRIER')
            if pd.notna(c):
                result['carrier_id'] = str(c).strip().strip("'")

        if not result['machine_name']:
            m = row.get('MACHINENAME')
            if pd.notna(m):
                result['machine_name'] = str(m)
                result['fab'] = get_fab_info(str(m))

        # CARRIERLOC ì¶”ì  (XML TEXT ë‚´ë¶€)
        loc = extract_xml_value(text, 'CARRIERLOC')
        if loc and loc.strip():
            if not carrier_locs or carrier_locs[-1]['loc'] != loc:
                floor = get_floor_from_carrierloc(loc)
                loc_type = get_location_type(loc)
                carrier_locs.append({
                    'loc': loc, 'floor': floor, 'type': loc_type,
                    'time': t, 'time_str': t.strftime('%H:%M:%S.%f')[:-3]
                })
                if loc.endswith('RM'):
                    result['has_rm'] = True
                if floor and floor != 'RM' and (not floors or floors[-1] != floor):
                    floors.append(floor)

        # CARRIERLOCATIONCHANGED ì´ë²¤íŠ¸ ì¶”ì 
        if 'LOCATIONCHANGED' in msg:
            loc_changed = extract_xml_value(text, 'CARRIERLOC')
            if loc_changed:
                floor_ch = get_floor_from_carrierloc(loc_changed)
                location_changes.append({
                    'loc': loc_changed, 'floor': floor_ch,
                    'time': t, 'time_str': t.strftime('%H:%M:%S.%f')[:-3],
                    'type': get_location_type(loc_changed)
                })

        # ì¸µ ì¶”ì¶œ (UNITNAME/CURRENTUNITNAME fallback)
        unit = extract_xml_value(text, 'UNITNAME') or extract_xml_value(text, 'CURRENTUNITNAME')
        if unit:
            fl = get_floor_from_unit(unit)
            if fl and (not floors or floors[-1] != fl):
                floors.append(fl)

        # ì´ë²¤íŠ¸ ì¶”ì¶œ
        if 'CARRIERIDREAD' in msg or 'CARRIERWAITIN' in msg:
            if not times['entry']:
                times['entry'] = t
                result['start_time'] = t

        if 'CARRIERTRANSFER' in msg and 'REPLY' not in msg and 'TRANSFERRING' not in msg and 'COMPLETED' not in msg and 'INITIATED' not in msg:
            # SOURCEUNIT/DESTUNIT ì¶”ì¶œ
            src = extract_xml_value(text, 'SOURCEUNIT')
            dst = extract_xml_value(text, 'DESTUNIT')
            if src and not result['source_unit']:
                result['source_unit'] = src
            if dst and not result['dest_unit']:
                result['dest_unit'] = dst

        if 'CARRIERTRANSFERREPLY' in msg:
            # HCACK ì½”ë“œ ë¶„ì„
            hcack = extract_xml_value(text, 'HCACK')
            if not hcack:
                hcack_match = re.search(r"\[HCACK\]\s*'(\d+)'", text)
                if hcack_match:
                    hcack = hcack_match.group(1)
            if hcack:
                meaning = HCACK_MEANINGS.get(hcack, ('ì•Œìˆ˜ì—†ìŒ', ''))
                result['hcack_events'].append({
                    'time': t, 'time_str': t.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3],
                    'hcack': hcack, 'status': meaning[0], 'desc': meaning[1]
                })

        if 'CRANEACTIVE' in msg:
            if not times['crane_start']:
                times['crane_start'] = t

        if 'CRANEIDLE' in msg:
            times['crane_end'] = t

        if 'TRANSFERINITIATED' in msg:
            times['transfer_start'] = t

        if 'TRANSFERCOMPLETED' in msg:
            times['transfer_end'] = t
            result['final_status'] = 'COMPLETED'

        if 'CARRIERREMOVED' in msg or 'CARRIERWAITOUT' in msg:
            times['exit'] = t
            if not result['end_time']:
                result['end_time'] = t

    if not result['end_time'] and times['transfer_end']:
        result['end_time'] = times['transfer_end']

    result['carrier_locations'] = carrier_locs
    result['location_changes'] = location_changes

    # ì¸µ ê²°ì • (CARRIERLOC ê¸°ë°˜ ìš°ì„ , UNITNAME fallback)
    if floors:
        result['source_floor'] = floors[0]
        result['dest_floor'] = floors[-1]
        try:
            src_num = int(floors[0].replace('F', ''))
            dst_num = int(floors[-1].replace('F', ''))
            result['direction'] = 'â¬†ï¸ ìƒìŠ¹' if dst_num > src_num else ('â¬‡ï¸ í•˜ê°•' if dst_num < src_num else '')
        except:
            pass

    if result['start_time'] and result['end_time']:
        result['total_duration_sec'] = (result['end_time'] - result['start_time']).total_seconds()

    # êµ¬ê°„ ìƒì„±
    segments = []
    seg_defs = [
        ('entry', 'crane_start', 'ì…êµ¬ ëŒ€ê¸°', 'entry_wait'),
        ('crane_start', 'crane_end', 'í¬ë ˆì¸ ë™ì‘', 'crane'),
        ('transfer_start', 'transfer_end', 'ì¸µê°„ ì´ë™', 'floor_move'),
        ('transfer_end', 'exit', 'ì¶œêµ¬ ëŒ€ê¸°', 'exit_wait'),
    ]

    for from_key, to_key, name, thresh_key in seg_defs:
        if times.get(from_key) and times.get(to_key):
            sec = (times[to_key] - times[from_key]).total_seconds()
            if sec < 0:
                continue
            status, emoji = get_status(sec, thresh_key)
            seg = {
                'name': name,
                'start_str': times[from_key].strftime('%H:%M:%S.%f')[:-3],
                'end_str': times[to_key].strftime('%H:%M:%S.%f')[:-3],
                'duration_sec': sec, 'duration_str': format_duration(sec),
                'status': status, 'emoji': emoji,
                'is_delay': status in ['ê²½ê³ ', 'ì§€ì—°']
            }
            segments.append(seg)
            if seg['is_delay']:
                causes = {
                    'ì…êµ¬ ëŒ€ê¸°': 'ë‚´ë¶€ ì ìœ ',
                    'í¬ë ˆì¸ ë™ì‘': 'í¬ë ˆì¸ ì˜¤ë¥˜',
                    'ì¸µê°„ ì´ë™': 'ì†ë„ ì €í•˜',
                    'ì¶œêµ¬ ëŒ€ê¸°': 'í¬íŠ¸ ì ìœ '
                }
                result['delays'].append({
                    'segment': name,
                    'duration_str': format_duration(sec),
                    'cause': causes.get(name, 'ì†Œìš”ì‹œê°„ ì´ˆê³¼')
                })

    result['segments'] = segments
    result['preprocessed_text'] = generate_prompt_text(result)
    return result


def analyze_lifter_multi(df: pd.DataFrame) -> Dict:
    """ë‹¤ì¤‘ ìºë¦¬ì–´ ì§€ì›: CARRIER ì»¬ëŸ¼ ê¸°ì¤€ ê·¸ë£¹í•‘ í›„ ê°ê° ë¶„ì„"""
    if 'CARRIER' not in df.columns:
        return analyze_lifter(df)

    carriers = df['CARRIER'].dropna().astype(str).str.strip().str.strip("'")
    unique_carriers = [c for c in carriers.unique() if c and c != 'nan']

    if len(unique_carriers) <= 1:
        return analyze_lifter(df)

    all_results = []
    combined_text_lines = []

    for carrier_id in unique_carriers:
        carrier_df = df[df['CARRIER'].astype(str).str.strip().str.strip("'") == carrier_id]
        if len(carrier_df) < 3:
            continue
        r = analyze_lifter(carrier_df)
        all_results.append(r)
        combined_text_lines.append(r.get('preprocessed_text', ''))

    if not all_results:
        return analyze_lifter(df)

    if len(all_results) == 1:
        return all_results[0]

    combined = {
        'carrier_id': ', '.join(r['carrier_id'] or 'N/A' for r in all_results),
        'machine_name': all_results[0].get('machine_name'),
        'fab': all_results[0].get('fab', ''),
        'source_floor': all_results[0].get('source_floor'),
        'dest_floor': all_results[-1].get('dest_floor'),
        'source_unit': all_results[0].get('source_unit'),
        'dest_unit': all_results[-1].get('dest_unit'),
        'carrier_locations': [],
        'location_changes': [],
        'hcack_events': [],
        'segments': [], 'delays': [],
        'total_duration_sec': sum(r['total_duration_sec'] for r in all_results),
        'final_status': 'COMPLETED' if all(r['final_status'] == 'COMPLETED' for r in all_results) else 'PARTIAL',
        'start_time': all_results[0].get('start_time'),
        'end_time': all_results[-1].get('end_time'),
        'direction': all_results[0].get('direction', ''),
        'has_rm': any(r.get('has_rm') for r in all_results),
        'multi_carrier': True,
        'carrier_results': all_results,
        'preprocessed_text': f"\n{'=' * 60}\nğŸ“¦ ë‹¤ì¤‘ ìºë¦¬ì–´ LIFTER ë¶„ì„ ({len(all_results)}ê±´)\n{'=' * 60}\n\n" + "\n\n".join(combined_text_lines)
    }
    return combined


def generate_prompt_text(analysis: Dict) -> str:
    lines = ["=" * 60, "ğŸ”¼ LIFTER ì´ì†¡ ë¶„ì„ ë¦¬í¬íŠ¸", "=" * 60]

    fab = analysis.get('fab', '')
    lines.append(f"\nğŸ“ ìºë¦¬ì–´: {analysis.get('carrier_id', 'N/A')}")
    if fab:
        lines.append(f"ğŸ­ FAB: {fab} Lifter ({analysis.get('machine_name', 'N/A')})")
    else:
        lines.append(f"ğŸ­ ì¥ë¹„: {analysis.get('machine_name', 'N/A')}")

    src = analysis.get('source_floor', 'N/A')
    dst = analysis.get('dest_floor', 'N/A')
    direction = analysis.get('direction', '')
    lines.append(f"ğŸ“ ì¸µê°„: {src} â†’ {dst} {direction}")

    # í¬íŠ¸ ì •ë³´
    src_unit = analysis.get('source_unit')
    dst_unit = analysis.get('dest_unit')
    if src_unit or dst_unit:
        lines.append(f"ğŸ“ í¬íŠ¸: {src_unit or 'N/A'} â†’ {dst_unit or 'N/A'}")

    total = analysis.get('total_duration_sec', 0)
    lines.append(f"\nâ±ï¸ ì´ ì†Œìš”ì‹œê°„: {format_duration(total)} (ì •ìƒ: 2ë¶„ ì´ë‚´)")
    lines.append(f"ğŸ“Œ ìƒíƒœ: {analysis.get('final_status', 'UNKNOWN')}")
    lines.append(f"{'ğŸ”´ ì§€ì—° ë°œìƒ' if total > 120 else 'âœ… ì •ìƒ ì™„ë£Œ'}")

    if analysis.get('segments'):
        lines.append("\n" + "-" * 60)
        lines.append("### ğŸ•’ êµ¬ê°„ë³„ ì†Œìš”ì‹œê°„")
        lines.append("\n| # | êµ¬ê°„ | ì‹œì‘ | ì¢…ë£Œ | ì†Œìš”ì‹œê°„ | ìƒíƒœ |")
        lines.append("|---|------|------|------|----------|------|")
        for i, s in enumerate(analysis['segments'], 1):
            m = "ğŸ”´ " if s.get('is_delay') else ""
            lines.append(f"| {i} | {m}{s['name']} | {s['start_str']} | {s['end_str']} | {s['duration_str']} | {s['emoji']} {s['status']} |")

    # CARRIERLOC ì´ë™ ê²½ë¡œ (ìƒì„¸)
    if analysis.get('carrier_locations'):
        lines.append("\n### ğŸ“ ìºë¦¬ì–´ ìœ„ì¹˜ ì´ë™ ê²½ë¡œ")
        for cl in analysis['carrier_locations']:
            floor_str = f" ({cl['floor']})" if cl.get('floor') else ""
            type_str = f" [{cl['type']}]" if cl.get('type') else ""
            lines.append(f"  [{cl['time_str']}] {cl['loc']}{floor_str}{type_str}")

    # RM ê°ì§€
    if analysis.get('has_rm'):
        lines.append("\n### ğŸ—ï¸ í¬ë ˆì¸ ë‚´ë¶€ì´ë™(RM) ê°ì§€ë¨")

    # HCACK ì´ë²¤íŠ¸
    all_hcack = analysis.get('hcack_events', [])
    if all_hcack:
        lines.append(f"\n### ğŸ“‹ HCACK ì‘ë‹µ ì´ë ¥")
        for h in all_hcack:
            status_str = h.get('status', '')
            desc_str = h.get('desc', '')
            lines.append(f"- [{h['time_str']}] HCACK={h['hcack']} ({status_str}: {desc_str})")

    rej = [h for h in all_hcack if h['hcack'] == '2']
    if rej:
        lines.append(f"\n### âš ï¸ HCACK=2 ê±°ì ˆ {len(rej)}íšŒ")
        lines.append("â†’ ë¦¬í”„í„° ì´ì†¡ ê±°ì ˆ ë˜ëŠ” í¬ë ˆì¸ ì ìœ ")

    if analysis.get('delays'):
        lines.append("\n### ğŸ”´ ì£¼ìš” ì§€ì—°")
        for d in analysis['delays']:
            lines.append(f"- {d['segment']}: {d['duration_str']} ({d['cause']})")

    lines.append("\n" + "=" * 60)
    return "\n".join(lines)


def is_lifter_data(df: pd.DataFrame) -> bool:
    if 'MESSAGENAME' not in df.columns:
        return False
    msgs = df['MESSAGENAME'].dropna().astype(str).tolist()
    return sum(1 for m in msgs if m.startswith('STORAGE-')) >= 5
