#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM ì‘ë‹µ í›„ì²˜ë¦¬ ëª¨ë“ˆ
- LLM ë¶„ì„ í˜¸ì¶œ
- ë§ˆí¬ë‹¤ìš´ ì œê±°
- URL/ì´ë¯¸ì§€ í™˜ê° ì œê±°
"""

import re
import logging
from typing import Optional

logger = logging.getLogger(__name__)


def generate_status_summary(status_text: str) -> str:
    """
    ìƒíƒœ ë¶„ì„ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•´ì„œ ìƒì„¸ ì„¤ëª… ìë™ ìƒì„±
    """
    lines = status_text.split('\n')
    
    normal_items = []
    caution_items = []  # ğŸŸ¡ ê´€ì‹¬
    warning_items = []  # âš ï¸ ì£¼ì˜
    critical_items = [] # ğŸ”´ ìœ„í—˜
    
    for line in lines:
        line = line.strip()
        if 'âœ…' in line and 'ì¢…í•©' not in line:
            # âœ… M14AM14B: 262.0 â†’ ì •ìƒ
            match = re.search(r'âœ…\s*([^:]+):\s*([\d.]+)', line)
            if match:
                normal_items.append((match.group(1).strip(), match.group(2)))
        elif 'ğŸŸ¡' in line:
            # ğŸŸ¡ TRANSPORT: 149.0 â†’ ê´€ì‹¬ (â‰¥ 145)
            match = re.search(r'ğŸŸ¡\s*([^:]+):\s*([\d.]+).*?â‰¥\s*([\d.]+)', line)
            if match:
                caution_items.append((match.group(1).strip(), match.group(2), match.group(3)))
        elif 'âš ï¸' in line:
            match = re.search(r'âš ï¸\s*([^:]+):\s*([\d.]+).*?â‰¥\s*([\d.]+)', line)
            if match:
                warning_items.append((match.group(1).strip(), match.group(2), match.group(3)))
        elif 'ğŸš¨' in line and 'ì¢…í•©' not in line:
            # ğŸš¨ M14AM14BSUM: 614.0 â†’ ì‹¬ê° (â‰¥ 588)
            match = re.search(r'ğŸš¨\s*([^:]+):\s*([\d.]+).*?â‰¥\s*([\d.]+)', line)
            if match:
                critical_items.append((match.group(1).strip(), match.group(2), match.group(3)))
        elif 'ğŸ”´' in line:
            match = re.search(r'ğŸ”´\s*([^:]+):\s*([\d.]+).*?â‰¥\s*([\d.]+)', line)
            if match:
                critical_items.append((match.group(1).strip(), match.group(2), match.group(3)))
    
    # ì„¤ëª… ìƒì„± (ì‹¬ê°í•œ ê²ƒë¶€í„°!)
    parts = []
    
    # ìœ„í—˜/ì‹¬ê° í•­ëª© (ê°€ì¥ ë¨¼ì €!)
    if critical_items:
        for name, value, threshold in critical_items:
            parts.append(f"ğŸš¨ {name}({value})ì´ ì‹¬ê° êµ¬ê°„({threshold} ì´ìƒ)! ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”!")
    
    # ì£¼ì˜ í•­ëª©
    for name, value, threshold in warning_items:
        parts.append(f"âš ï¸ {name}({value})ì´ ì£¼ì˜ êµ¬ê°„({threshold} ì´ìƒ). ì ê²€ í•„ìš”.")
    
    # ê´€ì‹¬ í•­ëª©
    for name, value, threshold in caution_items:
        parts.append(f"{name}({value})ì´ ê¸°ì¤€ê°’({threshold}) ì´ìƒìœ¼ë¡œ ê´€ì‹¬ êµ¬ê°„ ì§„ì…. ëª¨ë‹ˆí„°ë§ ê¶Œì¥.")
    
    # ì‹¬ê°/ì£¼ì˜ í•­ëª© ìˆìœ¼ë©´ â†’ ì •ìƒ í•­ëª© ìƒëµ, ê²½ê³  ë§ˆë¬´ë¦¬
    if critical_items:
        parts.append(f"âš ï¸ ì´ {len(critical_items)}ê°œ í•­ëª©ì´ ì‹¬ê° ìƒíƒœì…ë‹ˆë‹¤. ì¦‰ì‹œ ì ê²€í•˜ì„¸ìš”!")
    elif warning_items:
        parts.append(f"âš ï¸ ì´ {len(warning_items)}ê°œ í•­ëª©ì´ ì£¼ì˜ ìƒíƒœì…ë‹ˆë‹¤. ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    elif normal_items and not caution_items:
        # ì „ë¶€ ì •ìƒì¼ ë•Œë§Œ ì •ìƒ ì–¸ê¸‰
        names = ', '.join([item[0] for item in normal_items[:3]])
        if len(normal_items) > 3:
            names += f" ë“± {len(normal_items)}ê°œ"
        parts.append(f"{names} ëª¨ë‘ ì •ìƒ ë²”ìœ„ì…ë‹ˆë‹¤.")
    
    if not parts:
        return "ëª¨ë“  í•­ëª©ì´ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤."
    
    return ' '.join(parts)


def get_llm_analysis(data_text: str, llm, data_type: str = "m14") -> str:
    """
    LLM ë¶„ì„ í˜¸ì¶œ + í›„ì²˜ë¦¬
    """
    if llm is None:
        return "âš ï¸ LLM ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        # ìƒíƒœ ë¶„ì„ ë¶€ë¶„ ì¶”ì¶œ
        if "ğŸ“Š ìƒíƒœ ë¶„ì„" in data_text:
            status_part = data_text.split("ğŸ“Š ìƒíƒœ ë¶„ì„")[1][:300]
        else:
            status_part = data_text[:300]
        
        prompt = f"""<|im_start|>system
í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì˜ì–´ ê¸ˆì§€. ìƒê° ê³¼ì • ì—†ì´ ë°”ë¡œ ë‹µë³€í•˜ì„¸ìš”.
<|im_end|>
<|im_start|>user
{status_part}

ìœ„ ìƒíƒœë¥¼ í•œêµ­ì–´ 2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
<|im_end|>
<|im_start|>assistant
"""
        
        response = llm(
            prompt,
            max_tokens=80,
            temperature=0.3,
            stop=["<|im_end|>", "\n\n", "---"]
        )
        
        raw_analysis = response['choices'][0]['text'].strip()
        logger.info(f"LLM ì›ë³¸: {raw_analysis[:200]}")
        
        # <think> íƒœê·¸ ì œê±°
        raw_analysis = re.sub(r'<think>.*?</think>', '', raw_analysis, flags=re.DOTALL).strip()
        raw_analysis = re.sub(r'<[^>]+>', '', raw_analysis).strip()  # ëª¨ë“  íƒœê·¸ ì œê±°
        
        # ë¹ˆ ì‘ë‹µ ë˜ëŠ” ì˜ì–´ thinking ê°ì§€ â†’ í…œí”Œë¦¿ ê¸°ë°˜ ì‘ë‹µ
        if not raw_analysis or len(raw_analysis) < 5:
            return generate_status_summary(status_part)
        
        if "let me" in raw_analysis.lower() or "okay" in raw_analysis.lower():
            return generate_status_summary(status_part)
        
        # í›„ì²˜ë¦¬
        analysis = clean_llm_response(raw_analysis, max_lines=3)
        logger.info(f"LLM í›„ì²˜ë¦¬: {analysis[:200] if analysis else 'ì—†ìŒ'}")
        
        if analysis and len(analysis) > 10:
            return analysis
        else:
            return generate_status_summary(status_part)
            
    except Exception as e:
        logger.warning(f"LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
        # ìƒíƒœ ë¶„ì„ ë¶€ë¶„ ì¶”ì¶œ ì‹œë„
        if "ğŸ“Š ìƒíƒœ ë¶„ì„" in data_text:
            status_part = data_text.split("ğŸ“Š ìƒíƒœ ë¶„ì„")[1][:300]
            return generate_status_summary(status_part)
        return "ìƒíƒœ ë¶„ì„ì„ í™•ì¸í•´ì£¼ì„¸ìš”."


def get_prediction_llm_analysis(data_text: str, llm) -> str:
    """
    ì˜ˆì¸¡ ë¶„ì„ìš© LLM í˜¸ì¶œ + í›„ì²˜ë¦¬
    """
    # ì˜ˆì¸¡ ë¶„ì„ ë¶€ë¶„ ì¶”ì¶œ
    if "ğŸ”® ì˜ˆì¸¡ ë¶„ì„" not in data_text:
        return "ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    pred_part = data_text.split("ğŸ”® ì˜ˆì¸¡ ë¶„ì„")[1][:500]
    
    # í•µì‹¬ ì •ë³´ ì¶”ì¶œ
    import re
    
    current_match = re.search(r'í˜„ì¬TOTALCNT:\s*([\d,]+)', pred_part)
    pred_match = re.search(r'ë³´ì •ì˜ˆì¸¡:\s*([\d,]+)', pred_part)
    actual_match = re.search(r'ì‹¤ì œê°’:\s*([\d,]+)', pred_part)
    error_match = re.search(r'ì˜ˆì¸¡ ì˜¤ì°¨:\s*([+\-]?[\d,]+)', pred_part)
    error_rate_match = re.search(r'ì˜¤ì°¨ìœ¨:\s*([\d.]+)%', pred_part)
    direction_match = re.search(r'(ê³¼ì†Œì˜ˆì¸¡|ê³¼ëŒ€ì˜ˆì¸¡|ì •í™•)', pred_part)
    
    current_val = current_match.group(1) if current_match else "?"
    pred_val = pred_match.group(1) if pred_match else "?"
    actual_val = actual_match.group(1) if actual_match else "?"
    error_val = error_match.group(1) if error_match else "?"
    error_rate = error_rate_match.group(1) if error_rate_match else "?"
    direction = direction_match.group(1) if direction_match else "?"
    
    # LLM ì—†ìœ¼ë©´ í…œí”Œë¦¿
    if llm is None:
        return generate_prediction_summary(current_val, pred_val, actual_val, error_val, error_rate, direction)
    
    try:
        prompt = f"""<|im_start|>system
í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì˜ì–´ ê¸ˆì§€. ë°”ë¡œ ë‹µë³€í•˜ì„¸ìš”.
<|im_end|>
<|im_start|>user
ì˜ˆì¸¡ ê²°ê³¼:
- í˜„ì¬ê°’: {current_val}
- ì˜ˆì¸¡ê°’: {pred_val}
- ì‹¤ì œê°’: {actual_val}
- ì˜¤ì°¨: {error_val} ({error_rate}%)
- ë°©í–¥: {direction}

ìœ„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í•œêµ­ì–´ 2ë¬¸ì¥ìœ¼ë¡œ í•´ì„í•˜ì„¸ìš”.
<|im_end|>
<|im_start|>assistant
"""
        
        response = llm(
            prompt,
            max_tokens=100,
            temperature=0.3,
            stop=["<|im_end|>", "\n\n"]
        )
        
        raw = response['choices'][0]['text'].strip()
        raw = re.sub(r'<think>.*?</think>', '', raw, flags=re.DOTALL).strip()
        raw = re.sub(r'<[^>]+>', '', raw).strip()
        
        # ì˜ì–´ ê°ì§€ â†’ í…œí”Œë¦¿ í´ë°±
        english_patterns = ['let me', 'let\'s', 'okay', 'the ', 'this ', 'user', 'want', 'given', 'result']
        has_english = any(p in raw.lower() for p in english_patterns)
        
        if not raw or len(raw) < 10 or has_english:
            return generate_prediction_summary(current_val, pred_val, actual_val, error_val, error_rate, direction)
        
        return clean_llm_response(raw, max_lines=3)
        
    except Exception as e:
        logger.warning(f"ì˜ˆì¸¡ LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
        return generate_prediction_summary(current_val, pred_val, actual_val, error_val, error_rate, direction)


def generate_prediction_summary(current_val, pred_val, actual_val, error_val, error_rate, direction) -> str:
    """ì˜ˆì¸¡ ë¶„ì„ í…œí”Œë¦¿"""
    try:
        error_rate_f = float(error_rate.replace(',', ''))
    except:
        error_rate_f = 0
    
    if error_rate_f <= 2:
        accuracy = "ìš°ìˆ˜"
        emoji = "âœ…"
    elif error_rate_f <= 5:
        accuracy = "ì–‘í˜¸"
        emoji = "ğŸŸ¡"
    else:
        accuracy = "ê°œì„  í•„ìš”"
        emoji = "âš ï¸"
    
    result = f"{emoji} ì˜ˆì¸¡ ì •í™•ë„ {accuracy} (ì˜¤ì°¨ {error_rate}%). "
    
    if direction == "ê³¼ì†Œì˜ˆì¸¡":
        result += f"ì‹¤ì œê°’({actual_val})ì´ ì˜ˆì¸¡({pred_val})ë³´ë‹¤ ë†’ìŒ. ì˜ˆìƒë³´ë‹¤ ë¬¼ëŸ‰ ì¦ê°€!"
    elif direction == "ê³¼ëŒ€ì˜ˆì¸¡":
        result += f"ì‹¤ì œê°’({actual_val})ì´ ì˜ˆì¸¡({pred_val})ë³´ë‹¤ ë‚®ìŒ. ì˜ˆìƒë³´ë‹¤ ë¬¼ëŸ‰ ê°ì†Œ."
    else:
        result += f"ì˜ˆì¸¡ì´ ì •í™•í–ˆìŠµë‹ˆë‹¤."
    
    return result


def clean_llm_response(text: str, max_lines: int = 5) -> str:
    """
    LLM ì‘ë‹µ í›„ì²˜ë¦¬: ë§ˆí¬ë‹¤ìš´, URL, í™˜ê° ì œê±°
    
    Args:
        text: LLM ì›ë³¸ ì‘ë‹µ
        max_lines: ìµœëŒ€ ë°˜í™˜ ì¤„ ìˆ˜ (ê¸°ë³¸ 5ì¤„)
    
    Returns:
        ì •ì œëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return ""
    
    # 1. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ë§Œ ì œê±° (ë‚´ìš©ì€ ë³´ì¡´!)
    text = text.replace('```', '')  # ì½”ë“œë¸”ë¡ ê¸°í˜¸ë§Œ ì œê±°
    text = text.replace('`', '')  # ì¸ë¼ì¸ ì½”ë“œ ê¸°í˜¸ë§Œ ì œê±°
    text = re.sub(r'^#{1,6}\s*', '', text, flags=re.MULTILINE)  # í—¤ë”
    text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)  # ë³¼ë“œ â†’ ë‚´ìš©ë§Œ
    text = re.sub(r'\*([^*]+)\*', r'\1', text)  # ì´íƒ¤ë¦­ â†’ ë‚´ìš©ë§Œ
    text = re.sub(r'\[([^\]]*)\]', r'\1', text)  # [íƒœê·¸] â†’ ë‚´ìš©ë§Œ
    text = re.sub(r'^\s*[-*]\s+', '', text, flags=re.MULTILINE)  # ë¦¬ìŠ¤íŠ¸ ê¸°í˜¸ ì œê±°
    text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)  # ìˆ«ì ë¦¬ìŠ¤íŠ¸
    text = re.sub(r'[=\-]{3,}', '', text)  # ===, --- êµ¬ë¶„ì„ 
    
    # 2. í”„ë¡¬í”„íŠ¸ ë°˜ë³µ ì œê±°
    text = re.sub(r'ë°ì´í„°ì—ì„œ ì£¼ì–´ì§„.*', '', text)
    text = re.sub(r'ìœ„ ë°ì´í„°ë¥¼.*', '', text)
    text = re.sub(r'ë¶„ì„\s*\(í•œêµ­ì–´.*', '', text)
    text = re.sub(r'ë‹µë³€\s*\(í•œêµ­ì–´.*', '', text)
    text = re.sub(r'ë°ì´í„° ë¶„ì„ ê²°ê³¼', '', text)  # ì¶”ê°€
    
    # 3. í™˜ê° ì œê±°: URL, ì´ë¯¸ì§€ ì°¸ì¡°
    text = re.sub(r'https?://[^\s\)]+', '', text)  # URL ì œê±°
    text = re.sub(r'www\.[^\s\)]+', '', text)  # www. ì œê±°
    text = re.sub(r'\([^)]*https?[^)]*\)', '', text)  # (URL) ì œê±°
    text = re.sub(r'ì´ë¯¸ì§€\s*:\s*.*', '', text, flags=re.MULTILINE)  # ì´ë¯¸ì§€: ë¼ì¸ ì œê±°
    text = re.sub(r'ê·¸ë¦¼\s*:\s*.*', '', text, flags=re.MULTILINE)  # ê·¸ë¦¼: ë¼ì¸ ì œê±°
    text = re.sub(r'!\[.*?\]\(.*?\)', '', text)  # ![alt](url) ì œê±°
    
    # 4. ë¹ˆ ê´„í˜¸ ì œê±°
    text = re.sub(r'\(\s*\)', '', text)
    
    # 5. ë°˜ë³µ ë¼ì¸ ì œê±° ë° ì •ë¦¬
    lines = text.split('\n')
    seen = set()
    unique_lines = []
    for line in lines:
        line_clean = line.strip()
        if line_clean and line_clean not in seen and len(line_clean) > 2:
            seen.add(line_clean)
            unique_lines.append(line_clean)
    
    return '\n'.join(unique_lines[:max_lines])


def remove_markdown(text: str) -> str:
    """ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ë§Œ ì œê±°"""
    if not text:
        return ""
    
    text = re.sub(r'```[\s\S]*?```', '', text)
    text = re.sub(r'`[^`]+`', '', text)
    text = re.sub(r'^#{1,6}\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
    text = re.sub(r'\*([^*]+)\*', r'\1', text)
    text = re.sub(r'^\s*[-*]\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'[=\-]{3,}', '', text)
    
    return text.strip()


def remove_hallucinations(text: str) -> str:
    """URL, ì´ë¯¸ì§€ ë“± í™˜ê° ì œê±°"""
    if not text:
        return ""
    
    text = re.sub(r'https?://[^\s\)]+', '', text)
    text = re.sub(r'www\.[^\s\)]+', '', text)
    text = re.sub(r'\([^)]*https?[^)]*\)', '', text)
    text = re.sub(r'ì´ë¯¸ì§€\s*:\s*.*', '', text, flags=re.MULTILINE)
    text = re.sub(r'ê·¸ë¦¼\s*:\s*.*', '', text, flags=re.MULTILINE)
    text = re.sub(r'!\[.*?\]\(.*?\)', '', text)
    text = re.sub(r'\[.*?\]\(.*?\)', '', text)
    text = re.sub(r'\(\s*\)', '', text)
    text = re.sub(r'\[\s*\]', '', text)
    
    return text.strip()


def remove_duplicates(text: str, max_lines: Optional[int] = None) -> str:
    """ì¤‘ë³µ ë¼ì¸ ì œê±°"""
    if not text:
        return ""
    
    lines = text.split('\n')
    seen = set()
    unique_lines = []
    
    for line in lines:
        line_clean = line.strip()
        if line_clean and line_clean not in seen and len(line_clean) > 2:
            seen.add(line_clean)
            unique_lines.append(line_clean)
    
    if max_lines:
        unique_lines = unique_lines[:max_lines]
    
    return '\n'.join(unique_lines)


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    test_text = """
    **ë¶„ì„ ê²°ê³¼**
    
    ì •ìƒ ìƒíƒœì…ë‹ˆë‹¤. í˜„ì¬ í ìˆ˜ëŠ” 1304ê°œë¡œ, ë³‘ëª© ì§€í‘œì— ë”°ë¼ ì‹¬ê°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.
    ì´ë¯¸ì§€: (https://s7-98dxdyjzqf.s3.ap-northeast-1.amazonaws.com/queue.png)
    ì •ìƒ ìƒíƒœì…ë‹ˆë‹¤. í˜„ì¬ í ìˆ˜ëŠ” 1,400ì´ ë„˜ì§€ ì•Šìœ¼ë©° ë³‘ëª© ì§€í‘œì— ë”°ë¼ ì‹¬ê°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.
    
    - ë¦¬ìŠ¤íŠ¸ í•­ëª© 1
    - ë¦¬ìŠ¤íŠ¸ í•­ëª© 2
    
    ìœ„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ë©´...
    """
    
    print("ì›ë³¸:")
    print(test_text)
    print("\n" + "="*50 + "\n")
    print("ì •ì œ í›„:")
    print(clean_llm_response(test_text))