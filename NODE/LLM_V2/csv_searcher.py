#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSV ê²€ìƒ‰ ëª¨ë“ˆ
server.pyì—ì„œ importí•˜ì—¬ ì‚¬ìš©
"""

import os
import pandas as pd
import re
import json
import logging
from typing import Tuple, Optional, List, Dict, Any

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì „ì—­ ë³€ìˆ˜
_df = None
_csv_path = None
_column_config = None

# ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ ê²½ë¡œ
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

def load_column_config() -> dict:
    """ì»¬ëŸ¼ ì„¤ì • JSON ë¡œë“œ"""
    global _column_config
    
    config_path = os.path.join(SCRIPT_DIR, 'sort', 'column_config.json')
    
    if not os.path.exists(config_path):
        logger.warning(f"âš ï¸ ì»¬ëŸ¼ ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}")
        return {}
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            _column_config = json.load(f)
        logger.info(f"âœ… ì»¬ëŸ¼ ì„¤ì • ë¡œë“œ ì™„ë£Œ: {config_path}")
        return _column_config
    except Exception as e:
        logger.error(f"âŒ ì»¬ëŸ¼ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

def get_column_config() -> dict:
    """í˜„ì¬ ì»¬ëŸ¼ ì„¤ì • ë°˜í™˜"""
    global _column_config
    if _column_config is None:
        load_column_config()
    return _column_config or {}

def detect_data_type(columns: List[str]) -> str:
    """ë°ì´í„° íƒ€ì… ìë™ ê°ì§€ (m14/hub)"""
    config = get_column_config()
    
    # ê¸°ë³¸ ê°ì§€ ì»¬ëŸ¼ (config ì—†ì„ ë•Œ ì‚¬ìš©)
    DEFAULT_DETECT = {
        "m14": ["M14AM14B", "M14AM14BSUM", "TOTALCNT", "í˜„ì¬TOTALCNT", "queue_gap", "TRANSPORT"],
        "hub": ["CURRENT_M16A_3F_JOB_2", "HUBROOMTOTAL", "M16A_3F_STORAGE_UTIL", "M16HUB.QUE.ALL.CURRENTQCNT"]
    }
    
    if config:
        m14_detect = config.get('m14', {}).get('detect_columns', DEFAULT_DETECT["m14"])
        hub_detect = config.get('hub', {}).get('detect_columns', DEFAULT_DETECT["hub"])
    else:
        m14_detect = DEFAULT_DETECT["m14"]
        hub_detect = DEFAULT_DETECT["hub"]
    
    m14_count = sum(1 for col in m14_detect if col in columns)
    hub_count = sum(1 for col in hub_detect if col in columns)
    
    if m14_count > hub_count:
        return "m14"
    elif hub_count > 0:
        return "hub"
    else:
        return "unknown"

def has_prediction_data(row: pd.Series) -> bool:
    """ì˜ˆì¸¡ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸"""
    required = ['ë³´ì •ì˜ˆì¸¡', 'ì‹¤ì œê°’']
    return all(col in row.index and pd.notna(row[col]) for col in required)


def analyze_prediction(row: pd.Series) -> str:
    """
    ì˜ˆì¸¡ ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±
    
    Returns:
        ì˜ˆì¸¡ ë¶„ì„ í…ìŠ¤íŠ¸ (í˜„ì¬ê°’ â†’ ì˜ˆì¸¡ê°’ â†’ ì‹¤ì œê°’ â†’ ì˜¤ì°¨)
    """
    if not has_prediction_data(row):
        return ""
    
    # ì»¬ëŸ¼ ì¶”ì¶œ
    current_time = row.get('í˜„ì¬ì‹œê°„', 'N/A')
    current_value = row.get('í˜„ì¬TOTALCNT', 0)
    pred_time = row.get('ì˜ˆì¸¡ì‹œì ', 'N/A')
    actual_time = row.get('ì‹¤ì œì‹œì ', pred_time)
    actual_value = row.get('ì‹¤ì œê°’', 0)
    raw_pred = row.get('ì›ë³¸ì˜ˆì¸¡', 0)
    adj_pred = row.get('ë³´ì •ì˜ˆì¸¡', 0)
    error = row.get('ì˜¤ì°¨', 0)
    error_rate = row.get('ì˜¤ì°¨ìœ¨(%)', 0)
    
    # ìˆ«ì ë³€í™˜
    try:
        current_value = float(current_value) if pd.notna(current_value) else 0
        actual_value = float(actual_value) if pd.notna(actual_value) else 0
        raw_pred = float(raw_pred) if pd.notna(raw_pred) else 0
        adj_pred = float(adj_pred) if pd.notna(adj_pred) else 0
        error = float(error) if pd.notna(error) else 0
        error_rate = float(error_rate) if pd.notna(error_rate) else 0
    except:
        return ""
    
    # ë³€í™”ëŸ‰ ê³„ì‚°
    change = actual_value - current_value
    change_rate = (change / current_value * 100) if current_value > 0 else 0
    
    # ì˜ˆì¸¡ ì˜¤ì°¨ ë°©í–¥
    if error > 0:
        error_direction = "ê³¼ì†Œì˜ˆì¸¡"
        error_emoji = "ğŸ“ˆ"
    elif error < 0:
        error_direction = "ê³¼ëŒ€ì˜ˆì¸¡"
        error_emoji = "ğŸ“‰"
    else:
        error_direction = "ì •í™•"
        error_emoji = "âœ…"
    
    # í…ìŠ¤íŠ¸ ìƒì„±
    text = "\n" + "=" * 50 + "\n"
    text += "ğŸ”® ì˜ˆì¸¡ ë¶„ì„\n"
    text += "=" * 50 + "\n\n"
    
    # 1. í˜„ì¬ ì‹œì 
    text += f"ğŸ• í˜„ì¬ ì‹œì : {current_time}\n"
    text += f"   í˜„ì¬TOTALCNT: {current_value:,.0f}\n\n"
    
    # 2. ì˜ˆì¸¡
    text += f"ğŸ¯ ì˜ˆì¸¡ ì‹œì : {pred_time}\n"
    text += f"   ë³´ì •ì˜ˆì¸¡: {adj_pred:,.0f}\n"
    if raw_pred > 0:
        text += f"   (ì›ë³¸ì˜ˆì¸¡: {raw_pred:,.0f})\n"
    text += "\n"
    
    # 3. ì‹¤ì œ ê²°ê³¼
    text += f"ğŸ“Š ì‹¤ì œ ê²°ê³¼: {actual_time}\n"
    text += f"   ì‹¤ì œê°’: {actual_value:,.0f}\n\n"
    
    # 4. ì˜¤ì°¨ ë¶„ì„
    text += f"ğŸ“ ì˜¤ì°¨ ë¶„ì„\n"
    text += f"   ì˜ˆì¸¡ ì˜¤ì°¨: {error:+,.0f} ({error_emoji} {error_direction})\n"
    text += f"   ì˜¤ì°¨ìœ¨: {abs(error_rate):.1f}%\n\n"
    
    # 5. ë³€í™” ë¶„ì„
    text += f"ğŸ“ˆ ë³€í™” ë¶„ì„\n"
    text += f"   í˜„ì¬ê°’ â†’ ì‹¤ì œê°’: {current_value:,.0f} â†’ {actual_value:,.0f}\n"
    text += f"   ë³€í™”ëŸ‰: {change:+,.0f} ({change_rate:+.1f}%)\n\n"
    
    # 6. ì¢…í•© í‰ê°€
    text += "ğŸ’¡ ì¢…í•© í‰ê°€\n"
    
    if abs(error_rate) <= 2:
        text += f"   âœ… ì˜ˆì¸¡ ì •í™•ë„ ìš°ìˆ˜ (ì˜¤ì°¨ {abs(error_rate):.1f}%)\n"
    elif abs(error_rate) <= 5:
        text += f"   ğŸŸ¡ ì˜ˆì¸¡ ì •í™•ë„ ì–‘í˜¸ (ì˜¤ì°¨ {abs(error_rate):.1f}%)\n"
    else:
        text += f"   âš ï¸ ì˜ˆì¸¡ ì •í™•ë„ ê°œì„  í•„ìš” (ì˜¤ì°¨ {abs(error_rate):.1f}%)\n"
    
    if error > 0:
        text += f"   â†’ ì‹¤ì œê°’({actual_value:,.0f})ì´ ì˜ˆì¸¡({adj_pred:,.0f})ë³´ë‹¤ {abs(error):,.0f} ë†’ìŒ\n"
        text += f"   â†’ ì˜ˆìƒë³´ë‹¤ ë¬¼ëŸ‰ ì¦ê°€!\n"
    elif error < 0:
        text += f"   â†’ ì‹¤ì œê°’({actual_value:,.0f})ì´ ì˜ˆì¸¡({adj_pred:,.0f})ë³´ë‹¤ {abs(error):,.0f} ë‚®ìŒ\n"
        text += f"   â†’ ì˜ˆìƒë³´ë‹¤ ë¬¼ëŸ‰ ê°ì†Œ\n"
    else:
        text += f"   â†’ ì˜ˆì¸¡ì´ ì •í™•í–ˆìŠµë‹ˆë‹¤!\n"
    
    # 1700 ì„ê³„ê°’ ì²´í¬
    if actual_value >= 1700:
        text += f"\n   ğŸš¨ ì‹¤ì œê°’ {actual_value:,.0f} â†’ CRITICAL ìƒíƒœ (1700 ì´ìƒ)!\n"
    elif actual_value >= 1650:
        text += f"\n   âš ï¸ ì‹¤ì œê°’ {actual_value:,.0f} â†’ CAUTION ìƒíƒœ (1650 ì´ìƒ)\n"
    elif actual_value >= 1600:
        text += f"\n   ğŸŸ¡ ì‹¤ì œê°’ {actual_value:,.0f} â†’ ì£¼ì˜ êµ¬ê°„ (1600 ì´ìƒ)\n"
    
    return text


def analyze_status(row: pd.Series, data_type: str) -> str:
    """ì„ê³„ê°’ ê¸°ë°˜ ìƒíƒœ ë¶„ì„"""
    config = get_column_config()
    
    # ê¸°ë³¸ ì„ê³„ê°’ (config ì—†ì„ ë•Œ ì‚¬ìš©)
    DEFAULT_THRESHOLDS = {
        "m14": {
            "í˜„ì¬TOTALCNT": {"normal": 1600, "caution": 1650, "critical": 1700},
            "TOTALCNT": {"normal": 1600, "caution": 1650, "critical": 1700},
            "M14AM14B": {"normal": 497, "caution": 517, "critical": 520},
            "M14AM14BSUM": {"normal": 566, "caution": 576, "critical": 588},
            "queue_gap": {"normal": 200, "caution": 300, "critical": 400},
            "TRANSPORT": {"normal": 145, "caution": 151, "critical": 180},
            "OHT_UTIL": {"normal": 83.6, "caution": 84.6, "critical": 85.6}
        },
        "hub": {
            "CURRENT_M16A_3F_JOB_2": {"normal": 270, "caution": 280, "critical": 300},
            "HUBROOMTOTAL": {"normal": 620, "caution": 610, "critical": 590},
            "M16A_3F_STORAGE_UTIL": {"normal": 205, "caution": 206, "critical": 207},
            "CD_M163FSTORAGEUTIL": {"normal": 7, "caution": 8, "critical": 10},
            "M16HUB.QUE.ALL.CURRENTQCNT": {"normal": 1200, "caution": 1300, "critical": 1400}
        }
    }
    
    # config ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    if config and data_type in config:
        thresholds = config[data_type].get('thresholds', {})
    else:
        thresholds = DEFAULT_THRESHOLDS.get(data_type, {})
    
    if not thresholds:
        return ""
    
    results = []
    warnings = 0
    criticals = 0
    
    for col, limits in thresholds.items():
        if col not in row.index or pd.isna(row[col]):
            continue
        
        value = float(row[col])
        
        # HUBROOMTOTALì€ ë‚®ì„ìˆ˜ë¡ ìœ„í—˜ (ë°˜ëŒ€ ë¡œì§)
        if col == 'HUBROOMTOTAL':
            critical = limits.get('critical', 0)
            caution = limits.get('caution', 0)
            normal = limits.get('normal', 0)
            
            if value < critical:
                results.append(f"ğŸš¨ {col}: {value} â†’ ì‹¬ê° (< {critical})")
                criticals += 1
            elif value < caution:
                results.append(f"âš ï¸ {col}: {value} â†’ ì£¼ì˜ (< {caution})")
                warnings += 1
            else:
                results.append(f"âœ… {col}: {value} â†’ ì •ìƒ")
        else:
            # ì¼ë°˜ ì»¬ëŸ¼: ë†’ì„ìˆ˜ë¡ ìœ„í—˜
            critical = limits.get('critical', float('inf'))
            caution = limits.get('caution', float('inf'))
            normal = limits.get('normal', float('inf'))
            
            if value >= critical:
                results.append(f"ğŸš¨ {col}: {value} â†’ ì‹¬ê° (â‰¥ {critical})")
                criticals += 1
            elif value >= caution:
                results.append(f"âš ï¸ {col}: {value} â†’ ì£¼ì˜ (â‰¥ {caution})")
                warnings += 1
            elif value >= normal:
                results.append(f"ğŸŸ¡ {col}: {value} â†’ ê´€ì‹¬ (â‰¥ {normal})")
            else:
                results.append(f"âœ… {col}: {value} â†’ ì •ìƒ")
    
    if not results:
        return ""
    
    # ì¢…í•© íŒë‹¨
    if criticals > 0:
        summary = f"ğŸš¨ ì¢…í•©: ì‹¬ê° ({criticals}ê°œ í•­ëª© ì„ê³„ê°’ ì´ˆê³¼)"
    elif warnings > 0:
        summary = f"âš ï¸ ì¢…í•©: ì£¼ì˜ ({warnings}ê°œ í•­ëª© ì£¼ì˜ í•„ìš”)"
    else:
        summary = "âœ… ì¢…í•©: ì •ìƒ"
    
    analysis_text = "\nğŸ“Š ìƒíƒœ ë¶„ì„\n"
    analysis_text += "\n".join(results)
    analysis_text += f"\n\n{summary}"
    
    return analysis_text

def load_csv(csv_path: str) -> bool:
    """CSV íŒŒì¼ ë¡œë“œ"""
    global _df, _csv_path
    
    if not os.path.exists(csv_path):
        logger.error(f"âŒ CSV íŒŒì¼ ì—†ìŒ: {csv_path}")
        return False
    
    try:
        _df = pd.read_csv(csv_path, encoding='utf-8')
        _csv_path = csv_path
        logger.info(f"âœ… CSV ë¡œë“œ ì™„ë£Œ: {len(_df)}í–‰, {len(_df.columns)}ì»¬ëŸ¼")
        logger.info(f"ì»¬ëŸ¼: {list(_df.columns[:5])}...")
        return True
    except Exception as e:
        logger.error(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def get_df() -> Optional[pd.DataFrame]:
    """í˜„ì¬ ë¡œë“œëœ DataFrame ë°˜í™˜"""
    return _df

def get_columns() -> List[str]:
    """ì»¬ëŸ¼ ëª©ë¡ ë°˜í™˜"""
    if _df is None:
        return []
    return list(_df.columns)

def convert_time_format(time_str: str) -> List[str]:
    """
    ë‹¤ì–‘í•œ ì‹œê°„ í˜•ì‹ì„ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•ì‹ ëª©ë¡ ë°˜í™˜
    
    ì…ë ¥ ì˜ˆì‹œ:
    - 202509210014 â†’ ['2025-09-21 00:14', '2025-09-21 0:14']
    - 2025-10-14 04:39 â†’ ['2025-10-14 04:39', '2025-10-14 4:39']
    - 202510140439 â†’ ['2025-10-14 04:39', '2025-10-14 4:39']
    """
    formats = []
    time_str = time_str.strip()
    
    # 1. YYYYMMDDHHMM í˜•ì‹ (12ìë¦¬ ìˆ«ì)
    if re.match(r'^\d{12}$', time_str):
        year = time_str[0:4]
        month = time_str[4:6]
        day = time_str[6:8]
        hour = time_str[8:10]
        minute = time_str[10:12]
        
        # ì—¬ëŸ¬ í˜•ì‹ ìƒì„±
        formats.append(f"{year}-{month}-{day} {int(hour):02d}:{minute}")  # 2025-10-14 04:39
        formats.append(f"{year}-{month}-{day} {int(hour)}:{minute}")      # 2025-10-14 4:39
        formats.append(time_str)  # ì›ë³¸ë„ í¬í•¨
    
    # 2. YYYY-MM-DD HH:MM í˜•ì‹
    elif re.match(r'^\d{4}-\d{2}-\d{2}\s+\d{1,2}:\d{2}$', time_str):
        formats.append(time_str)
        # ì‹œê°„ ë¶€ë¶„ ì •ê·œí™”
        date_part, time_part = time_str.rsplit(' ', 1)
        if ':' in time_part:
            h, m = time_part.split(':')
            formats.append(f"{date_part} {int(h):02d}:{m}")
            formats.append(f"{date_part} {int(h)}:{m}")
    
    # 3. ê·¸ ì™¸ í˜•ì‹ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ
    else:
        formats.append(time_str)
    
    # ì¤‘ë³µ ì œê±°
    return list(set(formats))


def search_by_time(time_str: str) -> Tuple[Optional[pd.Series], str]:
    """
    ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰ (YYYYMMDDHHMM ë˜ëŠ” YYYY-MM-DD HH:MM í˜•ì‹)
    
    Returns:
        (ë§¤ì¹­ëœ í–‰, ì„¤ëª… í…ìŠ¤íŠ¸)
    """
    if _df is None:
        return None, "CSV íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # ì‹œê°„ ì»¬ëŸ¼ í›„ë³´
    time_cols = ['í˜„ì¬ì‹œê°„', 'STAT_DT', 'CURRTIME', 'ì‹œê°„', 'TIME', 'DATETIME']
    time_col = None
    
    for col in time_cols:
        if col in _df.columns:
            time_col = col
            break
    
    if time_col is None:
        return None, "ì‹œê°„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ê²€ìƒ‰ (ì—¬ëŸ¬ ë°©ì‹ ì‹œë„)
    time_col_str = _df[time_col].astype(str)
    
    # ì‹œê°„ í˜•ì‹ ë³€í™˜ (ì—¬ëŸ¬ í˜•ì‹ìœ¼ë¡œ)
    search_formats = convert_time_format(time_str)
    logger.info(f"ì‹œê°„ ê²€ìƒ‰ í˜•ì‹: {search_formats}")
    
    result = pd.DataFrame()
    
    # ê° í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰ ì‹œë„
    for fmt in search_formats:
        matched = _df[time_col_str.str.contains(fmt, na=False, regex=False)]
        if not matched.empty:
            result = matched
            break
    
    if result.empty:
        # ìœ ì‚¬í•œ ì‹œê°„ ì œì•ˆ
        sample_times = time_col_str.head(5).tolist()
        return None, f"ì‹œê°„ '{time_str}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\në³€í™˜ ì‹œë„: {search_formats}\nì˜ˆì‹œ: {sample_times}"
    
    row = result.iloc[0]
    
    # JSON ì„¤ì •ì—ì„œ ì»¬ëŸ¼ ë¡œë“œ
    config = get_column_config()
    
    m14_config = config.get('m14', {})
    hub_config = config.get('hub', {})
    
    m14_display = m14_config.get('display_columns', [])
    hub_display = hub_config.get('display_columns', [])
    m14_detect = m14_config.get('detect_columns', [])
    hub_detect = hub_config.get('detect_columns', [])
    
    # ë°ì´í„° íƒ€ì… ìë™ ê°ì§€
    m14_found = sum(1 for col in m14_detect if col in row.index and pd.notna(row[col]))
    hub_found = sum(1 for col in hub_detect if col in row.index and pd.notna(row[col]))
    
    # ê²°ê³¼ í¬ë§·íŒ…
    data_text = f"ì‹œê°„: {row[time_col]}\n"
    data_text += "-" * 40 + "\n"
    
    if m14_found > hub_found and m14_display:
        # M14 ë°ì´í„°
        data_type = "m14"
        icon = m14_config.get('icon', 'ğŸ“¦')
        name = m14_config.get('name', 'M14')
        data_text += f"{icon} [{name}]\n"
        for col in m14_display:
            if col in row.index and pd.notna(row[col]):
                data_text += f"{col}: {row[col]}\n"
    elif hub_found > 0 and hub_display:
        # HUB ë°ì´í„°
        data_type = "hub"
        icon = hub_config.get('icon', 'ğŸ­')
        name = hub_config.get('name', 'HUB')
        data_text += f"{icon} [{name}]\n"
        for col in hub_display:
            if col in row.index and pd.notna(row[col]):
                data_text += f"{col}: {row[col]}\n"
    else:
        # ë‘˜ ë‹¤ ì•„ë‹ˆë©´ ì „ì²´ í‘œì‹œ
        data_type = "unknown"
        data_text += "ğŸ“Š [ì „ì²´ ë°ì´í„°]\n"
        for col in row.index:
            if col != time_col and pd.notna(row[col]):
                data_text += f"{col}: {row[col]}\n"
    
    # â­ ì˜ˆì¸¡ ë¶„ì„ ì¶”ê°€ (ë³´ì •ì˜ˆì¸¡, ì‹¤ì œê°’ ìˆìœ¼ë©´)
    if has_prediction_data(row):
        pred_analysis = analyze_prediction(row)
        data_text += pred_analysis
    
    # ìƒíƒœ ë¶„ì„ ì¶”ê°€
    analysis = analyze_status(row, data_type)
    if analysis:
        data_text += "\n" + analysis
    
    return row, data_text

def search_by_columns(col_names: List[str], n_rows: int = 5) -> Tuple[Optional[pd.DataFrame], str]:
    """
    ì»¬ëŸ¼ëª…ìœ¼ë¡œ ê²€ìƒ‰ (ìµœê·¼ nê°œ ë°ì´í„°)
    
    Args:
        col_names: ê²€ìƒ‰í•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸
        n_rows: ë°˜í™˜í•  í–‰ ìˆ˜
    
    Returns:
        (ë§¤ì¹­ëœ DataFrame, ì„¤ëª… í…ìŠ¤íŠ¸)
    """
    if _df is None:
        return None, "CSV íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # ìœ íš¨í•œ ì»¬ëŸ¼ë§Œ í•„í„°
    valid_cols = [c for c in col_names if c in _df.columns]
    
    if not valid_cols:
        return None, f"ìœ íš¨í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {list(_df.columns[:10])}..."
    
    recent = _df.tail(n_rows)
    data_text = f"ìµœê·¼ {n_rows}ê°œ ë°ì´í„°:\n\n"
    
    # ì‹œê°„ ì»¬ëŸ¼
    time_cols = ['í˜„ì¬ì‹œê°„', 'STAT_DT', 'CURRTIME', 'ì‹œê°„']
    time_col = None
    for tc in time_cols:
        if tc in _df.columns:
            time_col = tc
            break
    
    for idx, row in recent.iterrows():
        if time_col:
            data_text += f"[{row[time_col]}]\n"
        else:
            data_text += f"[Row {idx}]\n"
        
        for col in valid_cols:
            data_text += f"  {col}: {row[col]}\n"
        data_text += "\n"
    
    return recent[valid_cols], data_text

def search_csv(query: str) -> Tuple[Optional[Any], str]:
    """
    ìì—°ì–´ ì¿¼ë¦¬ë¡œ CSV ê²€ìƒ‰ (ê¸°ì¡´ server.py í•¨ìˆ˜ì™€ í˜¸í™˜)
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì‹œê°„ ë˜ëŠ” ì»¬ëŸ¼ëª… í¬í•¨)
    
    Returns:
        (ê²°ê³¼ ë°ì´í„°, ì„¤ëª… í…ìŠ¤íŠ¸)
    """
    if _df is None:
        return None, "CSV íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # 0. ì‹œê°„ ë²”ìœ„ íŒ¨í„´ ë¨¼ì € ì²´í¬ (2025-10-14 4:45 ~ 2025-10-14 5:50)
    range_pattern = r'(\d{4}-\d{2}-\d{2}\s+\d{1,2}:\d{2})\s*[~\-]\s*(\d{4}-\d{2}-\d{2}\s+\d{1,2}:\d{2})'
    range_match = re.search(range_pattern, query)
    
    if range_match:
        start_time = range_match.group(1)
        end_time = range_match.group(2)
        logger.info(f"ì‹œê°„ ë²”ìœ„ ê²€ìƒ‰: {start_time} ~ {end_time}")
        return search_time_range(start_time, end_time)
    
    # 0-1. ë‚ ì§œ + ì¡°ê±´ íŒ¨í„´ ì²´í¬ (2025-10-14 ì—ì„œ 1700ì´ìƒ)
    # íŒ¨í„´: ë‚ ì§œ + (ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ) + ìˆ«ì  ë˜ëŠ”  ë‚ ì§œ + ìˆ«ì + (ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ)
    date_condition_patterns = [
        r'(\d{4}-\d{2}-\d{2}).*?(\d+(?:\.\d+)?)\s*(ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ)',  # 2025-10-14 1700 ì´ìƒ
        r'(\d{4}-\d{2}-\d{2}).*?(ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ)\s*(\d+(?:\.\d+)?)',  # 2025-10-14 ì´ìƒ 1700
    ]
    
    for pattern in date_condition_patterns:
        match = re.search(pattern, query)
        if match:
            groups = match.groups()
            if len(groups) == 3:
                date_str = groups[0]
                if groups[1] in ['ì´ìƒ', 'ì´í•˜', 'ì´ˆê³¼', 'ë¯¸ë§Œ']:
                    value = float(groups[0] if groups[0].replace('.','').isdigit() else groups[2])
                    operator = groups[1]
                else:
                    value = float(groups[1])
                    operator = groups[2]
                
                # ì»¬ëŸ¼ ì¶”ì¶œ (ì§€ì • ì•ˆ í•˜ë©´ ê¸°ë³¸ íƒ€ê²Ÿ)
                col_pattern = r'([A-Z][A-Z0-9_\.]+)'
                col_match = re.search(col_pattern, query, re.IGNORECASE)
                target_col = col_match.group(1) if col_match and col_match.group(1) in _df.columns else None
                
                logger.info(f"ë‚ ì§œ+ì¡°ê±´ ê²€ìƒ‰: {date_str}, {operator} {value}, ì»¬ëŸ¼={target_col}")
                return search_date_condition(date_str, operator, value, target_col)
    
    # 1. ì‹œê°„ íŒ¨í„´ ì¶”ì¶œ (202509210013 ë˜ëŠ” 2025-10-14 4:39 í˜•ì‹)
    time_patterns = [
        r'(\d{12})',  # 202509210013
        r'(\d{4}-\d{2}-\d{2}\s+\d{1,2}:\d{2})',  # 2025-10-14 4:39
    ]
    
    time_str = None
    for pattern in time_patterns:
        match = re.search(pattern, query)
        if match:
            time_str = match.group(1)
            break
    
    # 2. ì»¬ëŸ¼ëª… ì¶”ì¶œ (ì‹œê°„ ë¶€ë¶„ ì œì™¸í•˜ê³ )
    query_without_time = query
    if time_str:
        query_without_time = query.replace(time_str, '')
    
    # ì»¬ëŸ¼ íŒ¨í„´: ì˜ë¬¸ëŒ€ë¬¸ì, í•œê¸€, ìˆ«ì, _, ., (, ) í¬í•¨
    col_pattern = r'([A-Zê°€-í£][A-Zê°€-í£0-9_\.\(\)]+)'
    col_matches = re.findall(col_pattern, query_without_time, re.IGNORECASE)
    
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°
    valid_cols = [c for c in col_matches if c in _df.columns]
    
    # ìš”ì²­í–ˆì§€ë§Œ ì—†ëŠ” ì»¬ëŸ¼ ì°¾ê¸° (ì˜ë¬¸ í¬í•¨ëœ ê²ƒë§Œ - "ì‹œì ì˜" ê°™ì€ í•œê¸€ ì œì™¸)
    invalid_cols = [c for c in col_matches 
                    if c not in _df.columns 
                    and len(c) > 2 
                    and re.search(r'[A-Z]', c, re.IGNORECASE)]  # ì˜ë¬¸ í¬í•¨ëœ ê²ƒë§Œ
    
    # 3. ì‹œê°„ + ì»¬ëŸ¼ ë‘˜ ë‹¤ ìˆìœ¼ë©´ â†’ í•´ë‹¹ ì‹œê°„ì˜ íŠ¹ì • ì»¬ëŸ¼ê°’ë§Œ
    if time_str and valid_cols:
        logger.info(f"ì‹œê°„+ì»¬ëŸ¼ ê²€ìƒ‰: {time_str}, {valid_cols}")
        row, _ = search_by_time(time_str)
        
        if row is None:
            return None, f"ì‹œê°„ '{time_str}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # í•´ë‹¹ ì»¬ëŸ¼ê°’ë§Œ ë°˜í™˜
        data_text = f"ì‹œê°„: {time_str}\n"
        for col in valid_cols:
            if col in row.index:
                data_text += f"{col}: {row[col]}\n"
        
        return row, data_text
    
    # 3-1. ì‹œê°„ + ì˜ë¬¸ ì»¬ëŸ¼ ìš”ì²­í–ˆëŠ”ë° ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ â†’ ì—ëŸ¬
    if time_str and invalid_cols and not valid_cols:
        logger.info(f"ì»¬ëŸ¼ ì—†ìŒ: {invalid_cols}")
        # ìœ ì‚¬ ì»¬ëŸ¼ ì¶”ì²œ
        similar_cols = []
        for inv_col in invalid_cols:
            for col in _df.columns:
                if inv_col.upper() in col.upper() or col.upper() in inv_col.upper():
                    similar_cols.append(col)
        
        error_msg = f"âŒ ì»¬ëŸ¼ '{', '.join(invalid_cols)}'ì´(ê°€) í˜„ì¬ ë¡œë“œëœ CSVì— ì—†ìŠµë‹ˆë‹¤.\n"
        error_msg += f"\nâš ï¸ DB ë˜ëŠ” CSV íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\n"
        if similar_cols:
            error_msg += f"\nğŸ’¡ ìœ ì‚¬í•œ ì»¬ëŸ¼: {', '.join(similar_cols[:5])}\n"
        error_msg += f"\nğŸ“‹ í˜„ì¬ CSV ì»¬ëŸ¼ ({len(_df.columns)}ê°œ):\n"
        error_msg += ", ".join(list(_df.columns)[:15]) + "..."
        
        return None, error_msg
    
    # 4. ì‹œê°„ë§Œ ìˆìœ¼ë©´ â†’ ì „ì²´ í–‰ ë°ì´í„°
    if time_str:
        logger.info(f"ì‹œê°„ ê²€ìƒ‰: {time_str}")
        return search_by_time(time_str)
    
    # 5. ì»¬ëŸ¼ë§Œ ìˆìœ¼ë©´ â†’ ìµœê·¼ ë°ì´í„°
    if valid_cols:
        logger.info(f"ì»¬ëŸ¼ ê²€ìƒ‰: {valid_cols}")
        return search_by_columns(valid_cols)
    
    return None, "ê²€ìƒ‰ ì¡°ê±´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œê°„(ì˜ˆ: 2025-10-14 4:39) ë˜ëŠ” ì»¬ëŸ¼ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”."

def search_date_condition(date_str: str, operator: str, value: float, target_col: str = None) -> Tuple[Optional[pd.DataFrame], str]:
    """
    ë‚ ì§œ + ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰ (ì˜ˆ: 2025-10-14ì—ì„œ 1700 ì´ìƒ)
    
    Args:
        date_str: ë‚ ì§œ (YYYY-MM-DD)
        operator: ì´ìƒ/ì´í•˜/ì´ˆê³¼/ë¯¸ë§Œ
        value: ë¹„êµê°’
        target_col: ëŒ€ìƒ ì»¬ëŸ¼ (ì—†ìœ¼ë©´ ìë™ ê°ì§€)
    
    Returns:
        (ê²°ê³¼ DataFrame, ì„¤ëª… í…ìŠ¤íŠ¸)
    """
    if _df is None:
        return None, "CSV íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # ì‹œê°„ ì»¬ëŸ¼ ì°¾ê¸°
    time_cols = ['í˜„ì¬ì‹œê°„', 'STAT_DT', 'CURRTIME', 'ì‹œê°„']
    time_col = None
    for tc in time_cols:
        if tc in _df.columns:
            time_col = tc
            break
    
    if time_col is None:
        return None, "ì‹œê°„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # íƒ€ê²Ÿ ì»¬ëŸ¼ ê²°ì •
    if target_col is None:
        # ë°ì´í„° íƒ€ì… ê°ì§€í•´ì„œ ê¸°ë³¸ íƒ€ê²Ÿ ì„¤ì •
        data_type = detect_data_type(list(_df.columns))
        if data_type == "m14":
            target_col = "í˜„ì¬TOTALCNT" if "í˜„ì¬TOTALCNT" in _df.columns else "TOTALCNT"
        elif data_type == "hub":
            target_col = "CURRENT_M16A_3F_JOB_2"
        else:
            # ìˆ«ì ì»¬ëŸ¼ ì¤‘ ì²«ë²ˆì§¸
            for col in _df.columns:
                if _df[col].dtype in ['int64', 'float64']:
                    target_col = col
                    break
    
    if target_col not in _df.columns:
        return None, f"âŒ ì»¬ëŸ¼ '{target_col}'ì´(ê°€) ì—†ìŠµë‹ˆë‹¤."
    
    try:
        df_copy = _df.copy()
        df_copy[time_col] = pd.to_datetime(df_copy[time_col], errors='coerce')
        df_copy[target_col] = pd.to_numeric(df_copy[target_col], errors='coerce')
        
        # ë‚ ì§œ í•„í„°
        target_date = pd.to_datetime(date_str).date()
        date_mask = df_copy[time_col].dt.date == target_date
        
        # ì¡°ê±´ í•„í„°
        op_map = {
            'ì´ìƒ': '>=',
            'ì´í•˜': '<=',
            'ì´ˆê³¼': '>',
            'ë¯¸ë§Œ': '<'
        }
        op = op_map.get(operator, '>=')
        
        if op == '>=':
            cond_mask = df_copy[target_col] >= value
        elif op == '<=':
            cond_mask = df_copy[target_col] <= value
        elif op == '>':
            cond_mask = df_copy[target_col] > value
        elif op == '<':
            cond_mask = df_copy[target_col] < value
        else:
            cond_mask = df_copy[target_col] >= value
        
        result = _df[date_mask & cond_mask].copy()
        
        if result.empty:
            return None, f"âŒ {date_str}ì—ì„œ {target_col} {value} {operator} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ë°ì´í„° íƒ€ì… ê°ì§€
        data_type = detect_data_type(list(result.columns))
        config = get_column_config()
        
        if data_type == "m14":
            icon = "ğŸ“¦"
            name = "M14 ë¬¼ë¥˜"
        elif data_type == "hub":
            icon = "ğŸ­"
            name = "HUB ë¬¼ë¥˜"
        else:
            icon = "ğŸ“Š"
            name = "ë°ì´í„°"
        
        # ê²°ê³¼ í…ìŠ¤íŠ¸ ìƒì„±
        data_text = f"{icon} [{name}] ì¡°ê±´ ê²€ìƒ‰\n"
        data_text += f"ğŸ“… {date_str} | {target_col} {value} {operator} ({len(result)}ê±´)\n"
        data_text += "-" * 50 + "\n"
        
        # ê° í–‰ ì¶œë ¥
        for idx, row in result.iterrows():
            time_val = row[time_col]
            if pd.notna(time_val):
                if isinstance(time_val, str):
                    time_str_fmt = time_val
                else:
                    time_str_fmt = time_val.strftime('%Y-%m-%d %H:%M') if hasattr(time_val, 'strftime') else str(time_val)
                
                val = row[target_col]
                data_text += f"{time_str_fmt} : {target_col} = {val}\n"
        
        # í†µê³„
        vals = result[target_col].dropna()
        data_text += "\n" + "=" * 50 + "\n"
        data_text += f"ğŸ“ˆ í†µê³„\n"
        data_text += f"  ê±´ìˆ˜: {len(result)}ê±´\n"
        data_text += f"  ìµœì†Œ: {vals.min():.1f}\n"
        data_text += f"  ìµœëŒ€: {vals.max():.1f}\n"
        data_text += f"  í‰ê· : {vals.mean():.1f}\n"
        
        # ë§ˆì§€ë§‰ í–‰ ìƒíƒœ ë¶„ì„
        last_row = result.iloc[-1]
        last_time = last_row[time_col]
        if isinstance(last_time, str):
            last_time_str = last_time
        else:
            last_time_str = last_time.strftime('%Y-%m-%d %H:%M') if hasattr(last_time, 'strftime') else str(last_time)
        
        data_text += "\n" + "=" * 50 + "\n"
        data_text += f"ğŸ“Š ìƒíƒœ ë¶„ì„ ({last_time_str} ë§ˆì§€ë§‰ ë°ì´í„°)\n"
        
        analysis = analyze_status(last_row, data_type)
        if analysis:
            analysis = analysis.replace("\nğŸ“Š ìƒíƒœ ë¶„ì„\n", "\n")
            data_text += analysis
        
        return result, data_text
        
    except Exception as e:
        logger.error(f"ë‚ ì§œ+ì¡°ê±´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None, f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}"

def search_time_range(start_time: str, end_time: str) -> Tuple[Optional[pd.DataFrame], str]:
    """
    ì‹œê°„ ë²”ìœ„ë¡œ ê²€ìƒ‰ (ìš”ì•½ + ìƒíƒœ ë¶„ì„)
    
    Args:
        start_time: ì‹œì‘ ì‹œê°„
        end_time: ì¢…ë£Œ ì‹œê°„
    
    Returns:
        (ê²°ê³¼ DataFrame, ì„¤ëª… í…ìŠ¤íŠ¸)
    """
    if _df is None:
        return None, "CSV íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # ì‹œê°„ ì»¬ëŸ¼ ì°¾ê¸°
    time_cols = ['í˜„ì¬ì‹œê°„', 'STAT_DT', 'CURRTIME', 'ì‹œê°„']
    time_col = None
    for tc in time_cols:
        if tc in _df.columns:
            time_col = tc
            break
    
    if time_col is None:
        return None, "ì‹œê°„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        df_copy = _df.copy()
        df_copy[time_col] = pd.to_datetime(df_copy[time_col], errors='coerce')
        
        # ì‹œê°„ í˜•ì‹ ë³€í™˜
        start_formats = convert_time_format(start_time)
        end_formats = convert_time_format(end_time)
        
        start_dt = pd.to_datetime(start_formats[0])
        end_dt = pd.to_datetime(end_formats[0])
        
        mask = (df_copy[time_col] >= start_dt) & (df_copy[time_col] <= end_dt)
        result = _df[mask].copy()
        
        if result.empty:
            return None, f"âŒ {start_time} ~ {end_time} ë²”ìœ„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ë°ì´í„° íƒ€ì… ê°ì§€
        data_type = detect_data_type(list(result.columns))
        config = get_column_config()
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ ê²°ì •
        if data_type == "m14":
            target_col = "í˜„ì¬TOTALCNT" if "í˜„ì¬TOTALCNT" in result.columns else "TOTALCNT"
            icon = config.get('m14', {}).get('icon', 'ğŸ“¦')
            name = config.get('m14', {}).get('name', 'M14 ë¬¼ë¥˜')
        elif data_type == "hub":
            target_col = "CURRENT_M16A_3F_JOB_2"
            icon = config.get('hub', {}).get('icon', 'ğŸ­')
            name = config.get('hub', {}).get('name', 'HUB ë¬¼ë¥˜')
        else:
            target_col = result.columns[2] if len(result.columns) > 2 else result.columns[0]
            icon = "ğŸ“Š"
            name = "ë°ì´í„°"
        
        # ê²°ê³¼ í…ìŠ¤íŠ¸ ìƒì„±
        data_text = f"{icon} [{name}]\n"
        data_text += f"ğŸ“… {start_time} ~ {end_time} ({len(result)}ê±´)\n"
        data_text += "-" * 40 + "\n"
        
        # ê° í–‰ì˜ ì‹œê°„: íƒ€ê²Ÿê°’ ì¶œë ¥
        for idx, row in result.iterrows():
            time_val = row[time_col]
            if pd.notna(time_val):
                if isinstance(time_val, str):
                    time_str = time_val
                else:
                    time_str = time_val.strftime('%Y-%m-%d %H:%M') if hasattr(time_val, 'strftime') else str(time_val)
                
                if target_col in row.index and pd.notna(row[target_col]):
                    data_text += f"{time_str} : {target_col} = {row[target_col]}\n"
                else:
                    data_text += f"{time_str}\n"
        
        # ë§ˆì§€ë§‰ í–‰ ìƒíƒœ ë¶„ì„
        last_row = result.iloc[-1]
        last_time = last_row[time_col]
        if isinstance(last_time, str):
            last_time_str = last_time
        else:
            last_time_str = last_time.strftime('%Y-%m-%d %H:%M') if hasattr(last_time, 'strftime') else str(last_time)
        
        data_text += "\n" + "=" * 40 + "\n"
        data_text += f"ğŸ“Š ìƒíƒœ ë¶„ì„ ({last_time_str} ë§ˆì§€ë§‰ ë°ì´í„°)\n"
        
        analysis = analyze_status(last_row, data_type)
        if analysis:
            # "ğŸ“Š ìƒíƒœ ë¶„ì„" ì œëª© ì œê±° (ì¤‘ë³µ ë°©ì§€)
            analysis = analysis.replace("\nğŸ“Š ìƒíƒœ ë¶„ì„\n", "\n")
            data_text += analysis
        else:
            data_text += "âœ… ìƒíƒœ ë¶„ì„ ì •ë³´ ì—†ìŒ"
        
        return result, data_text
        
    except Exception as e:
        logger.error(f"ì‹œê°„ ë²”ìœ„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None, f"âŒ ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜: {e}"

def search_range(start_time: str, end_time: str) -> Tuple[Optional[pd.DataFrame], str]:
    """
    ì‹œê°„ ë²”ìœ„ë¡œ ê²€ìƒ‰
    
    Args:
        start_time: ì‹œì‘ ì‹œê°„
        end_time: ì¢…ë£Œ ì‹œê°„
    
    Returns:
        (ê²°ê³¼ DataFrame, ì„¤ëª… í…ìŠ¤íŠ¸)
    """
    if _df is None:
        return None, "CSV íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # ì‹œê°„ ì»¬ëŸ¼ ì°¾ê¸°
    time_cols = ['STAT_DT', 'í˜„ì¬ì‹œê°„', 'CURRTIME', 'ì‹œê°„']
    time_col = None
    for tc in time_cols:
        if tc in _df.columns:
            time_col = tc
            break
    
    if time_col is None:
        return None, "ì‹œê°„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        df_copy = _df.copy()
        df_copy[time_col] = pd.to_datetime(df_copy[time_col], errors='coerce')
        
        start_dt = pd.to_datetime(start_time)
        end_dt = pd.to_datetime(end_time)
        
        mask = (df_copy[time_col] >= start_dt) & (df_copy[time_col] <= end_dt)
        result = _df[mask]
        
        if result.empty:
            return None, f"{start_time} ~ {end_time} ë²”ìœ„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        data_text = f"ê²€ìƒ‰ ê²°ê³¼: {len(result)}ê±´ ({start_time} ~ {end_time})\n"
        return result, data_text
        
    except Exception as e:
        return None, f"ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜: {e}"

def search_condition(column: str, operator: str, value: Any) -> Tuple[Optional[pd.DataFrame], str]:
    """
    ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰
    
    Args:
        column: ì»¬ëŸ¼ëª…
        operator: ì—°ì‚°ì ('>', '<', '>=', '<=', '==', '!=')
        value: ë¹„êµê°’
    
    Returns:
        (ê²°ê³¼ DataFrame, ì„¤ëª… í…ìŠ¤íŠ¸)
    """
    if _df is None:
        return None, "CSV íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    if column not in _df.columns:
        return None, f"ì»¬ëŸ¼ '{column}'ì´ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        col_data = pd.to_numeric(_df[column], errors='coerce')
        value = float(value)
        
        if operator == '>':
            mask = col_data > value
        elif operator == '<':
            mask = col_data < value
        elif operator == '>=':
            mask = col_data >= value
        elif operator == '<=':
            mask = col_data <= value
        elif operator == '==':
            mask = col_data == value
        elif operator == '!=':
            mask = col_data != value
        else:
            return None, f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì—°ì‚°ì: {operator}"
        
        result = _df[mask]
        
        if result.empty:
            return None, f"{column} {operator} {value} ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        data_text = f"ê²€ìƒ‰ ê²°ê³¼: {len(result)}ê±´ ({column} {operator} {value})\n"
        return result, data_text
        
    except Exception as e:
        return None, f"ì¡°ê±´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}"

def get_statistics(column: str) -> Dict[str, Any]:
    """
    ì»¬ëŸ¼ í†µê³„ ì •ë³´
    
    Args:
        column: ì»¬ëŸ¼ëª…
    
    Returns:
        í†µê³„ ë”•ì…”ë„ˆë¦¬
    """
    if _df is None:
        return {'error': 'CSV íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}
    
    if column not in _df.columns:
        return {'error': f"ì»¬ëŸ¼ '{column}'ì´ ì—†ìŠµë‹ˆë‹¤."}
    
    try:
        col_data = pd.to_numeric(_df[column], errors='coerce').dropna()
        
        return {
            'count': len(col_data),
            'mean': float(col_data.mean()),
            'std': float(col_data.std()),
            'min': float(col_data.min()),
            'max': float(col_data.max()),
            'median': float(col_data.median()),
            'q25': float(col_data.quantile(0.25)),
            'q75': float(col_data.quantile(0.75))
        }
    except Exception as e:
        return {'error': str(e)}

def format_row(row: pd.Series, important_cols: List[str] = None) -> str:
    """
    í–‰ ë°ì´í„°ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
    
    Args:
        row: pandas Series
        important_cols: ìš°ì„  í‘œì‹œí•  ì»¬ëŸ¼ (ì—†ìœ¼ë©´ ì „ì²´)
    
    Returns:
        í¬ë§·íŒ…ëœ ë¬¸ìì—´
    """
    text = ""
    
    if important_cols:
        for col in important_cols:
            if col in row.index and pd.notna(row[col]):
                text += f"{col}: {row[col]}\n"
    else:
        for col in row.index:
            if pd.notna(row[col]):
                text += f"{col}: {row[col]}\n"
    
    return text


# í…ŒìŠ¤íŠ¸ëŠ” ë³„ë„ íŒŒì¼ì—ì„œ ì‹¤í–‰
# python -c "import csv_searcher; csv_searcher.load_csv('./csv/with.csv'); print(csv_searcher.get_columns())"