#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SK Hynix LLM API ëª¨ë¸ ëª©ë¡ í™•ì¸
"""

import requests
import os

# í† í° ë¡œë“œ
TOKEN_PATH = "token.txt"
API_BASE = "http://dev.assistant.llm.skhynix.com"

def load_token():
    if os.path.exists(TOKEN_PATH):
        with open(TOKEN_PATH, "r") as f:
            return f.read().strip()
    return None

def check_models():
    token = load_token()
    if not token:
        print("âŒ token.txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… í† í° ë¡œë“œ ì™„ë£Œ: {token[:20]}...")
    print(f"ğŸ”— API: {API_BASE}")
    print("=" * 60)
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    # 1. /v1/models ì—”ë“œí¬ì¸íŠ¸ ì‹œë„
    endpoints = [
        "/v1/models",
        "/models",
        "/v1/model/list",
        "/api/models"
    ]
    
    for endpoint in endpoints:
        url = f"{API_BASE}{endpoint}"
        print(f"\nğŸ” ì‹œë„: {url}")
        
        try:
            response = requests.get(url, headers=headers, timeout=10)
            print(f"   ìƒíƒœ: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                print(f"   âœ… ì„±ê³µ!")
                print("-" * 60)
                
                # OpenAI í˜•ì‹
                if "data" in data:
                    print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
                    for model in data["data"]:
                        model_id = model.get("id", model.get("name", "unknown"))
                        print(f"   â€¢ {model_id}")
                # ë¦¬ìŠ¤íŠ¸ í˜•ì‹
                elif isinstance(data, list):
                    print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
                    for model in data:
                        if isinstance(model, str):
                            print(f"   â€¢ {model}")
                        elif isinstance(model, dict):
                            print(f"   â€¢ {model.get('id', model.get('name', model))}")
                # ê¸°íƒ€
                else:
                    print("ğŸ“‹ ì‘ë‹µ ë°ì´í„°:")
                    import json
                    print(json.dumps(data, indent=2, ensure_ascii=False))
                
                return
            else:
                print(f"   ì‘ë‹µ: {response.text[:200]}")
                
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
    
    # 2. í˜„ì¬ ì„¤ì •ëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 60)
    print("ğŸ§ª í˜„ì¬ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (Qwen3-Coder-30B-A3B-Instruct)")
    
    test_url = f"{API_BASE}/v1/chat/completions"
    test_data = {
        "model": "Qwen3-Coder-30B-A3B-Instruct",
        "messages": [{"role": "user", "content": "ì•ˆë…•"}],
        "max_tokens": 10
    }
    
    try:
        response = requests.post(test_url, headers=headers, json=test_data, timeout=30)
        print(f"   ìƒíƒœ: {response.status_code}")
        
        if response.status_code == 200:
            print("   âœ… ëª¨ë¸ ì‘ë™ í™•ì¸!")
            result = response.json()
            if "choices" in result:
                print(f"   ì‘ë‹µ: {result['choices'][0]['message']['content'][:50]}...")
        else:
            print(f"   ì‘ë‹µ: {response.text[:300]}")
            
            # ì˜¤ë¥˜ ë©”ì‹œì§€ì—ì„œ ëª¨ë¸ ëª©ë¡ íŒíŠ¸ ì°¾ê¸°
            if "model" in response.text.lower():
                print("\nğŸ’¡ ì˜¤ë¥˜ ë©”ì‹œì§€ì—ì„œ ëª¨ë¸ ì •ë³´ í™•ì¸:")
                print(response.text)
                
    except Exception as e:
        print(f"   âŒ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    check_models()